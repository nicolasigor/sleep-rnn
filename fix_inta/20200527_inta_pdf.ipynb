{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import datetime\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "project_root = '..'\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from sleeprnn.data.inta_ss import IntaSS, NAMES\n",
    "from sleeprnn.data import utils, stamp_correction\n",
    "from sleeprnn.detection import metrics\n",
    "from sleeprnn.helpers import reader, misc, plotter\n",
    "from sleeprnn.common import constants, pkeys, viz\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "viz.notebook_full_width()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = IntaSS(load_checkpoint=True)\n",
    "dataset_name = dataset.dataset_name\n",
    "fs = dataset.fs\n",
    "marked_channel = 'F4-C4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Order: (from worst to best)\n",
    "# 11 TAGO [x] | 269 conflict pages\n",
    "# 08 CAPO [x] | 82\n",
    "# 02 ALUR [...] | 314\n",
    "# 06 BTOL08 | 9\n",
    "# 04 BRCA | 479\n",
    "# 09 CRCA | 308\n",
    "# 10 ESCI | 69\n",
    "# 05 BRLO | 156\n",
    "# 07 BTOL09 | 22\n",
    "# 03 BECA | 3\n",
    "# 01 ADGU | 232\n",
    "\n",
    "# Load stamps of subject\n",
    "subject_id = 2\n",
    "\n",
    "print('Loading S%02d' % subject_id)\n",
    "path_stamps = os.path.join(dataset.dataset_dir, 'label/spindle', 'SS_%s.txt' % NAMES[subject_id - 1])\n",
    "path_signals = os.path.join(dataset.dataset_dir, 'register', '%s.rec' % NAMES[subject_id - 1]) \n",
    "signal_dict = reader.read_signals_from_edf(path_signals)\n",
    "signal_names = list(signal_dict.keys())\n",
    "to_show_names = misc.get_inta_eeg_names(signal_names) + misc.get_inta_eog_emg_names(signal_names)\n",
    "for single_name in misc.get_inta_eeg_names(signal_names):\n",
    "    this_signal = signal_dict[single_name]\n",
    "    print('Filtering %s channel' % single_name)\n",
    "    this_signal = utils.broad_filter(this_signal, fs)\n",
    "    signal_dict[single_name] = this_signal\n",
    "raw_stamps_1, raw_stamps_2 = reader.load_raw_inta_stamps(path_stamps, path_signals, min_samples=20, chn_idx=0)\n",
    "durations_1 = (raw_stamps_1[:, 1] - raw_stamps_1[:, 0]) / fs\n",
    "durations_2 = (raw_stamps_2[:, 1] - raw_stamps_2[:, 0]) / fs\n",
    "print('V1', raw_stamps_1.shape, 'Min dur [s]', durations_1.min(), 'Max dur [s]', durations_1.max())\n",
    "print('V2', raw_stamps_2.shape, 'Min dur [s]', durations_2.min(), 'Max dur [s]', durations_2.max())\n",
    "overlap_m = utils.get_overlap_matrix(raw_stamps_1, raw_stamps_1)\n",
    "groups_overlap_1 = utils.overlapping_groups(overlap_m)\n",
    "overlap_m = utils.get_overlap_matrix(raw_stamps_2, raw_stamps_2)\n",
    "groups_overlap_2 = utils.overlapping_groups(overlap_m)\n",
    "n_overlaps_1 = [len(single_group) for single_group in groups_overlap_1]\n",
    "values_1, counts_1 = np.unique(n_overlaps_1, return_counts=True)\n",
    "print('\\nSize of overlapping groups for Valid 1')\n",
    "for value, count in zip(values_1, counts_1):\n",
    "    print('%d marks: %d times' % (value, count))\n",
    "n_overlaps_2 = [len(single_group) for single_group in groups_overlap_2]\n",
    "values_2, counts_2 = np.unique(n_overlaps_2, return_counts=True)\n",
    "print('\\nSize of overlapping groups for Valid 2')\n",
    "for value, count in zip(values_2, counts_2):\n",
    "    print('%d marks: %d times' % (value, count))\n",
    "max_overlaps = np.max([values_1.max(), values_2.max()]) - 1\n",
    "\n",
    "if subject_id != 3:\n",
    "    this_pages = dataset.get_subject_pages(subject_id=subject_id) \n",
    "else:\n",
    "    this_pages = np.arange(1, signal_dict[marked_channel].size//dataset.page_size - 1)\n",
    "print('This pages', this_pages.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select marks without doubt\n",
    "groups_in_doubt_v1_list = []\n",
    "groups_in_doubt_v2_list = []\n",
    "\n",
    "iou_to_accept = 0.8\n",
    "marks_without_doubt = []\n",
    "overlap_between_1_and_2 = utils.get_overlap_matrix(raw_stamps_1, raw_stamps_2)\n",
    "\n",
    "for single_group in groups_overlap_2:\n",
    "    if len(single_group) == 1:\n",
    "        marks_without_doubt.append(raw_stamps_2[single_group[0], :])\n",
    "    elif len(single_group) == 2:\n",
    "        # check if IOU between marks is close 1, if close, then just choose newer (second one)\n",
    "        option1_mark = raw_stamps_2[single_group[0], :]\n",
    "        option2_mark = raw_stamps_2[single_group[1], :]\n",
    "        iou_between_marks = metrics.get_iou(option1_mark, option2_mark)\n",
    "        if iou_between_marks >= iou_to_accept:\n",
    "            marks_without_doubt.append(option2_mark)\n",
    "        else:\n",
    "            groups_in_doubt_v2_list.append(single_group)\n",
    "    else:\n",
    "        groups_in_doubt_v2_list.append(single_group)\n",
    "        \n",
    "for single_group in groups_overlap_1:\n",
    "    is_in_doubt = False\n",
    "    # Check if entire group is overlapping\n",
    "    all_are_overlapping_2 = np.all(overlap_between_1_and_2[single_group, :].sum(axis=1))\n",
    "    if not all_are_overlapping_2:\n",
    "        # Consider the mark\n",
    "        if len(single_group) == 1:\n",
    "            # Since has size 1 and is no overlapping 2, accept it\n",
    "            marks_without_doubt.append(raw_stamps_1[single_group[0], :])\n",
    "        elif len(single_group) == 2:\n",
    "            # check if IOU between marks is close 1, if close, then just choose newer (second one) since there is no intersection\n",
    "            option1_mark = raw_stamps_1[single_group[0], :]\n",
    "            option2_mark = raw_stamps_1[single_group[1], :]\n",
    "            iou_between_marks = metrics.get_iou(option1_mark, option2_mark)\n",
    "            if iou_between_marks >= iou_to_accept:\n",
    "                marks_without_doubt.append(raw_stamps_1[single_group[1], :])\n",
    "            else:\n",
    "                is_in_doubt = True\n",
    "        else:\n",
    "            is_in_doubt = True\n",
    "    if is_in_doubt:\n",
    "        groups_in_doubt_v1_list.append(single_group)\n",
    "\n",
    "marks_without_doubt = np.stack(marks_without_doubt, axis=0)\n",
    "marks_without_doubt = np.sort(marks_without_doubt, axis=0)\n",
    "print('Marks automatically added:', marks_without_doubt.shape)\n",
    "print('Remaining conflicts:')\n",
    "print('    V1: %d' % len(groups_in_doubt_v1_list))\n",
    "print('    V2: %d' % len(groups_in_doubt_v2_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_complete_conflict_detail = False\n",
    "\n",
    "conflict_pages = []\n",
    "\n",
    "if show_complete_conflict_detail:\n",
    "    print('Conflict detail')\n",
    "for single_group in groups_in_doubt_v1_list:\n",
    "    group_stamps = raw_stamps_1[single_group, :]\n",
    "    min_sample = group_stamps.min()\n",
    "    max_sample = group_stamps.max()\n",
    "    center_group = (min_sample + max_sample) / 2\n",
    "    integer_page = int(center_group / dataset.page_size)\n",
    "    decimal_part = np.round(2 * (center_group % dataset.page_size) / dataset.page_size) / 2 - 0.5\n",
    "    page_location = integer_page + decimal_part\n",
    "    conflict_pages.append(page_location)\n",
    "    if show_complete_conflict_detail:\n",
    "        print('V1 - Group of size %d at page %1.1f' % (group_stamps.shape[0], page_location ))\n",
    "\n",
    "for single_group in groups_in_doubt_v2_list:\n",
    "    group_stamps = raw_stamps_2[single_group, :]\n",
    "    min_sample = group_stamps.min()\n",
    "    max_sample = group_stamps.max()\n",
    "    center_group = (min_sample + max_sample) / 2\n",
    "    integer_page = int(center_group / dataset.page_size)\n",
    "    decimal_part = np.round(2 * (center_group % dataset.page_size) / dataset.page_size) / 2 - 0.5\n",
    "    page_location = integer_page + decimal_part\n",
    "    conflict_pages.append(page_location)\n",
    "    if show_complete_conflict_detail:\n",
    "        print('V2 - Group of size %d at page %1.1f' % (group_stamps.shape[0], page_location ))\n",
    "conflict_pages = np.unique(conflict_pages)\n",
    "\n",
    "print('')\n",
    "print('Number of pages with conflict %d' % conflict_pages.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add available final versions of marks\n",
    "string_to_search = 'Revision_SS_%s.txt' % NAMES[subject_id-1]\n",
    "available_files = os.listdir('mark_files')\n",
    "res = [f for f in available_files if string_to_search in f]\n",
    "print('Files found for \"%s\":' % string_to_search)\n",
    "print(res)\n",
    "if res:\n",
    "    this_final_marks = np.loadtxt(os.path.join('mark_files', res[0]))\n",
    "    this_final_marks = this_final_marks[:, [0, 1]]\n",
    "else:\n",
    "    this_final_marks = np.array([])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotter functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_page_conflict(conflict_idx, ax, show_final=False):\n",
    "    signal_uv_to_display = 20\n",
    "    microvolt_per_second = 200  # Aspect ratio\n",
    "    page_chosen = conflict_pages[conflict_idx-1]\n",
    "    page_start = page_chosen * dataset.page_size\n",
    "    page_end = page_start + dataset.page_size\n",
    "    segment_stamps = utils.filter_stamps(marks_without_doubt, page_start, page_end)\n",
    "    segment_stamps_valid_1 = utils.filter_stamps(raw_stamps_1, page_start, page_end)\n",
    "    segment_stamps_valid_2 = utils.filter_stamps(raw_stamps_2, page_start, page_end)\n",
    "    segment_stamps_final = utils.filter_stamps(this_final_marks, page_start, page_end) if show_final else []    \n",
    "    time_axis = np.arange(page_start, page_end) / fs\n",
    "    x_ticks = np.arange(time_axis[0], time_axis[-1]+1, 1)\n",
    "    dy_valid = 40\n",
    "    shown_valid = False\n",
    "    valid_label = 'Candidate mark'\n",
    "    # Show valid 1\n",
    "    valid_start = -100\n",
    "    shown_groups_1 = []\n",
    "    for j, this_stamp in enumerate(segment_stamps_valid_1):\n",
    "        idx_stamp = np.where([np.all(this_stamp == single_stamp) for single_stamp in raw_stamps_1])[0]\n",
    "        idx_group = np.where([idx_stamp in single_group for single_group in groups_overlap_1])[0][0].item()\n",
    "        shown_groups_1.append(idx_group)\n",
    "    shown_groups_1 = np.unique(shown_groups_1)\n",
    "    max_size_shown = 0\n",
    "    for single_group in shown_groups_1:\n",
    "        group_stamps = [raw_stamps_1[single_idx] for single_idx in groups_overlap_1[single_group]]\n",
    "        group_stamps = np.stack(group_stamps, axis=0)\n",
    "        group_size = group_stamps.shape[0]\n",
    "        if group_size > max_size_shown:\n",
    "            max_size_shown = group_size\n",
    "        for j, single_stamp in enumerate(group_stamps):\n",
    "            stamp_idx = int(1 * 1e4 + groups_overlap_1[single_group][j])\n",
    "            color_for_display = viz.PALETTE['red']\n",
    "            ax.plot(\n",
    "                single_stamp/fs, [valid_start-j*dy_valid, valid_start-j*dy_valid], \n",
    "                color=color_for_display, linewidth=1.5, label=valid_label)\n",
    "            ax.annotate(\n",
    "                stamp_idx, (single_stamp[1]/fs+0.05, valid_start-j*dy_valid-10), fontsize=7)\n",
    "            shown_valid = True\n",
    "            valid_label = None\n",
    "    valid_1_center = valid_start - (max_size_shown//2) * dy_valid\n",
    "    # Show valid 2\n",
    "    valid_start = - max_size_shown * dy_valid - 200\n",
    "    shown_groups_2 = []\n",
    "    for j, this_stamp in enumerate(segment_stamps_valid_2):\n",
    "        idx_stamp = np.where([np.all(this_stamp == single_stamp) for single_stamp in raw_stamps_2])[0]\n",
    "        idx_group = np.where([idx_stamp in single_group for single_group in groups_overlap_2])[0][0].item()\n",
    "        shown_groups_2.append(idx_group)\n",
    "    shown_groups_2 = np.unique(shown_groups_2)\n",
    "    max_size_shown = 0\n",
    "    for single_group in shown_groups_2:\n",
    "        group_stamps = [raw_stamps_2[single_idx] for single_idx in groups_overlap_2[single_group]]\n",
    "        group_stamps = np.stack(group_stamps, axis=0)\n",
    "        group_size = group_stamps.shape[0]\n",
    "        if group_size > max_size_shown:\n",
    "            max_size_shown = group_size\n",
    "        for j, single_stamp in enumerate(group_stamps):\n",
    "            stamp_idx = int(2 * 1e4 + groups_overlap_2[single_group][j])\n",
    "            color_for_display = viz.PALETTE['red']\n",
    "            ax.plot(\n",
    "                single_stamp/fs, [valid_start-j*dy_valid, valid_start-j*dy_valid], \n",
    "                color=color_for_display, linewidth=1.5, label=valid_label)\n",
    "            ax.annotate(stamp_idx, (single_stamp[1]/fs+0.05, valid_start-j*dy_valid-10), fontsize=7)\n",
    "            shown_valid = True\n",
    "            valid_label = None\n",
    "    valid_2_center = valid_start - (max_size_shown//2) * dy_valid\n",
    "    # Signal\n",
    "    y_max = 150\n",
    "    y_sep = 300\n",
    "    start_signal_plot = valid_start - max_size_shown * dy_valid - y_sep\n",
    "    y_minor_ticks = []\n",
    "    for k, name in enumerate(to_show_names):\n",
    "        if name == 'F4-C4':\n",
    "            stamp_center = start_signal_plot-y_sep*k\n",
    "        #if name == 'EMG':\n",
    "        #    continue\n",
    "        segment_fs = fs\n",
    "        segment_start = int(page_chosen * dataset.page_duration * segment_fs)\n",
    "        segment_end = int(segment_start + dataset.page_duration * segment_fs)\n",
    "        segment_signal = signal_dict[name][segment_start:segment_end]\n",
    "        segment_time_axis = np.arange(segment_start, segment_end) / segment_fs\n",
    "        ax.plot(\n",
    "            segment_time_axis, start_signal_plot-y_sep*k + segment_signal, linewidth=0.7, color=viz.PALETTE['grey'])\n",
    "        y_minor_ticks.append(start_signal_plot-y_sep*k + signal_uv_to_display)\n",
    "        y_minor_ticks.append(start_signal_plot-y_sep*k - signal_uv_to_display)\n",
    "    plotter.add_scalebar(\n",
    "        ax, matchx=False, matchy=False, hidex=False, hidey=False, sizex=1, sizey=100, \n",
    "        labelx='1 s', labely='100 uV', loc=1)\n",
    "    expert_shown = False\n",
    "    for expert_stamp in segment_stamps:\n",
    "        label = None if expert_shown else 'Accepted mark (automatic)'\n",
    "        ax.plot(\n",
    "            expert_stamp / fs, [stamp_center-50, stamp_center-50], \n",
    "            color=viz.PALETTE['green'], linewidth=2, label=label)\n",
    "        expert_shown = True\n",
    "    expert_manual_shown = False\n",
    "    for final_stamp in segment_stamps_final:\n",
    "        label = None if expert_manual_shown else 'Expert Final Version'\n",
    "        ax.fill_between(\n",
    "            final_stamp / fs, 100+stamp_center, -100+stamp_center, \n",
    "            facecolor=viz.PALETTE['grey'], alpha=0.4,  label=label, edgecolor='k')\n",
    "        expert_manual_shown = True\n",
    "    ticks_valid = [valid_1_center, valid_2_center]\n",
    "    ticks_signal = [start_signal_plot-y_sep*k for k in range(len(to_show_names))]\n",
    "    ticklabels_valid = ['V1', 'V2']\n",
    "    total_ticks = ticks_valid + ticks_signal\n",
    "    total_ticklabels = ticklabels_valid + to_show_names[:-2] + ['MOR', 'EMG']\n",
    "    ax.set_yticks(total_ticks)\n",
    "    ax.set_yticklabels(total_ticklabels)\n",
    "    ax.set_xlim([time_axis[0], time_axis[-1]])\n",
    "    ax.set_ylim([-y_max - 30 + ticks_signal[-1], 100])\n",
    "    ax.set_title('Subject %d (%s INTA). Page in record: %1.1f. (intervals of 0.5s are shown as a vertical grid).' \n",
    "                 % (subject_id, NAMES[subject_id-1], page_chosen), fontsize=10, y=1.05)\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticks(np.arange(time_axis[0], time_axis[-1], 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    ax.tick_params(labelsize=7.5, labelbottom=True ,labeltop=True, bottom=True, top=True)\n",
    "    ax.set_aspect(1/microvolt_per_second)\n",
    "    ax.set_xlabel('Time [s]', fontsize=8)\n",
    "    if expert_shown or shown_valid:\n",
    "        lg = ax.legend(loc='lower left', fontsize=8)\n",
    "        for lh in lg.legendHandles:\n",
    "            lh.set_alpha(1.0)\n",
    "    plt.tight_layout()\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_from_conflict = 127\n",
    "\n",
    "folder_name = '%s_conflicts' % NAMES[subject_id - 1]\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "n_conflicts = conflict_pages.size\n",
    "print('Total conflicting pages: %d' % n_conflicts)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 1+len(to_show_names)), dpi=180)\n",
    "for conflict_id in range(start_from_conflict, n_conflicts + 1):\n",
    "    fname = os.path.join(folder_name, 'conflict_%03d.pdf' % conflict_id)\n",
    "    ax.clear()\n",
    "    ax = plot_page_conflict(conflict_id, ax)\n",
    "    plt.savefig(fname, dpi=200, bbox_inches=\"tight\", pad_inches=0.02)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify Correction Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_from_conflict = 127\n",
    "optional_end_conflict = 127 + 7\n",
    "\n",
    "if optional_end_conflict is None:\n",
    "    optional_end_conflict = n_conflicts\n",
    "\n",
    "folder_name = '%s_conflicts_final' % NAMES[subject_id - 1]\n",
    "os.makedirs(folder_name, exist_ok=True)\n",
    "n_conflicts = conflict_pages.size\n",
    "print('Total conflicting pages: %d' % n_conflicts)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 1+len(to_show_names)), dpi=180)\n",
    "for conflict_id in range(start_from_conflict, optional_end_conflict + 1):\n",
    "    fname = os.path.join(folder_name, 'conflict_%03d.pdf' % conflict_id)\n",
    "    ax.clear()\n",
    "    ax = plot_page_conflict(conflict_id, ax, show_final=True)\n",
    "    plt.savefig(fname, dpi=200, bbox_inches=\"tight\", pad_inches=0.02)\n",
    "plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
