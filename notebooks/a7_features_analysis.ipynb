{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "project_root = os.path.abspath('..')\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from sleeprnn.helpers.reader import load_dataset\n",
    "from sleeprnn.data import utils, stamp_correction\n",
    "from sleeprnn.detection import metrics\n",
    "from sleeprnn.common import constants, pkeys, viz\n",
    "\n",
    "GRID_PATH = os.path.join(\n",
    "    '/home/ntapia/projects/repos/sleep-rnn/resources/datasets/',\n",
    "    'output_mass_ss_second_grid_e1/output_mass_ss_second')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A7 original method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = constants.MASS_SS_NAME\n",
    "which_expert = 1\n",
    "fs = 200\n",
    "fs_predictions = 128\n",
    "\n",
    "dataset_params = {pkeys.FS: fs}\n",
    "task_mode = constants.N2_RECORD\n",
    "id_try_list = np.arange(10)\n",
    "\n",
    "# Load expert annotations\n",
    "dataset = load_dataset(dataset_name, params=dataset_params)\n",
    "all_train_ids = dataset.train_ids\n",
    "page_size = dataset.page_size\n",
    "print('Page size:', page_size)\n",
    "print('All train ids', all_train_ids)\n",
    "n2_dict = {}\n",
    "for subject_id in all_train_ids:\n",
    "    n2_dict[subject_id] = dataset.get_subject_pages(subject_id, pages_subset=task_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load grid search predictions (E1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_settings(full_settings, valid_absSigPow, valid_relSigPow, valid_sigCov, valid_sigCorr):\n",
    "    filtered_settings = []\n",
    "    for setting in full_settings:\n",
    "        setting_parse = setting.split(\"_\")\n",
    "        tmp_dict = {}\n",
    "        for param in setting_parse:\n",
    "            param = param.split(\"(\")\n",
    "            param_name = param[0]\n",
    "            param_value = param[1][:-1]\n",
    "            tmp_dict[param_name] = float(param_value)\n",
    "        cond1 = True if valid_absSigPow is None else tmp_dict['absSigPow'] in valid_absSigPow\n",
    "        cond2 = True if valid_relSigPow is None else tmp_dict['relSigPow'] in valid_relSigPow\n",
    "        cond3 = True if valid_sigCov is None else tmp_dict['sigCov'] in valid_sigCov\n",
    "        cond4 = True if valid_sigCorr is None else tmp_dict['sigCorr'] in valid_sigCorr\n",
    "        if cond1 and cond2 and cond3 and cond4:\n",
    "            filtered_settings.append(setting)\n",
    "    return filtered_settings\n",
    "\n",
    "\n",
    "def print_available_settings(full_settings):\n",
    "    absSigPow_list = []\n",
    "    relSigPow_list = []\n",
    "    sigCov_list = []\n",
    "    sigCorr_list = []\n",
    "    for setting in full_settings:\n",
    "        setting_parse = setting.split(\"_\")\n",
    "        tmp_dict = {}\n",
    "        for param in setting_parse:\n",
    "            param = param.split(\"(\")\n",
    "            param_name = param[0]\n",
    "            param_value = param[1][:-1]\n",
    "            tmp_dict[param_name] = float(param_value)\n",
    "        absSigPow_list.append(tmp_dict['absSigPow'])\n",
    "        relSigPow_list.append(tmp_dict['relSigPow'])\n",
    "        sigCov_list.append(tmp_dict['sigCov'])\n",
    "        sigCorr_list.append(tmp_dict['sigCorr'])\n",
    "    absSigPow_list = np.unique(absSigPow_list)\n",
    "    relSigPow_list = np.unique(relSigPow_list)\n",
    "    sigCov_list = np.unique(sigCov_list)\n",
    "    sigCorr_list = np.unique(sigCorr_list)\n",
    "    print(\"absSigPow: %s\" % absSigPow_list)\n",
    "    print(\"relSigPow: %s\" % relSigPow_list)\n",
    "    print(\"sigCov: %s\" % sigCov_list)\n",
    "    print(\"sigCorr: %s\" % sigCorr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load predictions\n",
    "pred_folder = os.path.join(GRID_PATH, 'e%d' % which_expert)\n",
    "print('Loading predictions from %s' % pred_folder, flush=True)\n",
    "pred_files = os.listdir(pred_folder)\n",
    "\n",
    "pred_dict = {}\n",
    "visited_settings = []\n",
    "for file in pred_files:\n",
    "    subject_id = int(file.split('_')[3][1:])\n",
    "    setting = '_'.join(file.split('_')[4:])[:-4]\n",
    "    if setting not in visited_settings:\n",
    "        pred_dict[setting] = {}\n",
    "        visited_settings.append(setting)\n",
    "    # sample marks\n",
    "    filepath = os.path.join(pred_folder, file)\n",
    "    pred_data = pd.read_csv(filepath, sep='\\t')\n",
    "    # We substract 1 to translate from matlab to numpy indexing system\n",
    "    start_samples = pred_data.start_sample.values - 1\n",
    "    end_samples = pred_data.end_sample.values - 1\n",
    "    pred_marks = np.stack([start_samples, end_samples], axis=1)\n",
    "    # Transform to correct sampling frequency\n",
    "    pred_marks = (pred_marks * fs / fs_predictions).astype(np.int32)\n",
    "    # Valid subset of marks\n",
    "    pred_marks_n2 = utils.extract_pages_for_stamps(pred_marks, n2_dict[subject_id], page_size)\n",
    "    # Postprocessing\n",
    "    pred_marks_n2 = stamp_correction.combine_close_stamps(\n",
    "        pred_marks_n2, fs, min_separation=0.3)\n",
    "    pred_marks_n2 = stamp_correction.filter_duration_stamps(\n",
    "        pred_marks_n2, fs, min_duration=0.3, max_duration=3.0)\n",
    "    # Save marks for evaluation\n",
    "    pred_dict[setting][subject_id] = pred_marks_n2\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total settings: %d\" % len(visited_settings))\n",
    "print_available_settings(visited_settings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_thr = 0.2\n",
    "perf_dict = {setting: {} for setting in visited_settings}\n",
    "for subject_id in all_train_ids:\n",
    "    expert_marks = dataset.get_subject_stamps(subject_id, which_expert=which_expert, pages_subset=task_mode)\n",
    "    for setting in visited_settings:\n",
    "        pred_marks_n2 = pred_dict[setting][subject_id]\n",
    "        # Compare\n",
    "        this_precision = metrics.metric_vs_iou(\n",
    "            expert_marks, pred_marks_n2, [iou_thr], metric_name=constants.PRECISION)[0]\n",
    "        this_recall = metrics.metric_vs_iou(\n",
    "            expert_marks, pred_marks_n2, [iou_thr], metric_name=constants.RECALL)[0]\n",
    "        tmp_results_dict = {\n",
    "            'precision': this_precision,\n",
    "            'recall': this_recall,\n",
    "        }\n",
    "        perf_dict[setting][subject_id] = tmp_results_dict\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize PR of val subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all settings\n",
    "subject_to_show = 19\n",
    "\n",
    "settings_to_show = filter_settings(\n",
    "    visited_settings, \n",
    "    valid_absSigPow=[1.75], \n",
    "    valid_relSigPow=[1.6], \n",
    "    valid_sigCov=[1.8], \n",
    "    valid_sigCorr=[0.75]\n",
    ")\n",
    "print(\"Plotting %d settings\" % len(settings_to_show))\n",
    "print_available_settings(settings_to_show)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=100)\n",
    "subject_recall_list = [perf_dict[setting][subject_to_show]['recall'] for setting in settings_to_show]\n",
    "subject_precision_list = [perf_dict[setting][subject_to_show]['precision'] for setting in settings_to_show]\n",
    "rest_recall_list = []\n",
    "rest_precision_list = []\n",
    "for setting in visited_settings:\n",
    "    if setting not in settings_to_show:\n",
    "        rest_recall_list.append(perf_dict[setting][subject_to_show]['recall'])\n",
    "        rest_precision_list.append(perf_dict[setting][subject_to_show]['precision'])\n",
    "if rest_recall_list:\n",
    "    ax.plot(\n",
    "    rest_recall_list, \n",
    "    rest_precision_list, \n",
    "    color=viz.GREY_COLORS[4], alpha=0.4,\n",
    "    marker='o', markersize=5, linestyle='None', zorder=2, label=\"Not selected\")\n",
    "ax.plot(\n",
    "    subject_recall_list, \n",
    "    subject_precision_list, \n",
    "    color=viz.PALETTE['blue'], alpha=0.6,\n",
    "    marker='o', markersize=5, linestyle='None', zorder=10, label=\"Selected\")\n",
    "ax.plot([0, 1], [0, 1], zorder=1, linewidth=1, color=viz.GREY_COLORS[4])\n",
    "ax.set_title('A7 - Subject %02d' % subject_to_show, fontsize=10)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_yticks(np.arange(11) / 10)\n",
    "ax.set_xticks(np.arange(11) / 10)\n",
    "ax.tick_params(labelsize=8) \n",
    "ax.grid()\n",
    "ax.set_ylabel('Precision (IoU>%1.1f)' % iou_thr, fontsize=10)\n",
    "ax.set_xlabel('Recall (IoU>%1.1f)' % iou_thr, fontsize=10)\n",
    "ax.set_aspect('equal')\n",
    "ax.legend(loc=\"lower left\", fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PR of val subjects for a single setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting to show\n",
    "valid_absSigPow = 1.75 \n",
    "valid_relSigPow = 1.6 \n",
    "valid_sigCov = 1.8\n",
    "valid_sigCorr = 0.75\n",
    "\n",
    "# Filter settings\n",
    "setting_to_show = filter_settings(\n",
    "    visited_settings, \n",
    "    valid_absSigPow=[valid_absSigPow], \n",
    "    valid_relSigPow=[valid_relSigPow], \n",
    "    valid_sigCov=[valid_sigCov], \n",
    "    valid_sigCorr=[valid_sigCorr]\n",
    ")[0]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=100)\n",
    "\n",
    "all_recall = []\n",
    "all_precision = []\n",
    "for subject_to_show in all_train_ids:\n",
    "    subject_recall = perf_dict[setting_to_show][subject_to_show]['recall']\n",
    "    subject_precision = perf_dict[setting_to_show][subject_to_show]['precision']\n",
    "    all_recall.append(subject_recall)\n",
    "    all_precision.append(subject_precision)\n",
    "    ax.plot(\n",
    "        subject_recall, \n",
    "        subject_precision, \n",
    "        color=viz.PALETTE['blue'],\n",
    "        marker='o', markersize=6, linestyle='None', zorder=10)\n",
    "    ax.annotate(\n",
    "        subject_to_show, (subject_recall, subject_precision), \n",
    "        horizontalalignment=\"center\", verticalalignment=\"center\", fontsize=4, color=\"w\", zorder=20)\n",
    "mean_recall = np.mean(all_recall)\n",
    "mean_precision = np.mean(all_precision)\n",
    "std_recall = np.std(all_recall)\n",
    "std_precision = np.std(all_precision)\n",
    "perf_string = \"P: %1.1f\\u00B1%1.1f, R: %1.1f\\u00B1%1.1f\" % (\n",
    "    100 * mean_precision, 100 * std_precision,\n",
    "    100 * mean_recall, 100 * std_recall, \n",
    ")\n",
    "ax.plot([0, 1], [0, 1], zorder=1, linewidth=1, color=viz.GREY_COLORS[4])\n",
    "ax.plot(\n",
    "    mean_recall, mean_precision, \n",
    "    marker='o', markersize=3, linestyle=\"None\",\n",
    "    color=viz.GREY_COLORS[6], zorder=30\n",
    ")\n",
    "ax.set_title('A7 Validation\\n%s\\n%s' % (setting_to_show, perf_string), fontsize=7)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_yticks(np.arange(11) / 10)\n",
    "ax.set_xticks(np.arange(11) / 10)\n",
    "ax.tick_params(labelsize=8) \n",
    "ax.grid()\n",
    "ax.set_ylabel('Precision (IoU>%1.1f)' % iou_thr, fontsize=10)\n",
    "ax.set_xlabel('Recall (IoU>%1.1f)' % iou_thr, fontsize=10)\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(\"pr_a7_val_%s.png\" % setting_to_show, dpi=200, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
