{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pprint import pprint\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import gridspec\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.interpolate import interp1d\n",
    "# from tqdm import tqdm\n",
    "\n",
    "project_root = '..'\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from sleeprnn.data.loader import load_dataset\n",
    "from sleeprnn.helpers.reader import RefactorUnpickler\n",
    "from sleeprnn.data import utils, stamp_correction\n",
    "from sleeprnn.detection.feeder_dataset import FeederDataset\n",
    "from sleeprnn.detection import metrics\n",
    "from sleeprnn.detection.postprocessor import PostProcessor\n",
    "from sleeprnn.common import constants, pkeys, viz\n",
    "\n",
    "SEED_LIST = [123, 234, 345, 456]\n",
    "RESULTS_PATH = os.path.join(project_root, 'results')\n",
    "COMPARISON_PATH = os.path.join(project_root, 'resources', 'comparison_data')\n",
    "DPI = 200\n",
    "CUSTOM_COLOR = {'red': '#c62828', 'grey': '#455a64', 'blue': '#0277bd', 'green': '#43a047'} \n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load database and predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimal_thr_for_ckpt_dict = {\n",
    "    os.path.join('20190504_bsf_wn_train_mass_ss', 'bsf'): [0.64, 0.52, 0.52, 0.48],\n",
    "    os.path.join('20190504_bsf_wn_train_mass_kc', 'bsf'): [0.52, 0.56, 0.54, 0.56],\n",
    "    os.path.join('20190506_bsf_n2_train_mass_ss', 'bsf'): [0.52, 0.46, 0.50, 0.50],\n",
    "    os.path.join('20190506_bsf_n2_train_mass_kc', 'bsf'): [0.52, 0.52, 0.56, 0.46],\n",
    "    os.path.join('20190516_bsf_n2_train_inta_ss', 'bsf'): [0.48, 0.52, 0.48, 0.44],\n",
    "    os.path.join('20190516_bsf_v2_n2_train_inta_ss', 'bsf'): [0.46, 0.52, 0.50, 0.46],\n",
    "    os.path.join('20190522_bsf_newer_wins_fix_n2_train_inta_ss', 'bsf'): [0.44, 0.5, 0.44, 0.42],\n",
    "    os.path.join('20190522_bsf_e1_n2_train_mass_ss', 'bsf'): [0.44, 0.56, 0.48, 0.48],\n",
    "    os.path.join('20190522_bsf_e2_n2_train_mass_ss', 'bsf'): [0.6, 0.44, 0.36, 0.56],\n",
    "    os.path.join('20190525_bsf_ch3_n2_train_inta_ss', 'bsf'): [0.48, 0.56, 0.52, 0.5],\n",
    "    os.path.join('20190525_bsf_v4_n2_train_mass_ss', 'bsf_1'): [0.46, 0.4, 0.5, 0.46],\n",
    "    os.path.join('20190527_bsf_v7_k3_n2_train_mass_ss', 'bsf_2'): [0.52, 0.44, 0.48, 0.42],\n",
    "    os.path.join('20190530_bsf_v10_n2_train_mass_ss', 'bsf'): [0.6, 0.44, 0.56, 0.42],\n",
    "    os.path.join('20190601_bsf_v11_n2_train_mass_ss', 'filters_32_64_128'): [0.64, 0.36, 0.58, 0.4],\n",
    "    os.path.join('20190601_bsf_v11_n2_train_mass_ss', 'filters_64_128_256'): [0.62, 0.6, 0.52, 0.44],\n",
    "    os.path.join('20190603_grid_cwt_fb05_n2_train_mass_ss', 'v12_f_32_64'): [0.66, 0.46, 0.52, 0.46],\n",
    "    os.path.join('20190605_grid_v15_v16_n2_train_mass_ss', 'v15_timef_64_128_256_cwtf_32_32_fb_0.5'): [0.46, 0.52, 0.62, 0.42],\n",
    "    os.path.join('20190614_bsf_global_std_n2_train_mass_ss', 'bsf'): [0.62, 0.4, 0.4, 0.48],\n",
    "    os.path.join('20190617_grid_normalization_n2_train_mass_ss', 'norm_global'): [0.58, 0.42, 0.4, 0.5],\n",
    "    os.path.join('20190608_bsf_ablation_n2_train_inta_ss', 'v15_tf_64-128-256_cwtf_32-32/rep0'): [0.48, 0.52, 0.5, 0.5],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_n2_train_dreams_ss', 'v11_None'): [0.22, 0.48, 0.28, 0.38],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_n2_train_dreams_ss', 'v12_True'): [0.36, 0.5, 0.34, 0.36],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_n2_train_dreams_ss', 'v17_True'): [0.34, 0.38, 0.28, 0.44],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_wn_train_dreams_ss', 'v11_None'): [0.36, 0.46, 0.4, 0.36],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_wn_train_dreams_ss', 'v12_True'): [0.48, 0.46, 0.46, 0.52],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_wn_train_dreams_ss', 'v17_True'): [0.3, 0.52, 0.28, 0.46],\n",
    "    os.path.join('20190704_inta_meeting_n2_train_mass_ss', 'v15'): [0.5, 0.42, 0.56, 0.58],\n",
    "    os.path.join('20190704_inta_meeting_n2_train_mass_ss', 'v20_indep'): [0.4, 0.62, 0.64, 0.56],\n",
    "    os.path.join('20190704_inta_meeting_n2_train_inta_ss', 'v15'): [0.48, 0.48, 0.5, 0.46],\n",
    "    os.path.join('20190704_inta_meeting_n2_train_inta_ss', 'v20_indep'): [0.54, 0.42, 0.5, 0.5],\n",
    "    os.path.join('20190706_inta_05_n2_train_inta_ss', 'v15'): [0.42, 0.44, 0.48, 0.5],\n",
    "    os.path.join('20190708_grid_v19_pte2_n2_train_mass_ss', 'r_1_i_1_m_1_p_0_fb_0.5'): [0.42, 0.58, 0.62, 0.54],\n",
    "    os.path.join('20190825_v22_grid_n2_train_mass_ss', 'r_1_i_1_m_1_p_0_drop_0.3_f_64'): [0.52, 0.48, 0.5, 0.52],\n",
    "    os.path.join('20190827_thesis_1_bsf_e1_n2_train_mass_ss', 'v19'): [0.54, 0.52, 0.64, 0.54],\n",
    "    os.path.join('20190827_thesis_1_bsf_e2_n2_train_mass_ss', 'v19'): [0.58, 0.5, 0.34, 0.6],\n",
    "    os.path.join('20190827_thesis_1_bsf_e1_n2_train_mass_kc', 'v19'): [0.54, 0.64, 0.52, 0.5],\n",
    "    os.path.join('20190827_thesis_1_bsf_e1_n2_train_inta_ss', 'v19'): [0.42, 0.42, 0.46, 0.44],\n",
    "    os.path.join('20190915_balancing_drop_n2_train_mass_ss', 'v11'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190915_balancing_drop_n2_train_mass_ss', 'v19'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190915_balancing_drop_n2_train_mass_kc', 'v11'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190915_balancing_drop_n2_train_mass_kc', 'v19'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190916_balancing_drop_v2_n2_train_mass_ss', 'v11'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190916_balancing_drop_v2_n2_train_mass_ss', 'v19'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190916_balancing_weight_n2_train_mass_ss', 'v11'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190916_balancing_weight_n2_train_mass_ss', 'v19'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190917_out_proba_init_grid_n2_train_mass_ss', 'p_0.01_lr_0.0001'): [0.44, 0.54, 0.56, 0.32],\n",
    "    os.path.join('20190917_out_proba_init_grid_n2_train_mass_ss', 'p_0.1_lr_0.0001'): [0.24, 0.42, 0.54, 0.48],\n",
    "    os.path.join('20190917_out_proba_init_equal_n2_train_mass_ss', 'v11'): [0.28, 0.58, 0.56, 0.4],\n",
    "    os.path.join('20190927_out_proba_cwt_grid_n2_train_mass_ss', 'p_0.5_lr_0.0001'): [0.36, 0.42, 0.62, 0.4],\n",
    "    os.path.join('20190927_out_proba_cwt_grid_n2_train_mass_ss', 'p_0.01_lr_0.0001'): [0.42, 0.46, 0.54, 0.36],\n",
    "    os.path.join('20191003_loss_grid_cwt_n2_train_mass_ss', 'v19_p_0.5_focal_loss_gamma_1.0'): [0.42, 0.60, 0.58, 0.44],\n",
    "    os.path.join('20191003_loss_grid_cwt_n2_train_mass_ss', 'v19_p_0.5_focal_loss_gamma_1.5'): [0.44, 0.50, 0.52, 0.52],\n",
    "    os.path.join('20191003_loss_grid_cwt_n2_train_mass_ss', 'v19_p_0.5_focal_loss_gamma_2.0'): [0.44, 0.52, 0.54, 0.50],\n",
    "    os.path.join('20191009_focal_loss_grid_n2_train_mass_ss', 'v19_p_0.5_focal_loss_gamma_2.5'): [0.46, 0.54, 0.54, 0.52],\n",
    "    os.path.join('20191009_focal_loss_grid_n2_train_mass_ss', 'v19_p_0.5_focal_loss_gamma_3.0'): [0.46, 0.52, 0.50, 0.46],\n",
    "    os.path.join('20191009_focal_loss_grid_n2_train_mass_ss', 'v19_p_0.5_focal_loss_gamma_3.5'): [0.44, 0.54, 0.50, 0.50],\n",
    "    os.path.join('20191009_focal_loss_grid_n2_train_mass_ss', 'v19_p_0.5_focal_loss_gamma_4.0'): [0.46, 0.52, 0.52, 0.50],\n",
    "    os.path.join('20190927_loss_grid_n2_train_mass_ss', 'v11_p_0.5_dice_loss_gamma_None'): [0.50, 0.50, 0.50, 0.50],\n",
    "    os.path.join('20190927_loss_grid_n2_train_mass_ss', 'v11_p_0.5_focal_loss_gamma_1.0'): [0.48, 0.50, 0.54, 0.50],\n",
    "    os.path.join('20190927_loss_grid_n2_train_mass_ss', 'v11_p_0.5_focal_loss_gamma_1.5'): [0.42, 0.50, 0.56, 0.44],\n",
    "    os.path.join('20190927_loss_grid_n2_train_mass_ss', 'v11_p_0.5_focal_loss_gamma_2.0'): [0.46, 0.54, 0.54, 0.46],\n",
    "    os.path.join('20191009_focal_loss_grid_n2_train_mass_ss', 'v11_p_0.5_focal_loss_gamma_2.5'): [0.44, 0.52, 0.46, 0.44],\n",
    "    os.path.join('20191009_focal_loss_grid_n2_train_mass_ss', 'v11_p_0.5_focal_loss_gamma_3.0'): [0.48, 0.54, 0.54, 0.50],\n",
    "    os.path.join('20191009_focal_loss_grid_n2_train_mass_ss', 'v11_p_0.5_focal_loss_gamma_3.5'): [0.48, 0.52, 0.52, 0.50],\n",
    "    os.path.join('20191009_focal_loss_grid_n2_train_mass_ss', 'v11_p_0.5_focal_loss_gamma_4.0'): [0.46, 0.48, 0.52, 0.48],\n",
    "    os.path.join('20191013_train_at_128Hz_n2_train_mass_ss', 'v19'): [0.26, 0.54, 0.68, 0.34],\n",
    "    os.path.join('20191017_elastic_grid_pte2_n2_train_mass_ss', 'v11_alpha_0.25_sigma_0.125_keepbest_True'): [0.54, 0.40, 0.42, 0.48],\n",
    "    os.path.join('20191017_elastic_grid_pte2_n2_train_mass_ss', 'v11_alpha_0.15_sigma_0.075_keepbest_True'): [0.50, 0.34, 0.36, 0.48],\n",
    "    os.path.join('20191017_elastic_grid_pte2_n2_train_mass_ss', 'v11_alpha_0.25_sigma_0.100_keepbest_False'): [0.36, 0.48, 0.52, 0.48]\n",
    "}\n",
    "\n",
    "ckpt_folder = os.path.join('20190827_thesis_1_bsf_e1_n2_train_mass_ss', 'v19')\n",
    "ckpt_fs = 200\n",
    "load_dataset_from_ckpt = True\n",
    "which_expert = 1\n",
    "\n",
    "new_split_version = True\n",
    "optimal_thr_list = optimal_thr_for_ckpt_dict[ckpt_folder]\n",
    "task_mode = constants.N2_RECORD\n",
    "dataset_name = constants.MASS_SS_NAME\n",
    "seed_id_list = [0, 1, 2, 3]\n",
    "# seed_id_list = [1]\n",
    "\n",
    "n_seeds = len(seed_id_list)\n",
    "set_list = [constants.TRAIN_SUBSET, constants.VAL_SUBSET, constants.TEST_SUBSET]\n",
    "# set_list = [constants.TEST_SUBSET]\n",
    "verbose = False\n",
    "\n",
    "# Load data\n",
    "dataset = load_dataset(dataset_name, load_checkpoint=load_dataset_from_ckpt, params={pkeys.NORM_COMPUTATION_MODE: constants.NORM_GLOBAL, pkeys.FS: ckpt_fs})\n",
    "fs = dataset.fs\n",
    "all_train_ids = dataset.train_ids\n",
    "test_ids = dataset.test_ids\n",
    "predictions_dict = {}\n",
    "for k in seed_id_list:\n",
    "    # Restore predictions\n",
    "    ckpt_path = os.path.abspath(os.path.join(\n",
    "        RESULTS_PATH,\n",
    "        'predictions_%s' % dataset_name,\n",
    "        ckpt_folder,\n",
    "        'seed%d' % k\n",
    "    ))\n",
    "    this_dict = {}\n",
    "    for set_name in set_list:\n",
    "        filename = os.path.join(\n",
    "                ckpt_path,\n",
    "                'prediction_%s_%s.pkl' % (task_mode, set_name))\n",
    "        with open(filename, 'rb') as handle:\n",
    "            this_pred = RefactorUnpickler(handle).load()\n",
    "        this_dict[set_name] = this_pred\n",
    "    predictions_dict[k] = this_dict\n",
    "    print('Loaded seed %d/%d from %s' % (k + 1, n_seeds, ckpt_path))\n",
    "print('Optimal thr:', optimal_thr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output thr selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_id_for_selection = 1\n",
    "\n",
    "\n",
    "# Adjust thr\n",
    "res_thr = 0.02\n",
    "start_thr = 0.3\n",
    "end_thr = 0.7\n",
    "n_thr = int(np.round((end_thr - start_thr) / res_thr + 1))\n",
    "thr_list = np.array([start_thr + res_thr * i for i in range(n_thr)])\n",
    "thr_list = np.round(thr_list, 2)\n",
    "print('%d thresholds to be evaluated between %1.4f and %1.4f'\n",
    "      % (n_thr, thr_list[0], thr_list[-1]))\n",
    "\n",
    "per_seed_af1 = []\n",
    "# Validation split\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_id_for_selection)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_id_for_selection])\n",
    "\n",
    "ids_dict = {\n",
    "    constants.TRAIN_SUBSET: train_ids,\n",
    "    constants.VAL_SUBSET: val_ids}\n",
    "for thr in thr_list:\n",
    "    events_list = []\n",
    "    detections_list = []\n",
    "    for set_name in [constants.TRAIN_SUBSET, constants.VAL_SUBSET]:\n",
    "        # Prepare expert labels\n",
    "        data_inference = FeederDataset(\n",
    "            dataset, ids_dict[set_name], task_mode,\n",
    "            which_expert=which_expert)\n",
    "        this_events = data_inference.get_stamps()\n",
    "        # Prepare model predictions\n",
    "        prediction_obj = predictions_dict[seed_id_for_selection][set_name]\n",
    "        prediction_obj.set_probability_threshold(thr)\n",
    "        this_detections = prediction_obj.get_stamps()\n",
    "        events_list = events_list + this_events\n",
    "        detections_list = detections_list + this_detections\n",
    "    # Compute AF1\n",
    "    af1_at_thr = metrics.average_metric_with_list(\n",
    "        events_list, detections_list, verbose=False)\n",
    "    per_seed_af1.append(af1_at_thr)\n",
    "print('Done')\n",
    "max_idx = np.argmax(per_seed_af1).item()\n",
    "this_best_thr = thr_list[max_idx]\n",
    "print('Best thr: %1.2f' % this_best_thr)\n",
    "\n",
    "# For best thr, compute F1 vs IoU curve\n",
    "events_list = []\n",
    "detections_list = []\n",
    "for set_name in [constants.TRAIN_SUBSET, constants.VAL_SUBSET]:\n",
    "    # Prepare expert labels\n",
    "    data_inference = FeederDataset(\n",
    "        dataset, ids_dict[set_name], task_mode,\n",
    "        which_expert=which_expert)\n",
    "    this_events = data_inference.get_stamps()\n",
    "    # Prepare model predictions\n",
    "    prediction_obj = predictions_dict[seed_id_for_selection][set_name]\n",
    "    prediction_obj.set_probability_threshold(this_best_thr)\n",
    "    this_detections = prediction_obj.get_stamps()\n",
    "    events_list = events_list + this_events\n",
    "    detections_list = detections_list + this_detections\n",
    "# Compute AF1\n",
    "first_iou = 0\n",
    "last_iou = 1\n",
    "res_iou = 0.01\n",
    "n_points = int(np.round((last_iou - first_iou) / res_iou))\n",
    "full_iou_list = np.arange(n_points + 1) * res_iou + first_iou\n",
    "f1_alltrain = metrics.metric_vs_iou_with_list(\n",
    "    events_list, detections_list, full_iou_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3), dpi=200)\n",
    "\n",
    "ax[0].plot(full_iou_list, f1_alltrain, color=CUSTOM_COLOR['red'])\n",
    "ax[0].fill_between(full_iou_list, f1_alltrain, 0, color=CUSTOM_COLOR['red'], alpha=0.5)\n",
    "ax[0].set_title('F1 vs IoU curve at $\\mu$=%1.2f' % this_best_thr, fontsize=10)\n",
    "ax[0].set_xlim([0, 1])\n",
    "ax[0].set_ylim([0, 1])\n",
    "ax[0].set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax[0].set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax[0].tick_params(labelsize=7)\n",
    "ax[0].set_xlabel('IoU Threshold', fontsize=7)\n",
    "ax[0].set_ylabel('F1-score', fontsize=7)\n",
    "\n",
    "min_y = np.min(per_seed_af1) - 0.05\n",
    "max_y = np.max(per_seed_af1) + 0.05\n",
    "ax[1].plot(\n",
    "    thr_list, per_seed_af1, \n",
    "    color=CUSTOM_COLOR['red'], marker='o', markersize=4, label='Train+val set', zorder=10)\n",
    "ax[1].plot(\n",
    "    [this_best_thr, this_best_thr], [min_y, max_y], \n",
    "    color=CUSTOM_COLOR['grey'], linestyle='--', linewidth=1.5, label='Optimal $\\mu$=%1.2f' % this_best_thr, zorder=5)\n",
    "ax[1].set_title('Adjustment of $\\mu$', fontsize=10)\n",
    "ax[1].set_xticks([0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "ax[1].set_ylim([min_y, max_y])\n",
    "ax[1].tick_params(labelsize=7)\n",
    "ax[1].set_xlabel('Model Output Threshold $\\mu$', fontsize=7)\n",
    "ax[1].set_ylabel('AF1', fontsize=7)\n",
    "ax[1].legend(loc='upper right', fontsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselines_names_to_show = [\n",
    "    '2019_lacourse'\n",
    "]\n",
    "baselines_plot_dict = {\n",
    "    '2019_lacourse': ('Lacourse et al. 2019', 'd')\n",
    "}\n",
    "\n",
    "n_folds = 10\n",
    "baselines_f1_dict = {}\n",
    "baselines_recall_dict = {}\n",
    "baselines_precision_dict = {}\n",
    "\n",
    "for baseline_name in baselines_names_to_show:\n",
    "    # Check if we have results for this baseline\n",
    "    folder_to_check = os.path.join(COMPARISON_PATH, 'baselines', baseline_name, dataset_name, 'e%d' % which_expert)\n",
    "    if os.path.exists(folder_to_check):\n",
    "        print('%s found. ' % baseline_name, end='', flush=True)\n",
    "        right_prefix = '%s_%s_e%d' % (baseline_name, dataset_name, which_expert)\n",
    "        iou_axis_appended = False\n",
    "        tmp_f1_baseline = []\n",
    "        tmp_recall_baseline = []\n",
    "        tmp_precision_baseline = []\n",
    "        for k in np.arange(n_folds):\n",
    "            print(' %d ' % k, end='', flush=True)\n",
    "            f1_seed = []\n",
    "            rec_seed = []\n",
    "            pre_seed = []\n",
    "            for subject_id in test_ids:\n",
    "                fname = '%s_fold%d_s%02d.npz' % (right_prefix, k, subject_id)\n",
    "                fname_path = os.path.join(folder_to_check, 'fold%d' % k, fname)\n",
    "                this_data = np.load(fname_path)\n",
    "                if not iou_axis_appended:\n",
    "                    tmp_iou_axis = this_data['iou_axis']\n",
    "                    tmp_f1_baseline.append(tmp_iou_axis)\n",
    "                    tmp_recall_baseline.append(tmp_iou_axis)\n",
    "                    tmp_precision_baseline.append(tmp_iou_axis)\n",
    "                    iou_axis_appended = True\n",
    "                f1_seed.append(this_data['f1_vs_iou'])\n",
    "                rec_seed.append(this_data['recall_vs_iou'])\n",
    "                pre_seed.append(this_data['precision_vs_iou'])\n",
    "            f1_seed = np.stack(f1_seed, axis=0).mean(axis=0)\n",
    "            rec_seed = np.stack(rec_seed, axis=0).mean(axis=0)\n",
    "            pre_seed = np.stack(pre_seed, axis=0).mean(axis=0)\n",
    "            tmp_f1_baseline.append(f1_seed)\n",
    "            tmp_recall_baseline.append(rec_seed)\n",
    "            tmp_precision_baseline.append(pre_seed)\n",
    "        tmp_f1_baseline = np.stack(tmp_f1_baseline, axis=1)\n",
    "        tmp_recall_baseline = np.stack(tmp_recall_baseline, axis=1)\n",
    "        tmp_precision_baseline = np.stack(tmp_precision_baseline, axis=1)\n",
    "        baselines_f1_dict[baseline_name] = tmp_f1_baseline\n",
    "        baselines_recall_dict[baseline_name] = tmp_recall_baseline\n",
    "        baselines_precision_dict[baseline_name] = tmp_precision_baseline\n",
    "        print('Loaded.')\n",
    "    else:\n",
    "        print('%s not found.' % baseline_name)\n",
    "        baselines_f1_dict[baseline_name] = None\n",
    "        baselines_recall_dict[baseline_name] = None\n",
    "        baselines_precision_dict[baseline_name] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: F1 vs IoU curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ---------------- Compute performance\n",
    "f1_vs_iou_dict = {}\n",
    "first_iou = 0.05\n",
    "last_iou = 0.95\n",
    "step_iou = 0.05\n",
    "n_points = int(np.round((last_iou - first_iou) / step_iou))\n",
    "iou_list = first_iou + np.arange(n_points + 1) * step_iou\n",
    "iou_list_short = np.arange(1, 10) * 0.1\n",
    "iou_list_short_idx = [np.where(np.isclose(iou_list, this_value))[0][0] for this_value in iou_list_short]\n",
    "\n",
    "# Prepare expert labels\n",
    "data_test = FeederDataset(\n",
    "    dataset, test_ids, task_mode, which_expert=which_expert)\n",
    "this_events = data_test.get_stamps()\n",
    "\n",
    "seed_stamps = []\n",
    "test_af1_list = []\n",
    "seed_mean_ioutp = []\n",
    "for k in seed_id_list:\n",
    "    # Prepare model predictions\n",
    "    prediction_test = predictions_dict[k][constants.TEST_SUBSET]\n",
    "    \n",
    "    prediction_test.set_probability_threshold(optimal_thr_list[k])\n",
    "    this_detections = prediction_test.get_stamps()\n",
    "    seed_stamps.append(this_detections)\n",
    "    this_f1_vs_iou = metrics.metric_vs_iou_with_list(\n",
    "        this_events, this_detections, iou_list)\n",
    "    this_af1 = metrics.average_metric_with_list(this_events, this_detections)\n",
    "    f1_vs_iou_dict[k] = this_f1_vs_iou\n",
    "    test_af1_list.append(this_af1)\n",
    "    \n",
    "    # Measure iou of TP\n",
    "    mean_iou_per_subject = []\n",
    "    for single_events, single_detections in zip(this_events, this_detections):\n",
    "        this_iou_array, idx_array = metrics.matching(single_events, single_detections)\n",
    "        this_iou_array = this_iou_array[idx_array > -1]\n",
    "        mean_iou_per_subject.append(np.mean(this_iou_array))\n",
    "    seed_mean_ioutp.append(np.mean(mean_iou_per_subject))\n",
    "    \n",
    "# Mean performance\n",
    "mean_f1_vs_iou = np.stack([f1_vs_iou_dict[k] for k in seed_id_list], axis=1).mean(axis=1)\n",
    "std_f1_vs_iou = np.stack([f1_vs_iou_dict[k] for k in seed_id_list], axis=1).std(axis=1)\n",
    "mean_f1_vs_iou_short = mean_f1_vs_iou[iou_list_short_idx]\n",
    "std_f1_vs_iou_short = std_f1_vs_iou[iou_list_short_idx]\n",
    "\n",
    "print('IoU   Mean    Std')\n",
    "for k in range(iou_list_short.size):\n",
    "    print('%1.2f  %1.4f  %1.4f' % (iou_list_short[k], mean_f1_vs_iou_short[k], std_f1_vs_iou_short[k]))\n",
    "    \n",
    "print('Test AF1: %1.4f +- %1.4f' % (np.mean(test_af1_list), np.std(test_af1_list)))\n",
    "print('Test AF1 per seed:', test_af1_list)\n",
    "print('Test Mean IoU at TP: %1.4f +- %1.4f' % (np.mean(seed_mean_ioutp), np.std(seed_mean_ioutp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "filename = '%s_f1_vs_iou.npy' % (ckpt_folder.split('/')[0])\n",
    "data = np.stack([iou_list, mean_f1_vs_iou, std_f1_vs_iou], axis=1).astype(np.float32)\n",
    "np.save(filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_thr = 0.5  # Majority vote is 0.5\n",
    "binarized_first = True\n",
    "\n",
    "detections_half_rule_list = []\n",
    "detections_greater_half_rule_list = []\n",
    "\n",
    "postprocessor = PostProcessor(\n",
    "    predictions_dict[0][constants.TEST_SUBSET].event_name, \n",
    "    predictions_dict[0][constants.TEST_SUBSET].params)\n",
    "\n",
    "for j in range(len(test_ids)):\n",
    "    if task_mode == constants.N2_RECORD:\n",
    "        pages_indices_subset = predictions_dict[0][constants.TEST_SUBSET].get_subject_pages(\n",
    "            test_ids[j], pages_subset=constants.N2_RECORD, verbose=False)\n",
    "    else:\n",
    "        pages_indices_subset = None\n",
    "    \n",
    "    this_subject_detections_list_seq = [predictions_dict[k][constants.TEST_SUBSET].get_probabilities()[j].astype(np.float32) for k in seed_id_list]\n",
    "    if binarized_first:\n",
    "        this_subject_detections_list_seq = [(this_det >= this_thr).astype(np.int32) for (this_det, this_thr) in zip(this_subject_detections_list_seq, optimal_thr_list)]\n",
    "    this_subject_detections_mean = np.stack(this_subject_detections_list_seq, axis=0).mean(axis=0)\n",
    "    \n",
    "    detections_half_rule = postprocessor.proba2stamps(\n",
    "        this_subject_detections_mean, None, pages_indices_subset, thr=ensamble_thr)\n",
    "    detections_half_rule_list.append(detections_half_rule)\n",
    "    \n",
    "half_rule_f1_vs_iou = metrics.metric_vs_iou_with_list(\n",
    "        this_events, detections_half_rule_list, iou_list)\n",
    "half_rule_af1 = metrics.average_metric_with_list(this_events, detections_half_rule_list)\n",
    "\n",
    "half_rule_f1_vs_iou_short = half_rule_f1_vs_iou[iou_list_short_idx]\n",
    "\n",
    "print('IoU   Mean')\n",
    "for k in range(iou_list_short.size):\n",
    "    print('%1.2f  %1.4f' % (iou_list_short[k], half_rule_f1_vs_iou_short[k]))\n",
    "\n",
    "print('Test AF1 Ensamble:')\n",
    "print('Half Rule: %1.4f' % half_rule_af1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bsf_name = 'Proposed Model'\n",
    "\n",
    "result_id = '%s-%s-E%d-%s' % (\n",
    "    dataset_name.split('_')[0].upper(), \n",
    "    dataset_name.split('_')[1].upper(), \n",
    "    which_expert,\n",
    "    task_mode.upper()\n",
    ")\n",
    "\n",
    "compare_expert = True\n",
    "compare_chambon = False\n",
    "compare_baselines = True\n",
    "show_seed_std = True\n",
    "show_seed_curves = False\n",
    "show_ensamble = False\n",
    "alpha = 0.3\n",
    "color_list = {'model_mean': CUSTOM_COLOR['red'] , 'expert': CUSTOM_COLOR['grey'], 'dosed': viz.PALETTE['dark'],\n",
    "              'generic_baseline': viz.PALETTE['blue']\n",
    "             }\n",
    "linewidth_model = 1.0\n",
    "markersize_model = 4\n",
    "linewidth_others = 1.0\n",
    "markersize_others = 4\n",
    "\n",
    "iou_thr_to_show = 0.3\n",
    "\n",
    "\n",
    "# -------------------- P L O T ----------------------    \n",
    "\n",
    "\n",
    "# Comparison data\n",
    "compare_expert = (compare_expert and (dataset.event_name == constants.SPINDLE))\n",
    "\n",
    "if compare_expert:\n",
    "    expert_f1_curve_mean = np.loadtxt(os.path.join(COMPARISON_PATH, 'expert', 'ss_f1_vs_iou_expert_mean.csv'), delimiter=',')\n",
    "    expert_f1_curve_std = np.loadtxt(os.path.join(COMPARISON_PATH, 'expert', 'ss_f1_vs_iou_expert_std.csv'), delimiter=',')\n",
    "    expert_f1_curve_mean = expert_f1_curve_mean[1:, :]\n",
    "    expert_f1_curve_std = expert_f1_curve_std[1:, :]\n",
    "\n",
    "if compare_chambon and (dataset_name == constants.MASS_SS_NAME):\n",
    "    dosed_f1_curve_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_ss_wn_f1_vs_iou_dosed_separately.csv'), delimiter=',')\n",
    "if compare_chambon and (dataset_name == constants.MASS_KC_NAME):\n",
    "    dosed_f1_curve_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_kc_wn_f1_vs_iou_dosed_separately.csv'), delimiter=',')\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "\n",
    "if show_seed_curves:\n",
    "    for k in seed_id_list:\n",
    "        ax.plot(iou_list, f1_vs_iou_dict[k], \n",
    "           linewidth=linewidth_model, markersize=markersize_model, marker='.', alpha=0.3,\n",
    "           color=color_list['model_mean'])\n",
    "        \n",
    "ax.plot(iou_list, mean_f1_vs_iou, \n",
    "           linewidth=linewidth_model,\n",
    "           label='%s' % bsf_name, color=color_list['model_mean'], zorder=20, marker='o', \n",
    "           markersize=markersize_model, markevery=(1, 2))\n",
    "\n",
    "idx_to_show = np.where(np.isclose(iou_list, iou_thr_to_show))[0][0]\n",
    "print('%1.4f F1 at 0.3 for Proposed Model' % mean_f1_vs_iou[idx_to_show])\n",
    "if show_seed_std:\n",
    "    ax.fill_between(\n",
    "        iou_list, \n",
    "        mean_f1_vs_iou - std_f1_vs_iou, \n",
    "        mean_f1_vs_iou + std_f1_vs_iou, \n",
    "        alpha=alpha, facecolor=color_list['model_mean'], zorder=20)\n",
    "\n",
    "if show_ensamble:\n",
    "    ax.plot(iou_list, half_rule_f1_vs_iou, \n",
    "           linewidth=linewidth_model, \n",
    "           label='%s (Ensemble)' % bsf_name, color=CUSTOM_COLOR['green'], zorder=25)\n",
    "    idx_to_show = np.where(np.isclose(iou_list, iou_thr_to_show))[0][0]\n",
    "    print('%1.4f F1 at 0.3 for Ensemble of Proposed Model' % half_rule_f1_vs_iou[idx_to_show])\n",
    "\n",
    "if compare_baselines:\n",
    "    for baseline_name in baselines_names_to_show:\n",
    "        bs_data = baselines_f1_dict[baseline_name]\n",
    "        if bs_data is not None:\n",
    "            bl_label = baselines_plot_dict[baseline_name][0]\n",
    "            bl_marker = baselines_plot_dict[baseline_name][1]\n",
    "            bl_iou_axis = bs_data[:, 0]\n",
    "            bl_f1_vs_iou_mean = bs_data[:, 1:].mean(axis=1)\n",
    "            bl_f1_vs_iou_std = bs_data[:, 1:].std(axis=1)\n",
    "            ax.plot(\n",
    "                bl_iou_axis, bl_f1_vs_iou_mean, \n",
    "                linewidth=linewidth_others,\n",
    "                label=bl_label, color=color_list['generic_baseline'], marker=bl_marker, \n",
    "                markersize=markersize_others, markevery=(1, 2))\n",
    "            if show_seed_std:\n",
    "                ax.fill_between(\n",
    "                    bl_iou_axis, \n",
    "                    bl_f1_vs_iou_mean - bl_f1_vs_iou_std, \n",
    "                    bl_f1_vs_iou_mean + bl_f1_vs_iou_std, \n",
    "                    alpha=alpha, facecolor=color_list['generic_baseline'])\n",
    "    idx_to_show = np.where(np.isclose(bl_iou_axis, iou_thr_to_show))[0][0]\n",
    "    print('%1.4f F1 at 0.3 for Baseline %s' % (bl_f1_vs_iou_mean[idx_to_show], bl_label))  \n",
    "\n",
    "if compare_chambon and (dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]):\n",
    "    ax.plot(dosed_f1_curve_wn[:, 0], dosed_f1_curve_wn[:, 1], linewidth=linewidth_others,\n",
    "               label='Chambon et al. 2019 (WN, Paper)', color=color_list['dosed'])\n",
    "    idx_to_show = np.where(np.isclose(dosed_f1_curve_wn[:, 0], iou_thr_to_show))[0][0]\n",
    "    print('%1.4f F1 at 0.3 for Chambon et al. 2019 (WN, Paper)' % dosed_f1_curve_wn[idx_to_show, 1])\n",
    "\n",
    "if compare_expert:\n",
    "    min_border = expert_f1_curve_mean[:, 1] - expert_f1_curve_std[:, 1]\n",
    "    max_border = expert_f1_curve_mean[:, 1] + expert_f1_curve_std[:, 1]\n",
    "    fn_min = interp1d(expert_f1_curve_mean[:, 0], min_border, kind='cubic')\n",
    "    fn_max = interp1d(expert_f1_curve_mean[:, 0], max_border, kind='cubic')\n",
    "    denser_iou = np.linspace(0.1, 0.9, num=50, endpoint=True)\n",
    "    min_border = fn_min(denser_iou)\n",
    "    max_border = fn_max(denser_iou)\n",
    "    \n",
    "    ax.fill_between(\n",
    "        denser_iou, \n",
    "        min_border, \n",
    "        max_border, \n",
    "        alpha=alpha*1.2, facecolor=color_list['expert'], label='Expert Performance\\nWarby et al. 2014\\nPrivate Dataset')\n",
    "    \n",
    "    idx_to_show = np.where(np.isclose(expert_f1_curve_mean[:, 0], iou_thr_to_show))[0][0]\n",
    "    print('%1.4f F1 at 0.3 for Expert' % expert_f1_curve_mean[idx_to_show, 1])\n",
    "#if compare_expert:\n",
    "#    # ax.plot(expert_f1_curve_mean[:, 0], expert_f1_curve_mean[:, 1], linewidth=linewidth_others, \n",
    "#    #            label='Expert Performance\\nPrivate Dataset\\nWarby et al. 2014', color=color_list['expert'])\n",
    "#    ax.fill_between(\n",
    "#        expert_f1_curve_mean[:, 0], \n",
    "#        expert_f1_curve_mean[:, 1] - expert_f1_curve_std[:, 1], \n",
    "#        expert_f1_curve_mean[:, 1] + expert_f1_curve_std[:, 1], \n",
    "#        alpha=alpha*1.1, facecolor=color_list['expert'], label='Expert Performance\\nWarby et al. 2014\\nPrivate Dataset'\n",
    "#    )\n",
    "                \n",
    "ax.set_title('Test Performance (%s)' % result_id, fontsize=9)\n",
    "ax.set_xlim([0.05, 0.95])\n",
    "ax.set_ylim([0.05, 0.95])\n",
    "ax.set_yticks([0.1 + 0.2*i for i in range(5)])\n",
    "ax.set_yticks([0.1*i for i in range(1, 10)], minor=True)\n",
    "ax.set_xticks([0.1 + 0.2*i for i in range(5)])\n",
    "ax.set_xticks([0.1*i for i in range(1, 10)], minor=True)\n",
    "ax.tick_params(labelsize=8)\n",
    "ax.set_xlabel('IoU Threshold', fontsize=8)\n",
    "ax.set_ylabel('F1-score', fontsize=8)\n",
    "ax.yaxis.grid(which='both')\n",
    "lg = ax.legend(loc='lower left', labelspacing=1.1, fontsize=6)\n",
    "for lh in lg.legendHandles:\n",
    "    lh.set_alpha(1.0)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only test set\n",
    "alpha = 0.2\n",
    "seed_id_for_scatter = 0\n",
    "\n",
    "\n",
    "# Prepare model predictions\n",
    "prediction_obj = predictions_dict[seed_id_for_scatter][constants.VAL_SUBSET]\n",
    "prediction_obj.set_probability_threshold(optimal_thr_list[seed_id_for_scatter])\n",
    "this_detections_list = prediction_obj.get_stamps()\n",
    "this_ids = prediction_obj.get_ids()\n",
    "\n",
    "# Prepare expert labels\n",
    "data_inference = FeederDataset(\n",
    "    dataset, this_ids, task_mode, which_expert)\n",
    "this_events_list = data_inference.get_stamps()\n",
    "\n",
    "expert_durations_list = []\n",
    "predicted_durations_list = []\n",
    "for i, single_id in enumerate(this_ids):\n",
    "    single_events = this_events_list[i]\n",
    "    single_detections = this_detections_list[i]\n",
    "    this_iou_array, this_idx_array = metrics.matching(single_events, single_detections)\n",
    "    idx_valid = (this_idx_array > -1)\n",
    "    matched_expert_durations = (single_events[idx_valid, 1] - single_events[idx_valid, 0]) / fs\n",
    "    matched_detections = single_detections[this_idx_array]\n",
    "    matched_predicted_durations = (matched_detections[idx_valid, 1] - matched_detections[idx_valid, 0]) / fs\n",
    "    expert_durations_list.append(matched_expert_durations)\n",
    "    predicted_durations_list.append(matched_predicted_durations)\n",
    "\n",
    "fig, ax = plt.subplots(1, len(this_ids), figsize=(8, 3), dpi=DPI)\n",
    "for i, subject_id in enumerate(this_ids):\n",
    "    ax[i].scatter(\n",
    "        expert_durations_list[i], predicted_durations_list[i], \n",
    "        label='S%02d' % subject_id, color='#455a64', alpha=alpha)\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "    lg = ax[i].legend(fontsize=7)\n",
    "    for lh in lg.legendHandles:\n",
    "        lh.set_facecolor(lh.get_facecolor())\n",
    "        lh.set_edgecolor(lh.get_edgecolor())\n",
    "        lh.set_alpha(1.0)\n",
    "    max_dur = max(expert_durations_list[i].max(), predicted_durations_list[i].max())\n",
    "    ax[i].set_xlim([0, max_dur + 0.1])\n",
    "    ax[i].set_ylim([0, max_dur + 0.1])\n",
    "    if i == 0 :\n",
    "        ax[i].set_ylabel('Detected duration [s]', fontsize=8.5)\n",
    "    ax[i].set_xlabel('Duration Real [s]', fontsize=8.5)\n",
    "    ax[i].plot([0.3, 2.0], [0.3, 2.0], '--k', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 vs IoU by subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_id_for_f1vsiou = 0\n",
    "\n",
    "# ---------------- Compute performance\n",
    "f1_vs_iou_subject_dict = {}\n",
    "pre_vs_iou_subject_dict = {}\n",
    "rec_vs_iou_subject_dict = {}\n",
    "\n",
    "# Validation split\n",
    "# train_ids, val_ids = utils.split_ids_list(\n",
    "#    all_train_ids, seed=SEED_LIST[seed_id_for_f1vsiou], verbose=False)\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_id_for_f1vsiou)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_id_for_f1vsiou])\n",
    "ids_dict = {\n",
    "    constants.TRAIN_SUBSET: train_ids,\n",
    "    constants.VAL_SUBSET: val_ids,\n",
    "    constants.TEST_SUBSET: test_ids\n",
    "}\n",
    "\n",
    "for set_name in set_list:\n",
    "    print('Processing %s' % set_name, flush=True)\n",
    "    # Prepare expert labels\n",
    "    data_inference = FeederDataset(\n",
    "        dataset, ids_dict[set_name], task_mode, which_expert)\n",
    "    this_ids = data_inference.get_ids()\n",
    "    this_events_list = data_inference.get_stamps()\n",
    "    # Prepare model predictions\n",
    "    prediction_obj = predictions_dict[seed_id_for_f1vsiou][set_name]\n",
    "    prediction_obj.set_probability_threshold(optimal_thr_list[seed_id_for_f1vsiou])\n",
    "    this_detections_list = prediction_obj.get_stamps()\n",
    "    for i, single_id in enumerate(this_ids):\n",
    "        single_events = this_events_list[i]\n",
    "        single_detections = this_detections_list[i]\n",
    "        this_precision = metrics.metric_vs_iou(single_events, single_detections, iou_list, metric_name=constants.PRECISION)\n",
    "        this_recall = metrics.metric_vs_iou(single_events, single_detections, iou_list, metric_name=constants.RECALL)\n",
    "        this_f1 = 2 * this_precision * this_recall / (this_precision + this_recall + 1e-8)\n",
    "        pre_vs_iou_subject_dict[single_id] = this_precision\n",
    "        rec_vs_iou_subject_dict[single_id] = this_recall\n",
    "        f1_vs_iou_subject_dict[single_id] = this_f1\n",
    "print('Done', flush=True)\n",
    "\n",
    "color_list = {'train': CUSTOM_COLOR['green'] , 'val': CUSTOM_COLOR['grey'], 'test': CUSTOM_COLOR['red']}\n",
    "marker_list = ['.', 's', '^', 'x', '*', 'd', 'v', 'p']\n",
    "linewidth_model = 1\n",
    "markersize_model = 5\n",
    "\n",
    "# -------------------- P L O T ----------------------    \n",
    "    \n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4), dpi=DPI)\n",
    "\n",
    "# F1\n",
    "for set_name in set_list:\n",
    "    for i, single_id in enumerate(ids_dict[set_name]):\n",
    "        ax[0].plot(iou_list, f1_vs_iou_subject_dict[single_id], \n",
    "                   linewidth=linewidth_model, markersize=markersize_model, marker=marker_list[i], \n",
    "                   label='S%02d' % single_id, color=color_list[set_name])\n",
    "\n",
    "    \n",
    "ax[0].set_title('Test Performance (%s Dataset) (%s)' \n",
    "             % (dataset_name.upper(), task_mode.upper()), fontsize=10)\n",
    "ax[0].set_xlim([0, 1])\n",
    "ax[0].set_ylim([0, 1])\n",
    "ax[0].set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax[0].set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax[0].tick_params(labelsize=8.5)\n",
    "ax[0].set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax[0].set_ylabel('F1-score', fontsize=8.5)\n",
    "ax[0].yaxis.grid()\n",
    "ax[0].legend(loc='lower left', fontsize=5)\n",
    "\n",
    "# Precision\n",
    "for set_name in set_list:\n",
    "    for i, single_id in enumerate(ids_dict[set_name]):\n",
    "        ax[1].plot(iou_list, pre_vs_iou_subject_dict[single_id], \n",
    "                   linewidth=linewidth_model, markersize=markersize_model, marker=marker_list[i], \n",
    "                   label='S%02d' % single_id, color=color_list[set_name])\n",
    "\n",
    "    \n",
    "ax[1].set_title('Test Performance (%s Dataset) (%s)' \n",
    "             % (dataset_name.upper(), task_mode.upper()), fontsize=10)\n",
    "ax[1].set_xlim([0, 1])\n",
    "ax[1].set_ylim([0, 1])\n",
    "ax[1].set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax[1].set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax[1].tick_params(labelsize=8.5)\n",
    "ax[1].set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax[1].set_ylabel('Precision', fontsize=8.5)\n",
    "ax[1].yaxis.grid()\n",
    "ax[1].legend(loc='lower left', fontsize=5)\n",
    "\n",
    "# Recall\n",
    "for set_name in set_list:\n",
    "    for i, single_id in enumerate(ids_dict[set_name]):\n",
    "        ax[2].plot(iou_list, rec_vs_iou_subject_dict[single_id], \n",
    "                   linewidth=linewidth_model, markersize=markersize_model, marker=marker_list[i], \n",
    "                   label='S%02d' % single_id, color=color_list[set_name])\n",
    "\n",
    "    \n",
    "ax[2].set_title('Test Performance (%s Dataset) (%s)' \n",
    "             % (dataset_name.upper(), task_mode.upper()), fontsize=10)\n",
    "ax[2].set_xlim([0, 1])\n",
    "ax[2].set_ylim([0, 1])\n",
    "ax[2].set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax[2].set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax[2].tick_params(labelsize=8.5)\n",
    "ax[2].set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax[2].set_ylabel('Recall', fontsize=8.5)\n",
    "ax[2].yaxis.grid()\n",
    "ax[2].legend(loc='lower left', fontsize=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR by subject, usando APrecision y ARecall\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "markersize = 10\n",
    "text_space = 0.01\n",
    "show_ids = True\n",
    "axis_lims = [0, 1]\n",
    "show_set_list = ['train', 'val', 'test']\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "\n",
    "levels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "levels = [level for level in levels if (level>axis_lims[0] and level<axis_lims[1])]\n",
    "\n",
    "CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=levels)\n",
    "ax.clabel(CS, fontsize=6, fmt='%1.2f')\n",
    "\n",
    "for set_name in set_list:\n",
    "    if set_name in show_set_list:\n",
    "        for i, single_id in enumerate(ids_dict[set_name]):\n",
    "            if i==0:\n",
    "                label = 'Proposed (%s) (%s)' % (task_mode.upper(), set_name.capitalize())\n",
    "            else:\n",
    "                label = None\n",
    "            this_arecall = rec_vs_iou_subject_dict[single_id].mean()\n",
    "            this_aprecision = pre_vs_iou_subject_dict[single_id].mean()\n",
    "            ax.scatter(\n",
    "                this_arecall, this_aprecision, \n",
    "                c=color_list[set_name], \n",
    "                label=label, marker='s',\n",
    "                s=markersize, zorder=10)\n",
    "            if show_ids:\n",
    "                ax.annotate(\n",
    "                    single_id, \n",
    "                    (this_arecall+text_space, this_aprecision+text_space), \n",
    "                    fontsize=7, color='#1b2631', zorder=20) \n",
    "ax.set_title('Seed %d ($\\mu$=%1.2f)' % (seed_id_for_f1vsiou, optimal_thr_list[seed_id_for_f1vsiou]), fontsize=7)\n",
    "ax.set_xlabel('A-Recall', fontsize=7)\n",
    "ax.set_ylabel('A-Precision', fontsize=7)\n",
    "ax.set_xlim(axis_lims)\n",
    "ax.set_ylim(axis_lims)\n",
    "ax.tick_params(labelsize=7)\n",
    "ax.legend(loc='lower left', fontsize=5)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: Precision-Recall curve, average per set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_thr = 0.3\n",
    "res_thr = 0.02\n",
    "start_thr = 0.1\n",
    "end_thr = 0.9\n",
    "n_thr = int(np.round((end_thr - start_thr) / res_thr + 1))\n",
    "thr_list = np.array([start_thr + res_thr * i for i in range(n_thr)])\n",
    "\n",
    "pr_curve = {}\n",
    "# Prepare expert labels\n",
    "data_test = FeederDataset(\n",
    "    dataset, test_ids, task_mode, which_expert=which_expert)\n",
    "this_events = data_test.get_stamps()\n",
    "for k in seed_id_list:\n",
    "    print('Processing seed %d' % k, flush=True)\n",
    "    # Columns are [x: recall, y: precision]\n",
    "    pr_curve[k] = np.zeros((n_thr, 2))\n",
    "    for i, thr in enumerate(thr_list):\n",
    "        # Prepare model predictions\n",
    "        prediction_test = predictions_dict[k][constants.TEST_SUBSET]\n",
    "        prediction_test.set_probability_threshold(thr)\n",
    "        this_detections = prediction_test.get_stamps()\n",
    "        \n",
    "        this_stats = [metrics.by_event_confusion(this_y, this_y_pred, iou_thr=iou_thr) \n",
    "                    for (this_y, this_y_pred) in zip(this_events, this_detections)]\n",
    "        this_recall = np.mean([m[constants.RECALL] for m in this_stats])\n",
    "        this_precision = np.mean([m[constants.PRECISION] for m in this_stats])\n",
    "        pr_curve[k][i, 0] = this_recall\n",
    "        pr_curve[k][i, 1] = this_precision\n",
    "\n",
    "# Mean of runs\n",
    "# pr_curve['mean_runs'] = np.stack([pr_curve[k] for k in seed_id_list], axis=2).mean(axis=2)\n",
    "print('Done', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "filename = '%s_pr_curve.npy' % (ckpt_folder.split('/')[0])\n",
    "data = []\n",
    "this_thr = np.asarray(thr_list)[:, np.newaxis]\n",
    "for k in seed_id_list:\n",
    "    this_pr = pr_curve[k]\n",
    "    this_pr = np.concatenate([this_thr, this_pr], axis=1)\n",
    "    data.append(this_pr)\n",
    "data = np.stack(data, axis=0).astype(np.float32)\n",
    "np.save(filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot \n",
    "bsf_name = 'Proposed Model'\n",
    "result_id = '%s-%s-E%d-%s' % (\n",
    "    dataset_name.split('_')[0].upper(), \n",
    "    dataset_name.split('_')[1].upper(), \n",
    "    which_expert,\n",
    "    task_mode.upper()\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "markersize = 6\n",
    "alpha = 0.5\n",
    "text_space = 0.01\n",
    "compare_chambon = False\n",
    "compare_baselines = True\n",
    "compare_expert = True\n",
    "show_seeds = True\n",
    "axis_lims = [0.4, 1.0]\n",
    "pr_major_ticks = np.linspace(0.5, 0.9, 3)\n",
    "pr_minor_ticks = np.linspace(axis_lims[0], axis_lims[1], 7)\n",
    "\n",
    "\n",
    "show_half_thr = False \n",
    "\n",
    "color_list = {'model_mean': CUSTOM_COLOR['red'] , 'expert': CUSTOM_COLOR['grey'], 'dosed': viz.PALETTE['dark'],\n",
    "              'generic_baseline': viz.PALETTE['blue']\n",
    "             }\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "\n",
    "levels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "levels = [level for level in levels if (level>axis_lims[0] and level<axis_lims[1])]\n",
    "\n",
    "CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=levels)\n",
    "ax.clabel(CS, fontsize=7.5, fmt='%1.2f')\n",
    "    \n",
    "if show_seeds:\n",
    "    # Show single seeds\n",
    "    seed_shown = False\n",
    "    for k in seed_id_list:\n",
    "        if not seed_shown:\n",
    "            seed_shown=True\n",
    "            label = '%s (Seeds)' % bsf_name\n",
    "            if show_half_thr:\n",
    "                label_2 = '%s (Seed 0.5 O.P.)' % bsf_name\n",
    "            else:\n",
    "                label_2 = '%s (Seed O.P.)' % bsf_name\n",
    "        else:\n",
    "            label = None\n",
    "            label_2 = None\n",
    "        \n",
    "        if show_half_thr:\n",
    "            print('Showing threshold 0.5 for all seeds')\n",
    "            chosen_thr_idx = np.where(np.isclose(thr_list, 0.5))[0].item()\n",
    "        else:\n",
    "            chosen_thr_idx = np.where(np.isclose(thr_list, optimal_thr_list[k]))[0].item()\n",
    "\n",
    "        ax.plot(\n",
    "            pr_curve[k][:, 0], pr_curve[k][:, 1], label=label,\n",
    "            linewidth=1, color=color_list['model_mean'], zorder=20, alpha=alpha, marker='o', \n",
    "            markersize=markersize, markevery=[chosen_thr_idx])\n",
    "        ax.plot(\n",
    "            pr_curve[k][:, 0], pr_curve[k][:, 1], \n",
    "            linestyle=\"None\", color=color_list['model_mean'], zorder=20, marker='o', \n",
    "            markersize=markersize, markevery=[chosen_thr_idx], alpha=0.6)\n",
    "            \n",
    "        # ax.scatter(pr_curve[k][chosen_thr_idx, 0], pr_curve[k][chosen_thr_idx, 1], \n",
    "        #            s=50, c=color_list['model_mean'], zorder=20, alpha=alpha, label=label_2)\n",
    "    \n",
    "if compare_baselines:\n",
    "    for baseline_name in baselines_names_to_show:\n",
    "        bs_recall_data = baselines_recall_dict[baseline_name]\n",
    "        if bs_recall_data is not None:\n",
    "            bs_precision_data = baselines_precision_dict[baseline_name]\n",
    "            \n",
    "            bl_label = baselines_plot_dict[baseline_name][0]\n",
    "            bl_marker = baselines_plot_dict[baseline_name][1]\n",
    "            \n",
    "            bl_iou_axis = bs_recall_data[:, 0]\n",
    "            useful_idx = np.argmin((bl_iou_axis - iou_thr)**2)\n",
    "            bl_recall = bs_recall_data[useful_idx, 1:].mean()\n",
    "            bl_precision = bs_precision_data[useful_idx, 1:].mean()\n",
    "            ax.plot(\n",
    "                bl_recall, bl_precision, \n",
    "                markersize=markersize, c=color_list['generic_baseline'], zorder=15, \n",
    "                label=bl_label, marker=bl_marker, linestyle=\"None\")\n",
    "\n",
    "# Chambon\n",
    "if compare_chambon and (dataset_name == constants.MASS_SS_NAME):\n",
    "    dosed_rec_prec_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_ss_wn_pr_dosed_separately.csv'), delimiter=',')\n",
    "    ax.plot(dosed_rec_prec_wn[0], dosed_rec_prec_wn[1], \n",
    "           markersize=markersize, c=color_list['dosed'], zorder=10, \n",
    "            label='Chambon et al. 2019 (WN, Paper)', marker='o', linestyle=\"None\")\n",
    "if compare_chambon and (dataset_name == constants.MASS_KC_NAME):\n",
    "    dosed_rec_prec_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_kc_wn_pr_dosed_separately.csv'), delimiter=',')\n",
    "    ax.plot(dosed_rec_prec_wn[0], dosed_rec_prec_wn[1], \n",
    "           markersize=markersize, c=color_list['dosed'], zorder=10, \n",
    "            label='Chambon et al. 2019 (WN, Paper)', marker='o', linestyle=\"None\")\n",
    "\n",
    "if compare_expert:\n",
    "    expert_rec_prec = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'expert', 'ss_pr_expert_mean.csv'), delimiter=',')\n",
    "    ax.plot(expert_rec_prec[0], expert_rec_prec[1], \n",
    "           markersize=markersize, c=color_list['expert'], zorder=10, \n",
    "            label='Expert Performance\\nWarby et al. 2014\\nPrivate Dataset', marker='o', linestyle=\"None\")\n",
    "    \n",
    "# Mean of runs\n",
    "# ax.plot(pr_curve['mean_runs'][:, 0], pr_curve['mean_runs'][:, 1], \n",
    "#         label='%s (Mean)' % bsf_name,\n",
    "#         linewidth=1.5, color=color_list['model_mean'], zorder=10)\n",
    "\n",
    "# Highlight chosen operating point\n",
    "# chosen_thr_idx = np.where(np.isclose(thr_list, thr_run))[0].item()\n",
    "# ax.scatter(pr_curve['mean_runs'][chosen_thr_idx, 0], pr_curve['mean_runs'][chosen_thr_idx, 1], \n",
    "#            s=50, c=color_list['model_mean'], zorder=10, label='Operating point $\\mu$=%1.2f' % thr_run)\n",
    "# ax.annotate('$\\mu$=%1.3f' % thr_run, \n",
    "#             (pr_curve['mean_runs'][chosen_thr_idx, 0], \n",
    "#              pr_curve['mean_runs'][chosen_thr_idx, 1] + text_space*2), \n",
    "#             fontsize=7, color='#1b2631', zorder=30)  \n",
    "\n",
    "ax.set_title('Test Performance with IoU$>$%1.1f (%s)' % (iou_thr, result_id), fontsize=9)\n",
    "ax.set_xlabel('Recall', fontsize=8)\n",
    "ax.set_ylabel('Precision', fontsize=8)\n",
    "ax.set_xlim(axis_lims)\n",
    "ax.set_ylim(axis_lims)\n",
    "ax.set_yticks(pr_major_ticks)\n",
    "ax.set_yticks(pr_minor_ticks, minor=True)\n",
    "ax.set_xticks(pr_major_ticks)\n",
    "ax.set_xticks(pr_minor_ticks, minor=True)\n",
    "# ax.xaxis.grid()\n",
    "# ax.yaxis.grid()\n",
    "\n",
    "lg = ax.legend(loc='lower left', labelspacing=1.1, fontsize=6)\n",
    "for lh in lg.legendHandles:\n",
    "    lh.set_alpha(1.0)\n",
    "    lh._legmarker.set_alpha(1.0)\n",
    "\n",
    "ax.tick_params(labelsize=8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: Precision-Recall plot, separated subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_thr = 0.3\n",
    "\n",
    "# Prepare model predictions\n",
    "be_stats = {}\n",
    "for k in seed_id_list:\n",
    "    print('Processing seed %d' % k, flush=True)\n",
    "    be_stats[k] = {}\n",
    "    if new_split_version:\n",
    "        train_ids, val_ids = utils.split_ids_list_v2(\n",
    "            all_train_ids, split_id=k)\n",
    "    else:\n",
    "        train_ids, val_ids = utils.split_ids_list(\n",
    "            all_train_ids, seed=SEED_LIST[k])\n",
    "    train_ids.sort()\n",
    "    val_ids.sort()\n",
    "    ids_per_set_dict = {\n",
    "        constants.TRAIN_SUBSET: train_ids,\n",
    "        constants.VAL_SUBSET: val_ids,\n",
    "        constants.TEST_SUBSET: test_ids\n",
    "    }\n",
    "    for set_name in set_list:\n",
    "        data_feeder = FeederDataset(\n",
    "            dataset, ids_per_set_dict[set_name], task_mode, which_expert=which_expert)\n",
    "        this_events = data_feeder.get_stamps()\n",
    "        prediction_set = predictions_dict[k][set_name]\n",
    "        prediction_set.set_probability_threshold(optimal_thr_list[k])\n",
    "        this_detections = prediction_set.get_stamps()\n",
    "        be_stats[k][set_name] = [\n",
    "            metrics.by_event_confusion(this_y, this_y_pred, iou_thr=iou_thr) \n",
    "            for (this_y, this_y_pred) in zip(this_events, this_detections)]\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot \n",
    "bsf_name = 'Proposed (%s)' % task_mode.upper()\n",
    "fig, ax = plt.subplots(1, n_seeds, figsize=(2.3*n_seeds, 2.3), dpi=DPI)\n",
    "markersize = 10\n",
    "alpha = 0.3\n",
    "text_space = 0.01\n",
    "compare_chambon = False\n",
    "show_ids = True\n",
    "axis_lims = [0.5, 1.0]\n",
    "show_set_list = ['train', 'val', 'test']\n",
    "color_list = {'train': CUSTOM_COLOR['green'] , 'val': CUSTOM_COLOR['grey'], 'test': CUSTOM_COLOR['red'], 'dosed': CUSTOM_COLOR['blue']}\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "\n",
    "levels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "levels = [level for level in levels if (level>axis_lims[0] and level<axis_lims[1])]\n",
    "\n",
    "# Chambon\n",
    "if compare_chambon and (dataset_name == constants.MASS_SS_NAME):\n",
    "    dosed_rec_prec_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_ss_wn_pr_dosed_separately.csv'), delimiter=',')\n",
    "if compare_chambon and (dataset_name == constants.MASS_KC_NAME):\n",
    "    dosed_rec_prec_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_kc_wn_pr_dosed_separately.csv'), delimiter=',')\n",
    "    \n",
    "for j in range(n_seeds):\n",
    "    seed_id = seed_id_list[j]\n",
    "    if new_split_version:\n",
    "        train_ids, val_ids = utils.split_ids_list_v2(\n",
    "            all_train_ids, split_id=seed_id)\n",
    "    else:\n",
    "        train_ids, val_ids = utils.split_ids_list(\n",
    "            all_train_ids, seed=SEED_LIST[seed_id])\n",
    "    train_ids.sort()\n",
    "    val_ids.sort()\n",
    "    ids_per_set_dict = {\n",
    "        constants.TRAIN_SUBSET: train_ids,\n",
    "        constants.VAL_SUBSET: val_ids,\n",
    "        constants.TEST_SUBSET: test_ids\n",
    "    }\n",
    "    \n",
    "    \n",
    "    CS = ax[j].contour(X, Y, Z, colors='k', alpha=0.3, levels=levels)\n",
    "    ax[j].clabel(CS, fontsize=6, fmt='%1.2f')\n",
    "    \n",
    "    if compare_chambon and (dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]):\n",
    "        ax[j].scatter(\n",
    "            dosed_rec_prec_wn[0], dosed_rec_prec_wn[1], \n",
    "            c=color_list['dosed'], \n",
    "            label='DOSED (WN)', marker='o',\n",
    "            s=markersize*3, zorder=10)\n",
    "    \n",
    "    for set_name in set_list:\n",
    "        if set_name in show_set_list:\n",
    "            for i, stats in enumerate(be_stats[seed_id][set_name]):\n",
    "                if i==0:\n",
    "                    label = 'Proposed (%s) (%s)' % (task_mode.upper(), set_name.capitalize())\n",
    "                else:\n",
    "                    label = None\n",
    "                ax[j].scatter(\n",
    "                    stats['recall'], stats['precision'], \n",
    "                    c=color_list[set_name], \n",
    "                    label=label, marker='s',\n",
    "                    s=markersize, zorder=10)\n",
    "                if show_ids:\n",
    "                    \n",
    "                    if j==0:\n",
    "                        f1_score = 2 * stats['recall'] * stats['precision'] / (stats['recall'] + stats['precision'])\n",
    "                        print('S%02d (%s) - Recall: %1.4f - Precision: %1.4f - F1: %1.4f' \n",
    "                              % (ids_per_set_dict[set_name][i], set_name.ljust(5), stats['recall'], stats['precision'], f1_score))\n",
    "                    \n",
    "                    ax[j].annotate(\n",
    "                        ids_per_set_dict[set_name][i], \n",
    "                        (stats['recall']+text_space, stats['precision']+text_space), \n",
    "                        fontsize=7, color='#1b2631', zorder=20) \n",
    "    ax[j].set_title('Seed %d ($\\mu$=%1.2f and IoU>%1.1f)' % (seed_id, optimal_thr_list[j], iou_thr), fontsize=7)\n",
    "    ax[j].set_xlabel('Recall', fontsize=7)\n",
    "    ax[j].set_ylabel('Precision', fontsize=7)\n",
    "    ax[j].set_xlim(axis_lims)\n",
    "    ax[j].set_ylim(axis_lims)\n",
    "    ax[j].tick_params(labelsize=7)\n",
    "    ax[j].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "ax[0].legend(loc='lower left', bbox_to_anchor=(0.5, -0.4), labelspacing=1, fontsize=6, ncol=(1 + len(show_set_list)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "if constants.TEST_SUBSET in show_set_list:\n",
    "    # mean test\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3), dpi=DPI)\n",
    "\n",
    "    CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=levels)\n",
    "    ax.clabel(CS, fontsize=6, fmt='%1.2f')\n",
    "\n",
    "    if compare_chambon and (dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]):\n",
    "        ax.scatter(\n",
    "            dosed_rec_prec_wn[0], dosed_rec_prec_wn[1], \n",
    "            c=color_list['dosed'], \n",
    "            label='DOSED (WN) (Paper)', marker='o',\n",
    "            s=markersize*4, zorder=10)\n",
    "        dosed_f1 = 2 * dosed_rec_prec_wn[0] * dosed_rec_prec_wn[1] / (dosed_rec_prec_wn[0] + dosed_rec_prec_wn[1])\n",
    "        # print('%1.4f Dosed F1 at 0.3' % dosed_f1)\n",
    "\n",
    "    set_name = constants.TEST_SUBSET\n",
    "\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    for i in range(len(test_ids)):\n",
    "\n",
    "        recall_mean = np.stack([be_stats[k][set_name][i]['recall'] for k in seed_id_list]).mean()\n",
    "        precision_mean = np.stack([be_stats[k][set_name][i]['precision'] for k in seed_id_list]).mean()\n",
    "        recall_list.append(recall_mean)\n",
    "        precision_list.append(precision_mean)\n",
    "        if i==0:\n",
    "            label = '%s (Single subject)' % bsf_name\n",
    "        else:\n",
    "            label = None\n",
    "        ax.scatter(\n",
    "            recall_mean, precision_mean, \n",
    "            c=color_list[set_name], \n",
    "            label=label, marker='s',\n",
    "            s=markersize, zorder=10)\n",
    "        if show_ids:\n",
    "            ax.annotate(\n",
    "                ids_per_set_dict[set_name][i], \n",
    "                (recall_mean+text_space, precision_mean+text_space), \n",
    "                fontsize=7, color='#1b2631', zorder=20)\n",
    "\n",
    "    # mean of subjects\n",
    "\n",
    "    ax.scatter(\n",
    "        np.mean(recall_list), np.mean(precision_list), \n",
    "        c=color_list[set_name], \n",
    "        label='%s (Mean of subjects)' % bsf_name, marker='o',\n",
    "        s=markersize*4, zorder=10)\n",
    "\n",
    "    ax.set_title('Mean Test PR for IoU>%1.1f (%s Detection)' % (iou_thr, dataset_name[-2:].upper()), fontsize=8)\n",
    "    ax.set_xlabel('Recall', fontsize=7)\n",
    "    ax.set_ylabel('Precision', fontsize=7)\n",
    "    ax.set_xlim(axis_lims)\n",
    "    ax.set_ylim(axis_lims)\n",
    "    ax.tick_params(labelsize=7)\n",
    "    ax.grid()\n",
    "    ax.legend(loc='lower left', fontsize=7)\n",
    "    plt.show()\n",
    "    \n",
    "    each_recall = np.asarray(recall_list)\n",
    "    each_precision = np.asarray(precision_list)\n",
    "    model_f1 = np.mean(2 * each_recall * each_precision / (each_recall + each_precision))\n",
    "    # print('%1.4f Proposed mean F1 at 0.3' % model_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_to_show = 2\n",
    "set_name = 'val'\n",
    "subject_id = 7\n",
    "\n",
    "# -----\n",
    "print(ckpt_folder)\n",
    "\n",
    "if dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]:\n",
    "    channel_name = 'C3-CLE'\n",
    "elif dataset_name in [constants.DREAMS_SS_NAME, constants.DREAMS_KC_NAME]:\n",
    "    channel_name = 'Cz-A1'\n",
    "else:\n",
    "    channel_name = 'F4-C4'\n",
    "\n",
    "\n",
    "pages_subset = constants.N2_RECORD\n",
    "\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_to_show)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_to_show])\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids, 'alltrain': all_train_ids}\n",
    "idx_subject = idx_dict[set_name].index(subject_id)\n",
    "\n",
    "this_pages = dataset.get_subject_pages(subject_id=subject_id, pages_subset=pages_subset)\n",
    "this_signal = dataset.get_subject_signal(subject_id=subject_id, normalization_mode=task_mode, which_expert=which_expert)\n",
    "this_stamps = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=which_expert)\n",
    "this_stamps_full = this_stamps.copy()\n",
    "event_name = dataset.event_name\n",
    "\n",
    "this_thr = optimal_thr_list[seed_to_show]\n",
    "smaller_proba_for_fp = this_thr / 2\n",
    "prediction_set = predictions_dict[seed_to_show][set_name]\n",
    "down_factor = prediction_set.params[pkeys.TOTAL_DOWNSAMPLING_FACTOR]\n",
    "predicted_proba = prediction_set.get_subject_probabilities(subject_id)\n",
    "\n",
    "# Look for probability in real events\n",
    "mean_proba_real_list = []\n",
    "max_proba_real_list = []\n",
    "for single_stamp in this_stamps_full:\n",
    "    proba_segment_idx = single_stamp // 8\n",
    "    proba_segment = predicted_proba[proba_segment_idx[0]:proba_segment_idx[1]+1]\n",
    "    mean_proba_real_list.append(np.mean(proba_segment))\n",
    "    max_proba_real_list.append(np.max(proba_segment))\n",
    "\n",
    "# Look for probability of fake events\n",
    "mean_proba_fake_list = []\n",
    "max_proba_fake_list = []\n",
    "prediction_set.set_probability_threshold(smaller_proba_for_fp)\n",
    "this_detections = prediction_set.get_subject_stamps(subject_id)\n",
    "# Matching:\n",
    "this_iou_array, this_idx_array = metrics.matching(this_stamps_full, this_detections)\n",
    "this_expert_iou = this_iou_array\n",
    "n_detections = this_detections.shape[0]\n",
    "this_detection_iou = np.zeros(n_detections)\n",
    "for i in range(n_detections):\n",
    "    if i in this_idx_array:\n",
    "        matching_idx = np.where(this_idx_array == i)[0][0]\n",
    "        this_detection_iou[i] = this_iou_array[matching_idx] \n",
    "# Recover events with zero iou\n",
    "fake_idx = np.where(this_detection_iou == 0)[0]\n",
    "this_fake_stamps = this_detections[fake_idx]\n",
    "for single_stamp in this_fake_stamps:\n",
    "    proba_segment_idx = single_stamp // 8\n",
    "    proba_segment = predicted_proba[proba_segment_idx[0]:proba_segment_idx[1]+1]\n",
    "    mean_proba_fake_list.append(np.mean(proba_segment))\n",
    "    max_proba_fake_list.append(np.max(proba_segment))\n",
    "    \n",
    "\n",
    "proba_bins = np.linspace(0.0, 1.0, num=21, endpoint=True) \n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8), dpi=100, sharey=True, sharex=True)\n",
    "values, _, _ = ax[0, 0].hist(mean_proba_real_list, bins=proba_bins, color=CUSTOM_COLOR['blue'], label='S%02d' % subject_id)\n",
    "ax[0, 0].tick_params(labelsize=8.5)\n",
    "ax[0, 0].legend(fontsize=8.5)\n",
    "ax[0, 0].set_xlim([0, 1])\n",
    "ax[0, 0].set_xlabel('Probability', fontsize=8.5)\n",
    "n_after_thr = np.sum(np.array(mean_proba_real_list) >= this_thr)\n",
    "ax[0, 0].set_title('Mean Proba of Real (%d greater than %1.2f)' % (n_after_thr, this_thr), fontsize=9)\n",
    "ax[0, 0].plot([this_thr, this_thr], [0, np.max(values)*1.05], '--k')\n",
    "\n",
    "values, _, _ = ax[0, 1].hist(max_proba_real_list, bins=proba_bins, color=CUSTOM_COLOR['blue'], label='S%02d' % subject_id)\n",
    "ax[0, 1].tick_params(labelsize=8.5)\n",
    "ax[0, 1].legend(fontsize=8.5)\n",
    "ax[0, 1].set_xlim([0, 1])\n",
    "ax[0, 1].set_xlabel('Probability', fontsize=8.5)\n",
    "n_after_thr = np.sum(np.array(max_proba_real_list) >= this_thr)\n",
    "ax[0, 1].set_title('Max Proba of Real (%d greater than %1.2f)' % (n_after_thr, this_thr), fontsize=9)\n",
    "ax[0, 1].plot([this_thr, this_thr], [0, np.max(values)*1.05], '--k')\n",
    "\n",
    "values, _, _ = ax[1, 0].hist(mean_proba_fake_list, bins=proba_bins, color=CUSTOM_COLOR['red'], label='S%02d' % subject_id)\n",
    "ax[1, 0].tick_params(labelsize=8.5)\n",
    "ax[1, 0].legend(fontsize=8.5)\n",
    "ax[1, 0].set_xlim([0, 1])\n",
    "ax[1, 0].set_xlabel('Probability', fontsize=8.5)\n",
    "n_after_thr = np.sum(np.array(mean_proba_fake_list) >= this_thr)\n",
    "ax[1, 0].set_title('Mean Proba of Fake (%d greater than %1.2f)' % (n_after_thr, this_thr), fontsize=9)\n",
    "ax[1, 0].plot([this_thr, this_thr], [0, np.max(values)*1.05], '--k')\n",
    "\n",
    "values, _, _ = ax[1, 1].hist(max_proba_fake_list, bins=proba_bins, color=CUSTOM_COLOR['red'], label='S%02d' % subject_id)\n",
    "ax[1, 1].tick_params(labelsize=8.5)\n",
    "ax[1, 1].legend(fontsize=8.5)\n",
    "ax[1, 1].set_xlim([0, 1])\n",
    "ax[1, 1].set_xlabel('Probability', fontsize=8.5)\n",
    "n_after_thr = np.sum(np.array(max_proba_fake_list) >= this_thr)\n",
    "ax[1, 1].set_title('Max Proba of Fake (%d greater than %1.2f)' % (n_after_thr, this_thr), fontsize=9)\n",
    "ax[1, 1].plot([this_thr, this_thr], [0, np.max(values)*1.05], '--k')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_to_show = 0\n",
    "set_name = 'test'\n",
    "subject_id = 12\n",
    "show_only_n2 = True\n",
    "show_hypno = False\n",
    "band_pass_freqs = [12, 14]\n",
    "\n",
    "# -----\n",
    "if dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]:\n",
    "    channel_name = 'C3-CLE'\n",
    "else:\n",
    "    channel_name = 'F4-C4'\n",
    "\n",
    "if show_only_n2:\n",
    "    pages_subset = constants.N2_RECORD\n",
    "else:\n",
    "    pages_subset = constants.WN_RECORD\n",
    "\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_to_show)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_to_show])    \n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids, 'alltrain': all_train_ids}\n",
    "idx_subject = idx_dict[set_name].index(subject_id)\n",
    "\n",
    "this_pages = dataset.get_subject_pages(subject_id=subject_id, pages_subset=pages_subset)\n",
    "if show_hypno:\n",
    "    this_hypnogram = dataset.get_subject_hypnogram(subject_id=subject_id)\n",
    "this_signal = dataset.get_subject_signal(subject_id=subject_id, normalization_mode=task_mode, which_expert=which_expert)\n",
    "this_stamps = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=which_expert)\n",
    "if (subject_id not in [4, 8, 15, 16]) and dataset_name == constants.MASS_SS_NAME:\n",
    "    this_stamps_2 = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=2)\n",
    "else:\n",
    "    this_stamps_2 = None\n",
    "\n",
    "event_name = dataset.event_name\n",
    "\n",
    "this_thr = optimal_thr_list[seed_to_show]\n",
    "prediction_set = predictions_dict[seed_to_show][set_name]\n",
    "prediction_set.set_probability_threshold(this_thr)\n",
    "this_predicted_stamps = prediction_set.get_subject_stamps(subject_id=subject_id, pages_subset=constants.WN_RECORD)\n",
    "this_proba = prediction_set.get_subject_probabilities(subject_id=subject_id)\n",
    "\n",
    "fs_real = dataset.fs\n",
    "down_factor = prediction_set.params[pkeys.TOTAL_DOWNSAMPLING_FACTOR]\n",
    "fs_proba = fs_real / down_factor\n",
    "\n",
    "# make a color map of fixed colors\n",
    "cmap = colors.ListedColormap(['white', '#c62828'])\n",
    "\n",
    "\n",
    "def filter_stamps(stamps, single_page, page_size):\n",
    "    pages_list = []\n",
    "    for i in range(stamps.shape[0]):\n",
    "        stamp_start_page = stamps[i, 0] // page_size\n",
    "        stamp_end_page = stamps[i, 1] // page_size\n",
    "\n",
    "        start_inside = (stamp_start_page == single_page)\n",
    "        end_inside = (stamp_end_page == single_page)\n",
    "\n",
    "        if start_inside or end_inside:\n",
    "            pages_list.append(stamps[i, :])\n",
    "    return pages_list\n",
    "\n",
    "\n",
    "def plot_page(page_idx):\n",
    "\n",
    "    if this_stamps_2 is None:\n",
    "        fig = plt.figure(figsize=(12, 4), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(3, 1, height_ratios=[4, 2, 1])\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(12, 5), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(4, 1, height_ratios=[4, 2, 1, 1])\n",
    "    \n",
    "    page_idx = page_idx - 1\n",
    "    page_chosen = this_pages[page_idx]\n",
    "    if show_hypno:\n",
    "        page_state = this_hypnogram[page_of_center]\n",
    "    else:\n",
    "        page_state = '?'\n",
    "    page_start = page_chosen * dataset.page_size\n",
    "    page_end = page_start + dataset.page_size\n",
    "    \n",
    "    segment_signal = this_signal[page_start:page_end]\n",
    "    \n",
    "    segment_stamps = filter_stamps(this_stamps, page_chosen, dataset.page_size)\n",
    "    if this_stamps_2 is not None:\n",
    "        segment_stamps_2 = filter_stamps(this_stamps_2, page_chosen, dataset.page_size)\n",
    "    segment_proba = this_proba[int(page_start/down_factor):int(page_end/down_factor)]\n",
    "    segment_predicted_stamps = filter_stamps(this_predicted_stamps, page_chosen, dataset.page_size)\n",
    "    \n",
    "    time_axis_real = np.arange(page_start, page_end) / fs_real\n",
    "    time_axis_proba = np.arange(int(page_start/down_factor), int(page_end/down_factor)) / fs_proba\n",
    "    \n",
    "    gs_idx = 0\n",
    "    \n",
    "    # Signal\n",
    "    y_max = 10\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(\n",
    "        time_axis_real, segment_signal, \n",
    "        linewidth=1, color=CUSTOM_COLOR['grey'], label='EEG %s' % channel_name)\n",
    "    stamp_label_used = False\n",
    "    for expert_stamp in segment_stamps:\n",
    "        if stamp_label_used:\n",
    "            label = None\n",
    "        else:\n",
    "            label = event_name\n",
    "            stamp_label_used = True\n",
    "        ax.fill_between(\n",
    "            expert_stamp / fs_real, y_max, -y_max, \n",
    "            facecolor=CUSTOM_COLOR['blue'], alpha=0.3, label=label,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_ylim([-y_max, y_max])\n",
    "    ax.set_title('Subject %d (%s-%s). Page in record: %d. State %s (intervals of 0.5s are shown).' \n",
    "                 % (subject_id, dataset_name.upper(), set_name.capitalize(), page_chosen, page_state), fontsize=10)\n",
    "    ax.set_xticks([\n",
    "        time_axis_real[0], \n",
    "        time_axis_real[0] + 5, \n",
    "        time_axis_real[0] + 10, \n",
    "        time_axis_real[0] + 15, \n",
    "        time_axis_real[0] + 20])\n",
    "    ax.set_xticks(np.arange(time_axis_real[0], time_axis_real[-1], 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    lg = ax.legend(loc='upper right', fontsize=8.5)\n",
    "    # lh = lg.legendHandles[1]\n",
    "    # lh.set_facecolor(lh.get_facecolor())\n",
    "    # lh.set_alpha(1.0)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Band pass Signal\n",
    "    y_max = 10\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    # segment_signal_filtered = utils.narrow_filter(segment_signal, fs_real, band_pass_freqs[0], band_pass_freqs[1])\n",
    "    segment_signal_filtered = utils.filter_windowed_sinusoidal(segment_signal, fs_real, 13, 41)\n",
    "    ax.plot(\n",
    "        time_axis_real, segment_signal_filtered, \n",
    "        linewidth=1, color=CUSTOM_COLOR['grey'], label='EEG %s' % channel_name)\n",
    "    stamp_label_used = False\n",
    "    for expert_stamp in segment_stamps:\n",
    "        if stamp_label_used:\n",
    "            label = None\n",
    "        else:\n",
    "            label = event_name\n",
    "            stamp_label_used = True\n",
    "        ax.fill_between(\n",
    "            expert_stamp / fs_real, y_max, -y_max, \n",
    "            facecolor=CUSTOM_COLOR['blue'], alpha=0.3, label=label,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_ylim([-y_max, y_max])\n",
    "    ax.set_title('Bandpass filtered signal (sigma)', fontsize=10)\n",
    "    ax.set_xticks([\n",
    "        time_axis_real[0], \n",
    "        time_axis_real[0] + 5, \n",
    "        time_axis_real[0] + 10, \n",
    "        time_axis_real[0] + 15, \n",
    "        time_axis_real[0] + 20])\n",
    "    ax.set_xticks(np.arange(time_axis_real[0], time_axis_real[-1], 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    lg = ax.legend(loc='upper right', fontsize=8.5)\n",
    "    # lh = lg.legendHandles[1]\n",
    "    # lh.set_facecolor(lh.get_facecolor())\n",
    "    # lh.set_alpha(1.0)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Neural net\n",
    "    delta_y = 0.1\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(\n",
    "        time_axis_proba, segment_proba, \n",
    "        color=CUSTOM_COLOR['red'], linewidth=1.5, zorder=7)\n",
    "    for model_stamp in segment_predicted_stamps:\n",
    "        ax.fill_between(\n",
    "            model_stamp / fs_real, 1+delta_y, -delta_y, \n",
    "            facecolor=CUSTOM_COLOR['red'], zorder=6, alpha=0.3,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_xticks([])\n",
    "    ax.set_ylim([-delta_y, 1+delta_y])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticks([this_thr], minor=True)\n",
    "    ax.grid(b=True, axis='y', linewidth=1.5, which='minor', zorder=5)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    ax.set_title('Model prediction: probability and postprocessed stamps (%1.2f threshold is shown)' % this_thr, fontsize=10)\n",
    "    \n",
    "    if this_stamps_2 is not None:\n",
    "        ax = fig.add_subplot(gs[gs_idx])\n",
    "        # ax.imshow(segment_marks_2[np.newaxis, :], interpolation=None, aspect='auto', cmap=cmap)\n",
    "        for expert_stamp in segment_stamps_2:\n",
    "            ax.fill_between(\n",
    "                expert_stamp / fs_real, y_max, -y_max, \n",
    "                facecolor=CUSTOM_COLOR['blue'], alpha=0.3,\n",
    "                edgecolor='k', linewidth=1.5, \n",
    "            )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_ylim([-delta_y, 1+delta_y])\n",
    "        ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "        ax.set_title('Second expert stamps (not used for training)', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(\n",
    "    lambda page_idx: plot_page(page_idx),\n",
    "    page_idx=widgets.IntSlider(min=1,max=this_pages.shape[0],step=1,value=447, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_to_show = 0\n",
    "set_name = 'test'\n",
    "subject_id = 12\n",
    "center_on_real = False\n",
    "iou_range = [0, 0]\n",
    "duration_range = [0, 5]\n",
    "show_hypno = True\n",
    "\n",
    "\n",
    "band_pass_freqs = [12, 14]\n",
    "\n",
    "# -----\n",
    "if dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]:\n",
    "    channel_name = 'C3-CLE'\n",
    "elif dataset_name in [constants.DREAMS_SS_NAME, constants.DREAMS_KC_NAME]:\n",
    "    channel_name = 'Cz-A1'\n",
    "else:\n",
    "    channel_name = 'F4-C4'\n",
    "\n",
    "\n",
    "pages_subset = constants.N2_RECORD\n",
    "\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_to_show)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_to_show])\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids, 'alltrain': all_train_ids}\n",
    "idx_subject = idx_dict[set_name].index(subject_id)\n",
    "\n",
    "this_pages = dataset.get_subject_pages(subject_id=subject_id, pages_subset=pages_subset)\n",
    "if show_hypno:\n",
    "    this_hypnogram = dataset.get_subject_hypnogram(subject_id=subject_id)\n",
    "this_signal = dataset.get_subject_signal(subject_id=subject_id, normalization_mode=task_mode, which_expert=which_expert)\n",
    "this_stamps = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=which_expert)\n",
    "this_stamps_full = this_stamps.copy()\n",
    "if (subject_id not in [4, 8, 15, 16]) and dataset_name == constants.MASS_SS_NAME:\n",
    "    this_stamps_2 = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=2)\n",
    "    this_stamps_2_full = this_stamps_2.copy()\n",
    "else:\n",
    "    this_stamps_2 = None\n",
    "\n",
    "event_name = dataset.event_name\n",
    "\n",
    "this_thr = optimal_thr_list[seed_to_show]\n",
    "prediction_set = predictions_dict[seed_to_show][set_name]\n",
    "prediction_set.set_probability_threshold(this_thr)\n",
    "this_predicted_stamps = prediction_set.get_subject_stamps(subject_id=subject_id, pages_subset=constants.WN_RECORD)\n",
    "this_predicted_stamps_full = this_predicted_stamps.copy()\n",
    "this_proba = prediction_set.get_subject_probabilities(subject_id=subject_id)\n",
    "\n",
    "fs_real = dataset.fs\n",
    "down_factor = prediction_set.params[pkeys.TOTAL_DOWNSAMPLING_FACTOR]\n",
    "fs_proba = fs_real / down_factor\n",
    "\n",
    "# make a color map of fixed colors\n",
    "cmap = colors.ListedColormap(['white', '#c62828'])\n",
    "\n",
    "# Matching:\n",
    "this_iou_array, this_idx_array = metrics.matching(this_stamps, this_predicted_stamps)\n",
    "this_expert_iou = this_iou_array\n",
    "n_detections = this_predicted_stamps.shape[0]\n",
    "this_dectection_iou = np.zeros(n_detections)\n",
    "\n",
    "for i in range(n_detections):\n",
    "    if i in this_idx_array:\n",
    "        matching_idx = np.where(this_idx_array == i)[0][0]\n",
    "        this_dectection_iou[i] = this_iou_array[matching_idx]        \n",
    "\n",
    "# Number of missed reals:\n",
    "n_ufn = np.sum(this_expert_iou == 0)\n",
    "# Number of false detections:\n",
    "n_ufp = np.sum(this_dectection_iou == 0)\n",
    "# Number of matched pairs\n",
    "n_matched = np.sum(this_expert_iou > 0)\n",
    "n_matched_v2 = np.sum(this_dectection_iou > 0)\n",
    "print('UFN:', n_ufn)\n",
    "print('UFP', n_ufp)\n",
    "print('Matched', n_matched, n_matched_v2)\n",
    "precision = n_matched / (n_matched + n_ufp)\n",
    "recall = n_matched / (n_matched + n_ufn)\n",
    "f1_at_iou0 = 2 * precision * recall / (precision + recall)\n",
    "print('F1 at IoU>0 %1.2f' % f1_at_iou0)\n",
    "\n",
    "# Fraction of UFP that does not match E1 but match E2\n",
    "print('** UFP and E2 intersection analysis ** ')\n",
    "all_ufp = this_predicted_stamps_full[this_dectection_iou == 0]\n",
    "overlap_ufp_e1 = utils.get_overlap_matrix(all_ufp, this_stamps_full)\n",
    "valid_ufp = np.where(overlap_ufp_e1.sum(axis=1) == 0)[0]\n",
    "print('UFP removed because E1 intersection: %d' % (all_ufp.shape[0] - valid_ufp.size))\n",
    "all_ufp = all_ufp[valid_ufp]\n",
    "overlap_ufp_e2 = utils.get_overlap_matrix(all_ufp, this_stamps_2_full)\n",
    "idx_with_e2_intersection = np.where(overlap_ufp_e2.sum(axis=1) > 0)[0]\n",
    "print('UFP with intersection with E2 and none with E1: %d (%1.2f %%)' % (idx_with_e2_intersection.size, 100*idx_with_e2_intersection.size/n_ufp))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 1), dpi=200)\n",
    "ax.hist(this_expert_iou[this_expert_iou > 0], bins=[0.1*i for i in range(11)], color=CUSTOM_COLOR['red'], label='S%02d' % subject_id)\n",
    "ax.legend(loc='upper left', fontsize=7)\n",
    "ax.set_title('IoU of Matchings', fontsize=8)\n",
    "ax.set_xticks([0.1*i for i in range(0, 11, 2)])\n",
    "ax.set_xlabel('IoU', fontsize=7)\n",
    "ax.tick_params(labelsize=7)\n",
    "plt.show()\n",
    "        \n",
    "# filter\n",
    "if center_on_real:\n",
    "    idx_useful_iou = np.where( (this_expert_iou >= iou_range[0]) & (this_expert_iou <= iou_range[1]) )[0]\n",
    "    duration_expert = (this_stamps[:, 1] - this_stamps[:, 0]) / fs_real\n",
    "    idx_useful_duration = np.where( (duration_expert >= duration_range[0]) & (duration_expert <= duration_range[1]) )[0]\n",
    "    idx_useful = [i for i in idx_useful_iou if i in idx_useful_duration]\n",
    "    this_stamps = this_stamps[idx_useful]\n",
    "    this_expert_iou = this_expert_iou[idx_useful]\n",
    "else:\n",
    "    idx_useful_iou = np.where( (this_dectection_iou >= iou_range[0]) & (this_dectection_iou <= iou_range[1]) )[0]\n",
    "    duration_det = (this_predicted_stamps[:, 1] - this_predicted_stamps[:, 0]) / fs_real\n",
    "    idx_useful_duration = np.where( (duration_det >= duration_range[0]) & (duration_det <= duration_range[1]) )[0]\n",
    "    idx_useful = [i for i in idx_useful_iou if i in idx_useful_duration]\n",
    "    this_predicted_stamps = this_predicted_stamps[idx_useful]\n",
    "    this_dectection_iou = this_dectection_iou[idx_useful]\n",
    "\n",
    "def filter_stamps(stamps, start_sample, end_sample):\n",
    "    pages_list = []\n",
    "    for i in range(stamps.shape[0]):\n",
    "        start_inside = (stamps[i, 0] > start_sample) and (stamps[i, 0] < end_sample)\n",
    "        end_inside = (stamps[i, 1] > start_sample) and (stamps[i, 1] < end_sample)\n",
    "\n",
    "        if start_inside or end_inside:\n",
    "            pages_list.append(stamps[i, :])\n",
    "    return pages_list\n",
    "\n",
    "\n",
    "def plot_event(event_idx):\n",
    "\n",
    "    if this_stamps_2 is None:\n",
    "        fig = plt.figure(figsize=(12, 4), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(3, 1, height_ratios=[4, 2, 1])\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(12, 5), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(4, 1, height_ratios=[4, 2, 1, 1])\n",
    "    \n",
    "    event_idx = event_idx - 1\n",
    "    \n",
    "    if center_on_real:\n",
    "        event_chosen = this_stamps[event_idx, :]\n",
    "        iou_chosen = this_expert_iou[event_idx]\n",
    "    else:\n",
    "        event_chosen = this_predicted_stamps[event_idx, :]\n",
    "        iou_chosen = this_dectection_iou[event_idx]\n",
    "\n",
    "    start_sample = int(event_chosen[0] - 10 * fs_real)\n",
    "    end_sample = int(event_chosen[1] + 10 * fs_real)\n",
    "\n",
    "    page_of_center = int(((end_sample + start_sample) / 2) / dataset.page_size)\n",
    "    if show_hypno:\n",
    "        page_state = this_hypnogram[page_of_center]\n",
    "    else:\n",
    "        page_state = '?'\n",
    "    \n",
    "    segment_signal = this_signal[start_sample:end_sample]\n",
    "    segment_stamps = filter_stamps(this_stamps_full, start_sample, end_sample)\n",
    "    if this_stamps_2 is not None:\n",
    "        segment_stamps_2 = filter_stamps(this_stamps_2_full, start_sample, end_sample)\n",
    "    segment_proba = this_proba[int(start_sample/down_factor):int(end_sample/down_factor)]\n",
    "    segment_predicted_stamps = filter_stamps(this_predicted_stamps_full, start_sample, end_sample)\n",
    "    \n",
    "    time_axis_real = np.arange(start_sample, end_sample) / fs_real\n",
    "    time_axis_proba = np.arange(int(start_sample/down_factor), int(end_sample/down_factor)) / fs_proba\n",
    "    \n",
    "    gs_idx = 0\n",
    "    \n",
    "    # Signal\n",
    "    y_max = 7\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(\n",
    "        time_axis_real, segment_signal, \n",
    "        linewidth=1, color=CUSTOM_COLOR['grey'], label='EEG %s' % channel_name)\n",
    "    stamp_label_used = False\n",
    "    for expert_stamp in segment_stamps:\n",
    "        if stamp_label_used:\n",
    "            label = None\n",
    "        else:\n",
    "            label = event_name\n",
    "            stamp_label_used = True\n",
    "        ax.fill_between(\n",
    "            expert_stamp / fs_real, y_max, -y_max, \n",
    "            facecolor=CUSTOM_COLOR['blue'], alpha=0.3, label=label,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_ylim([-y_max, y_max])\n",
    "    if center_on_real:\n",
    "        ax.set_title('Subject %d (%s-%s). Expert mark idx: %d. IoU %1.2f. State %s (intervals of 0.5s are shown).' \n",
    "                     % (subject_id, dataset_name.upper(), set_name.capitalize(), event_idx, iou_chosen, page_state), fontsize=10)\n",
    "    else:\n",
    "        ax.set_title('Subject %d (%s-%s). Detection idx: %d. IoU %1.2f. State %s (intervals of 0.5s are shown).' \n",
    "                     % (subject_id, dataset_name.upper(), set_name.capitalize(), event_idx, iou_chosen, page_state), fontsize=10)\n",
    "        \n",
    "    ax.set_xticks([\n",
    "        time_axis_real[0], \n",
    "        time_axis_real[0] + 5, \n",
    "        time_axis_real[0] + 10, \n",
    "        time_axis_real[0] + 15, \n",
    "        time_axis_real[0] + 20])\n",
    "    ax.set_xticks(np.arange(time_axis_real[0], time_axis_real[-1], 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    lg = ax.legend(loc='upper right', fontsize=8.5)\n",
    "    # lh = lg.legendHandles[1]\n",
    "    # lh.set_facecolor(lh.get_facecolor())\n",
    "    # lh.set_alpha(1.0)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Band pass Signal\n",
    "    y_max = 5\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    # segment_signal_filtered = utils.narrow_filter(segment_signal, fs_real, band_pass_freqs[0], band_pass_freqs[1])\n",
    "    segment_signal_filtered = utils.filter_windowed_sinusoidal(segment_signal, fs_real, 13, 41)\n",
    "    ax.plot(\n",
    "        time_axis_real, segment_signal_filtered, \n",
    "        linewidth=1, color=CUSTOM_COLOR['grey'], label='EEG %s' % channel_name)\n",
    "    stamp_label_used = False\n",
    "    for expert_stamp in segment_stamps:\n",
    "        if stamp_label_used:\n",
    "            label = None\n",
    "        else:\n",
    "            label = event_name\n",
    "            stamp_label_used = True\n",
    "        ax.fill_between(\n",
    "            expert_stamp / fs_real, y_max, -y_max, \n",
    "            facecolor=CUSTOM_COLOR['blue'], alpha=0.3, label=label,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_ylim([-y_max, y_max])\n",
    "    ax.set_title('Bandpass filtered signal (sigma)', fontsize=10)\n",
    "    ax.set_xticks([\n",
    "        time_axis_real[0], \n",
    "        time_axis_real[0] + 5, \n",
    "        time_axis_real[0] + 10, \n",
    "        time_axis_real[0] + 15, \n",
    "        time_axis_real[0] + 20])\n",
    "    ax.set_xticks(np.arange(time_axis_real[0], time_axis_real[-1], 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    lg = ax.legend(loc='upper right', fontsize=8.5)\n",
    "    # lh = lg.legendHandles[1]\n",
    "    # lh.set_facecolor(lh.get_facecolor())\n",
    "    # lh.set_alpha(1.0)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Neural net\n",
    "    delta_y = 0.1\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(\n",
    "        time_axis_proba, segment_proba, \n",
    "        color=CUSTOM_COLOR['red'], linewidth=1.5, zorder=7)\n",
    "    for model_stamp in segment_predicted_stamps:\n",
    "        ax.fill_between(\n",
    "            model_stamp / fs_real, 1+delta_y, -delta_y, \n",
    "            facecolor=CUSTOM_COLOR['red'], zorder=6, alpha=0.3,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_xticks([])\n",
    "    ax.set_ylim([-delta_y, 1+delta_y])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticks([this_thr], minor=True)\n",
    "    ax.grid(b=True, axis='y', linewidth=1.5, which='minor', zorder=5)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    ax.set_title('Model prediction: probability and postprocessed stamps (%1.2f threshold is shown)' % this_thr, fontsize=10)\n",
    "    \n",
    "    if this_stamps_2 is not None:\n",
    "        ax = fig.add_subplot(gs[gs_idx])\n",
    "        # ax.imshow(segment_marks_2[np.newaxis, :], interpolation=None, aspect='auto', cmap=cmap)\n",
    "        for expert_stamp in segment_stamps_2:\n",
    "            ax.fill_between(\n",
    "                expert_stamp / fs_real, y_max, -y_max, \n",
    "                facecolor=CUSTOM_COLOR['blue'], alpha=0.3,\n",
    "                edgecolor='k', linewidth=1.5, \n",
    "            )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_ylim([-delta_y, 1+delta_y])\n",
    "        ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "        ax.set_title('Second expert stamps (not used for training)', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Showing events with IoU in range %s' % iou_range)\n",
    "print('Showing events with duration in range %s [s]' % duration_range)\n",
    "if center_on_real:\n",
    "    max_value = this_stamps.shape[0]\n",
    "    print('Number of real events selected %d' % max_value)\n",
    "else:\n",
    "    max_value = this_predicted_stamps.shape[0]\n",
    "    print('Number of detected events selected %d' % max_value)\n",
    "\n",
    "widgets.interact(\n",
    "    lambda event_idx: plot_event(event_idx),\n",
    "    event_idx=widgets.IntSlider(min=1,max=max_value,step=1,value=1, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_set_error = 'test'\n",
    "thr = optimal_thr_list[0]\n",
    "\n",
    "y_thr = y_stamps[chosen_set_error]\n",
    "\n",
    "# Prepare model predictions\n",
    "n_subjects = len(y_thr)\n",
    "pred_stamps = []\n",
    "for i in range(n_subjects):\n",
    "    print('Processing subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    # Binarize\n",
    "    this_y_pred_thr = (y_pred[chosen_set_error][i] >= thr).astype(np.int32)\n",
    "    # Transform to intervals\n",
    "    this_y_pred_thr = data_ops.seq2inter_with_pages(\n",
    "        this_y_pred_thr, pages[chosen_set_error][i]\n",
    "    )\n",
    "    pred_stamps.append(this_y_pred_thr)\n",
    "fs_pred = 200 // 8 \n",
    "fs_real = 200\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Compute spacing ----------------------\n",
    "combine_thr = 0.3\n",
    "\n",
    "spacing = []\n",
    "spacing_expert = []\n",
    "for i in range(n_subjects):\n",
    "    print('Spacing for subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    this_spacing = (pred_stamps[i][1:, 0] - pred_stamps[i][:-1, 1]) / fs_pred\n",
    "    this_spacing_expert = (y_stamps[chosen_set_error][i][1:, 0] - y_stamps[chosen_set_error][i][:-1, 1]) / fs_real\n",
    "    # Only consider for this analysis, spacing less than one second\n",
    "    this_spacing = this_spacing[this_spacing < 1]\n",
    "    this_spacing_expert = this_spacing_expert[this_spacing_expert < 1]\n",
    "    spacing.append(this_spacing)\n",
    "    spacing_expert.append(this_spacing_expert)\n",
    "print('Done')\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Spacing between nearby expert marks', fontsize=10)\n",
    "ax[0, 1].set_title('Spacing between nearby detections', fontsize=10)\n",
    "y_max = 0\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Real\n",
    "    n_real, _, _ = ax[i, 0].hist(spacing_expert[i], bins=[k*0.1 for k in range(11)], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].set_xticks([k*0.2 for k in range(6)])\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "    # Predicted\n",
    "    n_pred, _, _ = ax[i, 1].hist(spacing[i], bins=[k*0.1 for k in range(11)], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].set_xticks([k*0.2 for k in range(6)])\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "    max_y = max(np.max(n_real), np.max(n_pred))\n",
    "    ax[i, 0].plot([combine_thr, combine_thr], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    ax[i, 1].plot([combine_thr, combine_thr], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    # y_max = max(max_y, y_max)\n",
    "# for i in range(n_subjects):\n",
    "#     ax[i, 0].plot([combine_thr, combine_thr], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "#     ax[i, 1].plot([combine_thr, combine_thr], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "ax[-1, 0].set_xlabel('Spacing [s]', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Spacing [s]', fontsize=8.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Durations\n",
    "\n",
    "if dataset_name == constants.MASSK_NAME:\n",
    "    postprocess_predicted = False\n",
    "else:\n",
    "    postprocess_predicted = True\n",
    "\n",
    "durations = []\n",
    "durations_expert = []\n",
    "for i in range(n_subjects):\n",
    "    print('Durations for subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    # First, combine close marks\n",
    "    if dataset_name == constants.MASSK_NAME:\n",
    "        this_pred_stamps = pred_stamps[i]\n",
    "    else:\n",
    "        this_pred_stamps = postprocessing.combine_close_marks(pred_stamps[i], fs_pred, combine_thr)\n",
    "    # Now compute durations\n",
    "    this_durations = (this_pred_stamps[:, 1] - this_pred_stamps[:, 0]) / fs_pred\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    # Only consider for this analysis, spacing less than one second\n",
    "    durations.append(this_durations)\n",
    "    durations_expert.append(this_durations_expert)\n",
    "print('Done')\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Duration of expert marks', fontsize=10)\n",
    "ax[0, 1].set_title('Duration of detections', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "y_max = 0\n",
    "min_duration = 0.3  \n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Real\n",
    "    n_real, _, _ = ax[i, 0].hist(durations_expert[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "    # Predicted\n",
    "    n_pred, _, _ = ax[i, 1].hist(durations[i], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "    max_y = max(np.max(n_real), np.max(n_pred))\n",
    "    ax[i, 0].plot([min_duration, min_duration], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    ax[i, 1].plot([min_duration, min_duration], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    y_max = max(max_y, y_max)\n",
    "    print(durations[i].max())\n",
    "    \n",
    "#for i in range(n_subjects):\n",
    "#    ax[i, 0].plot([min_duration, min_duration], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "#    ax[i, 1].plot([min_duration, min_duration], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "\n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location of Falses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == constants.MASSK_NAME:\n",
    "    min_separation = 0\n",
    "    min_duration = 0.3\n",
    "    max_duration = 4.0\n",
    "else:\n",
    "    min_separation = 0.5\n",
    "    min_duration = 0.4\n",
    "    max_duration = 4.0\n",
    "\n",
    "iou_array = []\n",
    "idx_array = []\n",
    "y_pred_thr = []\n",
    "for i in range(n_subjects):\n",
    "    print('Processing subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    events = y_stamps[chosen_set_error][i]\n",
    "    detections = postprocessing.generate_mark_intervals(\n",
    "        y_pred[chosen_set_error][i], pages[chosen_set_error][i], 200//8, 200, thr=thr, \n",
    "        min_separation=min_separation, min_duration=min_duration, max_duration=max_duration)\n",
    "    print(events.shape, detections.shape)\n",
    "    this_iou_array, this_idx_array = metrics.matching(events, detections)\n",
    "    iou_array.append(this_iou_array)\n",
    "    idx_array.append(this_idx_array)\n",
    "    y_pred_thr.append(detections)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- False negatives\n",
    "iou_thr = 0.3\n",
    "\n",
    "fn_center = []\n",
    "for i in range(n_subjects):\n",
    "    idx_fn = iou_array[i] < iou_thr\n",
    "    fn_stamps = y_stamps[chosen_set_error][i][idx_fn]\n",
    "    this_fn_center = np.mean(fn_stamps, axis=1).astype(np.int32)\n",
    "    fn_center.append(this_fn_center)\n",
    "    \n",
    "# --- False positives\n",
    "fp_center = []\n",
    "for i in range(n_subjects):\n",
    "    # matched detections:\n",
    "    idx_fp_1 = iou_array[i] < iou_thr\n",
    "    idx_fp_1 = idx_array[i][idx_fp_1]\n",
    "    idx_fp_1 = [idx for idx in idx_fp_1 if idx != -1]\n",
    "    # Unmatched events\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    idx_fp = idx_fp_1 + idx_fp_2\n",
    "    fp_stamps = y_pred_thr[i][idx_fp]\n",
    "    this_fp_center = np.mean(fp_stamps, axis=1).astype(np.int32)\n",
    "    fp_center.append(this_fp_center)\n",
    "\n",
    "    \n",
    "# --- Histogram of IoU values across real events\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(3.5, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0].set_title('IoU values on expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].hist(iou_array[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), bins=[0.05*i for i in range(21)])\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "    ax[i].legend(fontsize=8.5, loc='upper center')\n",
    "    ax[i].set_xticks([0.2*i for i in range(6)])\n",
    "ax[-1].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "plt.show()\n",
    "    \n",
    "# --- Location in page\n",
    "fn_loc_page = [np.mod(this_fn_center, 20*fs_real) for this_fn_center in fn_center]\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Location of expert marks with IoU < %1.2f' % (iou_thr), fontsize=11)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 0].hist(fn_loc_page[i] / fs_real, bins=[i*4 for i in range(6)], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5, loc='upper center')\n",
    "ax[-1, 0].set_xticks([i*4 for i in range(6)])\n",
    "ax[-1, 0].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "\n",
    "fp_loc_page = [np.mod(this_fp_center, 20*fs_real) for this_fp_center in fp_center]\n",
    "\n",
    "ax[0, 1].set_title('Location of detections with IoU < %1.2f' % (iou_thr), fontsize=10)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 1].hist(fp_loc_page[i] / fs_real, bins=[i*4 for i in range(6)], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5, loc='upper center')\n",
    "ax[-1, 1].set_xticks([i*4 for i in range(6)])\n",
    "ax[-1, 1].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --- Location in register\n",
    "\n",
    "fn_loc_register = [np.floor_divide(this_fn_center, 20*fs_real) for this_fn_center in fn_center]\n",
    "max_page_array = [np.max(pages[chosen_set_error][i]) for i in range(n_subjects)]\n",
    "\n",
    "max_of_all = np.max(max_page_array)\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Location in register of expert marks with IoU < %1.1f' % (iou_thr), fontsize=10)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 0].hist(fn_loc_register[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "ax[-1, 0].set_xlim([0, max_of_all+10])\n",
    "ax[-1, 0].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "fp_loc_register = [np.floor_divide(this_fp_center, 20*fs_real) for this_fp_center in fp_center]\n",
    "max_page_array = [np.max(pages[chosen_set_error][i]) for i in range(n_subjects)]\n",
    "\n",
    "max_of_all = np.max(max_page_array)\n",
    "\n",
    "ax[0, 1].set_title('Location in register of detections with IoU < %1.1f' % (iou_thr), fontsize=11)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 1].hist(fp_loc_register[i], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "ax[-1, 1].set_xlim([0, max_of_all+10])\n",
    "ax[-1, 1].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ----- N2 pages\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(3.5, 1*n_subjects), dpi=DPI, sharex=True, sharey=True)\n",
    "ax[0].set_title('Location in register of N2 pages (%s)' % (chosen_set_error.capitalize()), fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].hist(pages[chosen_set_error][i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "    ax[i].legend(fontsize=8.5)\n",
    "ax[-1].set_xlim([0, max_of_all+10])\n",
    "ax[-1].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IoU vs Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- Scatter of IoU values and duration of real and detected events\n",
    "alpha = 0.2\n",
    "markersize=10\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(7, 1*n_subjects), dpi=DPI, sharex=True, sharey=True)\n",
    "ax[0, 0].set_title('IoU vs duration of expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    ax[i, 0].scatter(this_durations_expert, iou_array[i], label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#455a64', alpha=alpha, s=markersize)\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 0].legend(fontsize=7, loc='upper right')\n",
    "    for lh in lg.legendHandles:\n",
    "        lh.set_facecolor(lh.get_facecolor())\n",
    "        lh.set_edgecolor(lh.get_edgecolor())\n",
    "        lh.set_alpha(1.0)\n",
    "    ax[i, 0].set_ylabel('IoU', fontsize=8.5)\n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('IoU vs duration of detections', fontsize=10)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations for IoU > 0 \n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    this_iou_1 = iou_array[i][idx_valid]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    this_durations_1 = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    # Now durations for IoU = 0\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_fp_2]\n",
    "    this_durations_2 = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    this_iou_2 = np.zeros(this_durations_2.shape[0])\n",
    "    # Concatenation\n",
    "    this_durations = np.concatenate([this_durations_1, this_durations_2])\n",
    "    this_iou = np.concatenate([this_iou_1, this_iou_2])\n",
    "    ax[i, 1].scatter(this_durations, this_iou, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#c62828', alpha=alpha, s=markersize)\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 1].legend(fontsize=7, loc='upper right')\n",
    "    for lh in lg.legendHandles:\n",
    "        lh.set_facecolor(lh.get_facecolor())\n",
    "        lh.set_edgecolor(lh.get_edgecolor())\n",
    "        lh.set_alpha(1.0)\n",
    "    # ax[i, 1].set_ylabel('IoU', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Histogram of duration for IoU == 0\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Duration of unpaired expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    idx_zero = (iou_array[i] == 0)\n",
    "    this_durations_expert_fn = this_durations_expert[idx_zero]\n",
    "    ax[i, 0].hist(this_durations_expert_fn, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#455a64')\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 0].legend(fontsize=8.5, loc='upper right')\n",
    "    \n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('Duration of unpaired detections', fontsize=10)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_fp_2]\n",
    "    this_durations_fp = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    ax[i, 1].hist(this_durations_fp, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#c62828')\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5, loc='upper right')\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration of events and matched detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(5, 5), dpi=DPI, sharex=False, sharey=False)\n",
    "# plt.suptitle('Duration of matched events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    # Now compute durations for real\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    this_durations_expert = this_durations_expert[idx_valid]\n",
    "    # Now compute durations for matched detections\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    this_durations_det = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    if i<2:\n",
    "        ax[0, i].scatter(this_durations_expert, this_durations_det, label='S%02d' % subject_idx, color='#455a64', alpha=alpha)\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "        lg = ax[0, i].legend(fontsize=7)\n",
    "        for lh in lg.legendHandles:\n",
    "            lh.set_facecolor(lh.get_facecolor())\n",
    "            lh.set_edgecolor(lh.get_edgecolor())\n",
    "            lh.set_alpha(1.0)\n",
    "        max_dur = max(this_durations_expert.max(), this_durations_det.max())\n",
    "        ax[0, i].set_xlim([0, max_dur + 0.1])\n",
    "        ax[0, i].set_ylim([0, max_dur + 0.1])\n",
    "        if i == 0 :\n",
    "            ax[0, i].set_ylabel('Detected duration [s]', fontsize=8.5)\n",
    "        # ax[0, i].set_xlabel('Duration Real [s]', fontsize=8.5)\n",
    "        ax[0, i].plot([0.3, 2.0], [0.3, 2.0], '--k', alpha=0.6)\n",
    "    else:\n",
    "        ax[1, i-2].scatter(this_durations_expert, this_durations_det, label='S%02d' % subject_idx, color='#455a64', alpha=alpha)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "        lg = ax[1, i-2].legend(fontsize=7)\n",
    "        for lh in lg.legendHandles:\n",
    "            lh.set_facecolor(lh.get_facecolor())\n",
    "            lh.set_edgecolor(lh.get_edgecolor())\n",
    "            lh.set_alpha(1.0)\n",
    "        max_dur = max(this_durations_expert.max(), this_durations_det.max())\n",
    "        ax[1, i-2].set_xlim([0, max_dur + 0.1])\n",
    "        ax[1, i-2].set_ylim([0, max_dur + 0.1])\n",
    "        if i == 2:\n",
    "            ax[1, i-2].set_ylabel('Detected duration [s]', fontsize=8.5)\n",
    "        ax[1, i-2].set_xlabel('Real duration [s]', fontsize=8.5)\n",
    "        ax[1, i-2].plot([0.3, 2.0], [0.3, 2.0], '--k', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted probability to matched and unmatched events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare probabilities\n",
    "whole_y_proba = []\n",
    "for i in range(n_subjects):\n",
    "    this_proba = y_pred[chosen_set_error][i]\n",
    "    this_pages = pages[chosen_set_error][i]\n",
    "    page_size = this_proba.shape[1]\n",
    "    max_page = np.max(this_pages)\n",
    "    max_size = (max_page + 1) * page_size\n",
    "    whole_y_proba.append(np.zeros(max_size, dtype=np.float32))\n",
    "    for k, page in enumerate(this_pages):\n",
    "        sample_start = page * page_size\n",
    "        sample_end = (page + 1) * page_size\n",
    "        whole_y_proba[i][sample_start:sample_end] = this_proba[k, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching probabilities (Candidates for TP according to IoU)\n",
    "# It is expected that they have more than 0.5 since that is the threshold used for detection\n",
    "print('Processing probability for matched events', flush=True)\n",
    "matching_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for the valid detections stamps \n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    y_pred_stamps = y_pred_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in y_pred_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    matching_proba.append(mean_proba_list)\n",
    "    \n",
    "# Unmatched real events (FN)\n",
    "# It is expected that they have less than 0.5 since they were missed by the tresholding\n",
    "print('Processing probability for unmatched real events', flush=True)\n",
    "unmatching_fn_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for the missed real events \n",
    "    idx_valid = (idx_array[i] == -1)\n",
    "    fn_stamps = y_stamps[chosen_set_error][i][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    fn_stamps = fn_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in fn_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    unmatching_fn_proba.append(mean_proba_list)\n",
    "    \n",
    "# Unmatched detected events (FP)\n",
    "# It is expected that they have more than 0.5 since they were detected\n",
    "print('Processing probability for unmatched detected events', flush=True)\n",
    "unmatching_fp_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for detected events with no match \n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_valid = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    fp_stamps = y_pred_thr[i][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    fp_stamps = fp_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in fp_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    unmatching_fp_proba.append(mean_proba_list)\n",
    "    \n",
    "\n",
    "# Probability for real events\n",
    "print('Processing probability for real events', flush=True)\n",
    "real_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    y_pred_stamps = y_stamps[chosen_set_error][i] // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in y_pred_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    real_proba.append(mean_proba_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 3, figsize=(14, 3*n_subjects), dpi=100, sharex=True)\n",
    "\n",
    "ax[0, 0].set_title('Model output on matched events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 0].hist(matching_proba[i], label='S%02d' % subject_idx, color='#43a047')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 0].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "ax[-1, 0].set_xlim([0, 1])\n",
    "ax[-1, 0].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('Probability on unmatched real events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 1].hist(unmatching_fn_proba[i], label='S%02d' % subject_idx, color='#455a64')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 1].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "ax[-1, 1].set_xlim([0, 1])\n",
    "ax[-1, 1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "ax[0, 2].set_title('Probability on unmatched detections (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 2].hist(unmatching_fp_proba[i], label='S%02d' % subject_idx, color='#c62828')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 2].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 2].tick_params(labelsize=8.5)\n",
    "    ax[i, 2].legend(fontsize=8.5)\n",
    "ax[-1, 2].set_xlim([0, 1])\n",
    "ax[-1, 2].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(6, 5*n_subjects), dpi=100, sharex=True)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].set_title('Predicted probability for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=11)\n",
    "\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "max_n = 0\n",
    "for i in range(n_subjects):\n",
    "    \n",
    "    n, _, _ = ax[i].hist(\n",
    "        matching_proba[i], label='Matched real', color='#43a047', alpha=0.4, density=True,\n",
    "        bins = [i*0.05 for i in range(21)])\n",
    "    kernel = gaussian_kde(matching_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    ax[i].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "ax[-1].set_xlim([0, 1])\n",
    "ax[-1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "# for i in range(n_subjects):\n",
    "#     subject_idx = idx_dict[chosen_set_error][i]\n",
    "#     n, _, _ = ax[i].hist(\n",
    "#         unmatching_fn_proba[i], label='Unmatched real', color='#455a64', alpha=0.4, density=True,\n",
    "#         bins = [i*0.05 for i in range(21)])\n",
    "#     kernel = gaussian_kde(unmatching_fn_proba[i])\n",
    "#     y_kde = kernel(x_points)\n",
    "#     ax[i].plot(x_points, y_kde, color='#455a64', linewidth=2)\n",
    "#     max_n = max(np.max(n), max_n)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i].hist(\n",
    "        unmatching_fp_proba[i], label='Unmatched detection', color='#c62828', alpha=0.4, density=True,\n",
    "        bins = [i*0.05 for i in range(21)])\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    ax[i].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i].legend(fontsize=8.5, loc='upper left')\n",
    "    ax[i].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(6, 5), dpi=DPI, sharex=True)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    if i < 2:\n",
    "        ax[0, i].set_title('Model Output for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=10)\n",
    "    else:\n",
    "        ax[1, i-2].set_title('Model Output for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=10)\n",
    "\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "max_n = 0\n",
    "for i in range(n_subjects):\n",
    "    if i < 2:\n",
    "        n, _, _ = ax[0, i].hist(\n",
    "            real_proba[i], label='Expert marks', color='#43a047', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "    else:\n",
    "        n, _, _ = ax[1, i-2].hist(\n",
    "            real_proba[i], label='Real events\\n(Expert marks)', color='#43a047', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "    kernel = gaussian_kde(real_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    if i<2:\n",
    "        ax[0, i].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "        ax[0, i].set_xlim([0, 1])\n",
    "    else:\n",
    "        ax[1, i-2].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "        ax[1, i-2].set_xlim([0, 1])\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    \n",
    "\n",
    "# ax[-1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    if i<2:\n",
    "        n, _, _ = ax[0, i].hist(\n",
    "            unmatching_fp_proba[i], label='Unpaired detections ($\\mu$=0.1)', color='#c62828', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "        ax[0, i].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "        # ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "        # lg = ax[0, i].legend(fontsize=8.5, loc='upper center', bbox_to_anchor=(1.05, 0.15))\n",
    "        # for lh in lg.legendHandles:\n",
    "        #     lh.set_facecolor(lh.get_facecolor())\n",
    "        #     lh.set_alpha(1.0)\n",
    "        ax[0, i].set_yticks([])\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "    else:\n",
    "        n, _, _ = ax[1, i-2].hist(\n",
    "            unmatching_fp_proba[i], label='False events\\n(Unpaired detections\\ngenerated with $\\mu$=0.1)', color='#c62828', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "        ax[1, i-2].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "        # ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "        ax[1, i-2].set_yticks([])\n",
    "        ax[1, i-2].set_xlabel('Class assignment', fontsize=8.5)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "lg = ax[1, 1].legend(fontsize=9, loc='upper left', bbox_to_anchor=(1.05, 1.35), labelspacing=3)\n",
    "for lh in lg.legendHandles:\n",
    "    lh.set_facecolor(lh.get_facecolor())\n",
    "    lh.set_alpha(1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Avg distributions over set\n",
    "\n",
    "\n",
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5), dpi=100, sharex=True)\n",
    "\n",
    "ax.set_title('Predicted probability. Average for %s set' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "\n",
    "y_kde_list = []\n",
    "for i in range(n_subjects):\n",
    "    kernel = gaussian_kde(matching_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    y_kde_list.append(y_kde)\n",
    "y_kde_avg_real = np.stack(y_kde_list, axis=1).mean(axis=1)\n",
    "ax.plot(x_points, y_kde_avg_real, color='#43a047', linewidth=2, label='Real event')\n",
    "ax.fill_between(x_points, y_kde_avg_real, 0*y_kde_avg_real, color='#43a047', alpha=0.4)\n",
    "\n",
    "y_kde_list = []\n",
    "for i in range(n_subjects):\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    y_kde_list.append(y_kde)\n",
    "y_kde_avg_false = np.stack(y_kde_list, axis=1).mean(axis=1)\n",
    "ax.plot(x_points, y_kde_avg_false, color='#c62828', linewidth=2, label='False event')\n",
    "ax.fill_between(x_points, y_kde_avg_false, 0*y_kde_avg_false, color='#c62828', alpha=0.4)\n",
    "\n",
    "max_y = max(np.max(y_kde_avg_real), np.max(y_kde_avg_false))\n",
    "\n",
    "# Find optimal threshold\n",
    "difference = y_kde_avg_false - y_kde_avg_real\n",
    "idx_thr = np.where(np.signbit(difference))[0][0]\n",
    "x_thr = x_points[idx_thr]\n",
    "print('Optimal Threshold: %1.4f' % x_thr)\n",
    "ax.plot([x_thr, x_thr], [0, max_y], '--', color='k', linewidth=1.5, alpha=0.6, label='Optimal Threshold')\n",
    "\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, max_y])\n",
    "ax.set_yticks([])\n",
    "ax.legend(fontsize=8.5, loc='upper left')\n",
    "ax.set_xlabel('Probability', fontsize=8.5)\n",
    "ax.set_xticks([i*0.1 for i in range(11)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of FP that are TP-E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unmatched events according to E1\n",
    "unmatched_stamps = []\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    # Unmatched detections\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    fp_stamps = y_pred_thr[i][idx_fp]\n",
    "    print('\\n%d / %d (%1.2f %%) unmatched detections with E1 for S%02d' % (fp_stamps.shape[0], n_detections, 100*fp_stamps.shape[0]/n_detections, subject_idx))\n",
    "    unmatched_stamps.append(fp_stamps)\n",
    "    # Now match with E2\n",
    "    events = y2_stamps[chosen_set_error][i]\n",
    "    detections = fp_stamps\n",
    "    n_detections = fp_stamps.shape[0]\n",
    "    this_iou_array, this_idx_array = metrics.matching(events, detections)\n",
    "    matched_2 =  (this_idx_array > -1).sum()\n",
    "    print('%d were matched with E2 (%1.2f%% of previously unmatched detections)' % (matched_2, 100*matched_2 / fp_stamps.shape[0]))\n",
    "    # print(fp_stamps[this_idx_array[this_idx_array > -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral information of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id_list = dataset.train_ids\n",
    "whole_night = True\n",
    "\n",
    "# Now plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4), dpi=150)\n",
    "if whole_night:\n",
    "    title_str = 'Whole night average'\n",
    "else:\n",
    "    title_str = 'N2 only average'\n",
    "    \n",
    "for subject_id in subject_id_list:\n",
    "    x, _ = dataset.get_subject_data(subject_id, which_expert=1, verbose=False, whole_night=whole_night)\n",
    "    # Compute fft of each page \n",
    "    print('Computing FFT for S%02d... ' % subject_id, end='', flush=True)\n",
    "    fft_list = []\n",
    "    for x_page in x:\n",
    "        fft_page, freq_axis = data_ops.power_spectrum(x_page, 200)\n",
    "        fft_list.append(fft_page)\n",
    "    # Now average the fft:\n",
    "    fft_mean = np.stack(fft_list, axis=1).mean(axis=1)\n",
    "    print('Done')\n",
    "    # Now plot\n",
    "    ax.plot(freq_axis, fft_mean, label='S%02d' % subject_id, linewidth=1)\n",
    "\n",
    "ax.set_title(title_str, fontsize=10)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Frequency [Hz]', fontsize=8.5)\n",
    "ax.set_ylabel('Power')\n",
    "ax.set_xlim([0, 25])\n",
    "ax.set_ylim([0.01, 0.5])\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.legend(loc='upper right', fontsize=8.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load invalid subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
