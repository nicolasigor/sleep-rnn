{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntapia/miniconda3/envs/tf/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pprint import pprint\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import gridspec\n",
    "from scipy.stats import gaussian_kde\n",
    "# from tqdm import tqdm\n",
    "\n",
    "project_root = '..'\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from sleeprnn.data.loader import load_dataset\n",
    "from sleeprnn.helpers.reader import RefactorUnpickler\n",
    "from sleeprnn.data import utils, stamp_correction\n",
    "from sleeprnn.detection.feeder_dataset import FeederDataset\n",
    "from sleeprnn.detection import metrics\n",
    "from sleeprnn.detection.postprocessor import PostProcessor\n",
    "from sleeprnn.common import constants, pkeys\n",
    "\n",
    "SEED_LIST = [123, 234, 345, 456]\n",
    "RESULTS_PATH = os.path.join(project_root, 'results')\n",
    "COMPARISON_PATH = os.path.join(project_root, 'resources', 'comparison_data')\n",
    "DPI = 200\n",
    "CUSTOM_COLOR = {'red': '#c62828', 'grey': '#455a64', 'blue': '#0277bd', 'green': '#43a047'} \n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load database and predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 11. Test size: 4\n",
      "Train subjects: \n",
      " [1, 3, 5, 7, 9, 10, 11, 14, 17, 18, 19]\n",
      "Test subjects: \n",
      " [2, 6, 12, 13]\n",
      "Dataset mass_ss with 15 patients.\n",
      "Loading from checkpoint... Loaded\n",
      "Global STD: 16.482037\n",
      "Loaded seed 1/4 from /home/ntapia/Projects/GitNico/sleep-rnn/results/predictions_mass_ss/20190927_out_proba_cwt_grid_n2_train_mass_ss/p_0.5_lr_0.0001/seed0\n",
      "Loaded seed 2/4 from /home/ntapia/Projects/GitNico/sleep-rnn/results/predictions_mass_ss/20190927_out_proba_cwt_grid_n2_train_mass_ss/p_0.5_lr_0.0001/seed1\n",
      "Loaded seed 3/4 from /home/ntapia/Projects/GitNico/sleep-rnn/results/predictions_mass_ss/20190927_out_proba_cwt_grid_n2_train_mass_ss/p_0.5_lr_0.0001/seed2\n",
      "Loaded seed 4/4 from /home/ntapia/Projects/GitNico/sleep-rnn/results/predictions_mass_ss/20190927_out_proba_cwt_grid_n2_train_mass_ss/p_0.5_lr_0.0001/seed3\n",
      "Optimal thr: [0.36, 0.42, 0.62, 0.4]\n"
     ]
    }
   ],
   "source": [
    "optimal_thr_for_ckpt_dict = {\n",
    "    os.path.join('20190504_bsf_wn_train_mass_ss', 'bsf'): [0.64, 0.52, 0.52, 0.48],\n",
    "    os.path.join('20190504_bsf_wn_train_mass_kc', 'bsf'): [0.52, 0.56, 0.54, 0.56],\n",
    "    os.path.join('20190506_bsf_n2_train_mass_ss', 'bsf'): [0.52, 0.46, 0.50, 0.50],\n",
    "    os.path.join('20190506_bsf_n2_train_mass_kc', 'bsf'): [0.52, 0.52, 0.56, 0.46],\n",
    "    os.path.join('20190516_bsf_n2_train_inta_ss', 'bsf'): [0.48, 0.52, 0.48, 0.44],\n",
    "    os.path.join('20190516_bsf_v2_n2_train_inta_ss', 'bsf'): [0.46, 0.52, 0.50, 0.46],\n",
    "    os.path.join('20190522_bsf_newer_wins_fix_n2_train_inta_ss', 'bsf'): [0.44, 0.5, 0.44, 0.42],\n",
    "    os.path.join('20190522_bsf_e1_n2_train_mass_ss', 'bsf'): [0.44, 0.56, 0.48, 0.48],\n",
    "    os.path.join('20190522_bsf_e2_n2_train_mass_ss', 'bsf'): [0.6, 0.44, 0.36, 0.56],\n",
    "    os.path.join('20190525_bsf_ch3_n2_train_inta_ss', 'bsf'): [0.48, 0.56, 0.52, 0.5],\n",
    "    os.path.join('20190525_bsf_v4_n2_train_mass_ss', 'bsf_1'): [0.46, 0.4, 0.5, 0.46],\n",
    "    os.path.join('20190527_bsf_v7_k3_n2_train_mass_ss', 'bsf_2'): [0.52, 0.44, 0.48, 0.42],\n",
    "    os.path.join('20190530_bsf_v10_n2_train_mass_ss', 'bsf'): [0.6, 0.44, 0.56, 0.42],\n",
    "    os.path.join('20190601_bsf_v11_n2_train_mass_ss', 'filters_32_64_128'): [0.64, 0.36, 0.58, 0.4],\n",
    "    os.path.join('20190601_bsf_v11_n2_train_mass_ss', 'filters_64_128_256'): [0.62, 0.6, 0.52, 0.44],\n",
    "    os.path.join('20190603_grid_cwt_fb05_n2_train_mass_ss', 'v12_f_32_64'): [0.66, 0.46, 0.52, 0.46],\n",
    "    os.path.join('20190605_grid_v15_v16_n2_train_mass_ss', 'v15_timef_64_128_256_cwtf_32_32_fb_0.5'): [0.46, 0.52, 0.62, 0.42],\n",
    "    os.path.join('20190614_bsf_global_std_n2_train_mass_ss', 'bsf'): [0.62, 0.4, 0.4, 0.48],\n",
    "    os.path.join('20190617_grid_normalization_n2_train_mass_ss', 'norm_global'): [0.58, 0.42, 0.4, 0.5],\n",
    "    os.path.join('20190608_bsf_ablation_n2_train_inta_ss', 'v15_tf_64-128-256_cwtf_32-32/rep0'): [0.48, 0.52, 0.5, 0.5],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_n2_train_dreams_ss', 'v11_None'): [0.22, 0.48, 0.28, 0.38],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_n2_train_dreams_ss', 'v12_True'): [0.36, 0.5, 0.34, 0.36],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_n2_train_dreams_ss', 'v17_True'): [0.34, 0.38, 0.28, 0.44],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_wn_train_dreams_ss', 'v11_None'): [0.36, 0.46, 0.4, 0.36],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_wn_train_dreams_ss', 'v12_True'): [0.48, 0.46, 0.46, 0.52],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_wn_train_dreams_ss', 'v17_True'): [0.3, 0.52, 0.28, 0.46],\n",
    "    os.path.join('20190704_inta_meeting_n2_train_mass_ss', 'v15'): [0.5, 0.42, 0.56, 0.58],\n",
    "    os.path.join('20190704_inta_meeting_n2_train_mass_ss', 'v20_indep'): [0.4, 0.62, 0.64, 0.56],\n",
    "    os.path.join('20190704_inta_meeting_n2_train_inta_ss', 'v15'): [0.48, 0.48, 0.5, 0.46],\n",
    "    os.path.join('20190704_inta_meeting_n2_train_inta_ss', 'v20_indep'): [0.54, 0.42, 0.5, 0.5],\n",
    "    os.path.join('20190706_inta_05_n2_train_inta_ss', 'v15'): [0.42, 0.44, 0.48, 0.5],\n",
    "    os.path.join('20190708_grid_v19_pte2_n2_train_mass_ss', 'r_1_i_1_m_1_p_0_fb_0.5'): [0.42, 0.58, 0.62, 0.54],\n",
    "    os.path.join('20190825_v22_grid_n2_train_mass_ss', 'r_1_i_1_m_1_p_0_drop_0.3_f_64'): [0.52, 0.48, 0.5, 0.52],\n",
    "    os.path.join('20190827_thesis_1_bsf_e1_n2_train_mass_ss', 'v19'): [0.54, 0.52, 0.64, 0.54],\n",
    "    os.path.join('20190915_balancing_drop_n2_train_mass_ss', 'v11'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190915_balancing_drop_n2_train_mass_ss', 'v19'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190915_balancing_drop_n2_train_mass_kc', 'v11'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190915_balancing_drop_n2_train_mass_kc', 'v19'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190916_balancing_drop_v2_n2_train_mass_ss', 'v11'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190916_balancing_drop_v2_n2_train_mass_ss', 'v19'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190916_balancing_weight_n2_train_mass_ss', 'v11'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190916_balancing_weight_n2_train_mass_ss', 'v19'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190917_out_proba_init_grid_n2_train_mass_ss', 'p_0.01_lr_0.0001'): [0.44, 0.54, 0.56, 0.32],\n",
    "    os.path.join('20190917_out_proba_init_grid_n2_train_mass_ss', 'p_0.1_lr_0.0001'): [0.24, 0.42, 0.54, 0.48],\n",
    "    os.path.join('20190917_out_proba_init_equal_n2_train_mass_ss', 'v11'): [0.28, 0.58, 0.56, 0.4],\n",
    "    os.path.join('20190927_out_proba_cwt_grid_n2_train_mass_ss', 'p_0.5_lr_0.0001'): [0.36, 0.42, 0.62, 0.4],\n",
    "    os.path.join('20190927_out_proba_cwt_grid_n2_train_mass_ss', 'p_0.01_lr_0.0001'): [0.42, 0.46, 0.54, 0.36],\n",
    "    os.path.join('20191003_loss_grid_cwt_n2_train_mass_ss', 'v19_p_0.5_focal_loss_gamma_1.0'): [0.42, 0.60, 0.58, 0.44],\n",
    "    os.path.join('20191003_loss_grid_cwt_n2_train_mass_ss', 'v19_p_0.5_focal_loss_gamma_1.5'): [0.44, 0.50, 0.52, 0.52],\n",
    "    os.path.join('20191003_loss_grid_cwt_n2_train_mass_ss', 'v19_p_0.5_focal_loss_gamma_2.0'): [0.44, 0.52, 0.54, 0.50],\n",
    "    os.path.join('20190927_loss_grid_n2_train_mass_ss', 'v11_p_0.5_focal_loss_gamma_1.0'): [0.48, 0.50, 0.54, 0.50],\n",
    "    os.path.join('20190927_loss_grid_n2_train_mass_ss', 'v11_p_0.5_focal_loss_gamma_1.5'): [0.42, 0.50, 0.56, 0.44],\n",
    "    os.path.join('20190927_loss_grid_n2_train_mass_ss', 'v11_p_0.5_focal_loss_gamma_2.0'): [0.46, 0.54, 0.54, 0.46],\n",
    "    os.path.join('20190927_loss_grid_n2_train_mass_ss', 'v11_p_0.5_dice_loss_gamma_None'): [0.50, 0.50, 0.50, 0.50],\n",
    "}\n",
    "\n",
    "ckpt_folder = os.path.join('20190927_out_proba_cwt_grid_n2_train_mass_ss', 'p_0.5_lr_0.0001')\n",
    "new_split_version = True\n",
    "optimal_thr_list = optimal_thr_for_ckpt_dict[ckpt_folder]\n",
    "task_mode = constants.N2_RECORD\n",
    "dataset_name = constants.MASS_SS_NAME\n",
    "seed_id_list = [0, 1, 2, 3]\n",
    "# seed_id_list = [1]\n",
    "\n",
    "n_seeds = len(seed_id_list)\n",
    "set_list = [constants.TRAIN_SUBSET, constants.VAL_SUBSET, constants.TEST_SUBSET]\n",
    "# set_list = [constants.TEST_SUBSET]\n",
    "which_expert = 1\n",
    "verbose = False\n",
    "\n",
    "# Load data\n",
    "dataset = load_dataset(dataset_name, params={pkeys.NORM_COMPUTATION_MODE: constants.NORM_GLOBAL})\n",
    "fs = dataset.fs\n",
    "all_train_ids = dataset.train_ids\n",
    "test_ids = dataset.test_ids\n",
    "predictions_dict = {}\n",
    "for k in seed_id_list:\n",
    "    # Restore predictions\n",
    "    ckpt_path = os.path.abspath(os.path.join(\n",
    "        RESULTS_PATH,\n",
    "        'predictions_%s' % dataset_name,\n",
    "        ckpt_folder,\n",
    "        'seed%d' % k\n",
    "    ))\n",
    "    this_dict = {}\n",
    "    for set_name in set_list:\n",
    "        filename = os.path.join(\n",
    "                ckpt_path,\n",
    "                'prediction_%s_%s.pkl' % (task_mode, set_name))\n",
    "        with open(filename, 'rb') as handle:\n",
    "            this_pred = RefactorUnpickler(handle).load()\n",
    "        this_dict[set_name] = this_pred\n",
    "    predictions_dict[k] = this_dict\n",
    "    print('Loaded seed %d/%d from %s' % (k + 1, n_seeds, ckpt_path))\n",
    "print('Optimal thr:', optimal_thr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output thr selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_id_for_selection = 1\n",
    "\n",
    "\n",
    "# Adjust thr\n",
    "res_thr = 0.02\n",
    "start_thr = 0.3\n",
    "end_thr = 0.7\n",
    "n_thr = int(np.round((end_thr - start_thr) / res_thr + 1))\n",
    "thr_list = np.array([start_thr + res_thr * i for i in range(n_thr)])\n",
    "thr_list = np.round(thr_list, 2)\n",
    "print('%d thresholds to be evaluated between %1.4f and %1.4f'\n",
    "      % (n_thr, thr_list[0], thr_list[-1]))\n",
    "\n",
    "per_seed_af1 = []\n",
    "# Validation split\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_id_for_selection)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_id_for_selection])\n",
    "\n",
    "ids_dict = {\n",
    "    constants.TRAIN_SUBSET: train_ids,\n",
    "    constants.VAL_SUBSET: val_ids}\n",
    "for thr in thr_list:\n",
    "    events_list = []\n",
    "    detections_list = []\n",
    "    for set_name in [constants.TRAIN_SUBSET, constants.VAL_SUBSET]:\n",
    "        # Prepare expert labels\n",
    "        data_inference = FeederDataset(\n",
    "            dataset, ids_dict[set_name], task_mode,\n",
    "            which_expert=which_expert)\n",
    "        this_events = data_inference.get_stamps()\n",
    "        # Prepare model predictions\n",
    "        prediction_obj = predictions_dict[seed_id_for_selection][set_name]\n",
    "        prediction_obj.set_probability_threshold(thr)\n",
    "        this_detections = prediction_obj.get_stamps()\n",
    "        events_list = events_list + this_events\n",
    "        detections_list = detections_list + this_detections\n",
    "    # Compute AF1\n",
    "    af1_at_thr = metrics.average_metric_with_list(\n",
    "        events_list, detections_list, verbose=False)\n",
    "    per_seed_af1.append(af1_at_thr)\n",
    "print('Done')\n",
    "max_idx = np.argmax(per_seed_af1).item()\n",
    "this_best_thr = thr_list[max_idx]\n",
    "print('Best thr: %1.2f' % this_best_thr)\n",
    "\n",
    "# For best thr, compute F1 vs IoU curve\n",
    "events_list = []\n",
    "detections_list = []\n",
    "for set_name in [constants.TRAIN_SUBSET, constants.VAL_SUBSET]:\n",
    "    # Prepare expert labels\n",
    "    data_inference = FeederDataset(\n",
    "        dataset, ids_dict[set_name], task_mode,\n",
    "        which_expert=which_expert)\n",
    "    this_events = data_inference.get_stamps()\n",
    "    # Prepare model predictions\n",
    "    prediction_obj = predictions_dict[seed_id_for_selection][set_name]\n",
    "    prediction_obj.set_probability_threshold(this_best_thr)\n",
    "    this_detections = prediction_obj.get_stamps()\n",
    "    events_list = events_list + this_events\n",
    "    detections_list = detections_list + this_detections\n",
    "# Compute AF1\n",
    "first_iou = 0\n",
    "last_iou = 1\n",
    "res_iou = 0.01\n",
    "n_points = int(np.round((last_iou - first_iou) / res_iou))\n",
    "full_iou_list = np.arange(n_points + 1) * res_iou + first_iou\n",
    "f1_alltrain = metrics.metric_vs_iou_with_list(\n",
    "    events_list, detections_list, full_iou_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3), dpi=200)\n",
    "\n",
    "ax[0].plot(full_iou_list, f1_alltrain, color=CUSTOM_COLOR['red'])\n",
    "ax[0].fill_between(full_iou_list, f1_alltrain, 0, color=CUSTOM_COLOR['red'], alpha=0.5)\n",
    "ax[0].set_title('F1 vs IoU curve at $\\mu$=%1.2f' % this_best_thr, fontsize=10)\n",
    "ax[0].set_xlim([0, 1])\n",
    "ax[0].set_ylim([0, 1])\n",
    "ax[0].set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax[0].set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax[0].tick_params(labelsize=7)\n",
    "ax[0].set_xlabel('IoU Threshold', fontsize=7)\n",
    "ax[0].set_ylabel('F1-score', fontsize=7)\n",
    "\n",
    "min_y = np.min(per_seed_af1) - 0.05\n",
    "max_y = np.max(per_seed_af1) + 0.05\n",
    "ax[1].plot(\n",
    "    thr_list, per_seed_af1, \n",
    "    color=CUSTOM_COLOR['red'], marker='o', markersize=4, label='Train+val set', zorder=10)\n",
    "ax[1].plot(\n",
    "    [this_best_thr, this_best_thr], [min_y, max_y], \n",
    "    color=CUSTOM_COLOR['grey'], linestyle='--', linewidth=1.5, label='Optimal $\\mu$=%1.2f' % this_best_thr, zorder=5)\n",
    "ax[1].set_title('Adjustment of $\\mu$', fontsize=10)\n",
    "ax[1].set_xticks([0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "ax[1].set_ylim([min_y, max_y])\n",
    "ax[1].tick_params(labelsize=7)\n",
    "ax[1].set_xlabel('Model Output Threshold $\\mu$', fontsize=7)\n",
    "ax[1].set_ylabel('AF1', fontsize=7)\n",
    "ax[1].legend(loc='upper right', fontsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: F1 vs IoU curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ---------------- Compute performance\n",
    "f1_vs_iou_dict = {}\n",
    "first_iou = 0.1\n",
    "last_iou = 0.9\n",
    "step_iou = 0.1\n",
    "n_points = int((last_iou - first_iou) / step_iou)\n",
    "iou_list = first_iou + np.arange(n_points + 1) * step_iou\n",
    "iou_list_short = np.arange(1, 10) * 0.1\n",
    "iou_list_short_idx = [np.where(np.isclose(iou_list, this_value))[0][0] for this_value in iou_list_short]\n",
    "\n",
    "# Prepare expert labels\n",
    "data_test = FeederDataset(\n",
    "    dataset, test_ids, task_mode, which_expert=which_expert)\n",
    "this_events = data_test.get_stamps()\n",
    "\n",
    "seed_stamps = []\n",
    "test_af1_list = []\n",
    "seed_mean_ioutp = []\n",
    "for k in seed_id_list:\n",
    "    # Prepare model predictions\n",
    "    prediction_test = predictions_dict[k][constants.TEST_SUBSET]\n",
    "    \n",
    "    prediction_test.set_probability_threshold(optimal_thr_list[k])\n",
    "    this_detections = prediction_test.get_stamps()\n",
    "    seed_stamps.append(this_detections)\n",
    "    this_f1_vs_iou = metrics.metric_vs_iou_with_list(\n",
    "        this_events, this_detections, iou_list)\n",
    "    this_af1 = metrics.average_metric_with_list(this_events, this_detections)\n",
    "    f1_vs_iou_dict[k] = this_f1_vs_iou\n",
    "    test_af1_list.append(this_af1)\n",
    "    \n",
    "    # Measure iou of TP\n",
    "    mean_iou_per_subject = []\n",
    "    for single_events, single_detections in zip(this_events, this_detections):\n",
    "        this_iou_array, idx_array = metrics.matching(single_events, single_detections)\n",
    "        this_iou_array = this_iou_array[idx_array > -1]\n",
    "        mean_iou_per_subject.append(np.mean(this_iou_array))\n",
    "    seed_mean_ioutp.append(np.mean(mean_iou_per_subject))\n",
    "    \n",
    "# Mean performance\n",
    "mean_f1_vs_iou = np.stack([f1_vs_iou_dict[k] for k in seed_id_list], axis=1).mean(axis=1)\n",
    "std_f1_vs_iou = np.stack([f1_vs_iou_dict[k] for k in seed_id_list], axis=1).std(axis=1)\n",
    "mean_f1_vs_iou_short = mean_f1_vs_iou[iou_list_short_idx]\n",
    "std_f1_vs_iou_short = std_f1_vs_iou[iou_list_short_idx]\n",
    "\n",
    "print('IoU   Mean    Std')\n",
    "for k in range(iou_list_short.size):\n",
    "    print('%1.2f  %1.4f  %1.4f' % (iou_list_short[k], mean_f1_vs_iou_short[k], std_f1_vs_iou_short[k]))\n",
    "    \n",
    "print('Test AF1: %1.4f +- %1.4f' % (np.mean(test_af1_list), np.std(test_af1_list)))\n",
    "print('Test AF1 per seed:', test_af1_list)\n",
    "print('Test Mean IoU at TP: %1.4f +- %1.4f' % (np.mean(seed_mean_ioutp), np.std(seed_mean_ioutp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "filename = '%s_f1_vs_iou.npy' % (ckpt_folder.split('/')[0])\n",
    "data = np.stack([iou_list, mean_f1_vs_iou, std_f1_vs_iou], axis=1).astype(np.float32)\n",
    "np.save(filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_thr = 0.5  # Majority vote is 0.5\n",
    "binarized_first = True\n",
    "\n",
    "detections_half_rule_list = []\n",
    "detections_greater_half_rule_list = []\n",
    "\n",
    "postprocessor = PostProcessor(\n",
    "    predictions_dict[0][constants.TEST_SUBSET].event_name, \n",
    "    predictions_dict[0][constants.TEST_SUBSET].params)\n",
    "\n",
    "for j in range(len(test_ids)):\n",
    "    if task_mode == constants.N2_RECORD:\n",
    "        pages_indices_subset = predictions_dict[0][constants.TEST_SUBSET].get_subject_pages(\n",
    "            test_ids[j], pages_subset=constants.N2_RECORD, verbose=False)\n",
    "    else:\n",
    "        pages_indices_subset = None\n",
    "    \n",
    "    this_subject_detections_list_seq = [predictions_dict[k][constants.TEST_SUBSET].get_probabilities()[j].astype(np.float32) for k in seed_id_list]\n",
    "    if binarized_first:\n",
    "        this_subject_detections_list_seq = [(this_det >= this_thr).astype(np.int32) for (this_det, this_thr) in zip(this_subject_detections_list_seq, optimal_thr_list)]\n",
    "    this_subject_detections_mean = np.stack(this_subject_detections_list_seq, axis=0).mean(axis=0)\n",
    "    \n",
    "    detections_half_rule = postprocessor.proba2stamps(\n",
    "        this_subject_detections_mean, None, pages_indices_subset, thr=ensamble_thr)\n",
    "    detections_half_rule_list.append(detections_half_rule)\n",
    "    \n",
    "half_rule_f1_vs_iou = metrics.metric_vs_iou_with_list(\n",
    "        this_events, detections_half_rule_list, iou_list)\n",
    "half_rule_af1 = metrics.average_metric_with_list(this_events, detections_half_rule_list)\n",
    "\n",
    "half_rule_f1_vs_iou_short = half_rule_f1_vs_iou[iou_list_short_idx]\n",
    "\n",
    "print('IoU   Mean')\n",
    "for k in range(iou_list_short.size):\n",
    "    print('%1.2f  %1.4f' % (iou_list_short[k], half_rule_f1_vs_iou_short[k]))\n",
    "\n",
    "print('Test AF1 Ensamble:')\n",
    "print('Half Rule: %1.4f' % half_rule_af1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bsf_name = 'Proposed (%s)' % task_mode.upper()\n",
    "\n",
    "compare_expert = True\n",
    "compare_chambon = False\n",
    "show_seed_std = True\n",
    "show_seed_curves = False\n",
    "show_ensamble = False\n",
    "alpha = 0.3\n",
    "color_list = {'model_mean': CUSTOM_COLOR['red'] , 'expert': CUSTOM_COLOR['grey'], 'dosed': CUSTOM_COLOR['blue']}\n",
    "linewidth_model = 1.5\n",
    "markersize_model = 7\n",
    "linewidth_others = 1.5\n",
    "markersize_others = 7\n",
    "\n",
    "# -------------------- P L O T ----------------------    \n",
    "\n",
    "# Comparison data\n",
    "compare_expert = (compare_expert and (dataset.event_name == constants.SPINDLE))\n",
    "if compare_expert:\n",
    "    expert_f1_curve_mean = np.loadtxt(os.path.join(COMPARISON_PATH, 'expert', 'ss_f1_vs_iou_expert_mean.csv'), delimiter=',')\n",
    "    expert_f1_curve_std = np.loadtxt(os.path.join(COMPARISON_PATH, 'expert', 'ss_f1_vs_iou_expert_std.csv'), delimiter=',')\n",
    "    expert_f1_curve_mean = expert_f1_curve_mean[1:, :]\n",
    "    expert_f1_curve_std = expert_f1_curve_std[1:, :]\n",
    "if compare_chambon and (dataset_name == constants.MASS_SS_NAME):\n",
    "    dosed_f1_curve_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_ss_wn_f1_vs_iou_dosed_separately.csv'), delimiter=',')\n",
    "if compare_chambon and (dataset_name == constants.MASS_KC_NAME):\n",
    "    dosed_f1_curve_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_kc_wn_f1_vs_iou_dosed_separately.csv'), delimiter=',')\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "\n",
    "\n",
    "# Complete plot\n",
    "if compare_expert:\n",
    "    ax.plot(expert_f1_curve_mean[:, 0], expert_f1_curve_mean[:, 1], linewidth=linewidth_others, \n",
    "               label='Expert Performance\\nPrivate Dataset\\nWarby et al. 2014', color=color_list['expert'])\n",
    "    ax.plot(expert_f1_curve_mean[:, 0], expert_f1_curve_mean[:, 1], linestyle='none', \n",
    "               markersize=markersize_others, marker='.', color=color_list['expert'])\n",
    "    ax.fill_between(\n",
    "        expert_f1_curve_mean[:, 0], \n",
    "        expert_f1_curve_mean[:, 1] - expert_f1_curve_std[:, 1], \n",
    "        expert_f1_curve_mean[:, 1] + expert_f1_curve_std[:, 1], \n",
    "        alpha=alpha, facecolor=color_list['expert'])\n",
    "\n",
    "if compare_chambon and (dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]):\n",
    "    ax.plot(dosed_f1_curve_wn[:, 0], dosed_f1_curve_wn[:, 1], linewidth=linewidth_others,\n",
    "               label='DOSED (WN) (Paper)\\nChambon et al. 2019', color=color_list['dosed'])\n",
    "    ax.plot(dosed_f1_curve_wn[:, 0], dosed_f1_curve_wn[:, 1], linestyle='none',\n",
    "               markersize=markersize_others, marker='.', color=color_list['dosed'])\n",
    "    idx_to_show = np.where(np.isclose(dosed_f1_curve_wn[:, 0], 0.3))[0][0]\n",
    "    print('%1.4f Dosed F1 at 0.3' % dosed_f1_curve_wn[idx_to_show, 1])\n",
    "\n",
    "if show_seed_curves:\n",
    "    for k in seed_id_list:\n",
    "        ax.plot(iou_list, f1_vs_iou_dict[k], \n",
    "           linewidth=linewidth_model, markersize=markersize_model, marker='.', alpha=0.3,\n",
    "           color=color_list['model_mean'])\n",
    "        \n",
    "ax.plot(iou_list, mean_f1_vs_iou, \n",
    "           linewidth=linewidth_model,\n",
    "           label='%s (Mean)' % bsf_name, color=color_list['model_mean'])\n",
    "ax.plot(iou_list_short, mean_f1_vs_iou_short, \n",
    "           linestyle='none', markersize=markersize_model, marker='.', \n",
    "           color=color_list['model_mean'])\n",
    "idx_to_show = np.where(np.isclose(iou_list, 0.3))[0][0]\n",
    "print('%1.4f Proposed mean F1 at 0.3' % mean_f1_vs_iou[idx_to_show])\n",
    "if show_seed_std:\n",
    "    ax.fill_between(\n",
    "        iou_list, \n",
    "        mean_f1_vs_iou - std_f1_vs_iou, \n",
    "        mean_f1_vs_iou + std_f1_vs_iou, \n",
    "        alpha=alpha, facecolor=color_list['model_mean'])\n",
    "\n",
    "if show_ensamble:\n",
    "    ax.plot(iou_list, half_rule_f1_vs_iou, \n",
    "           linewidth=linewidth_model, \n",
    "           label='%s (Ensemble)' % bsf_name, color=CUSTOM_COLOR['green'])\n",
    "    ax.plot(iou_list_short, half_rule_f1_vs_iou_short, \n",
    "           linestyle='none', markersize=markersize_model, marker='.', \n",
    "           color=CUSTOM_COLOR['green'])\n",
    "    \n",
    "ax.set_title('Test Performance (%s Dataset)' % dataset_name.upper(), fontsize=10)\n",
    "ax.set_xlim([0.1 - 0.02, 0.9 + 0.02])\n",
    "ax.set_ylim([0.1 - 0.02, 0.9 + 0.02])\n",
    "ax.set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax.set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax.set_ylabel('F1-score', fontsize=8.5)\n",
    "ax.yaxis.grid()\n",
    "ax.legend(loc='lower left', labelspacing=1.5, fontsize=6.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only test set\n",
    "alpha = 0.2\n",
    "seed_id_for_scatter = 0\n",
    "\n",
    "\n",
    "# Prepare model predictions\n",
    "prediction_obj = predictions_dict[seed_id_for_scatter][constants.VAL_SUBSET]\n",
    "prediction_obj.set_probability_threshold(optimal_thr_list[seed_id_for_scatter])\n",
    "this_detections_list = prediction_obj.get_stamps()\n",
    "this_ids = prediction_obj.get_ids()\n",
    "\n",
    "# Prepare expert labels\n",
    "data_inference = FeederDataset(\n",
    "    dataset, this_ids, task_mode, which_expert)\n",
    "this_events_list = data_inference.get_stamps()\n",
    "\n",
    "expert_durations_list = []\n",
    "predicted_durations_list = []\n",
    "for i, single_id in enumerate(this_ids):\n",
    "    single_events = this_events_list[i]\n",
    "    single_detections = this_detections_list[i]\n",
    "    this_iou_array, this_idx_array = metrics.matching(single_events, single_detections)\n",
    "    idx_valid = (this_idx_array > -1)\n",
    "    matched_expert_durations = (single_events[idx_valid, 1] - single_events[idx_valid, 0]) / fs\n",
    "    matched_detections = single_detections[this_idx_array]\n",
    "    matched_predicted_durations = (matched_detections[idx_valid, 1] - matched_detections[idx_valid, 0]) / fs\n",
    "    expert_durations_list.append(matched_expert_durations)\n",
    "    predicted_durations_list.append(matched_predicted_durations)\n",
    "\n",
    "fig, ax = plt.subplots(1, len(this_ids), figsize=(8, 3), dpi=DPI)\n",
    "for i, subject_id in enumerate(this_ids):\n",
    "    ax[i].scatter(\n",
    "        expert_durations_list[i], predicted_durations_list[i], \n",
    "        label='S%02d' % subject_id, color='#455a64', alpha=alpha)\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "    lg = ax[i].legend(fontsize=7)\n",
    "    for lh in lg.legendHandles:\n",
    "        lh.set_facecolor(lh.get_facecolor())\n",
    "        lh.set_edgecolor(lh.get_edgecolor())\n",
    "        lh.set_alpha(1.0)\n",
    "    max_dur = max(expert_durations_list[i].max(), predicted_durations_list[i].max())\n",
    "    ax[i].set_xlim([0, max_dur + 0.1])\n",
    "    ax[i].set_ylim([0, max_dur + 0.1])\n",
    "    if i == 0 :\n",
    "        ax[i].set_ylabel('Detected duration [s]', fontsize=8.5)\n",
    "    ax[i].set_xlabel('Duration Real [s]', fontsize=8.5)\n",
    "    ax[i].plot([0.3, 2.0], [0.3, 2.0], '--k', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 vs IoU by subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_id_for_f1vsiou = 0\n",
    "\n",
    "# ---------------- Compute performance\n",
    "f1_vs_iou_subject_dict = {}\n",
    "pre_vs_iou_subject_dict = {}\n",
    "rec_vs_iou_subject_dict = {}\n",
    "iou_list = np.arange(21) * 0.05\n",
    "\n",
    "# Validation split\n",
    "# train_ids, val_ids = utils.split_ids_list(\n",
    "#    all_train_ids, seed=SEED_LIST[seed_id_for_f1vsiou], verbose=False)\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_id_for_f1vsiou)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_id_for_f1vsiou])\n",
    "ids_dict = {\n",
    "    constants.TRAIN_SUBSET: train_ids,\n",
    "    constants.VAL_SUBSET: val_ids,\n",
    "    constants.TEST_SUBSET: test_ids\n",
    "}\n",
    "\n",
    "for set_name in set_list:\n",
    "    print('Processing %s' % set_name, flush=True)\n",
    "    # Prepare expert labels\n",
    "    data_inference = FeederDataset(\n",
    "        dataset, ids_dict[set_name], task_mode, which_expert)\n",
    "    this_ids = data_inference.get_ids()\n",
    "    this_events_list = data_inference.get_stamps()\n",
    "    # Prepare model predictions\n",
    "    prediction_obj = predictions_dict[seed_id_for_f1vsiou][set_name]\n",
    "    prediction_obj.set_probability_threshold(optimal_thr_list[seed_id_for_f1vsiou])\n",
    "    this_detections_list = prediction_obj.get_stamps()\n",
    "    for i, single_id in enumerate(this_ids):\n",
    "        single_events = this_events_list[i]\n",
    "        single_detections = this_detections_list[i]\n",
    "        this_precision = metrics.metric_vs_iou(single_events, single_detections, iou_list, metric_name=constants.PRECISION)\n",
    "        this_recall = metrics.metric_vs_iou(single_events, single_detections, iou_list, metric_name=constants.RECALL)\n",
    "        this_f1 = 2 * this_precision * this_recall / (this_precision + this_recall + 1e-8)\n",
    "        pre_vs_iou_subject_dict[single_id] = this_precision\n",
    "        rec_vs_iou_subject_dict[single_id] = this_recall\n",
    "        f1_vs_iou_subject_dict[single_id] = this_f1\n",
    "print('Done', flush=True)\n",
    "\n",
    "color_list = {'train': CUSTOM_COLOR['green'] , 'val': CUSTOM_COLOR['grey'], 'test': CUSTOM_COLOR['red']}\n",
    "marker_list = ['.', 's', '^', 'x', '*', 'd', 'v', 'p']\n",
    "linewidth_model = 1\n",
    "markersize_model = 5\n",
    "\n",
    "# -------------------- P L O T ----------------------    \n",
    "    \n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4), dpi=DPI)\n",
    "\n",
    "# F1\n",
    "for set_name in set_list:\n",
    "    for i, single_id in enumerate(ids_dict[set_name]):\n",
    "        ax[0].plot(iou_list, f1_vs_iou_subject_dict[single_id], \n",
    "                   linewidth=linewidth_model, markersize=markersize_model, marker=marker_list[i], \n",
    "                   label='S%02d' % single_id, color=color_list[set_name])\n",
    "\n",
    "    \n",
    "ax[0].set_title('Test Performance (%s Dataset) (%s)' \n",
    "             % (dataset_name.upper(), task_mode.upper()), fontsize=10)\n",
    "ax[0].set_xlim([0, 1])\n",
    "ax[0].set_ylim([0, 1])\n",
    "ax[0].set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax[0].set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax[0].tick_params(labelsize=8.5)\n",
    "ax[0].set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax[0].set_ylabel('F1-score', fontsize=8.5)\n",
    "ax[0].yaxis.grid()\n",
    "ax[0].legend(loc='lower left', fontsize=5)\n",
    "\n",
    "# Precision\n",
    "for set_name in set_list:\n",
    "    for i, single_id in enumerate(ids_dict[set_name]):\n",
    "        ax[1].plot(iou_list, pre_vs_iou_subject_dict[single_id], \n",
    "                   linewidth=linewidth_model, markersize=markersize_model, marker=marker_list[i], \n",
    "                   label='S%02d' % single_id, color=color_list[set_name])\n",
    "\n",
    "    \n",
    "ax[1].set_title('Test Performance (%s Dataset) (%s)' \n",
    "             % (dataset_name.upper(), task_mode.upper()), fontsize=10)\n",
    "ax[1].set_xlim([0, 1])\n",
    "ax[1].set_ylim([0, 1])\n",
    "ax[1].set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax[1].set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax[1].tick_params(labelsize=8.5)\n",
    "ax[1].set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax[1].set_ylabel('Precision', fontsize=8.5)\n",
    "ax[1].yaxis.grid()\n",
    "ax[1].legend(loc='lower left', fontsize=5)\n",
    "\n",
    "# Recall\n",
    "for set_name in set_list:\n",
    "    for i, single_id in enumerate(ids_dict[set_name]):\n",
    "        ax[2].plot(iou_list, rec_vs_iou_subject_dict[single_id], \n",
    "                   linewidth=linewidth_model, markersize=markersize_model, marker=marker_list[i], \n",
    "                   label='S%02d' % single_id, color=color_list[set_name])\n",
    "\n",
    "    \n",
    "ax[2].set_title('Test Performance (%s Dataset) (%s)' \n",
    "             % (dataset_name.upper(), task_mode.upper()), fontsize=10)\n",
    "ax[2].set_xlim([0, 1])\n",
    "ax[2].set_ylim([0, 1])\n",
    "ax[2].set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax[2].set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax[2].tick_params(labelsize=8.5)\n",
    "ax[2].set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax[2].set_ylabel('Recall', fontsize=8.5)\n",
    "ax[2].yaxis.grid()\n",
    "ax[2].legend(loc='lower left', fontsize=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR by subject, usando APrecision y ARecall\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "markersize = 10\n",
    "text_space = 0.01\n",
    "show_ids = True\n",
    "axis_lims = [0, 1]\n",
    "show_set_list = ['train', 'val', 'test']\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "\n",
    "levels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "levels = [level for level in levels if (level>axis_lims[0] and level<axis_lims[1])]\n",
    "\n",
    "CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=levels)\n",
    "ax.clabel(CS, fontsize=6, fmt='%1.2f')\n",
    "\n",
    "for set_name in set_list:\n",
    "    if set_name in show_set_list:\n",
    "        for i, single_id in enumerate(ids_dict[set_name]):\n",
    "            if i==0:\n",
    "                label = 'Proposed (%s) (%s)' % (task_mode.upper(), set_name.capitalize())\n",
    "            else:\n",
    "                label = None\n",
    "            this_arecall = rec_vs_iou_subject_dict[single_id].mean()\n",
    "            this_aprecision = pre_vs_iou_subject_dict[single_id].mean()\n",
    "            ax.scatter(\n",
    "                this_arecall, this_aprecision, \n",
    "                c=color_list[set_name], \n",
    "                label=label, marker='s',\n",
    "                s=markersize, zorder=10)\n",
    "            if show_ids:\n",
    "                ax.annotate(\n",
    "                    single_id, \n",
    "                    (this_arecall+text_space, this_aprecision+text_space), \n",
    "                    fontsize=7, color='#1b2631', zorder=20) \n",
    "ax.set_title('Seed %d ($\\mu$=%1.2f)' % (seed_id_for_f1vsiou, optimal_thr_list[seed_id_for_f1vsiou]), fontsize=7)\n",
    "ax.set_xlabel('A-Recall', fontsize=7)\n",
    "ax.set_ylabel('A-Precision', fontsize=7)\n",
    "ax.set_xlim(axis_lims)\n",
    "ax.set_ylim(axis_lims)\n",
    "ax.tick_params(labelsize=7)\n",
    "ax.legend(loc='lower left', fontsize=5)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: Precision-Recall curve, average per set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_thr = 0.3\n",
    "res_thr = 0.02\n",
    "start_thr = 0.1\n",
    "end_thr = 0.9\n",
    "n_thr = int(np.round((end_thr - start_thr) / res_thr + 1))\n",
    "thr_list = np.array([start_thr + res_thr * i for i in range(n_thr)])\n",
    "\n",
    "pr_curve = {}\n",
    "# Prepare expert labels\n",
    "data_test = FeederDataset(\n",
    "    dataset, test_ids, task_mode, which_expert=which_expert)\n",
    "this_events = data_test.get_stamps()\n",
    "for k in seed_id_list:\n",
    "    print('Processing seed %d' % k, flush=True)\n",
    "    # Columns are [x: recall, y: precision]\n",
    "    pr_curve[k] = np.zeros((n_thr, 2))\n",
    "    for i, thr in enumerate(thr_list):\n",
    "        # Prepare model predictions\n",
    "        prediction_test = predictions_dict[k][constants.TEST_SUBSET]\n",
    "        prediction_test.set_probability_threshold(thr)\n",
    "        this_detections = prediction_test.get_stamps()\n",
    "        \n",
    "        this_stats = [metrics.by_event_confusion(this_y, this_y_pred, iou_thr=iou_thr) \n",
    "                    for (this_y, this_y_pred) in zip(this_events, this_detections)]\n",
    "        this_recall = np.mean([m[constants.RECALL] for m in this_stats])\n",
    "        this_precision = np.mean([m[constants.PRECISION] for m in this_stats])\n",
    "        pr_curve[k][i, 0] = this_recall\n",
    "        pr_curve[k][i, 1] = this_precision\n",
    "\n",
    "# Mean of runs\n",
    "# pr_curve['mean_runs'] = np.stack([pr_curve[k] for k in seed_id_list], axis=2).mean(axis=2)\n",
    "print('Done', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "filename = '%s_pr_curve.npy' % (ckpt_folder.split('/')[0])\n",
    "data = []\n",
    "this_thr = np.asarray(thr_list)[:, np.newaxis]\n",
    "for k in seed_id_list:\n",
    "    this_pr = pr_curve[k]\n",
    "    this_pr = np.concatenate([this_thr, this_pr], axis=1)\n",
    "    data.append(this_pr)\n",
    "data = np.stack(data, axis=0).astype(np.float32)\n",
    "np.save(filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot \n",
    "bsf_name = 'Proposed (%s)' % task_mode.upper()\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "markersize = 6\n",
    "alpha = 0.4\n",
    "text_space = 0.01\n",
    "compare_chambon = False\n",
    "show_seeds = True\n",
    "axis_lims = [0.0, 1.0]\n",
    "color_list = {'model_mean': CUSTOM_COLOR['red'] , 'dosed': CUSTOM_COLOR['blue']}\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "\n",
    "levels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "levels = [level for level in levels if (level>axis_lims[0] and level<axis_lims[1])]\n",
    "\n",
    "CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=levels)\n",
    "ax.clabel(CS, fontsize=7.5, fmt='%1.2f')\n",
    "\n",
    "# Chambon\n",
    "if compare_chambon and (dataset_name == constants.MASS_SS_NAME):\n",
    "    dosed_rec_prec_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_ss_wn_pr_dosed_separately.csv'), delimiter=',')\n",
    "    ax.plot(dosed_rec_prec_wn[0], dosed_rec_prec_wn[1], \n",
    "           markersize=8, c=color_list['dosed'], zorder=10, \n",
    "            label='DOSED (WN) (Paper)', marker='o', linestyle=\"None\")\n",
    "if compare_chambon and (dataset_name == constants.MASS_KC_NAME):\n",
    "    dosed_rec_prec_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_kc_wn_pr_dosed_separately.csv'), delimiter=',')\n",
    "    ax.plot(dosed_rec_prec_wn[0], dosed_rec_prec_wn[1], \n",
    "           markersize=8, c=color_list['dosed'], zorder=10, \n",
    "            label='DOSED (WN) (Paper)', marker='o', linestyle=\"None\")\n",
    "    \n",
    "if show_seeds:\n",
    "    # Show single seeds\n",
    "    seed_shown = False\n",
    "    for k in seed_id_list:\n",
    "        if not seed_shown:\n",
    "            seed_shown=True\n",
    "            label = '%s (Seed curve)' % bsf_name\n",
    "            label_2 = '%s (Seed O.P.)' % bsf_name\n",
    "        else:\n",
    "            label = None\n",
    "            label_2 = None\n",
    "        ax.plot(pr_curve[k][:, 0], pr_curve[k][:, 1], \n",
    "            label=label,\n",
    "            linewidth=1, color=color_list['model_mean'], zorder=7, alpha=alpha)\n",
    "        \n",
    "        chosen_thr_idx = np.where(np.isclose(thr_list, optimal_thr_list[k]))[0].item()\n",
    "        ax.scatter(pr_curve[k][chosen_thr_idx, 0], pr_curve[k][chosen_thr_idx, 1], \n",
    "                   s=50, c=color_list['model_mean'], zorder=7, alpha=alpha, label=label_2)\n",
    "    \n",
    "# Mean of runs\n",
    "# ax.plot(pr_curve['mean_runs'][:, 0], pr_curve['mean_runs'][:, 1], \n",
    "#         label='%s (Mean)' % bsf_name,\n",
    "#         linewidth=1.5, color=color_list['model_mean'], zorder=10)\n",
    "\n",
    "# Highlight chosen operating point\n",
    "# chosen_thr_idx = np.where(np.isclose(thr_list, thr_run))[0].item()\n",
    "# ax.scatter(pr_curve['mean_runs'][chosen_thr_idx, 0], pr_curve['mean_runs'][chosen_thr_idx, 1], \n",
    "#            s=50, c=color_list['model_mean'], zorder=10, label='Operating point $\\mu$=%1.2f' % thr_run)\n",
    "# ax.annotate('$\\mu$=%1.3f' % thr_run, \n",
    "#             (pr_curve['mean_runs'][chosen_thr_idx, 0], \n",
    "#              pr_curve['mean_runs'][chosen_thr_idx, 1] + text_space*2), \n",
    "#             fontsize=7, color='#1b2631', zorder=30)  \n",
    "\n",
    "ax.set_title('Test PR Curve with IoU$>$%1.1f (%s)' % (iou_thr, dataset_name.upper()), fontsize=10)\n",
    "ax.set_xlabel('Recall', fontsize=8.5)\n",
    "ax.set_ylabel('Precision', fontsize=8.5)\n",
    "ax.set_xlim(axis_lims)\n",
    "ax.set_ylim(axis_lims)\n",
    "\n",
    "lg = ax.legend(loc='lower left', labelspacing=1, fontsize=6.5)\n",
    "for lh in lg.legendHandles:\n",
    "    lh.set_alpha(1.0)\n",
    "\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: Precision-Recall plot, separated subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_thr = 0.3\n",
    "\n",
    "# Prepare model predictions\n",
    "be_stats = {}\n",
    "for k in seed_id_list:\n",
    "    print('Processing seed %d' % k, flush=True)\n",
    "    be_stats[k] = {}\n",
    "    if new_split_version:\n",
    "        train_ids, val_ids = utils.split_ids_list_v2(\n",
    "            all_train_ids, split_id=k)\n",
    "    else:\n",
    "        train_ids, val_ids = utils.split_ids_list(\n",
    "            all_train_ids, seed=SEED_LIST[k])\n",
    "    train_ids.sort()\n",
    "    val_ids.sort()\n",
    "    ids_per_set_dict = {\n",
    "        constants.TRAIN_SUBSET: train_ids,\n",
    "        constants.VAL_SUBSET: val_ids,\n",
    "        constants.TEST_SUBSET: test_ids\n",
    "    }\n",
    "    for set_name in set_list:\n",
    "        data_feeder = FeederDataset(\n",
    "            dataset, ids_per_set_dict[set_name], task_mode, which_expert=which_expert)\n",
    "        this_events = data_feeder.get_stamps()\n",
    "        prediction_set = predictions_dict[k][set_name]\n",
    "        prediction_set.set_probability_threshold(optimal_thr_list[k])\n",
    "        this_detections = prediction_set.get_stamps()\n",
    "        be_stats[k][set_name] = [\n",
    "            metrics.by_event_confusion(this_y, this_y_pred, iou_thr=iou_thr) \n",
    "            for (this_y, this_y_pred) in zip(this_events, this_detections)]\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot \n",
    "bsf_name = 'Proposed (%s)' % task_mode.upper()\n",
    "fig, ax = plt.subplots(1, n_seeds, figsize=(2.3*n_seeds, 2.3), dpi=DPI)\n",
    "markersize = 10\n",
    "alpha = 0.3\n",
    "text_space = 0.01\n",
    "compare_chambon = False\n",
    "show_ids = True\n",
    "axis_lims = [0.5, 1.0]\n",
    "show_set_list = ['train', 'val', 'test']\n",
    "color_list = {'train': CUSTOM_COLOR['green'] , 'val': CUSTOM_COLOR['grey'], 'test': CUSTOM_COLOR['red'], 'dosed': CUSTOM_COLOR['blue']}\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "\n",
    "levels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "levels = [level for level in levels if (level>axis_lims[0] and level<axis_lims[1])]\n",
    "\n",
    "# Chambon\n",
    "if compare_chambon and (dataset_name == constants.MASS_SS_NAME):\n",
    "    dosed_rec_prec_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_ss_wn_pr_dosed_separately.csv'), delimiter=',')\n",
    "if compare_chambon and (dataset_name == constants.MASS_KC_NAME):\n",
    "    dosed_rec_prec_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_kc_wn_pr_dosed_separately.csv'), delimiter=',')\n",
    "    \n",
    "for j in range(n_seeds):\n",
    "    seed_id = seed_id_list[j]\n",
    "    if new_split_version:\n",
    "        train_ids, val_ids = utils.split_ids_list_v2(\n",
    "            all_train_ids, split_id=seed_id)\n",
    "    else:\n",
    "        train_ids, val_ids = utils.split_ids_list(\n",
    "            all_train_ids, seed=SEED_LIST[seed_id])\n",
    "    train_ids.sort()\n",
    "    val_ids.sort()\n",
    "    ids_per_set_dict = {\n",
    "        constants.TRAIN_SUBSET: train_ids,\n",
    "        constants.VAL_SUBSET: val_ids,\n",
    "        constants.TEST_SUBSET: test_ids\n",
    "    }\n",
    "    \n",
    "    \n",
    "    CS = ax[j].contour(X, Y, Z, colors='k', alpha=0.3, levels=levels)\n",
    "    ax[j].clabel(CS, fontsize=6, fmt='%1.2f')\n",
    "    \n",
    "    if compare_chambon and (dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]):\n",
    "        ax[j].scatter(\n",
    "            dosed_rec_prec_wn[0], dosed_rec_prec_wn[1], \n",
    "            c=color_list['dosed'], \n",
    "            label='DOSED (WN)', marker='o',\n",
    "            s=markersize*3, zorder=10)\n",
    "    \n",
    "    for set_name in set_list:\n",
    "        if set_name in show_set_list:\n",
    "            for i, stats in enumerate(be_stats[seed_id][set_name]):\n",
    "                if i==0:\n",
    "                    label = 'Proposed (%s) (%s)' % (task_mode.upper(), set_name.capitalize())\n",
    "                else:\n",
    "                    label = None\n",
    "                ax[j].scatter(\n",
    "                    stats['recall'], stats['precision'], \n",
    "                    c=color_list[set_name], \n",
    "                    label=label, marker='s',\n",
    "                    s=markersize, zorder=10)\n",
    "                if show_ids:\n",
    "                    \n",
    "                    if j==0:\n",
    "                        f1_score = 2 * stats['recall'] * stats['precision'] / (stats['recall'] + stats['precision'])\n",
    "                        print('S%02d (%s) - Recall: %1.4f - Precision: %1.4f - F1: %1.4f' \n",
    "                              % (ids_per_set_dict[set_name][i], set_name.ljust(5), stats['recall'], stats['precision'], f1_score))\n",
    "                    \n",
    "                    ax[j].annotate(\n",
    "                        ids_per_set_dict[set_name][i], \n",
    "                        (stats['recall']+text_space, stats['precision']+text_space), \n",
    "                        fontsize=7, color='#1b2631', zorder=20) \n",
    "    ax[j].set_title('Seed %d ($\\mu$=%1.2f and IoU>%1.1f)' % (seed_id, optimal_thr_list[j], iou_thr), fontsize=7)\n",
    "    ax[j].set_xlabel('Recall', fontsize=7)\n",
    "    ax[j].set_ylabel('Precision', fontsize=7)\n",
    "    ax[j].set_xlim(axis_lims)\n",
    "    ax[j].set_ylim(axis_lims)\n",
    "    ax[j].tick_params(labelsize=7)\n",
    "    ax[j].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "ax[0].legend(loc='lower left', bbox_to_anchor=(0.5, -0.4), labelspacing=1, fontsize=6, ncol=(1 + len(show_set_list)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "if constants.TEST_SUBSET in show_set_list:\n",
    "    # mean test\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3), dpi=DPI)\n",
    "\n",
    "    CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=levels)\n",
    "    ax.clabel(CS, fontsize=6, fmt='%1.2f')\n",
    "\n",
    "    if compare_chambon and (dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]):\n",
    "        ax.scatter(\n",
    "            dosed_rec_prec_wn[0], dosed_rec_prec_wn[1], \n",
    "            c=color_list['dosed'], \n",
    "            label='DOSED (WN) (Paper)', marker='o',\n",
    "            s=markersize*4, zorder=10)\n",
    "        dosed_f1 = 2 * dosed_rec_prec_wn[0] * dosed_rec_prec_wn[1] / (dosed_rec_prec_wn[0] + dosed_rec_prec_wn[1])\n",
    "        # print('%1.4f Dosed F1 at 0.3' % dosed_f1)\n",
    "\n",
    "    set_name = constants.TEST_SUBSET\n",
    "\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    for i in range(len(test_ids)):\n",
    "\n",
    "        recall_mean = np.stack([be_stats[k][set_name][i]['recall'] for k in seed_id_list]).mean()\n",
    "        precision_mean = np.stack([be_stats[k][set_name][i]['precision'] for k in seed_id_list]).mean()\n",
    "        recall_list.append(recall_mean)\n",
    "        precision_list.append(precision_mean)\n",
    "        if i==0:\n",
    "            label = '%s (Single subject)' % bsf_name\n",
    "        else:\n",
    "            label = None\n",
    "        ax.scatter(\n",
    "            recall_mean, precision_mean, \n",
    "            c=color_list[set_name], \n",
    "            label=label, marker='s',\n",
    "            s=markersize, zorder=10)\n",
    "        if show_ids:\n",
    "            ax.annotate(\n",
    "                ids_per_set_dict[set_name][i], \n",
    "                (recall_mean+text_space, precision_mean+text_space), \n",
    "                fontsize=7, color='#1b2631', zorder=20)\n",
    "\n",
    "    # mean of subjects\n",
    "\n",
    "    ax.scatter(\n",
    "        np.mean(recall_list), np.mean(precision_list), \n",
    "        c=color_list[set_name], \n",
    "        label='%s (Mean of subjects)' % bsf_name, marker='o',\n",
    "        s=markersize*4, zorder=10)\n",
    "\n",
    "    ax.set_title('Mean Test PR for IoU>%1.1f (%s Detection)' % (iou_thr, dataset_name[-2:].upper()), fontsize=8)\n",
    "    ax.set_xlabel('Recall', fontsize=7)\n",
    "    ax.set_ylabel('Precision', fontsize=7)\n",
    "    ax.set_xlim(axis_lims)\n",
    "    ax.set_ylim(axis_lims)\n",
    "    ax.tick_params(labelsize=7)\n",
    "    ax.grid()\n",
    "    ax.legend(loc='lower left', fontsize=7)\n",
    "    plt.show()\n",
    "    \n",
    "    each_recall = np.asarray(recall_list)\n",
    "    each_precision = np.asarray(precision_list)\n",
    "    model_f1 = np.mean(2 * each_recall * each_precision / (each_recall + each_precision))\n",
    "    # print('%1.4f Proposed mean F1 at 0.3' % model_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20190927_out_proba_cwt_grid_n2_train_mass_ss/p_0.5_lr_0.0001\n",
      "Normalizing with Global STD of 16.482037\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed_to_show = 2\n",
    "set_name = 'val'\n",
    "subject_id = 7\n",
    "\n",
    "# -----\n",
    "print(ckpt_folder)\n",
    "\n",
    "if dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]:\n",
    "    channel_name = 'C3-CLE'\n",
    "elif dataset_name in [constants.DREAMS_SS_NAME, constants.DREAMS_KC_NAME]:\n",
    "    channel_name = 'Cz-A1'\n",
    "else:\n",
    "    channel_name = 'F4-C4'\n",
    "\n",
    "\n",
    "pages_subset = constants.N2_RECORD\n",
    "\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_to_show)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_to_show])\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids, 'alltrain': all_train_ids}\n",
    "idx_subject = idx_dict[set_name].index(subject_id)\n",
    "\n",
    "this_pages = dataset.get_subject_pages(subject_id=subject_id, pages_subset=pages_subset)\n",
    "this_signal = dataset.get_subject_signal(subject_id=subject_id, normalization_mode=task_mode, which_expert=which_expert)\n",
    "this_stamps = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=which_expert)\n",
    "this_stamps_full = this_stamps.copy()\n",
    "event_name = dataset.event_name\n",
    "\n",
    "this_thr = optimal_thr_list[seed_to_show]\n",
    "smaller_proba_for_fp = this_thr / 2\n",
    "prediction_set = predictions_dict[seed_to_show][set_name]\n",
    "down_factor = prediction_set.params[pkeys.TOTAL_DOWNSAMPLING_FACTOR]\n",
    "predicted_proba = prediction_set.get_subject_probabilities(subject_id)\n",
    "\n",
    "# Look for probability in real events\n",
    "mean_proba_real_list = []\n",
    "max_proba_real_list = []\n",
    "for single_stamp in this_stamps_full:\n",
    "    proba_segment_idx = single_stamp // 8\n",
    "    proba_segment = predicted_proba[proba_segment_idx[0]:proba_segment_idx[1]+1]\n",
    "    mean_proba_real_list.append(np.mean(proba_segment))\n",
    "    max_proba_real_list.append(np.max(proba_segment))\n",
    "\n",
    "# Look for probability of fake events\n",
    "mean_proba_fake_list = []\n",
    "max_proba_fake_list = []\n",
    "prediction_set.set_probability_threshold(smaller_proba_for_fp)\n",
    "this_detections = prediction_set.get_subject_stamps(subject_id)\n",
    "# Matching:\n",
    "this_iou_array, this_idx_array = metrics.matching(this_stamps_full, this_detections)\n",
    "this_expert_iou = this_iou_array\n",
    "n_detections = this_detections.shape[0]\n",
    "this_detection_iou = np.zeros(n_detections)\n",
    "for i in range(n_detections):\n",
    "    if i in this_idx_array:\n",
    "        matching_idx = np.where(this_idx_array == i)[0][0]\n",
    "        this_detection_iou[i] = this_iou_array[matching_idx] \n",
    "# Recover events with zero iou\n",
    "fake_idx = np.where(this_detection_iou == 0)[0]\n",
    "this_fake_stamps = this_detections[fake_idx]\n",
    "for single_stamp in this_fake_stamps:\n",
    "    proba_segment_idx = single_stamp // 8\n",
    "    proba_segment = predicted_proba[proba_segment_idx[0]:proba_segment_idx[1]+1]\n",
    "    mean_proba_fake_list.append(np.mean(proba_segment))\n",
    "    max_proba_fake_list.append(np.max(proba_segment))\n",
    "    \n",
    "\n",
    "proba_bins = np.linspace(0.0, 1.0, num=21, endpoint=True) \n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8), dpi=100, sharey=True, sharex=True)\n",
    "values, _, _ = ax[0, 0].hist(mean_proba_real_list, bins=proba_bins, color=CUSTOM_COLOR['blue'], label='S%02d' % subject_id)\n",
    "ax[0, 0].tick_params(labelsize=8.5)\n",
    "ax[0, 0].legend(fontsize=8.5)\n",
    "ax[0, 0].set_xlim([0, 1])\n",
    "ax[0, 0].set_xlabel('Probability', fontsize=8.5)\n",
    "n_after_thr = np.sum(np.array(mean_proba_real_list) >= this_thr)\n",
    "ax[0, 0].set_title('Mean Proba of Real (%d greater than %1.2f)' % (n_after_thr, this_thr), fontsize=9)\n",
    "ax[0, 0].plot([this_thr, this_thr], [0, np.max(values)*1.05], '--k')\n",
    "\n",
    "values, _, _ = ax[0, 1].hist(max_proba_real_list, bins=proba_bins, color=CUSTOM_COLOR['blue'], label='S%02d' % subject_id)\n",
    "ax[0, 1].tick_params(labelsize=8.5)\n",
    "ax[0, 1].legend(fontsize=8.5)\n",
    "ax[0, 1].set_xlim([0, 1])\n",
    "ax[0, 1].set_xlabel('Probability', fontsize=8.5)\n",
    "n_after_thr = np.sum(np.array(max_proba_real_list) >= this_thr)\n",
    "ax[0, 1].set_title('Max Proba of Real (%d greater than %1.2f)' % (n_after_thr, this_thr), fontsize=9)\n",
    "ax[0, 1].plot([this_thr, this_thr], [0, np.max(values)*1.05], '--k')\n",
    "\n",
    "values, _, _ = ax[1, 0].hist(mean_proba_fake_list, bins=proba_bins, color=CUSTOM_COLOR['red'], label='S%02d' % subject_id)\n",
    "ax[1, 0].tick_params(labelsize=8.5)\n",
    "ax[1, 0].legend(fontsize=8.5)\n",
    "ax[1, 0].set_xlim([0, 1])\n",
    "ax[1, 0].set_xlabel('Probability', fontsize=8.5)\n",
    "n_after_thr = np.sum(np.array(mean_proba_fake_list) >= this_thr)\n",
    "ax[1, 0].set_title('Mean Proba of Fake (%d greater than %1.2f)' % (n_after_thr, this_thr), fontsize=9)\n",
    "ax[1, 0].plot([this_thr, this_thr], [0, np.max(values)*1.05], '--k')\n",
    "\n",
    "values, _, _ = ax[1, 1].hist(max_proba_fake_list, bins=proba_bins, color=CUSTOM_COLOR['red'], label='S%02d' % subject_id)\n",
    "ax[1, 1].tick_params(labelsize=8.5)\n",
    "ax[1, 1].legend(fontsize=8.5)\n",
    "ax[1, 1].set_xlim([0, 1])\n",
    "ax[1, 1].set_xlabel('Probability', fontsize=8.5)\n",
    "n_after_thr = np.sum(np.array(max_proba_fake_list) >= this_thr)\n",
    "ax[1, 1].set_title('Max Proba of Fake (%d greater than %1.2f)' % (n_after_thr, this_thr), fontsize=9)\n",
    "ax[1, 1].plot([this_thr, this_thr], [0, np.max(values)*1.05], '--k')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing with Global STD of 16.482037\n"
     ]
    }
   ],
   "source": [
    "seed_to_show = 0\n",
    "set_name = 'test'\n",
    "subject_id = 12\n",
    "show_only_n2 = True\n",
    "show_hypno = False\n",
    "band_pass_freqs = [12, 14]\n",
    "\n",
    "# -----\n",
    "if dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]:\n",
    "    channel_name = 'C3-CLE'\n",
    "else:\n",
    "    channel_name = 'F4-C4'\n",
    "\n",
    "if show_only_n2:\n",
    "    pages_subset = constants.N2_RECORD\n",
    "else:\n",
    "    pages_subset = constants.WN_RECORD\n",
    "\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_to_show)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_to_show])    \n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids, 'alltrain': all_train_ids}\n",
    "idx_subject = idx_dict[set_name].index(subject_id)\n",
    "\n",
    "this_pages = dataset.get_subject_pages(subject_id=subject_id, pages_subset=pages_subset)\n",
    "if show_hypno:\n",
    "    this_hypnogram = dataset.get_subject_hypnogram(subject_id=subject_id)\n",
    "this_signal = dataset.get_subject_signal(subject_id=subject_id, normalization_mode=task_mode, which_expert=which_expert)\n",
    "this_stamps = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=which_expert)\n",
    "if (subject_id not in [4, 8, 15, 16]) and dataset_name == constants.MASS_SS_NAME:\n",
    "    this_stamps_2 = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=2)\n",
    "else:\n",
    "    this_stamps_2 = None\n",
    "\n",
    "event_name = dataset.event_name\n",
    "\n",
    "this_thr = optimal_thr_list[seed_to_show]\n",
    "prediction_set = predictions_dict[seed_to_show][set_name]\n",
    "prediction_set.set_probability_threshold(this_thr)\n",
    "this_predicted_stamps = prediction_set.get_subject_stamps(subject_id=subject_id, pages_subset=constants.WN_RECORD)\n",
    "this_proba = prediction_set.get_subject_probabilities(subject_id=subject_id)\n",
    "\n",
    "fs_real = dataset.fs\n",
    "down_factor = prediction_set.params[pkeys.TOTAL_DOWNSAMPLING_FACTOR]\n",
    "fs_proba = fs_real / down_factor\n",
    "\n",
    "# make a color map of fixed colors\n",
    "cmap = colors.ListedColormap(['white', '#c62828'])\n",
    "\n",
    "\n",
    "def filter_stamps(stamps, single_page, page_size):\n",
    "    pages_list = []\n",
    "    for i in range(stamps.shape[0]):\n",
    "        stamp_start_page = stamps[i, 0] // page_size\n",
    "        stamp_end_page = stamps[i, 1] // page_size\n",
    "\n",
    "        start_inside = (stamp_start_page == single_page)\n",
    "        end_inside = (stamp_end_page == single_page)\n",
    "\n",
    "        if start_inside or end_inside:\n",
    "            pages_list.append(stamps[i, :])\n",
    "    return pages_list\n",
    "\n",
    "\n",
    "def plot_page(page_idx):\n",
    "\n",
    "    if this_stamps_2 is None:\n",
    "        fig = plt.figure(figsize=(12, 4), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(3, 1, height_ratios=[4, 2, 1])\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(12, 5), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(4, 1, height_ratios=[4, 2, 1, 1])\n",
    "    \n",
    "    page_idx = page_idx - 1\n",
    "    page_chosen = this_pages[page_idx]\n",
    "    if show_hypno:\n",
    "        page_state = this_hypnogram[page_of_center]\n",
    "    else:\n",
    "        page_state = '?'\n",
    "    page_start = page_chosen * dataset.page_size\n",
    "    page_end = page_start + dataset.page_size\n",
    "    \n",
    "    segment_signal = this_signal[page_start:page_end]\n",
    "    \n",
    "    segment_stamps = filter_stamps(this_stamps, page_chosen, dataset.page_size)\n",
    "    if this_stamps_2 is not None:\n",
    "        segment_stamps_2 = filter_stamps(this_stamps_2, page_chosen, dataset.page_size)\n",
    "    segment_proba = this_proba[int(page_start/down_factor):int(page_end/down_factor)]\n",
    "    segment_predicted_stamps = filter_stamps(this_predicted_stamps, page_chosen, dataset.page_size)\n",
    "    \n",
    "    time_axis_real = np.arange(page_start, page_end) / fs_real\n",
    "    time_axis_proba = np.arange(int(page_start/down_factor), int(page_end/down_factor)) / fs_proba\n",
    "    \n",
    "    gs_idx = 0\n",
    "    \n",
    "    # Signal\n",
    "    y_max = 10\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(\n",
    "        time_axis_real, segment_signal, \n",
    "        linewidth=1, color=CUSTOM_COLOR['grey'], label='EEG %s' % channel_name)\n",
    "    stamp_label_used = False\n",
    "    for expert_stamp in segment_stamps:\n",
    "        if stamp_label_used:\n",
    "            label = None\n",
    "        else:\n",
    "            label = event_name\n",
    "            stamp_label_used = True\n",
    "        ax.fill_between(\n",
    "            expert_stamp / fs_real, y_max, -y_max, \n",
    "            facecolor=CUSTOM_COLOR['blue'], alpha=0.3, label=label,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_ylim([-y_max, y_max])\n",
    "    ax.set_title('Subject %d (%s-%s). Page in record: %d. State %s (intervals of 0.5s are shown).' \n",
    "                 % (subject_id, dataset_name.upper(), set_name.capitalize(), page_chosen, page_state), fontsize=10)\n",
    "    ax.set_xticks([\n",
    "        time_axis_real[0], \n",
    "        time_axis_real[0] + 5, \n",
    "        time_axis_real[0] + 10, \n",
    "        time_axis_real[0] + 15, \n",
    "        time_axis_real[0] + 20])\n",
    "    ax.set_xticks(np.arange(time_axis_real[0], time_axis_real[-1], 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    lg = ax.legend(loc='upper right', fontsize=8.5)\n",
    "    # lh = lg.legendHandles[1]\n",
    "    # lh.set_facecolor(lh.get_facecolor())\n",
    "    # lh.set_alpha(1.0)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Band pass Signal\n",
    "    y_max = 10\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    # segment_signal_filtered = utils.narrow_filter(segment_signal, fs_real, band_pass_freqs[0], band_pass_freqs[1])\n",
    "    segment_signal_filtered = utils.filter_windowed_sinusoidal(segment_signal, fs_real, 13, 41)\n",
    "    ax.plot(\n",
    "        time_axis_real, segment_signal_filtered, \n",
    "        linewidth=1, color=CUSTOM_COLOR['grey'], label='EEG %s' % channel_name)\n",
    "    stamp_label_used = False\n",
    "    for expert_stamp in segment_stamps:\n",
    "        if stamp_label_used:\n",
    "            label = None\n",
    "        else:\n",
    "            label = event_name\n",
    "            stamp_label_used = True\n",
    "        ax.fill_between(\n",
    "            expert_stamp / fs_real, y_max, -y_max, \n",
    "            facecolor=CUSTOM_COLOR['blue'], alpha=0.3, label=label,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_ylim([-y_max, y_max])\n",
    "    ax.set_title('Bandpass filtered signal (sigma)', fontsize=10)\n",
    "    ax.set_xticks([\n",
    "        time_axis_real[0], \n",
    "        time_axis_real[0] + 5, \n",
    "        time_axis_real[0] + 10, \n",
    "        time_axis_real[0] + 15, \n",
    "        time_axis_real[0] + 20])\n",
    "    ax.set_xticks(np.arange(time_axis_real[0], time_axis_real[-1], 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    lg = ax.legend(loc='upper right', fontsize=8.5)\n",
    "    # lh = lg.legendHandles[1]\n",
    "    # lh.set_facecolor(lh.get_facecolor())\n",
    "    # lh.set_alpha(1.0)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Neural net\n",
    "    delta_y = 0.1\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(\n",
    "        time_axis_proba, segment_proba, \n",
    "        color=CUSTOM_COLOR['red'], linewidth=1.5, zorder=7)\n",
    "    for model_stamp in segment_predicted_stamps:\n",
    "        ax.fill_between(\n",
    "            model_stamp / fs_real, 1+delta_y, -delta_y, \n",
    "            facecolor=CUSTOM_COLOR['red'], zorder=6, alpha=0.3,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_xticks([])\n",
    "    ax.set_ylim([-delta_y, 1+delta_y])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticks([this_thr], minor=True)\n",
    "    ax.grid(b=True, axis='y', linewidth=1.5, which='minor', zorder=5)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    ax.set_title('Model prediction: probability and postprocessed stamps (%1.2f threshold is shown)' % this_thr, fontsize=10)\n",
    "    \n",
    "    if this_stamps_2 is not None:\n",
    "        ax = fig.add_subplot(gs[gs_idx])\n",
    "        # ax.imshow(segment_marks_2[np.newaxis, :], interpolation=None, aspect='auto', cmap=cmap)\n",
    "        for expert_stamp in segment_stamps_2:\n",
    "            ax.fill_between(\n",
    "                expert_stamp / fs_real, y_max, -y_max, \n",
    "                facecolor=CUSTOM_COLOR['blue'], alpha=0.3,\n",
    "                edgecolor='k', linewidth=1.5, \n",
    "            )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_ylim([-delta_y, 1+delta_y])\n",
    "        ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "        ax.set_title('Second expert stamps (not used for training)', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c66b2b7f9a4cd88e97c6a1ab63b75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=447, continuous_update=False, description='page_idx', max=689, min=1), O"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.interact(\n",
    "    lambda page_idx: plot_page(page_idx),\n",
    "    page_idx=widgets.IntSlider(min=1,max=this_pages.shape[0],step=1,value=447, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_to_show = 0\n",
    "set_name = 'test'\n",
    "subject_id = 12\n",
    "center_on_real = False\n",
    "iou_range = [0, 0]\n",
    "duration_range = [0, 5]\n",
    "show_hypno = True\n",
    "\n",
    "\n",
    "band_pass_freqs = [12, 14]\n",
    "\n",
    "# -----\n",
    "if dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]:\n",
    "    channel_name = 'C3-CLE'\n",
    "elif dataset_name in [constants.DREAMS_SS_NAME, constants.DREAMS_KC_NAME]:\n",
    "    channel_name = 'Cz-A1'\n",
    "else:\n",
    "    channel_name = 'F4-C4'\n",
    "\n",
    "\n",
    "pages_subset = constants.N2_RECORD\n",
    "\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_to_show)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_to_show])\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids, 'alltrain': all_train_ids}\n",
    "idx_subject = idx_dict[set_name].index(subject_id)\n",
    "\n",
    "this_pages = dataset.get_subject_pages(subject_id=subject_id, pages_subset=pages_subset)\n",
    "if show_hypno:\n",
    "    this_hypnogram = dataset.get_subject_hypnogram(subject_id=subject_id)\n",
    "this_signal = dataset.get_subject_signal(subject_id=subject_id, normalization_mode=task_mode, which_expert=which_expert)\n",
    "this_stamps = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=which_expert)\n",
    "this_stamps_full = this_stamps.copy()\n",
    "if (subject_id not in [4, 8, 15, 16]) and dataset_name == constants.MASS_SS_NAME:\n",
    "    this_stamps_2 = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=2)\n",
    "    this_stamps_2_full = this_stamps_2.copy()\n",
    "else:\n",
    "    this_stamps_2 = None\n",
    "\n",
    "event_name = dataset.event_name\n",
    "\n",
    "this_thr = optimal_thr_list[seed_to_show]\n",
    "prediction_set = predictions_dict[seed_to_show][set_name]\n",
    "prediction_set.set_probability_threshold(this_thr)\n",
    "this_predicted_stamps = prediction_set.get_subject_stamps(subject_id=subject_id, pages_subset=constants.WN_RECORD)\n",
    "this_predicted_stamps_full = this_predicted_stamps.copy()\n",
    "this_proba = prediction_set.get_subject_probabilities(subject_id=subject_id)\n",
    "\n",
    "fs_real = dataset.fs\n",
    "down_factor = prediction_set.params[pkeys.TOTAL_DOWNSAMPLING_FACTOR]\n",
    "fs_proba = fs_real / down_factor\n",
    "\n",
    "# make a color map of fixed colors\n",
    "cmap = colors.ListedColormap(['white', '#c62828'])\n",
    "\n",
    "# Matching:\n",
    "this_iou_array, this_idx_array = metrics.matching(this_stamps, this_predicted_stamps)\n",
    "this_expert_iou = this_iou_array\n",
    "n_detections = this_predicted_stamps.shape[0]\n",
    "this_dectection_iou = np.zeros(n_detections)\n",
    "\n",
    "for i in range(n_detections):\n",
    "    if i in this_idx_array:\n",
    "        matching_idx = np.where(this_idx_array == i)[0][0]\n",
    "        this_dectection_iou[i] = this_iou_array[matching_idx]        \n",
    "\n",
    "# Number of missed reals:\n",
    "n_ufn = np.sum(this_expert_iou == 0)\n",
    "# Number of false detections:\n",
    "n_ufp = np.sum(this_dectection_iou == 0)\n",
    "# Number of matched pairs\n",
    "n_matched = np.sum(this_expert_iou > 0)\n",
    "n_matched_v2 = np.sum(this_dectection_iou > 0)\n",
    "print('UFN:', n_ufn)\n",
    "print('UFP', n_ufp)\n",
    "print('Matched', n_matched, n_matched_v2)\n",
    "precision = n_matched / (n_matched + n_ufp)\n",
    "recall = n_matched / (n_matched + n_ufn)\n",
    "f1_at_iou0 = 2 * precision * recall / (precision + recall)\n",
    "print('F1 at IoU>0 %1.2f' % f1_at_iou0)\n",
    "\n",
    "# Fraction of UFP that does not match E1 but match E2\n",
    "print('** UFP and E2 intersection analysis ** ')\n",
    "all_ufp = this_predicted_stamps_full[this_dectection_iou == 0]\n",
    "overlap_ufp_e1 = utils.get_overlap_matrix(all_ufp, this_stamps_full)\n",
    "valid_ufp = np.where(overlap_ufp_e1.sum(axis=1) == 0)[0]\n",
    "print('UFP removed because E1 intersection: %d' % (all_ufp.shape[0] - valid_ufp.size))\n",
    "all_ufp = all_ufp[valid_ufp]\n",
    "overlap_ufp_e2 = utils.get_overlap_matrix(all_ufp, this_stamps_2_full)\n",
    "idx_with_e2_intersection = np.where(overlap_ufp_e2.sum(axis=1) > 0)[0]\n",
    "print('UFP with intersection with E2 and none with E1: %d (%1.2f %%)' % (idx_with_e2_intersection.size, 100*idx_with_e2_intersection.size/n_ufp))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 1), dpi=200)\n",
    "ax.hist(this_expert_iou[this_expert_iou > 0], bins=[0.1*i for i in range(11)], color=CUSTOM_COLOR['red'], label='S%02d' % subject_id)\n",
    "ax.legend(loc='upper left', fontsize=7)\n",
    "ax.set_title('IoU of Matchings', fontsize=8)\n",
    "ax.set_xticks([0.1*i for i in range(0, 11, 2)])\n",
    "ax.set_xlabel('IoU', fontsize=7)\n",
    "ax.tick_params(labelsize=7)\n",
    "plt.show()\n",
    "        \n",
    "# filter\n",
    "if center_on_real:\n",
    "    idx_useful_iou = np.where( (this_expert_iou >= iou_range[0]) & (this_expert_iou <= iou_range[1]) )[0]\n",
    "    duration_expert = (this_stamps[:, 1] - this_stamps[:, 0]) / fs_real\n",
    "    idx_useful_duration = np.where( (duration_expert >= duration_range[0]) & (duration_expert <= duration_range[1]) )[0]\n",
    "    idx_useful = [i for i in idx_useful_iou if i in idx_useful_duration]\n",
    "    this_stamps = this_stamps[idx_useful]\n",
    "    this_expert_iou = this_expert_iou[idx_useful]\n",
    "else:\n",
    "    idx_useful_iou = np.where( (this_dectection_iou >= iou_range[0]) & (this_dectection_iou <= iou_range[1]) )[0]\n",
    "    duration_det = (this_predicted_stamps[:, 1] - this_predicted_stamps[:, 0]) / fs_real\n",
    "    idx_useful_duration = np.where( (duration_det >= duration_range[0]) & (duration_det <= duration_range[1]) )[0]\n",
    "    idx_useful = [i for i in idx_useful_iou if i in idx_useful_duration]\n",
    "    this_predicted_stamps = this_predicted_stamps[idx_useful]\n",
    "    this_dectection_iou = this_dectection_iou[idx_useful]\n",
    "\n",
    "def filter_stamps(stamps, start_sample, end_sample):\n",
    "    pages_list = []\n",
    "    for i in range(stamps.shape[0]):\n",
    "        start_inside = (stamps[i, 0] > start_sample) and (stamps[i, 0] < end_sample)\n",
    "        end_inside = (stamps[i, 1] > start_sample) and (stamps[i, 1] < end_sample)\n",
    "\n",
    "        if start_inside or end_inside:\n",
    "            pages_list.append(stamps[i, :])\n",
    "    return pages_list\n",
    "\n",
    "\n",
    "def plot_event(event_idx):\n",
    "\n",
    "    if this_stamps_2 is None:\n",
    "        fig = plt.figure(figsize=(12, 4), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(3, 1, height_ratios=[4, 2, 1])\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(12, 5), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(4, 1, height_ratios=[4, 2, 1, 1])\n",
    "    \n",
    "    event_idx = event_idx - 1\n",
    "    \n",
    "    if center_on_real:\n",
    "        event_chosen = this_stamps[event_idx, :]\n",
    "        iou_chosen = this_expert_iou[event_idx]\n",
    "    else:\n",
    "        event_chosen = this_predicted_stamps[event_idx, :]\n",
    "        iou_chosen = this_dectection_iou[event_idx]\n",
    "\n",
    "    start_sample = int(event_chosen[0] - 10 * fs_real)\n",
    "    end_sample = int(event_chosen[1] + 10 * fs_real)\n",
    "\n",
    "    page_of_center = int(((end_sample + start_sample) / 2) / dataset.page_size)\n",
    "    if show_hypno:\n",
    "        page_state = this_hypnogram[page_of_center]\n",
    "    else:\n",
    "        page_state = '?'\n",
    "    \n",
    "    segment_signal = this_signal[start_sample:end_sample]\n",
    "    segment_stamps = filter_stamps(this_stamps_full, start_sample, end_sample)\n",
    "    if this_stamps_2 is not None:\n",
    "        segment_stamps_2 = filter_stamps(this_stamps_2_full, start_sample, end_sample)\n",
    "    segment_proba = this_proba[int(start_sample/down_factor):int(end_sample/down_factor)]\n",
    "    segment_predicted_stamps = filter_stamps(this_predicted_stamps_full, start_sample, end_sample)\n",
    "    \n",
    "    time_axis_real = np.arange(start_sample, end_sample) / fs_real\n",
    "    time_axis_proba = np.arange(int(start_sample/down_factor), int(end_sample/down_factor)) / fs_proba\n",
    "    \n",
    "    gs_idx = 0\n",
    "    \n",
    "    # Signal\n",
    "    y_max = 7\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(\n",
    "        time_axis_real, segment_signal, \n",
    "        linewidth=1, color=CUSTOM_COLOR['grey'], label='EEG %s' % channel_name)\n",
    "    stamp_label_used = False\n",
    "    for expert_stamp in segment_stamps:\n",
    "        if stamp_label_used:\n",
    "            label = None\n",
    "        else:\n",
    "            label = event_name\n",
    "            stamp_label_used = True\n",
    "        ax.fill_between(\n",
    "            expert_stamp / fs_real, y_max, -y_max, \n",
    "            facecolor=CUSTOM_COLOR['blue'], alpha=0.3, label=label,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_ylim([-y_max, y_max])\n",
    "    if center_on_real:\n",
    "        ax.set_title('Subject %d (%s-%s). Expert mark idx: %d. IoU %1.2f. State %s (intervals of 0.5s are shown).' \n",
    "                     % (subject_id, dataset_name.upper(), set_name.capitalize(), event_idx, iou_chosen, page_state), fontsize=10)\n",
    "    else:\n",
    "        ax.set_title('Subject %d (%s-%s). Detection idx: %d. IoU %1.2f. State %s (intervals of 0.5s are shown).' \n",
    "                     % (subject_id, dataset_name.upper(), set_name.capitalize(), event_idx, iou_chosen, page_state), fontsize=10)\n",
    "        \n",
    "    ax.set_xticks([\n",
    "        time_axis_real[0], \n",
    "        time_axis_real[0] + 5, \n",
    "        time_axis_real[0] + 10, \n",
    "        time_axis_real[0] + 15, \n",
    "        time_axis_real[0] + 20])\n",
    "    ax.set_xticks(np.arange(time_axis_real[0], time_axis_real[-1], 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    lg = ax.legend(loc='upper right', fontsize=8.5)\n",
    "    # lh = lg.legendHandles[1]\n",
    "    # lh.set_facecolor(lh.get_facecolor())\n",
    "    # lh.set_alpha(1.0)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Band pass Signal\n",
    "    y_max = 5\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    # segment_signal_filtered = utils.narrow_filter(segment_signal, fs_real, band_pass_freqs[0], band_pass_freqs[1])\n",
    "    segment_signal_filtered = utils.filter_windowed_sinusoidal(segment_signal, fs_real, 13, 41)\n",
    "    ax.plot(\n",
    "        time_axis_real, segment_signal_filtered, \n",
    "        linewidth=1, color=CUSTOM_COLOR['grey'], label='EEG %s' % channel_name)\n",
    "    stamp_label_used = False\n",
    "    for expert_stamp in segment_stamps:\n",
    "        if stamp_label_used:\n",
    "            label = None\n",
    "        else:\n",
    "            label = event_name\n",
    "            stamp_label_used = True\n",
    "        ax.fill_between(\n",
    "            expert_stamp / fs_real, y_max, -y_max, \n",
    "            facecolor=CUSTOM_COLOR['blue'], alpha=0.3, label=label,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_ylim([-y_max, y_max])\n",
    "    ax.set_title('Bandpass filtered signal (sigma)', fontsize=10)\n",
    "    ax.set_xticks([\n",
    "        time_axis_real[0], \n",
    "        time_axis_real[0] + 5, \n",
    "        time_axis_real[0] + 10, \n",
    "        time_axis_real[0] + 15, \n",
    "        time_axis_real[0] + 20])\n",
    "    ax.set_xticks(np.arange(time_axis_real[0], time_axis_real[-1], 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    lg = ax.legend(loc='upper right', fontsize=8.5)\n",
    "    # lh = lg.legendHandles[1]\n",
    "    # lh.set_facecolor(lh.get_facecolor())\n",
    "    # lh.set_alpha(1.0)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Neural net\n",
    "    delta_y = 0.1\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(\n",
    "        time_axis_proba, segment_proba, \n",
    "        color=CUSTOM_COLOR['red'], linewidth=1.5, zorder=7)\n",
    "    for model_stamp in segment_predicted_stamps:\n",
    "        ax.fill_between(\n",
    "            model_stamp / fs_real, 1+delta_y, -delta_y, \n",
    "            facecolor=CUSTOM_COLOR['red'], zorder=6, alpha=0.3,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_xticks([])\n",
    "    ax.set_ylim([-delta_y, 1+delta_y])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticks([this_thr], minor=True)\n",
    "    ax.grid(b=True, axis='y', linewidth=1.5, which='minor', zorder=5)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    ax.set_title('Model prediction: probability and postprocessed stamps (%1.2f threshold is shown)' % this_thr, fontsize=10)\n",
    "    \n",
    "    if this_stamps_2 is not None:\n",
    "        ax = fig.add_subplot(gs[gs_idx])\n",
    "        # ax.imshow(segment_marks_2[np.newaxis, :], interpolation=None, aspect='auto', cmap=cmap)\n",
    "        for expert_stamp in segment_stamps_2:\n",
    "            ax.fill_between(\n",
    "                expert_stamp / fs_real, y_max, -y_max, \n",
    "                facecolor=CUSTOM_COLOR['blue'], alpha=0.3,\n",
    "                edgecolor='k', linewidth=1.5, \n",
    "            )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_ylim([-delta_y, 1+delta_y])\n",
    "        ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "        ax.set_title('Second expert stamps (not used for training)', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Showing events with IoU in range %s' % iou_range)\n",
    "print('Showing events with duration in range %s [s]' % duration_range)\n",
    "if center_on_real:\n",
    "    max_value = this_stamps.shape[0]\n",
    "    print('Number of real events selected %d' % max_value)\n",
    "else:\n",
    "    max_value = this_predicted_stamps.shape[0]\n",
    "    print('Number of detected events selected %d' % max_value)\n",
    "\n",
    "widgets.interact(\n",
    "    lambda event_idx: plot_event(event_idx),\n",
    "    event_idx=widgets.IntSlider(min=1,max=max_value,step=1,value=1, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_set_error = 'test'\n",
    "thr = optimal_thr_list[0]\n",
    "\n",
    "y_thr = y_stamps[chosen_set_error]\n",
    "\n",
    "# Prepare model predictions\n",
    "n_subjects = len(y_thr)\n",
    "pred_stamps = []\n",
    "for i in range(n_subjects):\n",
    "    print('Processing subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    # Binarize\n",
    "    this_y_pred_thr = (y_pred[chosen_set_error][i] >= thr).astype(np.int32)\n",
    "    # Transform to intervals\n",
    "    this_y_pred_thr = data_ops.seq2inter_with_pages(\n",
    "        this_y_pred_thr, pages[chosen_set_error][i]\n",
    "    )\n",
    "    pred_stamps.append(this_y_pred_thr)\n",
    "fs_pred = 200 // 8 \n",
    "fs_real = 200\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Compute spacing ----------------------\n",
    "combine_thr = 0.3\n",
    "\n",
    "spacing = []\n",
    "spacing_expert = []\n",
    "for i in range(n_subjects):\n",
    "    print('Spacing for subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    this_spacing = (pred_stamps[i][1:, 0] - pred_stamps[i][:-1, 1]) / fs_pred\n",
    "    this_spacing_expert = (y_stamps[chosen_set_error][i][1:, 0] - y_stamps[chosen_set_error][i][:-1, 1]) / fs_real\n",
    "    # Only consider for this analysis, spacing less than one second\n",
    "    this_spacing = this_spacing[this_spacing < 1]\n",
    "    this_spacing_expert = this_spacing_expert[this_spacing_expert < 1]\n",
    "    spacing.append(this_spacing)\n",
    "    spacing_expert.append(this_spacing_expert)\n",
    "print('Done')\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Spacing between nearby expert marks', fontsize=10)\n",
    "ax[0, 1].set_title('Spacing between nearby detections', fontsize=10)\n",
    "y_max = 0\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Real\n",
    "    n_real, _, _ = ax[i, 0].hist(spacing_expert[i], bins=[k*0.1 for k in range(11)], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].set_xticks([k*0.2 for k in range(6)])\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "    # Predicted\n",
    "    n_pred, _, _ = ax[i, 1].hist(spacing[i], bins=[k*0.1 for k in range(11)], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].set_xticks([k*0.2 for k in range(6)])\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "    max_y = max(np.max(n_real), np.max(n_pred))\n",
    "    ax[i, 0].plot([combine_thr, combine_thr], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    ax[i, 1].plot([combine_thr, combine_thr], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    # y_max = max(max_y, y_max)\n",
    "# for i in range(n_subjects):\n",
    "#     ax[i, 0].plot([combine_thr, combine_thr], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "#     ax[i, 1].plot([combine_thr, combine_thr], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "ax[-1, 0].set_xlabel('Spacing [s]', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Spacing [s]', fontsize=8.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Durations\n",
    "\n",
    "if dataset_name == constants.MASSK_NAME:\n",
    "    postprocess_predicted = False\n",
    "else:\n",
    "    postprocess_predicted = True\n",
    "\n",
    "durations = []\n",
    "durations_expert = []\n",
    "for i in range(n_subjects):\n",
    "    print('Durations for subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    # First, combine close marks\n",
    "    if dataset_name == constants.MASSK_NAME:\n",
    "        this_pred_stamps = pred_stamps[i]\n",
    "    else:\n",
    "        this_pred_stamps = postprocessing.combine_close_marks(pred_stamps[i], fs_pred, combine_thr)\n",
    "    # Now compute durations\n",
    "    this_durations = (this_pred_stamps[:, 1] - this_pred_stamps[:, 0]) / fs_pred\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    # Only consider for this analysis, spacing less than one second\n",
    "    durations.append(this_durations)\n",
    "    durations_expert.append(this_durations_expert)\n",
    "print('Done')\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Duration of expert marks', fontsize=10)\n",
    "ax[0, 1].set_title('Duration of detections', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "y_max = 0\n",
    "min_duration = 0.3  \n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Real\n",
    "    n_real, _, _ = ax[i, 0].hist(durations_expert[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "    # Predicted\n",
    "    n_pred, _, _ = ax[i, 1].hist(durations[i], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "    max_y = max(np.max(n_real), np.max(n_pred))\n",
    "    ax[i, 0].plot([min_duration, min_duration], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    ax[i, 1].plot([min_duration, min_duration], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    y_max = max(max_y, y_max)\n",
    "    print(durations[i].max())\n",
    "    \n",
    "#for i in range(n_subjects):\n",
    "#    ax[i, 0].plot([min_duration, min_duration], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "#    ax[i, 1].plot([min_duration, min_duration], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "\n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location of Falses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == constants.MASSK_NAME:\n",
    "    min_separation = 0\n",
    "    min_duration = 0.3\n",
    "    max_duration = 4.0\n",
    "else:\n",
    "    min_separation = 0.5\n",
    "    min_duration = 0.4\n",
    "    max_duration = 4.0\n",
    "\n",
    "iou_array = []\n",
    "idx_array = []\n",
    "y_pred_thr = []\n",
    "for i in range(n_subjects):\n",
    "    print('Processing subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    events = y_stamps[chosen_set_error][i]\n",
    "    detections = postprocessing.generate_mark_intervals(\n",
    "        y_pred[chosen_set_error][i], pages[chosen_set_error][i], 200//8, 200, thr=thr, \n",
    "        min_separation=min_separation, min_duration=min_duration, max_duration=max_duration)\n",
    "    print(events.shape, detections.shape)\n",
    "    this_iou_array, this_idx_array = metrics.matching(events, detections)\n",
    "    iou_array.append(this_iou_array)\n",
    "    idx_array.append(this_idx_array)\n",
    "    y_pred_thr.append(detections)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- False negatives\n",
    "iou_thr = 0.3\n",
    "\n",
    "fn_center = []\n",
    "for i in range(n_subjects):\n",
    "    idx_fn = iou_array[i] < iou_thr\n",
    "    fn_stamps = y_stamps[chosen_set_error][i][idx_fn]\n",
    "    this_fn_center = np.mean(fn_stamps, axis=1).astype(np.int32)\n",
    "    fn_center.append(this_fn_center)\n",
    "    \n",
    "# --- False positives\n",
    "fp_center = []\n",
    "for i in range(n_subjects):\n",
    "    # matched detections:\n",
    "    idx_fp_1 = iou_array[i] < iou_thr\n",
    "    idx_fp_1 = idx_array[i][idx_fp_1]\n",
    "    idx_fp_1 = [idx for idx in idx_fp_1 if idx != -1]\n",
    "    # Unmatched events\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    idx_fp = idx_fp_1 + idx_fp_2\n",
    "    fp_stamps = y_pred_thr[i][idx_fp]\n",
    "    this_fp_center = np.mean(fp_stamps, axis=1).astype(np.int32)\n",
    "    fp_center.append(this_fp_center)\n",
    "\n",
    "    \n",
    "# --- Histogram of IoU values across real events\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(3.5, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0].set_title('IoU values on expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].hist(iou_array[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), bins=[0.05*i for i in range(21)])\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "    ax[i].legend(fontsize=8.5, loc='upper center')\n",
    "    ax[i].set_xticks([0.2*i for i in range(6)])\n",
    "ax[-1].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "plt.show()\n",
    "    \n",
    "# --- Location in page\n",
    "fn_loc_page = [np.mod(this_fn_center, 20*fs_real) for this_fn_center in fn_center]\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Location of expert marks with IoU < %1.2f' % (iou_thr), fontsize=11)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 0].hist(fn_loc_page[i] / fs_real, bins=[i*4 for i in range(6)], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5, loc='upper center')\n",
    "ax[-1, 0].set_xticks([i*4 for i in range(6)])\n",
    "ax[-1, 0].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "\n",
    "fp_loc_page = [np.mod(this_fp_center, 20*fs_real) for this_fp_center in fp_center]\n",
    "\n",
    "ax[0, 1].set_title('Location of detections with IoU < %1.2f' % (iou_thr), fontsize=10)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 1].hist(fp_loc_page[i] / fs_real, bins=[i*4 for i in range(6)], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5, loc='upper center')\n",
    "ax[-1, 1].set_xticks([i*4 for i in range(6)])\n",
    "ax[-1, 1].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --- Location in register\n",
    "\n",
    "fn_loc_register = [np.floor_divide(this_fn_center, 20*fs_real) for this_fn_center in fn_center]\n",
    "max_page_array = [np.max(pages[chosen_set_error][i]) for i in range(n_subjects)]\n",
    "\n",
    "max_of_all = np.max(max_page_array)\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Location in register of expert marks with IoU < %1.1f' % (iou_thr), fontsize=10)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 0].hist(fn_loc_register[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "ax[-1, 0].set_xlim([0, max_of_all+10])\n",
    "ax[-1, 0].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "fp_loc_register = [np.floor_divide(this_fp_center, 20*fs_real) for this_fp_center in fp_center]\n",
    "max_page_array = [np.max(pages[chosen_set_error][i]) for i in range(n_subjects)]\n",
    "\n",
    "max_of_all = np.max(max_page_array)\n",
    "\n",
    "ax[0, 1].set_title('Location in register of detections with IoU < %1.1f' % (iou_thr), fontsize=11)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 1].hist(fp_loc_register[i], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "ax[-1, 1].set_xlim([0, max_of_all+10])\n",
    "ax[-1, 1].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ----- N2 pages\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(3.5, 1*n_subjects), dpi=DPI, sharex=True, sharey=True)\n",
    "ax[0].set_title('Location in register of N2 pages (%s)' % (chosen_set_error.capitalize()), fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].hist(pages[chosen_set_error][i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "    ax[i].legend(fontsize=8.5)\n",
    "ax[-1].set_xlim([0, max_of_all+10])\n",
    "ax[-1].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IoU vs Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- Scatter of IoU values and duration of real and detected events\n",
    "alpha = 0.2\n",
    "markersize=10\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(7, 1*n_subjects), dpi=DPI, sharex=True, sharey=True)\n",
    "ax[0, 0].set_title('IoU vs duration of expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    ax[i, 0].scatter(this_durations_expert, iou_array[i], label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#455a64', alpha=alpha, s=markersize)\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 0].legend(fontsize=7, loc='upper right')\n",
    "    for lh in lg.legendHandles:\n",
    "        lh.set_facecolor(lh.get_facecolor())\n",
    "        lh.set_edgecolor(lh.get_edgecolor())\n",
    "        lh.set_alpha(1.0)\n",
    "    ax[i, 0].set_ylabel('IoU', fontsize=8.5)\n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('IoU vs duration of detections', fontsize=10)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations for IoU > 0 \n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    this_iou_1 = iou_array[i][idx_valid]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    this_durations_1 = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    # Now durations for IoU = 0\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_fp_2]\n",
    "    this_durations_2 = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    this_iou_2 = np.zeros(this_durations_2.shape[0])\n",
    "    # Concatenation\n",
    "    this_durations = np.concatenate([this_durations_1, this_durations_2])\n",
    "    this_iou = np.concatenate([this_iou_1, this_iou_2])\n",
    "    ax[i, 1].scatter(this_durations, this_iou, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#c62828', alpha=alpha, s=markersize)\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 1].legend(fontsize=7, loc='upper right')\n",
    "    for lh in lg.legendHandles:\n",
    "        lh.set_facecolor(lh.get_facecolor())\n",
    "        lh.set_edgecolor(lh.get_edgecolor())\n",
    "        lh.set_alpha(1.0)\n",
    "    # ax[i, 1].set_ylabel('IoU', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Histogram of duration for IoU == 0\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Duration of unpaired expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    idx_zero = (iou_array[i] == 0)\n",
    "    this_durations_expert_fn = this_durations_expert[idx_zero]\n",
    "    ax[i, 0].hist(this_durations_expert_fn, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#455a64')\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 0].legend(fontsize=8.5, loc='upper right')\n",
    "    \n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('Duration of unpaired detections', fontsize=10)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_fp_2]\n",
    "    this_durations_fp = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    ax[i, 1].hist(this_durations_fp, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#c62828')\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5, loc='upper right')\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration of events and matched detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(5, 5), dpi=DPI, sharex=False, sharey=False)\n",
    "# plt.suptitle('Duration of matched events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    # Now compute durations for real\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    this_durations_expert = this_durations_expert[idx_valid]\n",
    "    # Now compute durations for matched detections\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    this_durations_det = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    if i<2:\n",
    "        ax[0, i].scatter(this_durations_expert, this_durations_det, label='S%02d' % subject_idx, color='#455a64', alpha=alpha)\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "        lg = ax[0, i].legend(fontsize=7)\n",
    "        for lh in lg.legendHandles:\n",
    "            lh.set_facecolor(lh.get_facecolor())\n",
    "            lh.set_edgecolor(lh.get_edgecolor())\n",
    "            lh.set_alpha(1.0)\n",
    "        max_dur = max(this_durations_expert.max(), this_durations_det.max())\n",
    "        ax[0, i].set_xlim([0, max_dur + 0.1])\n",
    "        ax[0, i].set_ylim([0, max_dur + 0.1])\n",
    "        if i == 0 :\n",
    "            ax[0, i].set_ylabel('Detected duration [s]', fontsize=8.5)\n",
    "        # ax[0, i].set_xlabel('Duration Real [s]', fontsize=8.5)\n",
    "        ax[0, i].plot([0.3, 2.0], [0.3, 2.0], '--k', alpha=0.6)\n",
    "    else:\n",
    "        ax[1, i-2].scatter(this_durations_expert, this_durations_det, label='S%02d' % subject_idx, color='#455a64', alpha=alpha)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "        lg = ax[1, i-2].legend(fontsize=7)\n",
    "        for lh in lg.legendHandles:\n",
    "            lh.set_facecolor(lh.get_facecolor())\n",
    "            lh.set_edgecolor(lh.get_edgecolor())\n",
    "            lh.set_alpha(1.0)\n",
    "        max_dur = max(this_durations_expert.max(), this_durations_det.max())\n",
    "        ax[1, i-2].set_xlim([0, max_dur + 0.1])\n",
    "        ax[1, i-2].set_ylim([0, max_dur + 0.1])\n",
    "        if i == 2:\n",
    "            ax[1, i-2].set_ylabel('Detected duration [s]', fontsize=8.5)\n",
    "        ax[1, i-2].set_xlabel('Real duration [s]', fontsize=8.5)\n",
    "        ax[1, i-2].plot([0.3, 2.0], [0.3, 2.0], '--k', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted probability to matched and unmatched events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare probabilities\n",
    "whole_y_proba = []\n",
    "for i in range(n_subjects):\n",
    "    this_proba = y_pred[chosen_set_error][i]\n",
    "    this_pages = pages[chosen_set_error][i]\n",
    "    page_size = this_proba.shape[1]\n",
    "    max_page = np.max(this_pages)\n",
    "    max_size = (max_page + 1) * page_size\n",
    "    whole_y_proba.append(np.zeros(max_size, dtype=np.float32))\n",
    "    for k, page in enumerate(this_pages):\n",
    "        sample_start = page * page_size\n",
    "        sample_end = (page + 1) * page_size\n",
    "        whole_y_proba[i][sample_start:sample_end] = this_proba[k, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching probabilities (Candidates for TP according to IoU)\n",
    "# It is expected that they have more than 0.5 since that is the threshold used for detection\n",
    "print('Processing probability for matched events', flush=True)\n",
    "matching_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for the valid detections stamps \n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    y_pred_stamps = y_pred_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in y_pred_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    matching_proba.append(mean_proba_list)\n",
    "    \n",
    "# Unmatched real events (FN)\n",
    "# It is expected that they have less than 0.5 since they were missed by the tresholding\n",
    "print('Processing probability for unmatched real events', flush=True)\n",
    "unmatching_fn_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for the missed real events \n",
    "    idx_valid = (idx_array[i] == -1)\n",
    "    fn_stamps = y_stamps[chosen_set_error][i][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    fn_stamps = fn_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in fn_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    unmatching_fn_proba.append(mean_proba_list)\n",
    "    \n",
    "# Unmatched detected events (FP)\n",
    "# It is expected that they have more than 0.5 since they were detected\n",
    "print('Processing probability for unmatched detected events', flush=True)\n",
    "unmatching_fp_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for detected events with no match \n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_valid = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    fp_stamps = y_pred_thr[i][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    fp_stamps = fp_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in fp_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    unmatching_fp_proba.append(mean_proba_list)\n",
    "    \n",
    "\n",
    "# Probability for real events\n",
    "print('Processing probability for real events', flush=True)\n",
    "real_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    y_pred_stamps = y_stamps[chosen_set_error][i] // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in y_pred_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    real_proba.append(mean_proba_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 3, figsize=(14, 3*n_subjects), dpi=100, sharex=True)\n",
    "\n",
    "ax[0, 0].set_title('Model output on matched events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 0].hist(matching_proba[i], label='S%02d' % subject_idx, color='#43a047')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 0].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "ax[-1, 0].set_xlim([0, 1])\n",
    "ax[-1, 0].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('Probability on unmatched real events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 1].hist(unmatching_fn_proba[i], label='S%02d' % subject_idx, color='#455a64')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 1].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "ax[-1, 1].set_xlim([0, 1])\n",
    "ax[-1, 1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "ax[0, 2].set_title('Probability on unmatched detections (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 2].hist(unmatching_fp_proba[i], label='S%02d' % subject_idx, color='#c62828')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 2].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 2].tick_params(labelsize=8.5)\n",
    "    ax[i, 2].legend(fontsize=8.5)\n",
    "ax[-1, 2].set_xlim([0, 1])\n",
    "ax[-1, 2].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(6, 5*n_subjects), dpi=100, sharex=True)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].set_title('Predicted probability for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=11)\n",
    "\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "max_n = 0\n",
    "for i in range(n_subjects):\n",
    "    \n",
    "    n, _, _ = ax[i].hist(\n",
    "        matching_proba[i], label='Matched real', color='#43a047', alpha=0.4, density=True,\n",
    "        bins = [i*0.05 for i in range(21)])\n",
    "    kernel = gaussian_kde(matching_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    ax[i].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "ax[-1].set_xlim([0, 1])\n",
    "ax[-1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "# for i in range(n_subjects):\n",
    "#     subject_idx = idx_dict[chosen_set_error][i]\n",
    "#     n, _, _ = ax[i].hist(\n",
    "#         unmatching_fn_proba[i], label='Unmatched real', color='#455a64', alpha=0.4, density=True,\n",
    "#         bins = [i*0.05 for i in range(21)])\n",
    "#     kernel = gaussian_kde(unmatching_fn_proba[i])\n",
    "#     y_kde = kernel(x_points)\n",
    "#     ax[i].plot(x_points, y_kde, color='#455a64', linewidth=2)\n",
    "#     max_n = max(np.max(n), max_n)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i].hist(\n",
    "        unmatching_fp_proba[i], label='Unmatched detection', color='#c62828', alpha=0.4, density=True,\n",
    "        bins = [i*0.05 for i in range(21)])\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    ax[i].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i].legend(fontsize=8.5, loc='upper left')\n",
    "    ax[i].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(6, 5), dpi=DPI, sharex=True)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    if i < 2:\n",
    "        ax[0, i].set_title('Model Output for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=10)\n",
    "    else:\n",
    "        ax[1, i-2].set_title('Model Output for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=10)\n",
    "\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "max_n = 0\n",
    "for i in range(n_subjects):\n",
    "    if i < 2:\n",
    "        n, _, _ = ax[0, i].hist(\n",
    "            real_proba[i], label='Expert marks', color='#43a047', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "    else:\n",
    "        n, _, _ = ax[1, i-2].hist(\n",
    "            real_proba[i], label='Real events\\n(Expert marks)', color='#43a047', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "    kernel = gaussian_kde(real_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    if i<2:\n",
    "        ax[0, i].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "        ax[0, i].set_xlim([0, 1])\n",
    "    else:\n",
    "        ax[1, i-2].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "        ax[1, i-2].set_xlim([0, 1])\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    \n",
    "\n",
    "# ax[-1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    if i<2:\n",
    "        n, _, _ = ax[0, i].hist(\n",
    "            unmatching_fp_proba[i], label='Unpaired detections ($\\mu$=0.1)', color='#c62828', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "        ax[0, i].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "        # ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "        # lg = ax[0, i].legend(fontsize=8.5, loc='upper center', bbox_to_anchor=(1.05, 0.15))\n",
    "        # for lh in lg.legendHandles:\n",
    "        #     lh.set_facecolor(lh.get_facecolor())\n",
    "        #     lh.set_alpha(1.0)\n",
    "        ax[0, i].set_yticks([])\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "    else:\n",
    "        n, _, _ = ax[1, i-2].hist(\n",
    "            unmatching_fp_proba[i], label='False events\\n(Unpaired detections\\ngenerated with $\\mu$=0.1)', color='#c62828', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "        ax[1, i-2].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "        # ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "        ax[1, i-2].set_yticks([])\n",
    "        ax[1, i-2].set_xlabel('Class assignment', fontsize=8.5)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "lg = ax[1, 1].legend(fontsize=9, loc='upper left', bbox_to_anchor=(1.05, 1.35), labelspacing=3)\n",
    "for lh in lg.legendHandles:\n",
    "    lh.set_facecolor(lh.get_facecolor())\n",
    "    lh.set_alpha(1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Avg distributions over set\n",
    "\n",
    "\n",
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5), dpi=100, sharex=True)\n",
    "\n",
    "ax.set_title('Predicted probability. Average for %s set' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "\n",
    "y_kde_list = []\n",
    "for i in range(n_subjects):\n",
    "    kernel = gaussian_kde(matching_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    y_kde_list.append(y_kde)\n",
    "y_kde_avg_real = np.stack(y_kde_list, axis=1).mean(axis=1)\n",
    "ax.plot(x_points, y_kde_avg_real, color='#43a047', linewidth=2, label='Real event')\n",
    "ax.fill_between(x_points, y_kde_avg_real, 0*y_kde_avg_real, color='#43a047', alpha=0.4)\n",
    "\n",
    "y_kde_list = []\n",
    "for i in range(n_subjects):\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    y_kde_list.append(y_kde)\n",
    "y_kde_avg_false = np.stack(y_kde_list, axis=1).mean(axis=1)\n",
    "ax.plot(x_points, y_kde_avg_false, color='#c62828', linewidth=2, label='False event')\n",
    "ax.fill_between(x_points, y_kde_avg_false, 0*y_kde_avg_false, color='#c62828', alpha=0.4)\n",
    "\n",
    "max_y = max(np.max(y_kde_avg_real), np.max(y_kde_avg_false))\n",
    "\n",
    "# Find optimal threshold\n",
    "difference = y_kde_avg_false - y_kde_avg_real\n",
    "idx_thr = np.where(np.signbit(difference))[0][0]\n",
    "x_thr = x_points[idx_thr]\n",
    "print('Optimal Threshold: %1.4f' % x_thr)\n",
    "ax.plot([x_thr, x_thr], [0, max_y], '--', color='k', linewidth=1.5, alpha=0.6, label='Optimal Threshold')\n",
    "\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, max_y])\n",
    "ax.set_yticks([])\n",
    "ax.legend(fontsize=8.5, loc='upper left')\n",
    "ax.set_xlabel('Probability', fontsize=8.5)\n",
    "ax.set_xticks([i*0.1 for i in range(11)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of FP that are TP-E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unmatched events according to E1\n",
    "unmatched_stamps = []\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    # Unmatched detections\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    fp_stamps = y_pred_thr[i][idx_fp]\n",
    "    print('\\n%d / %d (%1.2f %%) unmatched detections with E1 for S%02d' % (fp_stamps.shape[0], n_detections, 100*fp_stamps.shape[0]/n_detections, subject_idx))\n",
    "    unmatched_stamps.append(fp_stamps)\n",
    "    # Now match with E2\n",
    "    events = y2_stamps[chosen_set_error][i]\n",
    "    detections = fp_stamps\n",
    "    n_detections = fp_stamps.shape[0]\n",
    "    this_iou_array, this_idx_array = metrics.matching(events, detections)\n",
    "    matched_2 =  (this_idx_array > -1).sum()\n",
    "    print('%d were matched with E2 (%1.2f%% of previously unmatched detections)' % (matched_2, 100*matched_2 / fp_stamps.shape[0]))\n",
    "    # print(fp_stamps[this_idx_array[this_idx_array > -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral information of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id_list = dataset.train_ids\n",
    "whole_night = True\n",
    "\n",
    "# Now plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4), dpi=150)\n",
    "if whole_night:\n",
    "    title_str = 'Whole night average'\n",
    "else:\n",
    "    title_str = 'N2 only average'\n",
    "    \n",
    "for subject_id in subject_id_list:\n",
    "    x, _ = dataset.get_subject_data(subject_id, which_expert=1, verbose=False, whole_night=whole_night)\n",
    "    # Compute fft of each page \n",
    "    print('Computing FFT for S%02d... ' % subject_id, end='', flush=True)\n",
    "    fft_list = []\n",
    "    for x_page in x:\n",
    "        fft_page, freq_axis = data_ops.power_spectrum(x_page, 200)\n",
    "        fft_list.append(fft_page)\n",
    "    # Now average the fft:\n",
    "    fft_mean = np.stack(fft_list, axis=1).mean(axis=1)\n",
    "    print('Done')\n",
    "    # Now plot\n",
    "    ax.plot(freq_axis, fft_mean, label='S%02d' % subject_id, linewidth=1)\n",
    "\n",
    "ax.set_title(title_str, fontsize=10)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Frequency [Hz]', fontsize=8.5)\n",
    "ax.set_ylabel('Power')\n",
    "ax.set_xlim([0, 25])\n",
    "ax.set_ylim([0.01, 0.5])\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.legend(loc='upper right', fontsize=8.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load invalid subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
