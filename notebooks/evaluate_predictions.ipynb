{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ntapia/miniconda3/envs/tf/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pprint import pprint\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import gridspec\n",
    "from scipy.stats import gaussian_kde\n",
    "# from tqdm import tqdm\n",
    "\n",
    "project_root = '..'\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from sleeprnn.data.loader import load_dataset\n",
    "from sleeprnn.helpers.reader import RefactorUnpickler\n",
    "from sleeprnn.data import utils, stamp_correction\n",
    "from sleeprnn.detection.feeder_dataset import FeederDataset\n",
    "from sleeprnn.detection import metrics\n",
    "from sleeprnn.detection.postprocessor import PostProcessor\n",
    "from sleeprnn.common import constants, pkeys\n",
    "\n",
    "SEED_LIST = [123, 234, 345, 456]\n",
    "RESULTS_PATH = os.path.join(project_root, 'results')\n",
    "COMPARISON_PATH = os.path.join(project_root, 'resources', 'comparison_data')\n",
    "DPI = 200\n",
    "CUSTOM_COLOR = {'red': '#c62828', 'grey': '#455a64', 'blue': '#0277bd', 'green': '#43a047'} \n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load database and predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 11. Test size: 4\n",
      "Train subjects: \n",
      " [1, 3, 5, 7, 9, 10, 11, 14, 17, 18, 19]\n",
      "Test subjects: \n",
      " [2, 6, 12, 13]\n",
      "Dataset mass_ss with 15 patients.\n",
      "Loading from checkpoint... Loaded\n",
      "Global STD: 16.482037\n",
      "Loaded seed 1/4 from /home/ntapia/Projects/GitNico/sleep-rnn/results/predictions_mass_ss/20190927_out_proba_cwt_grid_n2_train_mass_ss/p_0.01_lr_0.0001/seed0\n",
      "Loaded seed 2/4 from /home/ntapia/Projects/GitNico/sleep-rnn/results/predictions_mass_ss/20190927_out_proba_cwt_grid_n2_train_mass_ss/p_0.01_lr_0.0001/seed1\n",
      "Loaded seed 3/4 from /home/ntapia/Projects/GitNico/sleep-rnn/results/predictions_mass_ss/20190927_out_proba_cwt_grid_n2_train_mass_ss/p_0.01_lr_0.0001/seed2\n",
      "Loaded seed 4/4 from /home/ntapia/Projects/GitNico/sleep-rnn/results/predictions_mass_ss/20190927_out_proba_cwt_grid_n2_train_mass_ss/p_0.01_lr_0.0001/seed3\n",
      "Optimal thr: [0.42, 0.46, 0.54, 0.36]\n"
     ]
    }
   ],
   "source": [
    "optimal_thr_for_ckpt_dict = {\n",
    "    os.path.join('20190504_bsf_wn_train_mass_ss', 'bsf'): [0.64, 0.52, 0.52, 0.48],\n",
    "    os.path.join('20190504_bsf_wn_train_mass_kc', 'bsf'): [0.52, 0.56, 0.54, 0.56],\n",
    "    os.path.join('20190506_bsf_n2_train_mass_ss', 'bsf'): [0.52, 0.46, 0.50, 0.50],\n",
    "    os.path.join('20190506_bsf_n2_train_mass_kc', 'bsf'): [0.52, 0.52, 0.56, 0.46],\n",
    "    os.path.join('20190516_bsf_n2_train_inta_ss', 'bsf'): [0.48, 0.52, 0.48, 0.44],\n",
    "    os.path.join('20190516_bsf_v2_n2_train_inta_ss', 'bsf'): [0.46, 0.52, 0.50, 0.46],\n",
    "    os.path.join('20190522_bsf_newer_wins_fix_n2_train_inta_ss', 'bsf'): [0.44, 0.5, 0.44, 0.42],\n",
    "    os.path.join('20190522_bsf_e1_n2_train_mass_ss', 'bsf'): [0.44, 0.56, 0.48, 0.48],\n",
    "    os.path.join('20190522_bsf_e2_n2_train_mass_ss', 'bsf'): [0.6, 0.44, 0.36, 0.56],\n",
    "    os.path.join('20190525_bsf_ch3_n2_train_inta_ss', 'bsf'): [0.48, 0.56, 0.52, 0.5],\n",
    "    os.path.join('20190525_bsf_v4_n2_train_mass_ss', 'bsf_1'): [0.46, 0.4, 0.5, 0.46],\n",
    "    os.path.join('20190527_bsf_v7_k3_n2_train_mass_ss', 'bsf_2'): [0.52, 0.44, 0.48, 0.42],\n",
    "    os.path.join('20190530_bsf_v10_n2_train_mass_ss', 'bsf'): [0.6, 0.44, 0.56, 0.42],\n",
    "    os.path.join('20190601_bsf_v11_n2_train_mass_ss', 'filters_32_64_128'): [0.64, 0.36, 0.58, 0.4],\n",
    "    os.path.join('20190601_bsf_v11_n2_train_mass_ss', 'filters_64_128_256'): [0.62, 0.6, 0.52, 0.44],\n",
    "    os.path.join('20190603_grid_cwt_fb05_n2_train_mass_ss', 'v12_f_32_64'): [0.66, 0.46, 0.52, 0.46],\n",
    "    os.path.join('20190605_grid_v15_v16_n2_train_mass_ss', 'v15_timef_64_128_256_cwtf_32_32_fb_0.5'): [0.46, 0.52, 0.62, 0.42],\n",
    "    os.path.join('20190614_bsf_global_std_n2_train_mass_ss', 'bsf'): [0.62, 0.4, 0.4, 0.48],\n",
    "    os.path.join('20190617_grid_normalization_n2_train_mass_ss', 'norm_global'): [0.58, 0.42, 0.4, 0.5],\n",
    "    os.path.join('20190608_bsf_ablation_n2_train_inta_ss', 'v15_tf_64-128-256_cwtf_32-32/rep0'): [0.48, 0.52, 0.5, 0.5],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_n2_train_dreams_ss', 'v11_None'): [0.22, 0.48, 0.28, 0.38],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_n2_train_dreams_ss', 'v12_True'): [0.36, 0.5, 0.34, 0.36],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_n2_train_dreams_ss', 'v17_True'): [0.34, 0.38, 0.28, 0.44],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_wn_train_dreams_ss', 'v11_None'): [0.36, 0.46, 0.4, 0.36],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_wn_train_dreams_ss', 'v12_True'): [0.48, 0.46, 0.46, 0.52],\n",
    "    os.path.join('20190620_11_12_17_from_scratch_wn_train_dreams_ss', 'v17_True'): [0.3, 0.52, 0.28, 0.46],\n",
    "    os.path.join('20190704_inta_meeting_n2_train_mass_ss', 'v15'): [0.5, 0.42, 0.56, 0.58],\n",
    "    os.path.join('20190704_inta_meeting_n2_train_mass_ss', 'v20_indep'): [0.4, 0.62, 0.64, 0.56],\n",
    "    os.path.join('20190704_inta_meeting_n2_train_inta_ss', 'v15'): [0.48, 0.48, 0.5, 0.46],\n",
    "    os.path.join('20190704_inta_meeting_n2_train_inta_ss', 'v20_indep'): [0.54, 0.42, 0.5, 0.5],\n",
    "    os.path.join('20190706_inta_05_n2_train_inta_ss', 'v15'): [0.42, 0.44, 0.48, 0.5],\n",
    "    os.path.join('20190708_grid_v19_pte2_n2_train_mass_ss', 'r_1_i_1_m_1_p_0_fb_0.5'): [0.42, 0.58, 0.62, 0.54],\n",
    "    os.path.join('20190825_v22_grid_n2_train_mass_ss', 'r_1_i_1_m_1_p_0_drop_0.3_f_64'): [0.52, 0.48, 0.5, 0.52],\n",
    "    os.path.join('20190827_thesis_1_bsf_e1_n2_train_mass_ss', 'v19'): [0.54, 0.52, 0.64, 0.54],\n",
    "    os.path.join('20190915_balancing_drop_n2_train_mass_ss', 'v11'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190915_balancing_drop_n2_train_mass_ss', 'v19'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190915_balancing_drop_n2_train_mass_kc', 'v11'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190915_balancing_drop_n2_train_mass_kc', 'v19'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190916_balancing_drop_v2_n2_train_mass_ss', 'v11'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190916_balancing_drop_v2_n2_train_mass_ss', 'v19'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190916_balancing_weight_n2_train_mass_ss', 'v11'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190916_balancing_weight_n2_train_mass_ss', 'v19'): [0.5, 0.5, 0.5, 0.5],\n",
    "    os.path.join('20190917_out_proba_init_grid_n2_train_mass_ss', 'p_0.01_lr_0.0001'): [0.44, 0.54, 0.56, 0.32],\n",
    "    os.path.join('20190917_out_proba_init_grid_n2_train_mass_ss', 'p_0.1_lr_0.0001'): [0.24, 0.42, 0.54, 0.48],\n",
    "    os.path.join('20190917_out_proba_init_equal_n2_train_mass_ss', 'v11'): [0.28, 0.58, 0.56, 0.4],\n",
    "    os.path.join('20190927_out_proba_cwt_grid_n2_train_mass_ss', 'p_0.5_lr_0.0001'): [0.36, 0.42, 0.62, 0.4],\n",
    "    os.path.join('20190927_out_proba_cwt_grid_n2_train_mass_ss', 'p_0.01_lr_0.0001'): [0.42, 0.46, 0.54, 0.36],\n",
    "}\n",
    "\n",
    "ckpt_folder = os.path.join('20190927_out_proba_cwt_grid_n2_train_mass_ss', 'p_0.01_lr_0.0001')\n",
    "new_split_version = True\n",
    "optimal_thr_list = optimal_thr_for_ckpt_dict[ckpt_folder]\n",
    "task_mode = constants.N2_RECORD\n",
    "dataset_name = constants.MASS_SS_NAME\n",
    "seed_id_list = [0, 1, 2, 3]\n",
    "# seed_id_list = [1]\n",
    "\n",
    "n_seeds = len(seed_id_list)\n",
    "set_list = [constants.TRAIN_SUBSET, constants.VAL_SUBSET, constants.TEST_SUBSET]\n",
    "# set_list = [constants.TEST_SUBSET]\n",
    "which_expert = 1\n",
    "verbose = False\n",
    "\n",
    "# Load data\n",
    "dataset = load_dataset(dataset_name, params={pkeys.NORM_COMPUTATION_MODE: constants.NORM_GLOBAL})\n",
    "fs = dataset.fs\n",
    "all_train_ids = dataset.train_ids\n",
    "test_ids = dataset.test_ids\n",
    "predictions_dict = {}\n",
    "for k in seed_id_list:\n",
    "    # Restore predictions\n",
    "    ckpt_path = os.path.abspath(os.path.join(\n",
    "        RESULTS_PATH,\n",
    "        'predictions_%s' % dataset_name,\n",
    "        ckpt_folder,\n",
    "        'seed%d' % k\n",
    "    ))\n",
    "    this_dict = {}\n",
    "    for set_name in set_list:\n",
    "        filename = os.path.join(\n",
    "                ckpt_path,\n",
    "                'prediction_%s_%s.pkl' % (task_mode, set_name))\n",
    "        with open(filename, 'rb') as handle:\n",
    "            this_pred = RefactorUnpickler(handle).load()\n",
    "        this_dict[set_name] = this_pred\n",
    "    predictions_dict[k] = this_dict\n",
    "    print('Loaded seed %d/%d from %s' % (k + 1, n_seeds, ckpt_path))\n",
    "print('Optimal thr:', optimal_thr_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output thr selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_id_for_selection = 1\n",
    "\n",
    "\n",
    "# Adjust thr\n",
    "res_thr = 0.02\n",
    "start_thr = 0.3\n",
    "end_thr = 0.7\n",
    "n_thr = int(np.round((end_thr - start_thr) / res_thr + 1))\n",
    "thr_list = np.array([start_thr + res_thr * i for i in range(n_thr)])\n",
    "thr_list = np.round(thr_list, 2)\n",
    "print('%d thresholds to be evaluated between %1.4f and %1.4f'\n",
    "      % (n_thr, thr_list[0], thr_list[-1]))\n",
    "\n",
    "per_seed_af1 = []\n",
    "# Validation split\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_id_for_selection)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_id_for_selection])\n",
    "\n",
    "ids_dict = {\n",
    "    constants.TRAIN_SUBSET: train_ids,\n",
    "    constants.VAL_SUBSET: val_ids}\n",
    "for thr in thr_list:\n",
    "    events_list = []\n",
    "    detections_list = []\n",
    "    for set_name in [constants.TRAIN_SUBSET, constants.VAL_SUBSET]:\n",
    "        # Prepare expert labels\n",
    "        data_inference = FeederDataset(\n",
    "            dataset, ids_dict[set_name], task_mode,\n",
    "            which_expert=which_expert)\n",
    "        this_events = data_inference.get_stamps()\n",
    "        # Prepare model predictions\n",
    "        prediction_obj = predictions_dict[seed_id_for_selection][set_name]\n",
    "        prediction_obj.set_probability_threshold(thr)\n",
    "        this_detections = prediction_obj.get_stamps()\n",
    "        events_list = events_list + this_events\n",
    "        detections_list = detections_list + this_detections\n",
    "    # Compute AF1\n",
    "    af1_at_thr = metrics.average_metric_with_list(\n",
    "        events_list, detections_list, verbose=False)\n",
    "    per_seed_af1.append(af1_at_thr)\n",
    "print('Done')\n",
    "max_idx = np.argmax(per_seed_af1).item()\n",
    "this_best_thr = thr_list[max_idx]\n",
    "print('Best thr: %1.2f' % this_best_thr)\n",
    "\n",
    "# For best thr, compute F1 vs IoU curve\n",
    "events_list = []\n",
    "detections_list = []\n",
    "for set_name in [constants.TRAIN_SUBSET, constants.VAL_SUBSET]:\n",
    "    # Prepare expert labels\n",
    "    data_inference = FeederDataset(\n",
    "        dataset, ids_dict[set_name], task_mode,\n",
    "        which_expert=which_expert)\n",
    "    this_events = data_inference.get_stamps()\n",
    "    # Prepare model predictions\n",
    "    prediction_obj = predictions_dict[seed_id_for_selection][set_name]\n",
    "    prediction_obj.set_probability_threshold(this_best_thr)\n",
    "    this_detections = prediction_obj.get_stamps()\n",
    "    events_list = events_list + this_events\n",
    "    detections_list = detections_list + this_detections\n",
    "# Compute AF1\n",
    "first_iou = 0\n",
    "last_iou = 1\n",
    "res_iou = 0.01\n",
    "n_points = int(np.round((last_iou - first_iou) / res_iou))\n",
    "full_iou_list = np.arange(n_points + 1) * res_iou + first_iou\n",
    "f1_alltrain = metrics.metric_vs_iou_with_list(\n",
    "    events_list, detections_list, full_iou_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(6, 3), dpi=200)\n",
    "\n",
    "ax[0].plot(full_iou_list, f1_alltrain, color=CUSTOM_COLOR['red'])\n",
    "ax[0].fill_between(full_iou_list, f1_alltrain, 0, color=CUSTOM_COLOR['red'], alpha=0.5)\n",
    "ax[0].set_title('F1 vs IoU curve at $\\mu$=%1.2f' % this_best_thr, fontsize=10)\n",
    "ax[0].set_xlim([0, 1])\n",
    "ax[0].set_ylim([0, 1])\n",
    "ax[0].set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax[0].set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax[0].tick_params(labelsize=7)\n",
    "ax[0].set_xlabel('IoU Threshold', fontsize=7)\n",
    "ax[0].set_ylabel('F1-score', fontsize=7)\n",
    "\n",
    "min_y = np.min(per_seed_af1) - 0.05\n",
    "max_y = np.max(per_seed_af1) + 0.05\n",
    "ax[1].plot(\n",
    "    thr_list, per_seed_af1, \n",
    "    color=CUSTOM_COLOR['red'], marker='o', markersize=4, label='Train+val set', zorder=10)\n",
    "ax[1].plot(\n",
    "    [this_best_thr, this_best_thr], [min_y, max_y], \n",
    "    color=CUSTOM_COLOR['grey'], linestyle='--', linewidth=1.5, label='Optimal $\\mu$=%1.2f' % this_best_thr, zorder=5)\n",
    "ax[1].set_title('Adjustment of $\\mu$', fontsize=10)\n",
    "ax[1].set_xticks([0.3, 0.4, 0.5, 0.6, 0.7])\n",
    "ax[1].set_ylim([min_y, max_y])\n",
    "ax[1].tick_params(labelsize=7)\n",
    "ax[1].set_xlabel('Model Output Threshold $\\mu$', fontsize=7)\n",
    "ax[1].set_ylabel('AF1', fontsize=7)\n",
    "ax[1].legend(loc='upper right', fontsize=7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: F1 vs IoU curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ---------------- Compute performance\n",
    "f1_vs_iou_dict = {}\n",
    "first_iou = 0.1\n",
    "last_iou = 0.9\n",
    "step_iou = 0.1\n",
    "n_points = int((last_iou - first_iou) / step_iou)\n",
    "iou_list = first_iou + np.arange(n_points + 1) * step_iou\n",
    "iou_list_short = np.arange(1, 10) * 0.1\n",
    "iou_list_short_idx = [np.where(np.isclose(iou_list, this_value))[0][0] for this_value in iou_list_short]\n",
    "\n",
    "# Prepare expert labels\n",
    "data_test = FeederDataset(\n",
    "    dataset, test_ids, task_mode, which_expert=which_expert)\n",
    "this_events = data_test.get_stamps()\n",
    "\n",
    "seed_stamps = []\n",
    "test_af1_list = []\n",
    "seed_mean_ioutp = []\n",
    "for k in seed_id_list:\n",
    "    # Prepare model predictions\n",
    "    prediction_test = predictions_dict[k][constants.TEST_SUBSET]\n",
    "    \n",
    "    prediction_test.set_probability_threshold(optimal_thr_list[k])\n",
    "    this_detections = prediction_test.get_stamps()\n",
    "    seed_stamps.append(this_detections)\n",
    "    this_f1_vs_iou = metrics.metric_vs_iou_with_list(\n",
    "        this_events, this_detections, iou_list)\n",
    "    this_af1 = metrics.average_metric_with_list(this_events, this_detections)\n",
    "    f1_vs_iou_dict[k] = this_f1_vs_iou\n",
    "    test_af1_list.append(this_af1)\n",
    "    \n",
    "    # Measure iou of TP\n",
    "    mean_iou_per_subject = []\n",
    "    for single_events, single_detections in zip(this_events, this_detections):\n",
    "        this_iou_array, idx_array = metrics.matching(single_events, single_detections)\n",
    "        this_iou_array = this_iou_array[idx_array > -1]\n",
    "        mean_iou_per_subject.append(np.mean(this_iou_array))\n",
    "    seed_mean_ioutp.append(np.mean(mean_iou_per_subject))\n",
    "    \n",
    "# Mean performance\n",
    "mean_f1_vs_iou = np.stack([f1_vs_iou_dict[k] for k in seed_id_list], axis=1).mean(axis=1)\n",
    "std_f1_vs_iou = np.stack([f1_vs_iou_dict[k] for k in seed_id_list], axis=1).std(axis=1)\n",
    "mean_f1_vs_iou_short = mean_f1_vs_iou[iou_list_short_idx]\n",
    "std_f1_vs_iou_short = std_f1_vs_iou[iou_list_short_idx]\n",
    "\n",
    "print('IoU   Mean    Std')\n",
    "for k in range(iou_list_short.size):\n",
    "    print('%1.2f  %1.4f  %1.4f' % (iou_list_short[k], mean_f1_vs_iou_short[k], std_f1_vs_iou_short[k]))\n",
    "    \n",
    "print('Test AF1: %1.4f +- %1.4f' % (np.mean(test_af1_list), np.std(test_af1_list)))\n",
    "print('Test AF1 per seed:', test_af1_list)\n",
    "print('Test Mean IoU at TP: %1.4f +- %1.4f' % (np.mean(seed_mean_ioutp), np.std(seed_mean_ioutp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "filename = '%s_f1_vs_iou.npy' % (ckpt_folder.split('/')[0])\n",
    "data = np.stack([iou_list, mean_f1_vs_iou, std_f1_vs_iou], axis=1).astype(np.float32)\n",
    "np.save(filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensamble_thr = 0.5  # Majority vote is 0.5\n",
    "binarized_first = True\n",
    "\n",
    "detections_half_rule_list = []\n",
    "detections_greater_half_rule_list = []\n",
    "\n",
    "postprocessor = PostProcessor(\n",
    "    predictions_dict[0][constants.TEST_SUBSET].event_name, \n",
    "    predictions_dict[0][constants.TEST_SUBSET].params)\n",
    "\n",
    "for j in range(len(test_ids)):\n",
    "    if task_mode == constants.N2_RECORD:\n",
    "        pages_indices_subset = predictions_dict[0][constants.TEST_SUBSET].get_subject_pages(\n",
    "            test_ids[j], pages_subset=constants.N2_RECORD, verbose=False)\n",
    "    else:\n",
    "        pages_indices_subset = None\n",
    "    \n",
    "    this_subject_detections_list_seq = [predictions_dict[k][constants.TEST_SUBSET].get_probabilities()[j].astype(np.float32) for k in seed_id_list]\n",
    "    if binarized_first:\n",
    "        this_subject_detections_list_seq = [(this_det >= this_thr).astype(np.int32) for (this_det, this_thr) in zip(this_subject_detections_list_seq, optimal_thr_list)]\n",
    "    this_subject_detections_mean = np.stack(this_subject_detections_list_seq, axis=0).mean(axis=0)\n",
    "    \n",
    "    detections_half_rule = postprocessor.proba2stamps(\n",
    "        this_subject_detections_mean, None, pages_indices_subset, thr=ensamble_thr)\n",
    "    detections_half_rule_list.append(detections_half_rule)\n",
    "    \n",
    "half_rule_f1_vs_iou = metrics.metric_vs_iou_with_list(\n",
    "        this_events, detections_half_rule_list, iou_list)\n",
    "half_rule_af1 = metrics.average_metric_with_list(this_events, detections_half_rule_list)\n",
    "\n",
    "half_rule_f1_vs_iou_short = half_rule_f1_vs_iou[iou_list_short_idx]\n",
    "\n",
    "print('IoU   Mean')\n",
    "for k in range(iou_list_short.size):\n",
    "    print('%1.2f  %1.4f' % (iou_list_short[k], half_rule_f1_vs_iou_short[k]))\n",
    "\n",
    "print('Test AF1 Ensamble:')\n",
    "print('Half Rule: %1.4f' % half_rule_af1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bsf_name = 'Proposed (%s)' % task_mode.upper()\n",
    "\n",
    "compare_expert = True\n",
    "compare_chambon = False\n",
    "show_seed_std = True\n",
    "show_seed_curves = False\n",
    "show_ensamble = False\n",
    "alpha = 0.3\n",
    "color_list = {'model_mean': CUSTOM_COLOR['red'] , 'expert': CUSTOM_COLOR['grey'], 'dosed': CUSTOM_COLOR['blue']}\n",
    "linewidth_model = 1.5\n",
    "markersize_model = 7\n",
    "linewidth_others = 1.5\n",
    "markersize_others = 7\n",
    "\n",
    "# -------------------- P L O T ----------------------    \n",
    "\n",
    "# Comparison data\n",
    "compare_expert = (compare_expert and (dataset.event_name == constants.SPINDLE))\n",
    "if compare_expert:\n",
    "    expert_f1_curve_mean = np.loadtxt(os.path.join(COMPARISON_PATH, 'expert', 'ss_f1_vs_iou_expert_mean.csv'), delimiter=',')\n",
    "    expert_f1_curve_std = np.loadtxt(os.path.join(COMPARISON_PATH, 'expert', 'ss_f1_vs_iou_expert_std.csv'), delimiter=',')\n",
    "    expert_f1_curve_mean = expert_f1_curve_mean[1:, :]\n",
    "    expert_f1_curve_std = expert_f1_curve_std[1:, :]\n",
    "if compare_chambon and (dataset_name == constants.MASS_SS_NAME):\n",
    "    dosed_f1_curve_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_ss_wn_f1_vs_iou_dosed_separately.csv'), delimiter=',')\n",
    "if compare_chambon and (dataset_name == constants.MASS_KC_NAME):\n",
    "    dosed_f1_curve_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_kc_wn_f1_vs_iou_dosed_separately.csv'), delimiter=',')\n",
    "    \n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "\n",
    "\n",
    "# Complete plot\n",
    "if compare_expert:\n",
    "    ax.plot(expert_f1_curve_mean[:, 0], expert_f1_curve_mean[:, 1], linewidth=linewidth_others, \n",
    "               label='Expert Performance\\nPrivate Dataset\\nWarby et al. 2014', color=color_list['expert'])\n",
    "    ax.plot(expert_f1_curve_mean[:, 0], expert_f1_curve_mean[:, 1], linestyle='none', \n",
    "               markersize=markersize_others, marker='.', color=color_list['expert'])\n",
    "    ax.fill_between(\n",
    "        expert_f1_curve_mean[:, 0], \n",
    "        expert_f1_curve_mean[:, 1] - expert_f1_curve_std[:, 1], \n",
    "        expert_f1_curve_mean[:, 1] + expert_f1_curve_std[:, 1], \n",
    "        alpha=alpha, facecolor=color_list['expert'])\n",
    "\n",
    "if compare_chambon and (dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]):\n",
    "    ax.plot(dosed_f1_curve_wn[:, 0], dosed_f1_curve_wn[:, 1], linewidth=linewidth_others,\n",
    "               label='DOSED (WN) (Paper)\\nChambon et al. 2019', color=color_list['dosed'])\n",
    "    ax.plot(dosed_f1_curve_wn[:, 0], dosed_f1_curve_wn[:, 1], linestyle='none',\n",
    "               markersize=markersize_others, marker='.', color=color_list['dosed'])\n",
    "    idx_to_show = np.where(np.isclose(dosed_f1_curve_wn[:, 0], 0.3))[0][0]\n",
    "    print('%1.4f Dosed F1 at 0.3' % dosed_f1_curve_wn[idx_to_show, 1])\n",
    "\n",
    "if show_seed_curves:\n",
    "    for k in seed_id_list:\n",
    "        ax.plot(iou_list, f1_vs_iou_dict[k], \n",
    "           linewidth=linewidth_model, markersize=markersize_model, marker='.', alpha=0.3,\n",
    "           color=color_list['model_mean'])\n",
    "        \n",
    "ax.plot(iou_list, mean_f1_vs_iou, \n",
    "           linewidth=linewidth_model,\n",
    "           label='%s (Mean)' % bsf_name, color=color_list['model_mean'])\n",
    "ax.plot(iou_list_short, mean_f1_vs_iou_short, \n",
    "           linestyle='none', markersize=markersize_model, marker='.', \n",
    "           color=color_list['model_mean'])\n",
    "idx_to_show = np.where(np.isclose(iou_list, 0.3))[0][0]\n",
    "print('%1.4f Proposed mean F1 at 0.3' % mean_f1_vs_iou[idx_to_show])\n",
    "if show_seed_std:\n",
    "    ax.fill_between(\n",
    "        iou_list, \n",
    "        mean_f1_vs_iou - std_f1_vs_iou, \n",
    "        mean_f1_vs_iou + std_f1_vs_iou, \n",
    "        alpha=alpha, facecolor=color_list['model_mean'])\n",
    "\n",
    "if show_ensamble:\n",
    "    ax.plot(iou_list, half_rule_f1_vs_iou, \n",
    "           linewidth=linewidth_model, \n",
    "           label='%s (Ensemble)' % bsf_name, color=CUSTOM_COLOR['green'])\n",
    "    ax.plot(iou_list_short, half_rule_f1_vs_iou_short, \n",
    "           linestyle='none', markersize=markersize_model, marker='.', \n",
    "           color=CUSTOM_COLOR['green'])\n",
    "    \n",
    "ax.set_title('Test Performance (%s Dataset)' % dataset_name.upper(), fontsize=10)\n",
    "ax.set_xlim([0.1 - 0.02, 0.9 + 0.02])\n",
    "ax.set_ylim([0.1 - 0.02, 0.9 + 0.02])\n",
    "ax.set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax.set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax.set_ylabel('F1-score', fontsize=8.5)\n",
    "ax.yaxis.grid()\n",
    "ax.legend(loc='lower left', labelspacing=1.5, fontsize=6.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only test set\n",
    "alpha = 0.2\n",
    "seed_id_for_scatter = 0\n",
    "\n",
    "\n",
    "# Prepare model predictions\n",
    "prediction_obj = predictions_dict[seed_id_for_scatter][constants.VAL_SUBSET]\n",
    "prediction_obj.set_probability_threshold(optimal_thr_list[seed_id_for_scatter])\n",
    "this_detections_list = prediction_obj.get_stamps()\n",
    "this_ids = prediction_obj.get_ids()\n",
    "\n",
    "# Prepare expert labels\n",
    "data_inference = FeederDataset(\n",
    "    dataset, this_ids, task_mode, which_expert)\n",
    "this_events_list = data_inference.get_stamps()\n",
    "\n",
    "expert_durations_list = []\n",
    "predicted_durations_list = []\n",
    "for i, single_id in enumerate(this_ids):\n",
    "    single_events = this_events_list[i]\n",
    "    single_detections = this_detections_list[i]\n",
    "    this_iou_array, this_idx_array = metrics.matching(single_events, single_detections)\n",
    "    idx_valid = (this_idx_array > -1)\n",
    "    matched_expert_durations = (single_events[idx_valid, 1] - single_events[idx_valid, 0]) / fs\n",
    "    matched_detections = single_detections[this_idx_array]\n",
    "    matched_predicted_durations = (matched_detections[idx_valid, 1] - matched_detections[idx_valid, 0]) / fs\n",
    "    expert_durations_list.append(matched_expert_durations)\n",
    "    predicted_durations_list.append(matched_predicted_durations)\n",
    "\n",
    "fig, ax = plt.subplots(1, len(this_ids), figsize=(8, 3), dpi=DPI)\n",
    "for i, subject_id in enumerate(this_ids):\n",
    "    ax[i].scatter(\n",
    "        expert_durations_list[i], predicted_durations_list[i], \n",
    "        label='S%02d' % subject_id, color='#455a64', alpha=alpha)\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "    lg = ax[i].legend(fontsize=7)\n",
    "    for lh in lg.legendHandles:\n",
    "        lh.set_facecolor(lh.get_facecolor())\n",
    "        lh.set_edgecolor(lh.get_edgecolor())\n",
    "        lh.set_alpha(1.0)\n",
    "    max_dur = max(expert_durations_list[i].max(), predicted_durations_list[i].max())\n",
    "    ax[i].set_xlim([0, max_dur + 0.1])\n",
    "    ax[i].set_ylim([0, max_dur + 0.1])\n",
    "    if i == 0 :\n",
    "        ax[i].set_ylabel('Detected duration [s]', fontsize=8.5)\n",
    "    ax[i].set_xlabel('Duration Real [s]', fontsize=8.5)\n",
    "    ax[i].plot([0.3, 2.0], [0.3, 2.0], '--k', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 vs IoU by subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_id_for_f1vsiou = 0\n",
    "\n",
    "# ---------------- Compute performance\n",
    "f1_vs_iou_subject_dict = {}\n",
    "pre_vs_iou_subject_dict = {}\n",
    "rec_vs_iou_subject_dict = {}\n",
    "iou_list = np.arange(21) * 0.05\n",
    "\n",
    "# Validation split\n",
    "# train_ids, val_ids = utils.split_ids_list(\n",
    "#    all_train_ids, seed=SEED_LIST[seed_id_for_f1vsiou], verbose=False)\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_id_for_f1vsiou)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_id_for_f1vsiou])\n",
    "ids_dict = {\n",
    "    constants.TRAIN_SUBSET: train_ids,\n",
    "    constants.VAL_SUBSET: val_ids,\n",
    "    constants.TEST_SUBSET: test_ids\n",
    "}\n",
    "\n",
    "for set_name in set_list:\n",
    "    print('Processing %s' % set_name, flush=True)\n",
    "    # Prepare expert labels\n",
    "    data_inference = FeederDataset(\n",
    "        dataset, ids_dict[set_name], task_mode, which_expert)\n",
    "    this_ids = data_inference.get_ids()\n",
    "    this_events_list = data_inference.get_stamps()\n",
    "    # Prepare model predictions\n",
    "    prediction_obj = predictions_dict[seed_id_for_f1vsiou][set_name]\n",
    "    prediction_obj.set_probability_threshold(optimal_thr_list[seed_id_for_f1vsiou])\n",
    "    this_detections_list = prediction_obj.get_stamps()\n",
    "    for i, single_id in enumerate(this_ids):\n",
    "        single_events = this_events_list[i]\n",
    "        single_detections = this_detections_list[i]\n",
    "        this_precision = metrics.metric_vs_iou(single_events, single_detections, iou_list, metric_name=constants.PRECISION)\n",
    "        this_recall = metrics.metric_vs_iou(single_events, single_detections, iou_list, metric_name=constants.RECALL)\n",
    "        this_f1 = 2 * this_precision * this_recall / (this_precision + this_recall + 1e-8)\n",
    "        pre_vs_iou_subject_dict[single_id] = this_precision\n",
    "        rec_vs_iou_subject_dict[single_id] = this_recall\n",
    "        f1_vs_iou_subject_dict[single_id] = this_f1\n",
    "print('Done', flush=True)\n",
    "\n",
    "color_list = {'train': CUSTOM_COLOR['green'] , 'val': CUSTOM_COLOR['grey'], 'test': CUSTOM_COLOR['red']}\n",
    "marker_list = ['.', 's', '^', 'x', '*', 'd', 'v', 'p']\n",
    "linewidth_model = 1\n",
    "markersize_model = 5\n",
    "\n",
    "# -------------------- P L O T ----------------------    \n",
    "    \n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 4), dpi=DPI)\n",
    "\n",
    "# F1\n",
    "for set_name in set_list:\n",
    "    for i, single_id in enumerate(ids_dict[set_name]):\n",
    "        ax[0].plot(iou_list, f1_vs_iou_subject_dict[single_id], \n",
    "                   linewidth=linewidth_model, markersize=markersize_model, marker=marker_list[i], \n",
    "                   label='S%02d' % single_id, color=color_list[set_name])\n",
    "\n",
    "    \n",
    "ax[0].set_title('Test Performance (%s Dataset) (%s)' \n",
    "             % (dataset_name.upper(), task_mode.upper()), fontsize=10)\n",
    "ax[0].set_xlim([0, 1])\n",
    "ax[0].set_ylim([0, 1])\n",
    "ax[0].set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax[0].set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax[0].tick_params(labelsize=8.5)\n",
    "ax[0].set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax[0].set_ylabel('F1-score', fontsize=8.5)\n",
    "ax[0].yaxis.grid()\n",
    "ax[0].legend(loc='lower left', fontsize=5)\n",
    "\n",
    "# Precision\n",
    "for set_name in set_list:\n",
    "    for i, single_id in enumerate(ids_dict[set_name]):\n",
    "        ax[1].plot(iou_list, pre_vs_iou_subject_dict[single_id], \n",
    "                   linewidth=linewidth_model, markersize=markersize_model, marker=marker_list[i], \n",
    "                   label='S%02d' % single_id, color=color_list[set_name])\n",
    "\n",
    "    \n",
    "ax[1].set_title('Test Performance (%s Dataset) (%s)' \n",
    "             % (dataset_name.upper(), task_mode.upper()), fontsize=10)\n",
    "ax[1].set_xlim([0, 1])\n",
    "ax[1].set_ylim([0, 1])\n",
    "ax[1].set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax[1].set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax[1].tick_params(labelsize=8.5)\n",
    "ax[1].set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax[1].set_ylabel('Precision', fontsize=8.5)\n",
    "ax[1].yaxis.grid()\n",
    "ax[1].legend(loc='lower left', fontsize=5)\n",
    "\n",
    "# Recall\n",
    "for set_name in set_list:\n",
    "    for i, single_id in enumerate(ids_dict[set_name]):\n",
    "        ax[2].plot(iou_list, rec_vs_iou_subject_dict[single_id], \n",
    "                   linewidth=linewidth_model, markersize=markersize_model, marker=marker_list[i], \n",
    "                   label='S%02d' % single_id, color=color_list[set_name])\n",
    "\n",
    "    \n",
    "ax[2].set_title('Test Performance (%s Dataset) (%s)' \n",
    "             % (dataset_name.upper(), task_mode.upper()), fontsize=10)\n",
    "ax[2].set_xlim([0, 1])\n",
    "ax[2].set_ylim([0, 1])\n",
    "ax[2].set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax[2].set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax[2].tick_params(labelsize=8.5)\n",
    "ax[2].set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax[2].set_ylabel('Recall', fontsize=8.5)\n",
    "ax[2].yaxis.grid()\n",
    "ax[2].legend(loc='lower left', fontsize=5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR by subject, usando APrecision y ARecall\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "markersize = 10\n",
    "text_space = 0.01\n",
    "show_ids = True\n",
    "axis_lims = [0, 1]\n",
    "show_set_list = ['train', 'val', 'test']\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "\n",
    "levels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "levels = [level for level in levels if (level>axis_lims[0] and level<axis_lims[1])]\n",
    "\n",
    "CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=levels)\n",
    "ax.clabel(CS, fontsize=6, fmt='%1.2f')\n",
    "\n",
    "for set_name in set_list:\n",
    "    if set_name in show_set_list:\n",
    "        for i, single_id in enumerate(ids_dict[set_name]):\n",
    "            if i==0:\n",
    "                label = 'Proposed (%s) (%s)' % (task_mode.upper(), set_name.capitalize())\n",
    "            else:\n",
    "                label = None\n",
    "            this_arecall = rec_vs_iou_subject_dict[single_id].mean()\n",
    "            this_aprecision = pre_vs_iou_subject_dict[single_id].mean()\n",
    "            ax.scatter(\n",
    "                this_arecall, this_aprecision, \n",
    "                c=color_list[set_name], \n",
    "                label=label, marker='s',\n",
    "                s=markersize, zorder=10)\n",
    "            if show_ids:\n",
    "                ax.annotate(\n",
    "                    single_id, \n",
    "                    (this_arecall+text_space, this_aprecision+text_space), \n",
    "                    fontsize=7, color='#1b2631', zorder=20) \n",
    "ax.set_title('Seed %d ($\\mu$=%1.2f)' % (seed_id_for_f1vsiou, optimal_thr_list[seed_id_for_f1vsiou]), fontsize=7)\n",
    "ax.set_xlabel('A-Recall', fontsize=7)\n",
    "ax.set_ylabel('A-Precision', fontsize=7)\n",
    "ax.set_xlim(axis_lims)\n",
    "ax.set_ylim(axis_lims)\n",
    "ax.tick_params(labelsize=7)\n",
    "ax.legend(loc='lower left', fontsize=5)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: Precision-Recall curve, average per set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_thr = 0.3\n",
    "res_thr = 0.02\n",
    "start_thr = 0.1\n",
    "end_thr = 0.9\n",
    "n_thr = int(np.round((end_thr - start_thr) / res_thr + 1))\n",
    "thr_list = np.array([start_thr + res_thr * i for i in range(n_thr)])\n",
    "\n",
    "pr_curve = {}\n",
    "# Prepare expert labels\n",
    "data_test = FeederDataset(\n",
    "    dataset, test_ids, task_mode, which_expert=which_expert)\n",
    "this_events = data_test.get_stamps()\n",
    "for k in seed_id_list:\n",
    "    print('Processing seed %d' % k, flush=True)\n",
    "    # Columns are [x: recall, y: precision]\n",
    "    pr_curve[k] = np.zeros((n_thr, 2))\n",
    "    for i, thr in enumerate(thr_list):\n",
    "        # Prepare model predictions\n",
    "        prediction_test = predictions_dict[k][constants.TEST_SUBSET]\n",
    "        prediction_test.set_probability_threshold(thr)\n",
    "        this_detections = prediction_test.get_stamps()\n",
    "        \n",
    "        this_stats = [metrics.by_event_confusion(this_y, this_y_pred, iou_thr=iou_thr) \n",
    "                    for (this_y, this_y_pred) in zip(this_events, this_detections)]\n",
    "        this_recall = np.mean([m[constants.RECALL] for m in this_stats])\n",
    "        this_precision = np.mean([m[constants.PRECISION] for m in this_stats])\n",
    "        pr_curve[k][i, 0] = this_recall\n",
    "        pr_curve[k][i, 1] = this_precision\n",
    "\n",
    "# Mean of runs\n",
    "# pr_curve['mean_runs'] = np.stack([pr_curve[k] for k in seed_id_list], axis=2).mean(axis=2)\n",
    "print('Done', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "filename = '%s_pr_curve.npy' % (ckpt_folder.split('/')[0])\n",
    "data = []\n",
    "this_thr = np.asarray(thr_list)[:, np.newaxis]\n",
    "for k in seed_id_list:\n",
    "    this_pr = pr_curve[k]\n",
    "    this_pr = np.concatenate([this_thr, this_pr], axis=1)\n",
    "    data.append(this_pr)\n",
    "data = np.stack(data, axis=0).astype(np.float32)\n",
    "np.save(filename, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot \n",
    "bsf_name = 'Proposed (%s)' % task_mode.upper()\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "markersize = 6\n",
    "alpha = 0.4\n",
    "text_space = 0.01\n",
    "compare_chambon = False\n",
    "show_seeds = True\n",
    "axis_lims = [0.0, 1.0]\n",
    "color_list = {'model_mean': CUSTOM_COLOR['red'] , 'dosed': CUSTOM_COLOR['blue']}\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "\n",
    "levels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "levels = [level for level in levels if (level>axis_lims[0] and level<axis_lims[1])]\n",
    "\n",
    "CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=levels)\n",
    "ax.clabel(CS, fontsize=7.5, fmt='%1.2f')\n",
    "\n",
    "# Chambon\n",
    "if compare_chambon and (dataset_name == constants.MASS_SS_NAME):\n",
    "    dosed_rec_prec_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_ss_wn_pr_dosed_separately.csv'), delimiter=',')\n",
    "    ax.plot(dosed_rec_prec_wn[0], dosed_rec_prec_wn[1], \n",
    "           markersize=8, c=color_list['dosed'], zorder=10, \n",
    "            label='DOSED (WN) (Paper)', marker='o', linestyle=\"None\")\n",
    "if compare_chambon and (dataset_name == constants.MASS_KC_NAME):\n",
    "    dosed_rec_prec_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_kc_wn_pr_dosed_separately.csv'), delimiter=',')\n",
    "    ax.plot(dosed_rec_prec_wn[0], dosed_rec_prec_wn[1], \n",
    "           markersize=8, c=color_list['dosed'], zorder=10, \n",
    "            label='DOSED (WN) (Paper)', marker='o', linestyle=\"None\")\n",
    "    \n",
    "if show_seeds:\n",
    "    # Show single seeds\n",
    "    seed_shown = False\n",
    "    for k in seed_id_list:\n",
    "        if not seed_shown:\n",
    "            seed_shown=True\n",
    "            label = '%s (Seed curve)' % bsf_name\n",
    "            label_2 = '%s (Seed O.P.)' % bsf_name\n",
    "        else:\n",
    "            label = None\n",
    "            label_2 = None\n",
    "        ax.plot(pr_curve[k][:, 0], pr_curve[k][:, 1], \n",
    "            label=label,\n",
    "            linewidth=1, color=color_list['model_mean'], zorder=7, alpha=alpha)\n",
    "        \n",
    "        chosen_thr_idx = np.where(np.isclose(thr_list, optimal_thr_list[k]))[0].item()\n",
    "        ax.scatter(pr_curve[k][chosen_thr_idx, 0], pr_curve[k][chosen_thr_idx, 1], \n",
    "                   s=50, c=color_list['model_mean'], zorder=7, alpha=alpha, label=label_2)\n",
    "    \n",
    "# Mean of runs\n",
    "# ax.plot(pr_curve['mean_runs'][:, 0], pr_curve['mean_runs'][:, 1], \n",
    "#         label='%s (Mean)' % bsf_name,\n",
    "#         linewidth=1.5, color=color_list['model_mean'], zorder=10)\n",
    "\n",
    "# Highlight chosen operating point\n",
    "# chosen_thr_idx = np.where(np.isclose(thr_list, thr_run))[0].item()\n",
    "# ax.scatter(pr_curve['mean_runs'][chosen_thr_idx, 0], pr_curve['mean_runs'][chosen_thr_idx, 1], \n",
    "#            s=50, c=color_list['model_mean'], zorder=10, label='Operating point $\\mu$=%1.2f' % thr_run)\n",
    "# ax.annotate('$\\mu$=%1.3f' % thr_run, \n",
    "#             (pr_curve['mean_runs'][chosen_thr_idx, 0], \n",
    "#              pr_curve['mean_runs'][chosen_thr_idx, 1] + text_space*2), \n",
    "#             fontsize=7, color='#1b2631', zorder=30)  \n",
    "\n",
    "ax.set_title('Test PR Curve with IoU$>$%1.1f (%s)' % (iou_thr, dataset_name.upper()), fontsize=10)\n",
    "ax.set_xlabel('Recall', fontsize=8.5)\n",
    "ax.set_ylabel('Precision', fontsize=8.5)\n",
    "ax.set_xlim(axis_lims)\n",
    "ax.set_ylim(axis_lims)\n",
    "\n",
    "lg = ax.legend(loc='lower left', labelspacing=1, fontsize=6.5)\n",
    "for lh in lg.legendHandles:\n",
    "    lh.set_alpha(1.0)\n",
    "\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: Precision-Recall plot, separated subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_thr = 0.3\n",
    "\n",
    "# Prepare model predictions\n",
    "be_stats = {}\n",
    "for k in seed_id_list:\n",
    "    print('Processing seed %d' % k, flush=True)\n",
    "    be_stats[k] = {}\n",
    "    if new_split_version:\n",
    "        train_ids, val_ids = utils.split_ids_list_v2(\n",
    "            all_train_ids, split_id=k)\n",
    "    else:\n",
    "        train_ids, val_ids = utils.split_ids_list(\n",
    "            all_train_ids, seed=SEED_LIST[k])\n",
    "    train_ids.sort()\n",
    "    val_ids.sort()\n",
    "    ids_per_set_dict = {\n",
    "        constants.TRAIN_SUBSET: train_ids,\n",
    "        constants.VAL_SUBSET: val_ids,\n",
    "        constants.TEST_SUBSET: test_ids\n",
    "    }\n",
    "    for set_name in set_list:\n",
    "        data_feeder = FeederDataset(\n",
    "            dataset, ids_per_set_dict[set_name], task_mode, which_expert=which_expert)\n",
    "        this_events = data_feeder.get_stamps()\n",
    "        prediction_set = predictions_dict[k][set_name]\n",
    "        prediction_set.set_probability_threshold(optimal_thr_list[k])\n",
    "        this_detections = prediction_set.get_stamps()\n",
    "        be_stats[k][set_name] = [\n",
    "            metrics.by_event_confusion(this_y, this_y_pred, iou_thr=iou_thr) \n",
    "            for (this_y, this_y_pred) in zip(this_events, this_detections)]\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot \n",
    "bsf_name = 'Proposed (%s)' % task_mode.upper()\n",
    "fig, ax = plt.subplots(1, n_seeds, figsize=(2.3*n_seeds, 2.3), dpi=DPI)\n",
    "markersize = 10\n",
    "alpha = 0.3\n",
    "text_space = 0.01\n",
    "compare_chambon = False\n",
    "show_ids = True\n",
    "axis_lims = [0.5, 1.0]\n",
    "show_set_list = ['train', 'val', 'test']\n",
    "color_list = {'train': CUSTOM_COLOR['green'] , 'val': CUSTOM_COLOR['grey'], 'test': CUSTOM_COLOR['red'], 'dosed': CUSTOM_COLOR['blue']}\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "\n",
    "levels = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "levels = [level for level in levels if (level>axis_lims[0] and level<axis_lims[1])]\n",
    "\n",
    "# Chambon\n",
    "if compare_chambon and (dataset_name == constants.MASS_SS_NAME):\n",
    "    dosed_rec_prec_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_ss_wn_pr_dosed_separately.csv'), delimiter=',')\n",
    "if compare_chambon and (dataset_name == constants.MASS_KC_NAME):\n",
    "    dosed_rec_prec_wn = np.loadtxt(\n",
    "        os.path.join(COMPARISON_PATH, 'dosed_paper', 'mass_kc_wn_pr_dosed_separately.csv'), delimiter=',')\n",
    "    \n",
    "for j in range(n_seeds):\n",
    "    seed_id = seed_id_list[j]\n",
    "    if new_split_version:\n",
    "        train_ids, val_ids = utils.split_ids_list_v2(\n",
    "            all_train_ids, split_id=seed_id)\n",
    "    else:\n",
    "        train_ids, val_ids = utils.split_ids_list(\n",
    "            all_train_ids, seed=SEED_LIST[seed_id])\n",
    "    train_ids.sort()\n",
    "    val_ids.sort()\n",
    "    ids_per_set_dict = {\n",
    "        constants.TRAIN_SUBSET: train_ids,\n",
    "        constants.VAL_SUBSET: val_ids,\n",
    "        constants.TEST_SUBSET: test_ids\n",
    "    }\n",
    "    \n",
    "    \n",
    "    CS = ax[j].contour(X, Y, Z, colors='k', alpha=0.3, levels=levels)\n",
    "    ax[j].clabel(CS, fontsize=6, fmt='%1.2f')\n",
    "    \n",
    "    if compare_chambon and (dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]):\n",
    "        ax[j].scatter(\n",
    "            dosed_rec_prec_wn[0], dosed_rec_prec_wn[1], \n",
    "            c=color_list['dosed'], \n",
    "            label='DOSED (WN)', marker='o',\n",
    "            s=markersize*3, zorder=10)\n",
    "    \n",
    "    for set_name in set_list:\n",
    "        if set_name in show_set_list:\n",
    "            for i, stats in enumerate(be_stats[seed_id][set_name]):\n",
    "                if i==0:\n",
    "                    label = 'Proposed (%s) (%s)' % (task_mode.upper(), set_name.capitalize())\n",
    "                else:\n",
    "                    label = None\n",
    "                ax[j].scatter(\n",
    "                    stats['recall'], stats['precision'], \n",
    "                    c=color_list[set_name], \n",
    "                    label=label, marker='s',\n",
    "                    s=markersize, zorder=10)\n",
    "                if show_ids:\n",
    "                    \n",
    "                    if j==0:\n",
    "                        f1_score = 2 * stats['recall'] * stats['precision'] / (stats['recall'] + stats['precision'])\n",
    "                        print('S%02d (%s) - Recall: %1.4f - Precision: %1.4f - F1: %1.4f' \n",
    "                              % (ids_per_set_dict[set_name][i], set_name.ljust(5), stats['recall'], stats['precision'], f1_score))\n",
    "                    \n",
    "                    ax[j].annotate(\n",
    "                        ids_per_set_dict[set_name][i], \n",
    "                        (stats['recall']+text_space, stats['precision']+text_space), \n",
    "                        fontsize=7, color='#1b2631', zorder=20) \n",
    "    ax[j].set_title('Seed %d ($\\mu$=%1.2f and IoU>%1.1f)' % (seed_id, optimal_thr_list[j], iou_thr), fontsize=7)\n",
    "    ax[j].set_xlabel('Recall', fontsize=7)\n",
    "    ax[j].set_ylabel('Precision', fontsize=7)\n",
    "    ax[j].set_xlim(axis_lims)\n",
    "    ax[j].set_ylim(axis_lims)\n",
    "    ax[j].tick_params(labelsize=7)\n",
    "    ax[j].grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "ax[0].legend(loc='lower left', bbox_to_anchor=(0.5, -0.4), labelspacing=1, fontsize=6, ncol=(1 + len(show_set_list)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "if constants.TEST_SUBSET in show_set_list:\n",
    "    # mean test\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(3, 3), dpi=DPI)\n",
    "\n",
    "    CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=levels)\n",
    "    ax.clabel(CS, fontsize=6, fmt='%1.2f')\n",
    "\n",
    "    if compare_chambon and (dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]):\n",
    "        ax.scatter(\n",
    "            dosed_rec_prec_wn[0], dosed_rec_prec_wn[1], \n",
    "            c=color_list['dosed'], \n",
    "            label='DOSED (WN) (Paper)', marker='o',\n",
    "            s=markersize*4, zorder=10)\n",
    "        dosed_f1 = 2 * dosed_rec_prec_wn[0] * dosed_rec_prec_wn[1] / (dosed_rec_prec_wn[0] + dosed_rec_prec_wn[1])\n",
    "        # print('%1.4f Dosed F1 at 0.3' % dosed_f1)\n",
    "\n",
    "    set_name = constants.TEST_SUBSET\n",
    "\n",
    "    recall_list = []\n",
    "    precision_list = []\n",
    "    for i in range(len(test_ids)):\n",
    "\n",
    "        recall_mean = np.stack([be_stats[k][set_name][i]['recall'] for k in seed_id_list]).mean()\n",
    "        precision_mean = np.stack([be_stats[k][set_name][i]['precision'] for k in seed_id_list]).mean()\n",
    "        recall_list.append(recall_mean)\n",
    "        precision_list.append(precision_mean)\n",
    "        if i==0:\n",
    "            label = '%s (Single subject)' % bsf_name\n",
    "        else:\n",
    "            label = None\n",
    "        ax.scatter(\n",
    "            recall_mean, precision_mean, \n",
    "            c=color_list[set_name], \n",
    "            label=label, marker='s',\n",
    "            s=markersize, zorder=10)\n",
    "        if show_ids:\n",
    "            ax.annotate(\n",
    "                ids_per_set_dict[set_name][i], \n",
    "                (recall_mean+text_space, precision_mean+text_space), \n",
    "                fontsize=7, color='#1b2631', zorder=20)\n",
    "\n",
    "    # mean of subjects\n",
    "\n",
    "    ax.scatter(\n",
    "        np.mean(recall_list), np.mean(precision_list), \n",
    "        c=color_list[set_name], \n",
    "        label='%s (Mean of subjects)' % bsf_name, marker='o',\n",
    "        s=markersize*4, zorder=10)\n",
    "\n",
    "    ax.set_title('Mean Test PR for IoU>%1.1f (%s Detection)' % (iou_thr, dataset_name[-2:].upper()), fontsize=8)\n",
    "    ax.set_xlabel('Recall', fontsize=7)\n",
    "    ax.set_ylabel('Precision', fontsize=7)\n",
    "    ax.set_xlim(axis_lims)\n",
    "    ax.set_ylim(axis_lims)\n",
    "    ax.tick_params(labelsize=7)\n",
    "    ax.grid()\n",
    "    ax.legend(loc='lower left', fontsize=7)\n",
    "    plt.show()\n",
    "    \n",
    "    each_recall = np.asarray(recall_list)\n",
    "    each_precision = np.asarray(precision_list)\n",
    "    model_f1 = np.mean(2 * each_recall * each_precision / (each_recall + each_precision))\n",
    "    # print('%1.4f Proposed mean F1 at 0.3' % model_f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalizing with Global STD of 16.482037\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x800 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seed_to_show = 2\n",
    "set_name = 'val'\n",
    "subject_id = 7\n",
    "\n",
    "# -----\n",
    "if dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]:\n",
    "    channel_name = 'C3-CLE'\n",
    "elif dataset_name in [constants.DREAMS_SS_NAME, constants.DREAMS_KC_NAME]:\n",
    "    channel_name = 'Cz-A1'\n",
    "else:\n",
    "    channel_name = 'F4-C4'\n",
    "\n",
    "\n",
    "pages_subset = constants.N2_RECORD\n",
    "\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_to_show)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_to_show])\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids, 'alltrain': all_train_ids}\n",
    "idx_subject = idx_dict[set_name].index(subject_id)\n",
    "\n",
    "this_pages = dataset.get_subject_pages(subject_id=subject_id, pages_subset=pages_subset)\n",
    "this_signal = dataset.get_subject_signal(subject_id=subject_id, normalization_mode=task_mode, which_expert=which_expert)\n",
    "this_stamps = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=which_expert)\n",
    "this_stamps_full = this_stamps.copy()\n",
    "event_name = dataset.event_name\n",
    "\n",
    "this_thr = optimal_thr_list[seed_to_show]\n",
    "smaller_proba_for_fp = this_thr / 2\n",
    "prediction_set = predictions_dict[seed_to_show][set_name]\n",
    "down_factor = prediction_set.params[pkeys.TOTAL_DOWNSAMPLING_FACTOR]\n",
    "predicted_proba = prediction_set.get_subject_probabilities(subject_id)\n",
    "\n",
    "# Look for probability in real events\n",
    "mean_proba_real_list = []\n",
    "max_proba_real_list = []\n",
    "for single_stamp in this_stamps_full:\n",
    "    proba_segment_idx = single_stamp // 8\n",
    "    proba_segment = predicted_proba[proba_segment_idx[0]:proba_segment_idx[1]+1]\n",
    "    mean_proba_real_list.append(np.mean(proba_segment))\n",
    "    max_proba_real_list.append(np.max(proba_segment))\n",
    "\n",
    "# Look for probability of fake events\n",
    "mean_proba_fake_list = []\n",
    "max_proba_fake_list = []\n",
    "prediction_set.set_probability_threshold(smaller_proba_for_fp)\n",
    "this_detections = prediction_set.get_subject_stamps(subject_id)\n",
    "# Matching:\n",
    "this_iou_array, this_idx_array = metrics.matching(this_stamps_full, this_detections)\n",
    "this_expert_iou = this_iou_array\n",
    "n_detections = this_detections.shape[0]\n",
    "this_detection_iou = np.zeros(n_detections)\n",
    "for i in range(n_detections):\n",
    "    if i in this_idx_array:\n",
    "        matching_idx = np.where(this_idx_array == i)[0][0]\n",
    "        this_detection_iou[i] = this_iou_array[matching_idx] \n",
    "# Recover events with zero iou\n",
    "fake_idx = np.where(this_detection_iou == 0)[0]\n",
    "this_fake_stamps = this_detections[fake_idx]\n",
    "for single_stamp in this_fake_stamps:\n",
    "    proba_segment_idx = single_stamp // 8\n",
    "    proba_segment = predicted_proba[proba_segment_idx[0]:proba_segment_idx[1]+1]\n",
    "    mean_proba_fake_list.append(np.mean(proba_segment))\n",
    "    max_proba_fake_list.append(np.max(proba_segment))\n",
    "    \n",
    "\n",
    "proba_bins = np.linspace(0.0, 1.0, num=21, endpoint=True) \n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8), dpi=100, sharey=True, sharex=True)\n",
    "values, _, _ = ax[0, 0].hist(mean_proba_real_list, bins=proba_bins, color=CUSTOM_COLOR['blue'], label='S%02d' % subject_id)\n",
    "ax[0, 0].tick_params(labelsize=8.5)\n",
    "ax[0, 0].legend(fontsize=8.5)\n",
    "ax[0, 0].set_xlim([0, 1])\n",
    "ax[0, 0].set_xlabel('Probability', fontsize=8.5)\n",
    "n_after_thr = np.sum(np.array(mean_proba_real_list) >= this_thr)\n",
    "ax[0, 0].set_title('Mean Proba of Real (%d greater than %1.2f)' % (n_after_thr, this_thr), fontsize=9)\n",
    "ax[0, 0].plot([this_thr, this_thr], [0, np.max(values)*1.05], '--k')\n",
    "\n",
    "values, _, _ = ax[0, 1].hist(max_proba_real_list, bins=proba_bins, color=CUSTOM_COLOR['blue'], label='S%02d' % subject_id)\n",
    "ax[0, 1].tick_params(labelsize=8.5)\n",
    "ax[0, 1].legend(fontsize=8.5)\n",
    "ax[0, 1].set_xlim([0, 1])\n",
    "ax[0, 1].set_xlabel('Probability', fontsize=8.5)\n",
    "n_after_thr = np.sum(np.array(max_proba_real_list) >= this_thr)\n",
    "ax[0, 1].set_title('Max Proba of Real (%d greater than %1.2f)' % (n_after_thr, this_thr), fontsize=9)\n",
    "ax[0, 1].plot([this_thr, this_thr], [0, np.max(values)*1.05], '--k')\n",
    "\n",
    "values, _, _ = ax[1, 0].hist(mean_proba_fake_list, bins=proba_bins, color=CUSTOM_COLOR['red'], label='S%02d' % subject_id)\n",
    "ax[1, 0].tick_params(labelsize=8.5)\n",
    "ax[1, 0].legend(fontsize=8.5)\n",
    "ax[1, 0].set_xlim([0, 1])\n",
    "ax[1, 0].set_xlabel('Probability', fontsize=8.5)\n",
    "n_after_thr = np.sum(np.array(mean_proba_fake_list) >= this_thr)\n",
    "ax[1, 0].set_title('Mean Proba of Fake (%d greater than %1.2f)' % (n_after_thr, this_thr), fontsize=9)\n",
    "ax[1, 0].plot([this_thr, this_thr], [0, np.max(values)*1.05], '--k')\n",
    "\n",
    "values, _, _ = ax[1, 1].hist(max_proba_fake_list, bins=proba_bins, color=CUSTOM_COLOR['red'], label='S%02d' % subject_id)\n",
    "ax[1, 1].tick_params(labelsize=8.5)\n",
    "ax[1, 1].legend(fontsize=8.5)\n",
    "ax[1, 1].set_xlim([0, 1])\n",
    "ax[1, 1].set_xlabel('Probability', fontsize=8.5)\n",
    "n_after_thr = np.sum(np.array(max_proba_fake_list) >= this_thr)\n",
    "ax[1, 1].set_title('Max Proba of Fake (%d greater than %1.2f)' % (n_after_thr, this_thr), fontsize=9)\n",
    "ax[1, 1].plot([this_thr, this_thr], [0, np.max(values)*1.05], '--k')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_to_show = 0\n",
    "set_name = 'test'\n",
    "subject_id = 12\n",
    "show_only_n2 = True\n",
    "show_hypno = False\n",
    "band_pass_freqs = [12, 14]\n",
    "\n",
    "# -----\n",
    "if dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]:\n",
    "    channel_name = 'C3-CLE'\n",
    "else:\n",
    "    channel_name = 'F4-C4'\n",
    "\n",
    "if show_only_n2:\n",
    "    pages_subset = constants.N2_RECORD\n",
    "else:\n",
    "    pages_subset = constants.WN_RECORD\n",
    "\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_to_show)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_to_show])    \n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids, 'alltrain': all_train_ids}\n",
    "idx_subject = idx_dict[set_name].index(subject_id)\n",
    "\n",
    "this_pages = dataset.get_subject_pages(subject_id=subject_id, pages_subset=pages_subset)\n",
    "if show_hypno:\n",
    "    this_hypnogram = dataset.get_subject_hypnogram(subject_id=subject_id)\n",
    "this_signal = dataset.get_subject_signal(subject_id=subject_id, normalization_mode=task_mode, which_expert=which_expert)\n",
    "this_stamps = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=which_expert)\n",
    "if (subject_id not in [4, 8, 15, 16]) and dataset_name == constants.MASS_SS_NAME:\n",
    "    this_stamps_2 = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=2)\n",
    "else:\n",
    "    this_stamps_2 = None\n",
    "\n",
    "event_name = dataset.event_name\n",
    "\n",
    "this_thr = optimal_thr_list[seed_to_show]\n",
    "prediction_set = predictions_dict[seed_to_show][set_name]\n",
    "prediction_set.set_probability_threshold(this_thr)\n",
    "this_predicted_stamps = prediction_set.get_subject_stamps(subject_id=subject_id, pages_subset=constants.WN_RECORD)\n",
    "this_proba = prediction_set.get_subject_probabilities(subject_id=subject_id)\n",
    "\n",
    "fs_real = dataset.fs\n",
    "down_factor = prediction_set.params[pkeys.TOTAL_DOWNSAMPLING_FACTOR]\n",
    "fs_proba = fs_real / down_factor\n",
    "\n",
    "# make a color map of fixed colors\n",
    "cmap = colors.ListedColormap(['white', '#c62828'])\n",
    "\n",
    "\n",
    "def filter_stamps(stamps, single_page, page_size):\n",
    "    pages_list = []\n",
    "    for i in range(stamps.shape[0]):\n",
    "        stamp_start_page = stamps[i, 0] // page_size\n",
    "        stamp_end_page = stamps[i, 1] // page_size\n",
    "\n",
    "        start_inside = (stamp_start_page == single_page)\n",
    "        end_inside = (stamp_end_page == single_page)\n",
    "\n",
    "        if start_inside or end_inside:\n",
    "            pages_list.append(stamps[i, :])\n",
    "    return pages_list\n",
    "\n",
    "\n",
    "def plot_page(page_idx):\n",
    "\n",
    "    if this_stamps_2 is None:\n",
    "        fig = plt.figure(figsize=(12, 4), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(3, 1, height_ratios=[4, 2, 1])\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(12, 5), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(4, 1, height_ratios=[4, 2, 1, 1])\n",
    "    \n",
    "    page_idx = page_idx - 1\n",
    "    page_chosen = this_pages[page_idx]\n",
    "    if show_hypno:\n",
    "        page_state = this_hypnogram[page_of_center]\n",
    "    else:\n",
    "        page_state = '?'\n",
    "    page_start = page_chosen * dataset.page_size\n",
    "    page_end = page_start + dataset.page_size\n",
    "    \n",
    "    segment_signal = this_signal[page_start:page_end]\n",
    "    \n",
    "    segment_stamps = filter_stamps(this_stamps, page_chosen, dataset.page_size)\n",
    "    if this_stamps_2 is not None:\n",
    "        segment_stamps_2 = filter_stamps(this_stamps_2, page_chosen, dataset.page_size)\n",
    "    segment_proba = this_proba[int(page_start/down_factor):int(page_end/down_factor)]\n",
    "    segment_predicted_stamps = filter_stamps(this_predicted_stamps, page_chosen, dataset.page_size)\n",
    "    \n",
    "    time_axis_real = np.arange(page_start, page_end) / fs_real\n",
    "    time_axis_proba = np.arange(int(page_start/down_factor), int(page_end/down_factor)) / fs_proba\n",
    "    \n",
    "    gs_idx = 0\n",
    "    \n",
    "    # Signal\n",
    "    y_max = 10\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(\n",
    "        time_axis_real, segment_signal, \n",
    "        linewidth=1, color=CUSTOM_COLOR['grey'], label='EEG %s' % channel_name)\n",
    "    stamp_label_used = False\n",
    "    for expert_stamp in segment_stamps:\n",
    "        if stamp_label_used:\n",
    "            label = None\n",
    "        else:\n",
    "            label = event_name\n",
    "            stamp_label_used = True\n",
    "        ax.fill_between(\n",
    "            expert_stamp / fs_real, y_max, -y_max, \n",
    "            facecolor=CUSTOM_COLOR['blue'], alpha=0.3, label=label,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_ylim([-y_max, y_max])\n",
    "    ax.set_title('Subject %d (%s-%s). Page in record: %d. State %s (intervals of 0.5s are shown).' \n",
    "                 % (subject_id, dataset_name.upper(), set_name.capitalize(), page_chosen, page_state), fontsize=10)\n",
    "    ax.set_xticks([\n",
    "        time_axis_real[0], \n",
    "        time_axis_real[0] + 5, \n",
    "        time_axis_real[0] + 10, \n",
    "        time_axis_real[0] + 15, \n",
    "        time_axis_real[0] + 20])\n",
    "    ax.set_xticks(np.arange(time_axis_real[0], time_axis_real[-1], 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    lg = ax.legend(loc='upper right', fontsize=8.5)\n",
    "    # lh = lg.legendHandles[1]\n",
    "    # lh.set_facecolor(lh.get_facecolor())\n",
    "    # lh.set_alpha(1.0)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Band pass Signal\n",
    "    y_max = 10\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    # segment_signal_filtered = utils.narrow_filter(segment_signal, fs_real, band_pass_freqs[0], band_pass_freqs[1])\n",
    "    segment_signal_filtered = utils.filter_windowed_sinusoidal(segment_signal, fs_real, 13, 41)\n",
    "    ax.plot(\n",
    "        time_axis_real, segment_signal_filtered, \n",
    "        linewidth=1, color=CUSTOM_COLOR['grey'], label='EEG %s' % channel_name)\n",
    "    stamp_label_used = False\n",
    "    for expert_stamp in segment_stamps:\n",
    "        if stamp_label_used:\n",
    "            label = None\n",
    "        else:\n",
    "            label = event_name\n",
    "            stamp_label_used = True\n",
    "        ax.fill_between(\n",
    "            expert_stamp / fs_real, y_max, -y_max, \n",
    "            facecolor=CUSTOM_COLOR['blue'], alpha=0.3, label=label,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_ylim([-y_max, y_max])\n",
    "    ax.set_title('Bandpass filtered signal (sigma)', fontsize=10)\n",
    "    ax.set_xticks([\n",
    "        time_axis_real[0], \n",
    "        time_axis_real[0] + 5, \n",
    "        time_axis_real[0] + 10, \n",
    "        time_axis_real[0] + 15, \n",
    "        time_axis_real[0] + 20])\n",
    "    ax.set_xticks(np.arange(time_axis_real[0], time_axis_real[-1], 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    lg = ax.legend(loc='upper right', fontsize=8.5)\n",
    "    # lh = lg.legendHandles[1]\n",
    "    # lh.set_facecolor(lh.get_facecolor())\n",
    "    # lh.set_alpha(1.0)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Neural net\n",
    "    delta_y = 0.1\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(\n",
    "        time_axis_proba, segment_proba, \n",
    "        color=CUSTOM_COLOR['red'], linewidth=1.5, zorder=7)\n",
    "    for model_stamp in segment_predicted_stamps:\n",
    "        ax.fill_between(\n",
    "            model_stamp / fs_real, 1+delta_y, -delta_y, \n",
    "            facecolor=CUSTOM_COLOR['red'], zorder=6, alpha=0.3,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_xticks([])\n",
    "    ax.set_ylim([-delta_y, 1+delta_y])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticks([this_thr], minor=True)\n",
    "    ax.grid(b=True, axis='y', linewidth=1.5, which='minor', zorder=5)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    ax.set_title('Model prediction: probability and postprocessed stamps (%1.2f threshold is shown)' % this_thr, fontsize=10)\n",
    "    \n",
    "    if this_stamps_2 is not None:\n",
    "        ax = fig.add_subplot(gs[gs_idx])\n",
    "        # ax.imshow(segment_marks_2[np.newaxis, :], interpolation=None, aspect='auto', cmap=cmap)\n",
    "        for expert_stamp in segment_stamps_2:\n",
    "            ax.fill_between(\n",
    "                expert_stamp / fs_real, y_max, -y_max, \n",
    "                facecolor=CUSTOM_COLOR['blue'], alpha=0.3,\n",
    "                edgecolor='k', linewidth=1.5, \n",
    "            )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_ylim([-delta_y, 1+delta_y])\n",
    "        ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "        ax.set_title('Second expert stamps (not used for training)', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(\n",
    "    lambda page_idx: plot_page(page_idx),\n",
    "    page_idx=widgets.IntSlider(min=1,max=this_pages.shape[0],step=1,value=20, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization centered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_to_show = 0\n",
    "set_name = 'test'\n",
    "subject_id = 12\n",
    "center_on_real = False\n",
    "iou_range = [0, 0]\n",
    "duration_range = [0, 5]\n",
    "show_hypno = True\n",
    "\n",
    "\n",
    "band_pass_freqs = [12, 14]\n",
    "\n",
    "# -----\n",
    "if dataset_name in [constants.MASS_SS_NAME, constants.MASS_KC_NAME]:\n",
    "    channel_name = 'C3-CLE'\n",
    "elif dataset_name in [constants.DREAMS_SS_NAME, constants.DREAMS_KC_NAME]:\n",
    "    channel_name = 'Cz-A1'\n",
    "else:\n",
    "    channel_name = 'F4-C4'\n",
    "\n",
    "\n",
    "pages_subset = constants.N2_RECORD\n",
    "\n",
    "if new_split_version:\n",
    "    train_ids, val_ids = utils.split_ids_list_v2(\n",
    "        all_train_ids, split_id=seed_to_show)\n",
    "else:\n",
    "    train_ids, val_ids = utils.split_ids_list(\n",
    "        all_train_ids, seed=SEED_LIST[seed_to_show])\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids, 'alltrain': all_train_ids}\n",
    "idx_subject = idx_dict[set_name].index(subject_id)\n",
    "\n",
    "this_pages = dataset.get_subject_pages(subject_id=subject_id, pages_subset=pages_subset)\n",
    "if show_hypno:\n",
    "    this_hypnogram = dataset.get_subject_hypnogram(subject_id=subject_id)\n",
    "this_signal = dataset.get_subject_signal(subject_id=subject_id, normalization_mode=task_mode, which_expert=which_expert)\n",
    "this_stamps = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=which_expert)\n",
    "this_stamps_full = this_stamps.copy()\n",
    "if (subject_id not in [4, 8, 15, 16]) and dataset_name == constants.MASS_SS_NAME:\n",
    "    this_stamps_2 = dataset.get_subject_stamps(subject_id=subject_id, pages_subset=pages_subset, which_expert=2)\n",
    "    this_stamps_2_full = this_stamps_2.copy()\n",
    "else:\n",
    "    this_stamps_2 = None\n",
    "\n",
    "event_name = dataset.event_name\n",
    "\n",
    "this_thr = optimal_thr_list[seed_to_show]\n",
    "prediction_set = predictions_dict[seed_to_show][set_name]\n",
    "prediction_set.set_probability_threshold(this_thr)\n",
    "this_predicted_stamps = prediction_set.get_subject_stamps(subject_id=subject_id, pages_subset=constants.WN_RECORD)\n",
    "this_predicted_stamps_full = this_predicted_stamps.copy()\n",
    "this_proba = prediction_set.get_subject_probabilities(subject_id=subject_id)\n",
    "\n",
    "fs_real = dataset.fs\n",
    "down_factor = prediction_set.params[pkeys.TOTAL_DOWNSAMPLING_FACTOR]\n",
    "fs_proba = fs_real / down_factor\n",
    "\n",
    "# make a color map of fixed colors\n",
    "cmap = colors.ListedColormap(['white', '#c62828'])\n",
    "\n",
    "# Matching:\n",
    "this_iou_array, this_idx_array = metrics.matching(this_stamps, this_predicted_stamps)\n",
    "this_expert_iou = this_iou_array\n",
    "n_detections = this_predicted_stamps.shape[0]\n",
    "this_dectection_iou = np.zeros(n_detections)\n",
    "\n",
    "for i in range(n_detections):\n",
    "    if i in this_idx_array:\n",
    "        matching_idx = np.where(this_idx_array == i)[0][0]\n",
    "        this_dectection_iou[i] = this_iou_array[matching_idx]        \n",
    "\n",
    "# Number of missed reals:\n",
    "n_ufn = np.sum(this_expert_iou == 0)\n",
    "# Number of false detections:\n",
    "n_ufp = np.sum(this_dectection_iou == 0)\n",
    "# Number of matched pairs\n",
    "n_matched = np.sum(this_expert_iou > 0)\n",
    "n_matched_v2 = np.sum(this_dectection_iou > 0)\n",
    "print('UFN:', n_ufn)\n",
    "print('UFP', n_ufp)\n",
    "print('Matched', n_matched, n_matched_v2)\n",
    "precision = n_matched / (n_matched + n_ufp)\n",
    "recall = n_matched / (n_matched + n_ufn)\n",
    "f1_at_iou0 = 2 * precision * recall / (precision + recall)\n",
    "print('F1 at IoU>0 %1.2f' % f1_at_iou0)\n",
    "\n",
    "# Fraction of UFP that does not match E1 but match E2\n",
    "print('** UFP and E2 intersection analysis ** ')\n",
    "all_ufp = this_predicted_stamps_full[this_dectection_iou == 0]\n",
    "overlap_ufp_e1 = utils.get_overlap_matrix(all_ufp, this_stamps_full)\n",
    "valid_ufp = np.where(overlap_ufp_e1.sum(axis=1) == 0)[0]\n",
    "print('UFP removed because E1 intersection: %d' % (all_ufp.shape[0] - valid_ufp.size))\n",
    "all_ufp = all_ufp[valid_ufp]\n",
    "overlap_ufp_e2 = utils.get_overlap_matrix(all_ufp, this_stamps_2_full)\n",
    "idx_with_e2_intersection = np.where(overlap_ufp_e2.sum(axis=1) > 0)[0]\n",
    "print('UFP with intersection with E2 and none with E1: %d (%1.2f %%)' % (idx_with_e2_intersection.size, 100*idx_with_e2_intersection.size/n_ufp))\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3, 1), dpi=200)\n",
    "ax.hist(this_expert_iou[this_expert_iou > 0], bins=[0.1*i for i in range(11)], color=CUSTOM_COLOR['red'], label='S%02d' % subject_id)\n",
    "ax.legend(loc='upper left', fontsize=7)\n",
    "ax.set_title('IoU of Matchings', fontsize=8)\n",
    "ax.set_xticks([0.1*i for i in range(0, 11, 2)])\n",
    "ax.set_xlabel('IoU', fontsize=7)\n",
    "ax.tick_params(labelsize=7)\n",
    "plt.show()\n",
    "        \n",
    "# filter\n",
    "if center_on_real:\n",
    "    idx_useful_iou = np.where( (this_expert_iou >= iou_range[0]) & (this_expert_iou <= iou_range[1]) )[0]\n",
    "    duration_expert = (this_stamps[:, 1] - this_stamps[:, 0]) / fs_real\n",
    "    idx_useful_duration = np.where( (duration_expert >= duration_range[0]) & (duration_expert <= duration_range[1]) )[0]\n",
    "    idx_useful = [i for i in idx_useful_iou if i in idx_useful_duration]\n",
    "    this_stamps = this_stamps[idx_useful]\n",
    "    this_expert_iou = this_expert_iou[idx_useful]\n",
    "else:\n",
    "    idx_useful_iou = np.where( (this_dectection_iou >= iou_range[0]) & (this_dectection_iou <= iou_range[1]) )[0]\n",
    "    duration_det = (this_predicted_stamps[:, 1] - this_predicted_stamps[:, 0]) / fs_real\n",
    "    idx_useful_duration = np.where( (duration_det >= duration_range[0]) & (duration_det <= duration_range[1]) )[0]\n",
    "    idx_useful = [i for i in idx_useful_iou if i in idx_useful_duration]\n",
    "    this_predicted_stamps = this_predicted_stamps[idx_useful]\n",
    "    this_dectection_iou = this_dectection_iou[idx_useful]\n",
    "\n",
    "def filter_stamps(stamps, start_sample, end_sample):\n",
    "    pages_list = []\n",
    "    for i in range(stamps.shape[0]):\n",
    "        start_inside = (stamps[i, 0] > start_sample) and (stamps[i, 0] < end_sample)\n",
    "        end_inside = (stamps[i, 1] > start_sample) and (stamps[i, 1] < end_sample)\n",
    "\n",
    "        if start_inside or end_inside:\n",
    "            pages_list.append(stamps[i, :])\n",
    "    return pages_list\n",
    "\n",
    "\n",
    "def plot_event(event_idx):\n",
    "\n",
    "    if this_stamps_2 is None:\n",
    "        fig = plt.figure(figsize=(12, 4), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(3, 1, height_ratios=[4, 2, 1])\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(12, 5), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(4, 1, height_ratios=[4, 2, 1, 1])\n",
    "    \n",
    "    event_idx = event_idx - 1\n",
    "    \n",
    "    if center_on_real:\n",
    "        event_chosen = this_stamps[event_idx, :]\n",
    "        iou_chosen = this_expert_iou[event_idx]\n",
    "    else:\n",
    "        event_chosen = this_predicted_stamps[event_idx, :]\n",
    "        iou_chosen = this_dectection_iou[event_idx]\n",
    "\n",
    "    start_sample = int(event_chosen[0] - 10 * fs_real)\n",
    "    end_sample = int(event_chosen[1] + 10 * fs_real)\n",
    "\n",
    "    page_of_center = int(((end_sample + start_sample) / 2) / dataset.page_size)\n",
    "    if show_hypno:\n",
    "        page_state = this_hypnogram[page_of_center]\n",
    "    else:\n",
    "        page_state = '?'\n",
    "    \n",
    "    segment_signal = this_signal[start_sample:end_sample]\n",
    "    segment_stamps = filter_stamps(this_stamps_full, start_sample, end_sample)\n",
    "    if this_stamps_2 is not None:\n",
    "        segment_stamps_2 = filter_stamps(this_stamps_2_full, start_sample, end_sample)\n",
    "    segment_proba = this_proba[int(start_sample/down_factor):int(end_sample/down_factor)]\n",
    "    segment_predicted_stamps = filter_stamps(this_predicted_stamps_full, start_sample, end_sample)\n",
    "    \n",
    "    time_axis_real = np.arange(start_sample, end_sample) / fs_real\n",
    "    time_axis_proba = np.arange(int(start_sample/down_factor), int(end_sample/down_factor)) / fs_proba\n",
    "    \n",
    "    gs_idx = 0\n",
    "    \n",
    "    # Signal\n",
    "    y_max = 7\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(\n",
    "        time_axis_real, segment_signal, \n",
    "        linewidth=1, color=CUSTOM_COLOR['grey'], label='EEG %s' % channel_name)\n",
    "    stamp_label_used = False\n",
    "    for expert_stamp in segment_stamps:\n",
    "        if stamp_label_used:\n",
    "            label = None\n",
    "        else:\n",
    "            label = event_name\n",
    "            stamp_label_used = True\n",
    "        ax.fill_between(\n",
    "            expert_stamp / fs_real, y_max, -y_max, \n",
    "            facecolor=CUSTOM_COLOR['blue'], alpha=0.3, label=label,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_ylim([-y_max, y_max])\n",
    "    if center_on_real:\n",
    "        ax.set_title('Subject %d (%s-%s). Expert mark idx: %d. IoU %1.2f. State %s (intervals of 0.5s are shown).' \n",
    "                     % (subject_id, dataset_name.upper(), set_name.capitalize(), event_idx, iou_chosen, page_state), fontsize=10)\n",
    "    else:\n",
    "        ax.set_title('Subject %d (%s-%s). Detection idx: %d. IoU %1.2f. State %s (intervals of 0.5s are shown).' \n",
    "                     % (subject_id, dataset_name.upper(), set_name.capitalize(), event_idx, iou_chosen, page_state), fontsize=10)\n",
    "        \n",
    "    ax.set_xticks([\n",
    "        time_axis_real[0], \n",
    "        time_axis_real[0] + 5, \n",
    "        time_axis_real[0] + 10, \n",
    "        time_axis_real[0] + 15, \n",
    "        time_axis_real[0] + 20])\n",
    "    ax.set_xticks(np.arange(time_axis_real[0], time_axis_real[-1], 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    lg = ax.legend(loc='upper right', fontsize=8.5)\n",
    "    # lh = lg.legendHandles[1]\n",
    "    # lh.set_facecolor(lh.get_facecolor())\n",
    "    # lh.set_alpha(1.0)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Band pass Signal\n",
    "    y_max = 5\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    # segment_signal_filtered = utils.narrow_filter(segment_signal, fs_real, band_pass_freqs[0], band_pass_freqs[1])\n",
    "    segment_signal_filtered = utils.filter_windowed_sinusoidal(segment_signal, fs_real, 13, 41)\n",
    "    ax.plot(\n",
    "        time_axis_real, segment_signal_filtered, \n",
    "        linewidth=1, color=CUSTOM_COLOR['grey'], label='EEG %s' % channel_name)\n",
    "    stamp_label_used = False\n",
    "    for expert_stamp in segment_stamps:\n",
    "        if stamp_label_used:\n",
    "            label = None\n",
    "        else:\n",
    "            label = event_name\n",
    "            stamp_label_used = True\n",
    "        ax.fill_between(\n",
    "            expert_stamp / fs_real, y_max, -y_max, \n",
    "            facecolor=CUSTOM_COLOR['blue'], alpha=0.3, label=label,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_ylim([-y_max, y_max])\n",
    "    ax.set_title('Bandpass filtered signal (sigma)', fontsize=10)\n",
    "    ax.set_xticks([\n",
    "        time_axis_real[0], \n",
    "        time_axis_real[0] + 5, \n",
    "        time_axis_real[0] + 10, \n",
    "        time_axis_real[0] + 15, \n",
    "        time_axis_real[0] + 20])\n",
    "    ax.set_xticks(np.arange(time_axis_real[0], time_axis_real[-1], 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    lg = ax.legend(loc='upper right', fontsize=8.5)\n",
    "    # lh = lg.legendHandles[1]\n",
    "    # lh.set_facecolor(lh.get_facecolor())\n",
    "    # lh.set_alpha(1.0)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Neural net\n",
    "    delta_y = 0.1\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(\n",
    "        time_axis_proba, segment_proba, \n",
    "        color=CUSTOM_COLOR['red'], linewidth=1.5, zorder=7)\n",
    "    for model_stamp in segment_predicted_stamps:\n",
    "        ax.fill_between(\n",
    "            model_stamp / fs_real, 1+delta_y, -delta_y, \n",
    "            facecolor=CUSTOM_COLOR['red'], zorder=6, alpha=0.3,\n",
    "            edgecolor='k', linewidth=1.5, \n",
    "        )\n",
    "    ax.set_xticks([])\n",
    "    ax.set_ylim([-delta_y, 1+delta_y])\n",
    "    ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticks([this_thr], minor=True)\n",
    "    ax.grid(b=True, axis='y', linewidth=1.5, which='minor', zorder=5)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    ax.set_title('Model prediction: probability and postprocessed stamps (%1.2f threshold is shown)' % this_thr, fontsize=10)\n",
    "    \n",
    "    if this_stamps_2 is not None:\n",
    "        ax = fig.add_subplot(gs[gs_idx])\n",
    "        # ax.imshow(segment_marks_2[np.newaxis, :], interpolation=None, aspect='auto', cmap=cmap)\n",
    "        for expert_stamp in segment_stamps_2:\n",
    "            ax.fill_between(\n",
    "                expert_stamp / fs_real, y_max, -y_max, \n",
    "                facecolor=CUSTOM_COLOR['blue'], alpha=0.3,\n",
    "                edgecolor='k', linewidth=1.5, \n",
    "            )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_ylim([-delta_y, 1+delta_y])\n",
    "        ax.set_xlim([time_axis_real[0], time_axis_real[-1]])\n",
    "        ax.set_title('Second expert stamps (not used for training)', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Showing events with IoU in range %s' % iou_range)\n",
    "print('Showing events with duration in range %s [s]' % duration_range)\n",
    "if center_on_real:\n",
    "    max_value = this_stamps.shape[0]\n",
    "    print('Number of real events selected %d' % max_value)\n",
    "else:\n",
    "    max_value = this_predicted_stamps.shape[0]\n",
    "    print('Number of detected events selected %d' % max_value)\n",
    "\n",
    "widgets.interact(\n",
    "    lambda event_idx: plot_event(event_idx),\n",
    "    event_idx=widgets.IntSlider(min=1,max=max_value,step=1,value=1, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_set_error = 'test'\n",
    "thr = optimal_thr_list[0]\n",
    "\n",
    "y_thr = y_stamps[chosen_set_error]\n",
    "\n",
    "# Prepare model predictions\n",
    "n_subjects = len(y_thr)\n",
    "pred_stamps = []\n",
    "for i in range(n_subjects):\n",
    "    print('Processing subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    # Binarize\n",
    "    this_y_pred_thr = (y_pred[chosen_set_error][i] >= thr).astype(np.int32)\n",
    "    # Transform to intervals\n",
    "    this_y_pred_thr = data_ops.seq2inter_with_pages(\n",
    "        this_y_pred_thr, pages[chosen_set_error][i]\n",
    "    )\n",
    "    pred_stamps.append(this_y_pred_thr)\n",
    "fs_pred = 200 // 8 \n",
    "fs_real = 200\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Compute spacing ----------------------\n",
    "combine_thr = 0.3\n",
    "\n",
    "spacing = []\n",
    "spacing_expert = []\n",
    "for i in range(n_subjects):\n",
    "    print('Spacing for subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    this_spacing = (pred_stamps[i][1:, 0] - pred_stamps[i][:-1, 1]) / fs_pred\n",
    "    this_spacing_expert = (y_stamps[chosen_set_error][i][1:, 0] - y_stamps[chosen_set_error][i][:-1, 1]) / fs_real\n",
    "    # Only consider for this analysis, spacing less than one second\n",
    "    this_spacing = this_spacing[this_spacing < 1]\n",
    "    this_spacing_expert = this_spacing_expert[this_spacing_expert < 1]\n",
    "    spacing.append(this_spacing)\n",
    "    spacing_expert.append(this_spacing_expert)\n",
    "print('Done')\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Spacing between nearby expert marks', fontsize=10)\n",
    "ax[0, 1].set_title('Spacing between nearby detections', fontsize=10)\n",
    "y_max = 0\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Real\n",
    "    n_real, _, _ = ax[i, 0].hist(spacing_expert[i], bins=[k*0.1 for k in range(11)], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].set_xticks([k*0.2 for k in range(6)])\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "    # Predicted\n",
    "    n_pred, _, _ = ax[i, 1].hist(spacing[i], bins=[k*0.1 for k in range(11)], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].set_xticks([k*0.2 for k in range(6)])\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "    max_y = max(np.max(n_real), np.max(n_pred))\n",
    "    ax[i, 0].plot([combine_thr, combine_thr], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    ax[i, 1].plot([combine_thr, combine_thr], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    # y_max = max(max_y, y_max)\n",
    "# for i in range(n_subjects):\n",
    "#     ax[i, 0].plot([combine_thr, combine_thr], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "#     ax[i, 1].plot([combine_thr, combine_thr], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "ax[-1, 0].set_xlabel('Spacing [s]', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Spacing [s]', fontsize=8.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Durations\n",
    "\n",
    "if dataset_name == constants.MASSK_NAME:\n",
    "    postprocess_predicted = False\n",
    "else:\n",
    "    postprocess_predicted = True\n",
    "\n",
    "durations = []\n",
    "durations_expert = []\n",
    "for i in range(n_subjects):\n",
    "    print('Durations for subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    # First, combine close marks\n",
    "    if dataset_name == constants.MASSK_NAME:\n",
    "        this_pred_stamps = pred_stamps[i]\n",
    "    else:\n",
    "        this_pred_stamps = postprocessing.combine_close_marks(pred_stamps[i], fs_pred, combine_thr)\n",
    "    # Now compute durations\n",
    "    this_durations = (this_pred_stamps[:, 1] - this_pred_stamps[:, 0]) / fs_pred\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    # Only consider for this analysis, spacing less than one second\n",
    "    durations.append(this_durations)\n",
    "    durations_expert.append(this_durations_expert)\n",
    "print('Done')\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Duration of expert marks', fontsize=10)\n",
    "ax[0, 1].set_title('Duration of detections', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "y_max = 0\n",
    "min_duration = 0.3  \n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Real\n",
    "    n_real, _, _ = ax[i, 0].hist(durations_expert[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "    # Predicted\n",
    "    n_pred, _, _ = ax[i, 1].hist(durations[i], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "    max_y = max(np.max(n_real), np.max(n_pred))\n",
    "    ax[i, 0].plot([min_duration, min_duration], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    ax[i, 1].plot([min_duration, min_duration], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    y_max = max(max_y, y_max)\n",
    "    print(durations[i].max())\n",
    "    \n",
    "#for i in range(n_subjects):\n",
    "#    ax[i, 0].plot([min_duration, min_duration], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "#    ax[i, 1].plot([min_duration, min_duration], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "\n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location of Falses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == constants.MASSK_NAME:\n",
    "    min_separation = 0\n",
    "    min_duration = 0.3\n",
    "    max_duration = 4.0\n",
    "else:\n",
    "    min_separation = 0.5\n",
    "    min_duration = 0.4\n",
    "    max_duration = 4.0\n",
    "\n",
    "iou_array = []\n",
    "idx_array = []\n",
    "y_pred_thr = []\n",
    "for i in range(n_subjects):\n",
    "    print('Processing subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    events = y_stamps[chosen_set_error][i]\n",
    "    detections = postprocessing.generate_mark_intervals(\n",
    "        y_pred[chosen_set_error][i], pages[chosen_set_error][i], 200//8, 200, thr=thr, \n",
    "        min_separation=min_separation, min_duration=min_duration, max_duration=max_duration)\n",
    "    print(events.shape, detections.shape)\n",
    "    this_iou_array, this_idx_array = metrics.matching(events, detections)\n",
    "    iou_array.append(this_iou_array)\n",
    "    idx_array.append(this_idx_array)\n",
    "    y_pred_thr.append(detections)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- False negatives\n",
    "iou_thr = 0.3\n",
    "\n",
    "fn_center = []\n",
    "for i in range(n_subjects):\n",
    "    idx_fn = iou_array[i] < iou_thr\n",
    "    fn_stamps = y_stamps[chosen_set_error][i][idx_fn]\n",
    "    this_fn_center = np.mean(fn_stamps, axis=1).astype(np.int32)\n",
    "    fn_center.append(this_fn_center)\n",
    "    \n",
    "# --- False positives\n",
    "fp_center = []\n",
    "for i in range(n_subjects):\n",
    "    # matched detections:\n",
    "    idx_fp_1 = iou_array[i] < iou_thr\n",
    "    idx_fp_1 = idx_array[i][idx_fp_1]\n",
    "    idx_fp_1 = [idx for idx in idx_fp_1 if idx != -1]\n",
    "    # Unmatched events\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    idx_fp = idx_fp_1 + idx_fp_2\n",
    "    fp_stamps = y_pred_thr[i][idx_fp]\n",
    "    this_fp_center = np.mean(fp_stamps, axis=1).astype(np.int32)\n",
    "    fp_center.append(this_fp_center)\n",
    "\n",
    "    \n",
    "# --- Histogram of IoU values across real events\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(3.5, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0].set_title('IoU values on expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].hist(iou_array[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), bins=[0.05*i for i in range(21)])\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "    ax[i].legend(fontsize=8.5, loc='upper center')\n",
    "    ax[i].set_xticks([0.2*i for i in range(6)])\n",
    "ax[-1].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "plt.show()\n",
    "    \n",
    "# --- Location in page\n",
    "fn_loc_page = [np.mod(this_fn_center, 20*fs_real) for this_fn_center in fn_center]\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Location of expert marks with IoU < %1.2f' % (iou_thr), fontsize=11)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 0].hist(fn_loc_page[i] / fs_real, bins=[i*4 for i in range(6)], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5, loc='upper center')\n",
    "ax[-1, 0].set_xticks([i*4 for i in range(6)])\n",
    "ax[-1, 0].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "\n",
    "fp_loc_page = [np.mod(this_fp_center, 20*fs_real) for this_fp_center in fp_center]\n",
    "\n",
    "ax[0, 1].set_title('Location of detections with IoU < %1.2f' % (iou_thr), fontsize=10)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 1].hist(fp_loc_page[i] / fs_real, bins=[i*4 for i in range(6)], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5, loc='upper center')\n",
    "ax[-1, 1].set_xticks([i*4 for i in range(6)])\n",
    "ax[-1, 1].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --- Location in register\n",
    "\n",
    "fn_loc_register = [np.floor_divide(this_fn_center, 20*fs_real) for this_fn_center in fn_center]\n",
    "max_page_array = [np.max(pages[chosen_set_error][i]) for i in range(n_subjects)]\n",
    "\n",
    "max_of_all = np.max(max_page_array)\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Location in register of expert marks with IoU < %1.1f' % (iou_thr), fontsize=10)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 0].hist(fn_loc_register[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "ax[-1, 0].set_xlim([0, max_of_all+10])\n",
    "ax[-1, 0].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "fp_loc_register = [np.floor_divide(this_fp_center, 20*fs_real) for this_fp_center in fp_center]\n",
    "max_page_array = [np.max(pages[chosen_set_error][i]) for i in range(n_subjects)]\n",
    "\n",
    "max_of_all = np.max(max_page_array)\n",
    "\n",
    "ax[0, 1].set_title('Location in register of detections with IoU < %1.1f' % (iou_thr), fontsize=11)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 1].hist(fp_loc_register[i], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "ax[-1, 1].set_xlim([0, max_of_all+10])\n",
    "ax[-1, 1].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ----- N2 pages\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(3.5, 1*n_subjects), dpi=DPI, sharex=True, sharey=True)\n",
    "ax[0].set_title('Location in register of N2 pages (%s)' % (chosen_set_error.capitalize()), fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].hist(pages[chosen_set_error][i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "    ax[i].legend(fontsize=8.5)\n",
    "ax[-1].set_xlim([0, max_of_all+10])\n",
    "ax[-1].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IoU vs Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- Scatter of IoU values and duration of real and detected events\n",
    "alpha = 0.2\n",
    "markersize=10\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(7, 1*n_subjects), dpi=DPI, sharex=True, sharey=True)\n",
    "ax[0, 0].set_title('IoU vs duration of expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    ax[i, 0].scatter(this_durations_expert, iou_array[i], label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#455a64', alpha=alpha, s=markersize)\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 0].legend(fontsize=7, loc='upper right')\n",
    "    for lh in lg.legendHandles:\n",
    "        lh.set_facecolor(lh.get_facecolor())\n",
    "        lh.set_edgecolor(lh.get_edgecolor())\n",
    "        lh.set_alpha(1.0)\n",
    "    ax[i, 0].set_ylabel('IoU', fontsize=8.5)\n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('IoU vs duration of detections', fontsize=10)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations for IoU > 0 \n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    this_iou_1 = iou_array[i][idx_valid]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    this_durations_1 = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    # Now durations for IoU = 0\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_fp_2]\n",
    "    this_durations_2 = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    this_iou_2 = np.zeros(this_durations_2.shape[0])\n",
    "    # Concatenation\n",
    "    this_durations = np.concatenate([this_durations_1, this_durations_2])\n",
    "    this_iou = np.concatenate([this_iou_1, this_iou_2])\n",
    "    ax[i, 1].scatter(this_durations, this_iou, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#c62828', alpha=alpha, s=markersize)\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 1].legend(fontsize=7, loc='upper right')\n",
    "    for lh in lg.legendHandles:\n",
    "        lh.set_facecolor(lh.get_facecolor())\n",
    "        lh.set_edgecolor(lh.get_edgecolor())\n",
    "        lh.set_alpha(1.0)\n",
    "    # ax[i, 1].set_ylabel('IoU', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Histogram of duration for IoU == 0\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Duration of unpaired expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    idx_zero = (iou_array[i] == 0)\n",
    "    this_durations_expert_fn = this_durations_expert[idx_zero]\n",
    "    ax[i, 0].hist(this_durations_expert_fn, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#455a64')\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 0].legend(fontsize=8.5, loc='upper right')\n",
    "    \n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('Duration of unpaired detections', fontsize=10)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_fp_2]\n",
    "    this_durations_fp = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    ax[i, 1].hist(this_durations_fp, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#c62828')\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5, loc='upper right')\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration of events and matched detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(5, 5), dpi=DPI, sharex=False, sharey=False)\n",
    "# plt.suptitle('Duration of matched events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    # Now compute durations for real\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    this_durations_expert = this_durations_expert[idx_valid]\n",
    "    # Now compute durations for matched detections\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    this_durations_det = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    if i<2:\n",
    "        ax[0, i].scatter(this_durations_expert, this_durations_det, label='S%02d' % subject_idx, color='#455a64', alpha=alpha)\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "        lg = ax[0, i].legend(fontsize=7)\n",
    "        for lh in lg.legendHandles:\n",
    "            lh.set_facecolor(lh.get_facecolor())\n",
    "            lh.set_edgecolor(lh.get_edgecolor())\n",
    "            lh.set_alpha(1.0)\n",
    "        max_dur = max(this_durations_expert.max(), this_durations_det.max())\n",
    "        ax[0, i].set_xlim([0, max_dur + 0.1])\n",
    "        ax[0, i].set_ylim([0, max_dur + 0.1])\n",
    "        if i == 0 :\n",
    "            ax[0, i].set_ylabel('Detected duration [s]', fontsize=8.5)\n",
    "        # ax[0, i].set_xlabel('Duration Real [s]', fontsize=8.5)\n",
    "        ax[0, i].plot([0.3, 2.0], [0.3, 2.0], '--k', alpha=0.6)\n",
    "    else:\n",
    "        ax[1, i-2].scatter(this_durations_expert, this_durations_det, label='S%02d' % subject_idx, color='#455a64', alpha=alpha)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "        lg = ax[1, i-2].legend(fontsize=7)\n",
    "        for lh in lg.legendHandles:\n",
    "            lh.set_facecolor(lh.get_facecolor())\n",
    "            lh.set_edgecolor(lh.get_edgecolor())\n",
    "            lh.set_alpha(1.0)\n",
    "        max_dur = max(this_durations_expert.max(), this_durations_det.max())\n",
    "        ax[1, i-2].set_xlim([0, max_dur + 0.1])\n",
    "        ax[1, i-2].set_ylim([0, max_dur + 0.1])\n",
    "        if i == 2:\n",
    "            ax[1, i-2].set_ylabel('Detected duration [s]', fontsize=8.5)\n",
    "        ax[1, i-2].set_xlabel('Real duration [s]', fontsize=8.5)\n",
    "        ax[1, i-2].plot([0.3, 2.0], [0.3, 2.0], '--k', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted probability to matched and unmatched events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare probabilities\n",
    "whole_y_proba = []\n",
    "for i in range(n_subjects):\n",
    "    this_proba = y_pred[chosen_set_error][i]\n",
    "    this_pages = pages[chosen_set_error][i]\n",
    "    page_size = this_proba.shape[1]\n",
    "    max_page = np.max(this_pages)\n",
    "    max_size = (max_page + 1) * page_size\n",
    "    whole_y_proba.append(np.zeros(max_size, dtype=np.float32))\n",
    "    for k, page in enumerate(this_pages):\n",
    "        sample_start = page * page_size\n",
    "        sample_end = (page + 1) * page_size\n",
    "        whole_y_proba[i][sample_start:sample_end] = this_proba[k, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching probabilities (Candidates for TP according to IoU)\n",
    "# It is expected that they have more than 0.5 since that is the threshold used for detection\n",
    "print('Processing probability for matched events', flush=True)\n",
    "matching_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for the valid detections stamps \n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    y_pred_stamps = y_pred_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in y_pred_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    matching_proba.append(mean_proba_list)\n",
    "    \n",
    "# Unmatched real events (FN)\n",
    "# It is expected that they have less than 0.5 since they were missed by the tresholding\n",
    "print('Processing probability for unmatched real events', flush=True)\n",
    "unmatching_fn_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for the missed real events \n",
    "    idx_valid = (idx_array[i] == -1)\n",
    "    fn_stamps = y_stamps[chosen_set_error][i][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    fn_stamps = fn_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in fn_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    unmatching_fn_proba.append(mean_proba_list)\n",
    "    \n",
    "# Unmatched detected events (FP)\n",
    "# It is expected that they have more than 0.5 since they were detected\n",
    "print('Processing probability for unmatched detected events', flush=True)\n",
    "unmatching_fp_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for detected events with no match \n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_valid = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    fp_stamps = y_pred_thr[i][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    fp_stamps = fp_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in fp_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    unmatching_fp_proba.append(mean_proba_list)\n",
    "    \n",
    "\n",
    "# Probability for real events\n",
    "print('Processing probability for real events', flush=True)\n",
    "real_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    y_pred_stamps = y_stamps[chosen_set_error][i] // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in y_pred_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    real_proba.append(mean_proba_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 3, figsize=(14, 3*n_subjects), dpi=100, sharex=True)\n",
    "\n",
    "ax[0, 0].set_title('Model output on matched events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 0].hist(matching_proba[i], label='S%02d' % subject_idx, color='#43a047')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 0].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "ax[-1, 0].set_xlim([0, 1])\n",
    "ax[-1, 0].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('Probability on unmatched real events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 1].hist(unmatching_fn_proba[i], label='S%02d' % subject_idx, color='#455a64')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 1].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "ax[-1, 1].set_xlim([0, 1])\n",
    "ax[-1, 1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "ax[0, 2].set_title('Probability on unmatched detections (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 2].hist(unmatching_fp_proba[i], label='S%02d' % subject_idx, color='#c62828')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 2].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 2].tick_params(labelsize=8.5)\n",
    "    ax[i, 2].legend(fontsize=8.5)\n",
    "ax[-1, 2].set_xlim([0, 1])\n",
    "ax[-1, 2].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(6, 5*n_subjects), dpi=100, sharex=True)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].set_title('Predicted probability for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=11)\n",
    "\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "max_n = 0\n",
    "for i in range(n_subjects):\n",
    "    \n",
    "    n, _, _ = ax[i].hist(\n",
    "        matching_proba[i], label='Matched real', color='#43a047', alpha=0.4, density=True,\n",
    "        bins = [i*0.05 for i in range(21)])\n",
    "    kernel = gaussian_kde(matching_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    ax[i].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "ax[-1].set_xlim([0, 1])\n",
    "ax[-1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "# for i in range(n_subjects):\n",
    "#     subject_idx = idx_dict[chosen_set_error][i]\n",
    "#     n, _, _ = ax[i].hist(\n",
    "#         unmatching_fn_proba[i], label='Unmatched real', color='#455a64', alpha=0.4, density=True,\n",
    "#         bins = [i*0.05 for i in range(21)])\n",
    "#     kernel = gaussian_kde(unmatching_fn_proba[i])\n",
    "#     y_kde = kernel(x_points)\n",
    "#     ax[i].plot(x_points, y_kde, color='#455a64', linewidth=2)\n",
    "#     max_n = max(np.max(n), max_n)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i].hist(\n",
    "        unmatching_fp_proba[i], label='Unmatched detection', color='#c62828', alpha=0.4, density=True,\n",
    "        bins = [i*0.05 for i in range(21)])\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    ax[i].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i].legend(fontsize=8.5, loc='upper left')\n",
    "    ax[i].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(6, 5), dpi=DPI, sharex=True)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    if i < 2:\n",
    "        ax[0, i].set_title('Model Output for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=10)\n",
    "    else:\n",
    "        ax[1, i-2].set_title('Model Output for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=10)\n",
    "\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "max_n = 0\n",
    "for i in range(n_subjects):\n",
    "    if i < 2:\n",
    "        n, _, _ = ax[0, i].hist(\n",
    "            real_proba[i], label='Expert marks', color='#43a047', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "    else:\n",
    "        n, _, _ = ax[1, i-2].hist(\n",
    "            real_proba[i], label='Real events\\n(Expert marks)', color='#43a047', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "    kernel = gaussian_kde(real_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    if i<2:\n",
    "        ax[0, i].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "        ax[0, i].set_xlim([0, 1])\n",
    "    else:\n",
    "        ax[1, i-2].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "        ax[1, i-2].set_xlim([0, 1])\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    \n",
    "\n",
    "# ax[-1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    if i<2:\n",
    "        n, _, _ = ax[0, i].hist(\n",
    "            unmatching_fp_proba[i], label='Unpaired detections ($\\mu$=0.1)', color='#c62828', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "        ax[0, i].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "        # ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "        # lg = ax[0, i].legend(fontsize=8.5, loc='upper center', bbox_to_anchor=(1.05, 0.15))\n",
    "        # for lh in lg.legendHandles:\n",
    "        #     lh.set_facecolor(lh.get_facecolor())\n",
    "        #     lh.set_alpha(1.0)\n",
    "        ax[0, i].set_yticks([])\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "    else:\n",
    "        n, _, _ = ax[1, i-2].hist(\n",
    "            unmatching_fp_proba[i], label='False events\\n(Unpaired detections\\ngenerated with $\\mu$=0.1)', color='#c62828', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "        ax[1, i-2].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "        # ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "        ax[1, i-2].set_yticks([])\n",
    "        ax[1, i-2].set_xlabel('Class assignment', fontsize=8.5)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "lg = ax[1, 1].legend(fontsize=9, loc='upper left', bbox_to_anchor=(1.05, 1.35), labelspacing=3)\n",
    "for lh in lg.legendHandles:\n",
    "    lh.set_facecolor(lh.get_facecolor())\n",
    "    lh.set_alpha(1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Avg distributions over set\n",
    "\n",
    "\n",
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5), dpi=100, sharex=True)\n",
    "\n",
    "ax.set_title('Predicted probability. Average for %s set' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "\n",
    "y_kde_list = []\n",
    "for i in range(n_subjects):\n",
    "    kernel = gaussian_kde(matching_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    y_kde_list.append(y_kde)\n",
    "y_kde_avg_real = np.stack(y_kde_list, axis=1).mean(axis=1)\n",
    "ax.plot(x_points, y_kde_avg_real, color='#43a047', linewidth=2, label='Real event')\n",
    "ax.fill_between(x_points, y_kde_avg_real, 0*y_kde_avg_real, color='#43a047', alpha=0.4)\n",
    "\n",
    "y_kde_list = []\n",
    "for i in range(n_subjects):\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    y_kde_list.append(y_kde)\n",
    "y_kde_avg_false = np.stack(y_kde_list, axis=1).mean(axis=1)\n",
    "ax.plot(x_points, y_kde_avg_false, color='#c62828', linewidth=2, label='False event')\n",
    "ax.fill_between(x_points, y_kde_avg_false, 0*y_kde_avg_false, color='#c62828', alpha=0.4)\n",
    "\n",
    "max_y = max(np.max(y_kde_avg_real), np.max(y_kde_avg_false))\n",
    "\n",
    "# Find optimal threshold\n",
    "difference = y_kde_avg_false - y_kde_avg_real\n",
    "idx_thr = np.where(np.signbit(difference))[0][0]\n",
    "x_thr = x_points[idx_thr]\n",
    "print('Optimal Threshold: %1.4f' % x_thr)\n",
    "ax.plot([x_thr, x_thr], [0, max_y], '--', color='k', linewidth=1.5, alpha=0.6, label='Optimal Threshold')\n",
    "\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, max_y])\n",
    "ax.set_yticks([])\n",
    "ax.legend(fontsize=8.5, loc='upper left')\n",
    "ax.set_xlabel('Probability', fontsize=8.5)\n",
    "ax.set_xticks([i*0.1 for i in range(11)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of FP that are TP-E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unmatched events according to E1\n",
    "unmatched_stamps = []\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    # Unmatched detections\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    fp_stamps = y_pred_thr[i][idx_fp]\n",
    "    print('\\n%d / %d (%1.2f %%) unmatched detections with E1 for S%02d' % (fp_stamps.shape[0], n_detections, 100*fp_stamps.shape[0]/n_detections, subject_idx))\n",
    "    unmatched_stamps.append(fp_stamps)\n",
    "    # Now match with E2\n",
    "    events = y2_stamps[chosen_set_error][i]\n",
    "    detections = fp_stamps\n",
    "    n_detections = fp_stamps.shape[0]\n",
    "    this_iou_array, this_idx_array = metrics.matching(events, detections)\n",
    "    matched_2 =  (this_idx_array > -1).sum()\n",
    "    print('%d were matched with E2 (%1.2f%% of previously unmatched detections)' % (matched_2, 100*matched_2 / fp_stamps.shape[0]))\n",
    "    # print(fp_stamps[this_idx_array[this_idx_array > -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral information of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id_list = dataset.train_ids\n",
    "whole_night = True\n",
    "\n",
    "# Now plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6, 4), dpi=150)\n",
    "if whole_night:\n",
    "    title_str = 'Whole night average'\n",
    "else:\n",
    "    title_str = 'N2 only average'\n",
    "    \n",
    "for subject_id in subject_id_list:\n",
    "    x, _ = dataset.get_subject_data(subject_id, which_expert=1, verbose=False, whole_night=whole_night)\n",
    "    # Compute fft of each page \n",
    "    print('Computing FFT for S%02d... ' % subject_id, end='', flush=True)\n",
    "    fft_list = []\n",
    "    for x_page in x:\n",
    "        fft_page, freq_axis = data_ops.power_spectrum(x_page, 200)\n",
    "        fft_list.append(fft_page)\n",
    "    # Now average the fft:\n",
    "    fft_mean = np.stack(fft_list, axis=1).mean(axis=1)\n",
    "    print('Done')\n",
    "    # Now plot\n",
    "    ax.plot(freq_axis, fft_mean, label='S%02d' % subject_id, linewidth=1)\n",
    "\n",
    "ax.set_title(title_str, fontsize=10)\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Frequency [Hz]', fontsize=8.5)\n",
    "ax.set_ylabel('Power')\n",
    "ax.set_xlim([0, 25])\n",
    "ax.set_ylim([0.01, 0.5])\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.legend(loc='upper right', fontsize=8.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load invalid subjects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
