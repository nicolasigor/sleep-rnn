{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyedflib\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from sleeprnn.data import utils, stamp_correction\n",
    "from sleeprnn.common import viz\n",
    "%matplotlib inline\n",
    "viz.notebook_full_width()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fs = 256\n",
    "subject_id = 19\n",
    "mass_folder = \"/home/ntapia/projects/repos/sleep-rnn/resources/datasets/mass2/\"\n",
    "eeg_file = \"register/01-02-00%02d PSG.edf\" % subject_id\n",
    "ss_file = \"label/spindle/01-02-00%02d Spindles_E1.edf\" % subject_id\n",
    "kc_file = \"label/kcomplex/01-02-00%02d KComplexes_E1.edf\" % subject_id\n",
    "hypno_file = \"label/state/01-02-00%02d Base.edf\"  % subject_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load signal\n",
    "with pyedflib.EdfReader(os.path.join(mass_folder, eeg_file)) as file:\n",
    "    channel_names = file.getSignalLabels()\n",
    "    channel_to_extract = channel_names.index(\"EEG C3-CLE\")\n",
    "    signal = file.readSignal(channel_to_extract)\n",
    "    fs = file.samplefrequency(channel_to_extract)\n",
    "    print('Channel extracted: %s (%s Hz)' % (file.getLabel(channel_to_extract), fs))\n",
    "    fs = int(fs)\n",
    "# signal = utils.broad_filter(signal, fs_old)\n",
    "# signal = utils.resample_signal(signal, fs_old=fs_old, fs_new=fs)\n",
    "signal = signal.astype(np.float32)\n",
    "\n",
    "print(\"Signal\", signal.shape, signal.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load annotations -- SS\n",
    "min_ss_duration = 0.3\n",
    "max_ss_duration = 3.0\n",
    "with pyedflib.EdfReader(os.path.join(mass_folder, ss_file)) as file:\n",
    "    annotations = file.readAnnotations()\n",
    "onsets = np.array(annotations[0])\n",
    "durations = np.array(annotations[1])\n",
    "offsets = onsets + durations\n",
    "marks_time = np.stack((onsets, offsets), axis=1)  # time-stamps\n",
    "marks_ss = np.round(marks_time * fs).astype(np.int32)\n",
    "# marks = stamp_correction.combine_close_stamps(marks, fs, min_ss_duration)\n",
    "# marks_ss = stamp_correction.filter_duration_stamps(marks, fs, min_ss_duration, max_ss_duration)\n",
    "\n",
    "# Load annotations -- KC\n",
    "min_kc_duration = 0.2\n",
    "max_kc_duration = None\n",
    "with pyedflib.EdfReader(os.path.join(mass_folder, kc_file)) as file:\n",
    "    annotations = file.readAnnotations()\n",
    "onsets = np.array(annotations[0])\n",
    "durations = np.array(annotations[1])\n",
    "offsets = onsets + durations\n",
    "marks_time = np.stack((onsets, offsets), axis=1)  # time-stamps\n",
    "marks_kc = np.round(marks_time * fs).astype(np.int32)\n",
    "# marks_kc = stamp_correction.filter_duration_stamps(marks, fs, min_kc_duration, max_kc_duration)\n",
    "\n",
    "print(\"Marks SS\", marks_ss.shape, marks_ss.dtype)\n",
    "print(\"Marks KC\", marks_kc.shape, marks_kc.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Signal and Marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for _ in range(10):\n",
    "    mark_correction = -0.9\n",
    "    \n",
    "    mark_linewidth = 1\n",
    "    window_size = int(fs * 15)\n",
    "    random_loc = np.random.choice(range(marks_kc.shape[0]))  # 676\n",
    "    random_center = marks_kc[random_loc].mean()\n",
    "    start_sample = int((random_center - (window_size // 2)) / fs) * fs\n",
    "    end_sample = start_sample + window_size\n",
    "\n",
    "    segment_time = np.arange(start_sample, end_sample) / fs\n",
    "    segment_signal = signal[start_sample:end_sample]\n",
    "    segment_marks_ss = utils.filter_stamps(marks_ss, start_sample, end_sample) / fs\n",
    "    segment_marks_kc = utils.filter_stamps(marks_kc, start_sample, end_sample) / fs\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, dpi=80, figsize=(10, 2))\n",
    "    ax.plot(segment_time, segment_signal, linewidth=0.8, color=viz.GREY_COLORS[8])\n",
    "    for mark in segment_marks_ss:\n",
    "        mark = mark +  mark_correction\n",
    "        ax.axvline(mark[0], linewidth=0.8, color=viz.PALETTE[\"blue\"])\n",
    "        ax.axvline(mark[1], linewidth=0.8, color=viz.PALETTE[\"blue\"])\n",
    "        ax.fill_between(mark, -150, 150, facecolor=viz.PALETTE[\"blue\"], alpha=0.5)\n",
    "    for mark in segment_marks_kc:\n",
    "        mark = mark + mark_correction\n",
    "        ax.axvline(mark[0], linewidth=0.8, color=viz.PALETTE[\"red\"])\n",
    "        ax.axvline(mark[1], linewidth=0.8, color=viz.PALETTE[\"red\"])\n",
    "        ax.fill_between(mark, -150, 150, facecolor=viz.PALETTE[\"red\"], alpha=0.5)\n",
    "    ax.set_ylim([-150, 150])\n",
    "    ax.set_yticks([-50, 0, 50])\n",
    "    ax.set_xlabel(\"Time [s]\")\n",
    "    ax.set_ylabel(r\"EEG [$\\mu$V]\")\n",
    "    ax.set_xticks(np.arange(start_sample / fs, end_sample / fs, 0.5), minor=True)\n",
    "    ax.set_xlim([start_sample / fs, end_sample / fs])\n",
    "    ax.set_title(\"Subject %02d, KC Mark %d\" % (subject_id, random_loc))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparar con archivos viejos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for subject_id in range(1, 20):\n",
    "\n",
    "    print(\"\\n\\nSubject %d\" % subject_id)\n",
    "\n",
    "    # New\n",
    "    mass_folder = \"/home/ntapia/projects/repos/sleep-rnn/resources/datasets/mass2/\"\n",
    "    eeg_file = \"register/01-02-00%02d PSG.edf\" % subject_id\n",
    "    ss_file = \"label/spindle/01-02-00%02d Spindles_E1.edf\" % subject_id\n",
    "    kc_file = \"label/kcomplex/01-02-00%02d KComplexes_E1.edf\" % subject_id\n",
    "    with pyedflib.EdfReader(os.path.join(mass_folder, eeg_file)) as file:\n",
    "        channel_names = file.getSignalLabels()\n",
    "        channel_to_extract = channel_names.index(\"EEG C3-CLE\")\n",
    "        signal = file.readSignal(channel_to_extract)\n",
    "        fs_new = file.samplefrequency(channel_to_extract)\n",
    "        print('Channel extracted: %s (%s Hz)' % (file.getLabel(channel_to_extract), fs_new))\n",
    "    signal_new = signal.astype(np.float32)\n",
    "    with pyedflib.EdfReader(os.path.join(mass_folder, ss_file)) as file:\n",
    "        annotations = file.readAnnotations()\n",
    "    onsets = np.array(annotations[0])\n",
    "    durations = np.array(annotations[1])\n",
    "    offsets = onsets + durations\n",
    "    marks_ss_new = np.stack((onsets, offsets), axis=1)  # time-stamps\n",
    "\n",
    "    # Old\n",
    "    mass_folder = \"/home/ntapia/projects/repos/sleep-rnn/resources/datasets/mass_old/\"\n",
    "    eeg_file = \"register/01-02-00%02d PSG.edf\" % subject_id\n",
    "    ss_file = \"label/spindle/01-02-00%02d SpindleE1.edf\" % subject_id\n",
    "    kc_file = \"label/kcomplex/01-02-00%02d KComplexesE1.edf\" % subject_id\n",
    "    with pyedflib.EdfReader(os.path.join(mass_folder, eeg_file)) as file:\n",
    "        channel_names = file.getSignalLabels()\n",
    "        channel_to_extract = channel_names.index(\"EEG C3-CLE\")\n",
    "        signal = file.readSignal(channel_to_extract)\n",
    "        fs_old = file.samplefrequency(channel_to_extract)\n",
    "        print('Channel extracted: %s (%s Hz)' % (file.getLabel(channel_to_extract), fs_old))\n",
    "    signal_old = signal.astype(np.float32)\n",
    "    with pyedflib.EdfReader(os.path.join(mass_folder, ss_file)) as file:\n",
    "        annotations = file.readAnnotations()\n",
    "    onsets = np.array(annotations[0])\n",
    "    durations = np.array(annotations[1])\n",
    "    offsets = onsets + durations\n",
    "    marks_ss_old = np.stack((onsets, offsets), axis=1)  # time-stamps\n",
    "\n",
    "    print(\"Total duration Old [s]\", signal_old.size / fs_old)\n",
    "    print(\"Total duration New [s]\", signal_new.size / fs_new)\n",
    "    print(\"Ratio sizes Old:New\", signal_old.size / signal_new.size)\n",
    "    print(\"Ratio fs Old:New\", fs_old / fs_new)\n",
    "    half_duration_difference = ((signal_old.size / fs_old) - (signal_new.size / fs_new)) / 2\n",
    "    print(\"Half duration difference [s]\", half_duration_difference)\n",
    "\n",
    "    n_samples = 100\n",
    "    start_sample = 1000000\n",
    "    fig, ax = plt.subplots(1, 1, dpi=80, figsize=(8, 2))\n",
    "    ax.plot(\n",
    "        np.arange(start_sample, start_sample+n_samples)/fs_old, \n",
    "        signal_old[start_sample:start_sample+n_samples], linewidth=0.8, label=\"old\")\n",
    "    ax.plot(\n",
    "        np.arange(start_sample, start_sample+n_samples)/fs_new, \n",
    "        signal_new[start_sample:start_sample+n_samples], linewidth=0.8, label=\"new\")\n",
    "    ax.legend(loc=\"upper right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Comparacion de marcas\n",
    "    marks_ss_old_fix = stamp_correction.filter_duration_stamps(marks_ss_old * fs_old, fs_old, None, 5) / fs_old\n",
    "    print(\"Number of marks old_fix:\", marks_ss_old_fix.shape[0])\n",
    "    print(\"Number of marks new:\", marks_ss_new.shape[0])\n",
    "\n",
    "    difference_in_onset = marks_ss_old_fix[:, 0] - marks_ss_new[:, 0]\n",
    "    print(\"Mean Gap: % 1.4f [s]\" % np.mean(difference_in_onset))\n",
    "    plt.hist(difference_in_onset)\n",
    "    plt.title(\"Onset difference Old_fix - New [s] - Subject %02d\" % subject_id)\n",
    "    plt.show()\n",
    "\n",
    "    # Comparacion de señales\n",
    "    signal_old_resample = utils.resample_signal_linear(signal_old, fs_old, fs_new)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1, dpi=80, figsize=(8, 2))\n",
    "    ax.plot(\n",
    "        np.arange(start_sample, start_sample+n_samples)/fs_new, \n",
    "        signal_old_resample[start_sample:start_sample+n_samples], linewidth=0.8, label=\"old_resample\")\n",
    "    ax.plot(\n",
    "        np.arange(start_sample, start_sample+n_samples)/fs_new, \n",
    "        signal_new[start_sample:start_sample+n_samples], linewidth=0.8, label=\"new\")\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    n_samples_to_mse = min(signal_old_resample.size, signal_new.size)\n",
    "    error = signal_old_resample[:n_samples_to_mse] - signal_new[:n_samples_to_mse]\n",
    "    rmse = np.sqrt(np.mean(error ** 2))\n",
    "    print(\"RMSE between old_resample and new:\", rmse)\n",
    "    print(\"|Error| range\", np.abs(error).min(), np.abs(error).max())\n",
    "\n",
    "    cases_loc = np.where((np.abs(error) > 1) & (np.abs(error) < 1000000))[0]\n",
    "    print(\"Number of error cases greater than 1: %d (%1.4f %%)\" % (len(cases_loc), 100 * len(cases_loc) / n_samples_to_mse))\n",
    "    signal_old_resample = np.concatenate([signal_old_resample, np.zeros(int(fs_new * 10))])\n",
    "    signal_new = np.concatenate([signal_new, np.zeros(int(fs_new * 10))])\n",
    "    for _ in range(5):\n",
    "        single_case = np.random.choice(cases_loc)\n",
    "        case_error = error[single_case]\n",
    "        case_start = single_case - int(fs_new * 2)\n",
    "        case_end = single_case + int(fs_new * 2)\n",
    "        fig, ax = plt.subplots(1, 1, dpi=80, figsize=(9, 2))\n",
    "        ax.plot(\n",
    "            np.arange(case_start, case_end)/fs_new, \n",
    "            signal_old_resample[case_start:case_end], linewidth=0.8, label=\"old_resample\")\n",
    "        ax.plot(\n",
    "            np.arange(case_start, case_end)/fs_new, \n",
    "            signal_new[case_start:case_end], linewidth=0.8, label=\"new\")\n",
    "        ax.legend()\n",
    "        ax.set_title(\"Case visualization of signal mismatch (Error %1.6f)\" % case_error)\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check hypnogram alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load hypnogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
