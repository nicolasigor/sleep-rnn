{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pyedflib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import gridspec\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.signal import hilbert, filtfilt, find_peaks, lfilter\n",
    "\n",
    "project_root = '..'\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from sleeprnn.data.inta_ss import IntaSS, NAMES, IDS_TEST\n",
    "from sleeprnn.data import utils, stamp_correction\n",
    "from sleeprnn.detection import metrics\n",
    "from sleeprnn.data.loader import RefactorUnpickler\n",
    "from sleeprnn.common import constants, pkeys\n",
    "\n",
    "SEED_LIST = [123, 234, 345, 456]\n",
    "RESULTS_PATH = os.path.join(project_root, 'results')\n",
    "COMPARISON_PATH = os.path.join(project_root, 'resources', 'comparison_data')\n",
    "DPI = 100\n",
    "CUSTOM_COLOR = {'red': '#c62828', 'grey': '#455a64', 'blue': '#0277bd', 'green': '#43a047'} \n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# look for intersections between stamps of the same validity\n",
    "def overlap_matrix(events, detections):\n",
    "    # Matrix of overlap, rows are events, columns are detections\n",
    "    n_det = detections.shape[0]\n",
    "    n_gs = events.shape[0]\n",
    "    overlaps = np.zeros((n_gs, n_det))\n",
    "    for i in range(n_gs):\n",
    "        candidates = np.where(\n",
    "            (detections[:, 0] <= events[i, 1])\n",
    "            & (detections[:, 1] >= events[i, 0]))[0]\n",
    "        for j in candidates:\n",
    "            intersection = min(\n",
    "                events[i, 1], detections[j, 1]\n",
    "            ) - max(\n",
    "                events[i, 0], detections[j, 0]\n",
    "            ) + 1\n",
    "            if intersection > 0:\n",
    "                overlaps[i, j] = 1\n",
    "    return overlaps\n",
    "\n",
    "def overlapping_groups(overlap_matrix):\n",
    "    groups_overlap = [[0]]\n",
    "    for i in range(overlap_matrix.shape[0]):\n",
    "        visited = np.any([i in single_group for single_group in groups_overlap])\n",
    "        if not visited:\n",
    "            # Check if intersects with an existent group\n",
    "            added = False\n",
    "            for single_group in groups_overlap:\n",
    "                is_overlapping = np.any(overlap_matrix[i, single_group])\n",
    "                if is_overlapping:\n",
    "                    single_group.append(i)\n",
    "                    added = True\n",
    "            if not added:\n",
    "                # Then variable is a new group\n",
    "                groups_overlap.append([i])\n",
    "    return groups_overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = IntaSS(load_checkpoint=True, params={pkeys.NORM_COMPUTATION_MODE: constants.NORM_GLOBAL})\n",
    "dataset_name = constants.INTA_SS_NAME\n",
    "\n",
    "# Load predictions\n",
    "ckpt_folder = os.path.join('20190706_inta_05_n2_train_inta_ss', 'v15')\n",
    "optimal_thr_list = [0.42, 0.44, 0.48, 0.5]\n",
    "task_mode = constants.N2_RECORD\n",
    "seed_id_list = [0, 1, 2, 3]\n",
    "n_seeds = len(seed_id_list)\n",
    "set_list = [constants.TRAIN_SUBSET, constants.VAL_SUBSET, constants.TEST_SUBSET]\n",
    "which_expert = 1\n",
    "verbose = False\n",
    "predictions_dict = {}\n",
    "for k in seed_id_list:\n",
    "    # Restore predictions\n",
    "    ckpt_path = os.path.abspath(os.path.join(\n",
    "        RESULTS_PATH,\n",
    "        'predictions_%s' % dataset_name,\n",
    "        ckpt_folder,\n",
    "        'seed%d' % k\n",
    "    ))\n",
    "    this_dict = {}\n",
    "    for set_name in set_list:\n",
    "        filename = os.path.join(\n",
    "                ckpt_path,\n",
    "                'prediction_%s_%s.pkl' % (task_mode, set_name))\n",
    "        with open(filename, 'rb') as handle:\n",
    "            this_pred = RefactorUnpickler(handle).load()\n",
    "        this_dict[set_name] = this_pred\n",
    "    predictions_dict[k] = this_dict\n",
    "    print('Loaded seed %d/%d from %s' % (k + 1, n_seeds, ckpt_path))\n",
    "print('Optimal thr:', optimal_thr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load stamps of subject\n",
    "subject_id = 11  # 4, 11\n",
    "\n",
    "print('Loading S%02d' % subject_id)\n",
    "fs = dataset.fs\n",
    "path_dataset = dataset.dataset_dir\n",
    "path_stamps = os.path.join(path_dataset, 'label/spindle', 'SS_%s.txt' % NAMES[subject_id - 1])\n",
    "path_signals = os.path.join(path_dataset, 'register', '%s.rec' % NAMES[subject_id - 1]) \n",
    "\n",
    "with pyedflib.EdfReader(path_signals) as file:\n",
    "    signal = file.readSignal(0)\n",
    "    channel_name = file.getLabel(0)\n",
    "    print('Reading', channel_name)\n",
    "    signal_len = signal.shape[0]\n",
    "data = np.loadtxt(path_stamps)\n",
    "for_this_channel = (data[:, -1] == 1)\n",
    "data = data[for_this_channel]\n",
    "data = np.round(data).astype(np.int32)\n",
    "\n",
    "# Remove zero duration marks, and ensure that start time < end time\n",
    "new_data = []\n",
    "for i in range(data.shape[0]):\n",
    "    if data[i, 0] > data[i, 1]:\n",
    "        print('End time < Start time fixed')\n",
    "        aux = data[i, 0]\n",
    "        data[i, 0] = data[i, 1]\n",
    "        data[i, 1] = aux\n",
    "        new_data.append(data[i, :])\n",
    "    elif data[i, 0] < data[i, 1]:\n",
    "        new_data.append(data[i, :])\n",
    "    else:  # Zero duration (equality)\n",
    "        print('Zero duration stamp found and removed')\n",
    "data = np.stack(new_data, axis=0)\n",
    "\n",
    "# Remove stamps outside signal boundaries\n",
    "new_data = []\n",
    "for i in range(data.shape[0]):\n",
    "    if data[i, 1] < signal_len:\n",
    "        new_data.append(data[i, :])\n",
    "    else:\n",
    "        print('Stamp outside boundaries found and removed')\n",
    "data = np.stack(new_data, axis=0)\n",
    "\n",
    "raw_stamps = data[:, [0, 1]]\n",
    "valid = data[:, 4]\n",
    "raw_stamps_0 = raw_stamps[valid == 0]\n",
    "raw_stamps_1 = raw_stamps[valid == 1]\n",
    "raw_stamps_2 = raw_stamps[valid == 2]\n",
    "print(\n",
    "    'Valid 0', raw_stamps_0.shape, 'Min dur [s]', (raw_stamps_0[:, 1] - raw_stamps_0[:, 0]).min()/fs, \n",
    "    'Max dur [s]', (raw_stamps_0[:, 1] - raw_stamps_0[:, 0]).max()/fs)\n",
    "print(\n",
    "    'Valid 1', raw_stamps_1.shape, 'Min dur [s]', (raw_stamps_1[:, 1] - raw_stamps_1[:, 0]).min()/fs, \n",
    "    'Max dur [s]', (raw_stamps_1[:, 1] - raw_stamps_1[:, 0]).max()/fs)\n",
    "print(\n",
    "    'Valid 2', raw_stamps_2.shape, 'Min dur [s]', (raw_stamps_2[:, 1] - raw_stamps_2[:, 0]).min()/fs, \n",
    "    'Max dur [s]', (raw_stamps_2[:, 1] - raw_stamps_2[:, 0]).max()/fs)\n",
    "\n",
    "del raw_stamps_0\n",
    "\n",
    "overlap_m = overlap_matrix(raw_stamps_1, raw_stamps_1)\n",
    "groups_overlap_1 = overlapping_groups(overlap_m)\n",
    "\n",
    "n_overlaps_1 = [len(single_group) for single_group in groups_overlap_1]\n",
    "values_1, counts_1 = np.unique(n_overlaps_1, return_counts=True)\n",
    "print('\\nSize of overlapping groups for Valid 1')\n",
    "for value, count in zip(values_1, counts_1):\n",
    "    print('%d marks: %d times' % (value, count))\n",
    "\n",
    "overlap_m = overlap_matrix(raw_stamps_2, raw_stamps_2)\n",
    "groups_overlap_2 = overlapping_groups(overlap_m)\n",
    "n_overlaps_2 = [len(single_group) for single_group in groups_overlap_2]\n",
    "values_2, counts_2 = np.unique(n_overlaps_2, return_counts=True)\n",
    "print('\\nSize of overlapping groups for Valid 2')\n",
    "for value, count in zip(values_2, counts_2):\n",
    "    print('%d marks: %d times' % (value, count))\n",
    "\n",
    "max_overlaps_1 = values_1.max() - 1\n",
    "max_overlaps_2 = values_2.max() - 1\n",
    "max_overlaps = np.max([max_overlaps_1, max_overlaps_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal\n",
    "signal_dict = {}\n",
    "fs_dict = {}\n",
    "with pyedflib.EdfReader(path_signals) as file:\n",
    "    signal_names = file.getSignalLabels()\n",
    "    \n",
    "print(signal_names)\n",
    "eeg_names = signal_names[:5]\n",
    "other_names = signal_names[5:6]  + signal_names[7:8]\n",
    "to_show_names = eeg_names + other_names\n",
    "print(to_show_names)  \n",
    "\n",
    "with pyedflib.EdfReader(path_signals) as file:   \n",
    "    for k, name in enumerate(signal_names):\n",
    "        if name in to_show_names:\n",
    "            this_signal = file.readSignal(k)\n",
    "            fs_dict[name] = file.getSampleFrequency(k)\n",
    "            signal_dict[name] = this_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# -*- mode: python -*-\n",
    "# Adapted from mpl_toolkits.axes_grid1\n",
    "# LICENSE: Python Software Foundation (http://docs.python.org/license.html)\n",
    "\n",
    "from matplotlib.offsetbox import AnchoredOffsetbox\n",
    "class AnchoredScaleBar(AnchoredOffsetbox):\n",
    "    def __init__(self, transform, sizex=0, sizey=0, labelx=None, labely=None, loc=4,\n",
    "                 pad=0.1, borderpad=0.1, sep=2, prop=None, barcolor=\"black\", barwidth=None, \n",
    "                 **kwargs):\n",
    "        \"\"\"\n",
    "        Draw a horizontal and/or vertical  bar with the size in data coordinate\n",
    "        of the give axes. A label will be drawn underneath (center-aligned).\n",
    "        - transform : the coordinate frame (typically axes.transData)\n",
    "        - sizex,sizey : width of x,y bar, in data units. 0 to omit\n",
    "        - labelx,labely : labels for x,y bars; None to omit\n",
    "        - loc : position in containing axes\n",
    "        - pad, borderpad : padding, in fraction of the legend font size (or prop)\n",
    "        - sep : separation between labels and bars in points.\n",
    "        - **kwargs : additional arguments passed to base class constructor\n",
    "        \"\"\"\n",
    "        from matplotlib.patches import Rectangle\n",
    "        from matplotlib.offsetbox import AuxTransformBox, VPacker, HPacker, TextArea, DrawingArea\n",
    "        bars = AuxTransformBox(transform)\n",
    "        if sizex:\n",
    "            bars.add_artist(Rectangle((0,0), sizex, 0, ec=barcolor, lw=barwidth, fc=\"none\"))\n",
    "        if sizey:\n",
    "            bars.add_artist(Rectangle((0,0), 0, sizey, ec=barcolor, lw=barwidth, fc=\"none\"))\n",
    "\n",
    "        if sizex and labelx:\n",
    "            self.xlabel = TextArea(labelx, minimumdescent=False)\n",
    "            bars = VPacker(children=[bars, self.xlabel], align=\"center\", pad=0, sep=sep)\n",
    "        if sizey and labely:\n",
    "            self.ylabel = TextArea(labely)\n",
    "            bars = HPacker(children=[self.ylabel, bars], align=\"center\", pad=0, sep=sep)\n",
    "\n",
    "        AnchoredOffsetbox.__init__(self, loc, pad=pad, borderpad=borderpad,\n",
    "                                   child=bars, prop=prop, frameon=False, **kwargs)\n",
    "\n",
    "        \n",
    "def add_scalebar(ax, matchx=True, matchy=True, hidex=True, hidey=True, **kwargs):\n",
    "    \"\"\" Add scalebars to axes\n",
    "    Adds a set of scale bars to *ax*, matching the size to the ticks of the plot\n",
    "    and optionally hiding the x and y axes\n",
    "    - ax : the axis to attach ticks to\n",
    "    - matchx,matchy : if True, set size of scale bars to spacing between ticks\n",
    "                    if False, size should be set using sizex and sizey params\n",
    "    - hidex,hidey : if True, hide x-axis and y-axis of parent\n",
    "    - **kwargs : additional arguments passed to AnchoredScaleBars\n",
    "    Returns created scalebar object\n",
    "    \"\"\"\n",
    "    def f(axis):\n",
    "        l = axis.get_majorticklocs()\n",
    "        return len(l)>1 and (l[1] - l[0])\n",
    "    \n",
    "    if matchx:\n",
    "        kwargs['sizex'] = f(ax.xaxis)\n",
    "        kwargs['labelx'] = str(kwargs['sizex'])\n",
    "    if matchy:\n",
    "        kwargs['sizey'] = f(ax.yaxis)\n",
    "        kwargs['labely'] = str(kwargs['sizey'])\n",
    "        \n",
    "    sb = AnchoredScaleBar(ax.transData, **kwargs)\n",
    "    ax.add_artist(sb)\n",
    "\n",
    "    if hidex : ax.xaxis.set_visible(False)\n",
    "    if hidey : ax.yaxis.set_visible(False)\n",
    "    if hidex and hidey: ax.set_frame_on(False)\n",
    "\n",
    "    return sb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "subject_seed_set_dict = {\n",
    "    1: (2, constants.VAL_SUBSET),\n",
    "    2: (1, constants.VAL_SUBSET),\n",
    "    4: (0, constants.VAL_SUBSET),\n",
    "    5: (0, constants.TEST_SUBSET),\n",
    "    6: (1, constants.VAL_SUBSET),\n",
    "    7: (0, constants.TEST_SUBSET),\n",
    "    8: (3, constants.VAL_SUBSET),\n",
    "    9: (0, constants.TEST_SUBSET),\n",
    "    10: (2, constants.VAL_SUBSET),\n",
    "    11: (0, constants.VAL_SUBSET),\n",
    "}\n",
    "\n",
    "this_pages = dataset.get_subject_pages(subject_id=subject_id) \n",
    "this_stamps = dataset.get_subject_stamps(subject_id=subject_id)\n",
    "\n",
    "# Power\n",
    "# Sigma relative amplitude\n",
    "low_sigma_freq = 10\n",
    "high_sigma_freq = 16\n",
    "window_size = 101\n",
    "# signal_to_power = utils.broad_filter(signal_dict['F4-C4'], fs, lowcut=0.1, highcut=30)\n",
    "signal_original = dataset.get_subject_signal(subject_id=subject_id, normalize_clip=False)\n",
    "signal_to_power, _ = utils.norm_clip_signal_global(signal_original, dataset.global_std, clip_value=3)\n",
    "print(signal_to_power.min(), signal_to_power.max())\n",
    "signal_sigma = utils.filter_windowed_sinusoidal(signal_to_power, fs, 13, 41)\n",
    "\n",
    "kernel = np.ones(window_size) / window_size\n",
    "rms_broad = lfilter(kernel, 1.0, signal_to_power ** 2)\n",
    "n_shift = (window_size-1) // 2\n",
    "instantaneous_rms_broad = np.zeros(rms_broad.shape)\n",
    "instantaneous_rms_broad[:-n_shift] = rms_broad[n_shift:]\n",
    "\n",
    "kernel = np.ones(window_size) / window_size\n",
    "rms_narrow = lfilter(kernel, 1.0, signal_sigma ** 2)\n",
    "n_shift = (window_size-1) // 2\n",
    "instantaneous_rms_narrow = np.zeros(rms_narrow.shape)\n",
    "instantaneous_rms_narrow[:-n_shift] = rms_narrow[n_shift:]\n",
    "\n",
    "absolute_power = instantaneous_rms_narrow\n",
    "relative_power = instantaneous_rms_narrow / (instantaneous_rms_broad + 1e-3)\n",
    "\n",
    "max_absolute_power = np.percentile(absolute_power, 99.5)\n",
    "# max_absolute_power = absolute_power.max()\n",
    "min_absolute_power = absolute_power.min()\n",
    "max_relative_power = np.percentile(relative_power, 99.5)\n",
    "# max_relative_power = relative_power.max()\n",
    "min_relative_power = relative_power.min()\n",
    "\n",
    "absolute_power = (absolute_power-min_absolute_power) / (max_absolute_power-min_absolute_power)\n",
    "relative_power = (relative_power-min_relative_power) / (max_relative_power-min_relative_power)\n",
    "\n",
    "# Peak density\n",
    "window_size = 101\n",
    "signal_for_peaks = utils.broad_filter(signal_dict['F4-C4'], fs, lowcut=0.1, highcut=20)\n",
    "segment_peaks, _ = find_peaks(signal_for_peaks)\n",
    "peaks_onehot = np.zeros(signal_for_peaks.shape)\n",
    "peaks_onehot[segment_peaks] = 1\n",
    "kernel = np.ones(window_size)\n",
    "peak_density = lfilter(kernel, 1.0, peaks_onehot) / (window_size / fs)\n",
    "n_shift = (window_size-1) // 2\n",
    "instantaneous_frequency = np.zeros(peak_density.shape)\n",
    "instantaneous_frequency[:-n_shift] = peak_density[n_shift:]\n",
    "kernel = np.hanning(21)\n",
    "kernel = kernel / kernel.sum()\n",
    "instantaneous_frequency = lfilter(kernel, 1.0, instantaneous_frequency)\n",
    "n_shift = (kernel.size-1) // 2\n",
    "tmp = instantaneous_frequency\n",
    "instantaneous_frequency_complete = np.zeros(tmp.shape)\n",
    "instantaneous_frequency_complete[:-n_shift] = tmp[n_shift:]\n",
    "\n",
    "abs_tol = 0.1\n",
    "rel_tol = 0.15\n",
    "low_sigma_freq = 10\n",
    "high_sigma_freq = 16\n",
    "valid_abs = (absolute_power >= abs_tol).astype(np.int32)\n",
    "valid_rel = (relative_power >= rel_tol).astype(np.int32)\n",
    "valid_freq = (instantaneous_frequency_complete >= low_sigma_freq).astype(np.int32) * (instantaneous_frequency_complete <= high_sigma_freq).astype(np.int32)\n",
    "valid_both = valid_abs * valid_rel * valid_freq\n",
    "primitive_mark = utils.seq2stamp(valid_both)\n",
    "\n",
    "print_idx = np.where((primitive_mark[:, 0]>=1660000) & (primitive_mark[:, 0]<=1664000))[0]\n",
    "print_stamps = primitive_mark[print_idx, :]\n",
    "print('First pass (power and freq thresholding)')\n",
    "print(print_stamps/fs)\n",
    "\n",
    "primitive_mark = stamp_correction.combine_close_stamps(\n",
    "    primitive_mark, fs, 0.1)\n",
    "primitive_mark = stamp_correction.filter_duration_stamps(\n",
    "    primitive_mark, fs, 0.1, 5)\n",
    "primitive_mark = stamp_correction.combine_close_stamps(\n",
    "    primitive_mark, fs, 0.3)\n",
    "\n",
    "print_idx = np.where((primitive_mark[:, 0]>=1660000) & (primitive_mark[:, 0]<=1664000))[0]\n",
    "print_stamps = primitive_mark[print_idx, :]\n",
    "print('Second pass (duration control sep 0.1, dur [0.1 5], then sep 0.3)')\n",
    "print(print_stamps/fs)\n",
    "\n",
    "# Now remove low power marks\n",
    "mean_power_abs_tol = 0.15\n",
    "mean_power_rel_tol = 0.2\n",
    "improved_primitive_mark = []\n",
    "abs_power_list = []\n",
    "rel_power_list = []\n",
    "for single_primitive in primitive_mark:\n",
    "    stamp_abs_power = np.mean(absolute_power[single_primitive[0]:single_primitive[1]])\n",
    "    stamp_rel_power = np.mean(relative_power[single_primitive[0]:single_primitive[1]])\n",
    "    abs_power_list.append(stamp_abs_power)\n",
    "    rel_power_list.append(stamp_rel_power)\n",
    "    if (stamp_abs_power >= mean_power_abs_tol) and (stamp_rel_power >= mean_power_rel_tol):\n",
    "        improved_primitive_mark.append(single_primitive)\n",
    "primitive_mark = np.stack(improved_primitive_mark, axis=0)\n",
    "\n",
    "print_idx = np.where((primitive_mark[:, 0]>=1660000) & (primitive_mark[:, 0]<=1664000))[0]\n",
    "print_stamps = primitive_mark[print_idx, :]\n",
    "print('Third pass (mean power thresholding)')\n",
    "print(print_stamps/fs)\n",
    "\n",
    "primitive_mark = stamp_correction.combine_close_stamps(\n",
    "    primitive_mark, fs, 0.8)\n",
    "primitive_mark = stamp_correction.filter_duration_stamps(\n",
    "    primitive_mark, fs, 0.3, 3)\n",
    "\n",
    "print_idx = np.where((primitive_mark[:, 0]>=1660000) & (primitive_mark[:, 0]<=1664000))[0]\n",
    "print_stamps = primitive_mark[print_idx, :]\n",
    "print('Fourth pass (duration control sep 0.8, dur [0.3 3])')\n",
    "print(print_stamps/fs)\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.title('Mean absolute power inside primitive')\n",
    "plt.hist(abs_power_list, bins=100)\n",
    "#plt.xlim([0, 1])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 3))\n",
    "plt.title('Mean relative power inside primitive')\n",
    "plt.hist(rel_power_list, bins=100)\n",
    "#plt.xlim([0, 1])\n",
    "plt.show()\n",
    "    \n",
    "    \n",
    "# Model predictions\n",
    "model_stamps_list = []\n",
    "iou_list = np.arange(1, 10) * 0.1\n",
    "f1_vs_iou_list = []\n",
    "this_seed = subject_seed_set_dict[subject_id][0]\n",
    "set_name = subject_seed_set_dict[subject_id][1]\n",
    "prediction_obj = predictions_dict[this_seed][set_name]\n",
    "prediction_obj.set_probability_threshold(optimal_thr_list[this_seed])\n",
    "this_detections = prediction_obj.get_subject_stamps(subject_id=subject_id)\n",
    "model_stamps_list.append(this_detections)\n",
    "f1_vs_iou = metrics.metric_vs_iou(\n",
    "    this_stamps, this_detections, iou_list)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=80)\n",
    "ax.plot(iou_list, f1_vs_iou)\n",
    "ax.set_xlim([0.1 - 0.02, 0.9 + 0.02])\n",
    "ax.set_ylim([0.1 - 0.02, 0.9 + 0.02])\n",
    "ax.set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax.set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax.set_ylabel('F1-score', fontsize=8.5)\n",
    "ax.yaxis.grid()\n",
    "plt.show()\n",
    "\n",
    "thr_size = 5\n",
    "print('Overlapping groups for Valid 2 with size at least %d' % thr_size)\n",
    "to_print_list = [sub_group for sub_group in groups_overlap_2 if len(sub_group)>=thr_size]\n",
    "for single_group in to_print_list:\n",
    "    single_page = int(raw_stamps_2[single_group[0], :].mean() / dataset.page_size)\n",
    "    print('Group size %d. Page idx: %d. Group: %s' % (len(single_group), this_pages.tolist().index(single_page), single_group))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_stamps_color = CUSTOM_COLOR['blue']\n",
    "expert_stamps_color = CUSTOM_COLOR['red']\n",
    "stamps_color = '#B71C1C'\n",
    "\n",
    "def filter_stamps(stamps, single_page, page_size):\n",
    "    stamps_pages = (stamps / page_size).astype(np.int32)\n",
    "    useful_idx = np.where((stamps_pages[:, 0] == single_page) | (stamps_pages[:, 1] == single_page))[0]\n",
    "    useful_stamps = stamps[useful_idx, :]\n",
    "    return useful_stamps\n",
    "\n",
    "def plot_page(page_idx, show_model, show_expert, show_primitive):\n",
    "    \n",
    "    microvolt_per_second = 100  # Aspect ratio\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 1.2*len(to_show_names)+5), dpi=DPI)\n",
    "    gs = gridspec.GridSpec(6, 1, height_ratios=[1, 1, 2, 2, 2, 4*len(to_show_names)])\n",
    "    \n",
    "    page_chosen = this_pages[page_idx]\n",
    "    page_start = page_chosen * dataset.page_size\n",
    "    page_end = page_start + dataset.page_size\n",
    "    \n",
    "    if show_expert:\n",
    "        segment_stamps = filter_stamps(this_stamps, page_chosen, dataset.page_size)\n",
    "        segment_stamps_valid_1 = filter_stamps(raw_stamps_1, page_chosen, dataset.page_size)\n",
    "        segment_stamps_valid_2 = filter_stamps(raw_stamps_2, page_chosen, dataset.page_size)\n",
    "    else:\n",
    "        segment_stamps = []\n",
    "        segment_stamps_valid_1 = []\n",
    "        segment_stamps_valid_2 = []\n",
    "        \n",
    "    segment_model_stamps = []\n",
    "    for single_stamps in model_stamps_list:\n",
    "        if show_model:\n",
    "            segment_single_stamps = filter_stamps(single_stamps, page_chosen, dataset.page_size)\n",
    "            segment_model_stamps.append(segment_single_stamps)\n",
    "        else:\n",
    "            segment_model_stamps.append([])\n",
    "            \n",
    "    if show_primitive:\n",
    "        segment_primitive = filter_stamps(primitive_mark, page_chosen, dataset.page_size)\n",
    "    else:\n",
    "        segment_primitive = []\n",
    "    \n",
    "    time_axis = np.arange(page_start, page_end) / fs\n",
    "    x_ticks = time_axis[0] + np.arange(5, 21, 5)\n",
    "    \n",
    "    gs_idx = 0\n",
    "\n",
    "    # Show valid 1\n",
    "    delta_y = 0.1\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "\n",
    "    for j, this_stamp in enumerate(segment_stamps_valid_1):\n",
    "        n_stamps = len(segment_stamps_valid_1)\n",
    "        dy_for_stamp = 1/n_stamps\n",
    "        ax.plot(this_stamp/fs, [j*dy_for_stamp, j*dy_for_stamp], color=stamps_color, linewidth=1.5)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylim([-delta_y, 1+delta_y])\n",
    "    ax.set_xlim([time_axis[0], time_axis[-1]])\n",
    "    ax.set_ylabel('V1', fontsize=8)\n",
    "    \n",
    "    # Show valid 2\n",
    "    delta_y = 0.1\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    for j, this_stamp in enumerate(segment_stamps_valid_2):\n",
    "        n_stamps = len(segment_stamps_valid_2)\n",
    "        dy_for_stamp = 1/n_stamps\n",
    "        ax.plot(this_stamp/fs, [j*dy_for_stamp, j*dy_for_stamp], color=stamps_color, linewidth=1.5)\n",
    "    ax.set_xticks(np.arange(time_axis[0], time_axis[-1], 0.5), minor=True)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylim([-delta_y, 1+delta_y])\n",
    "    ax.set_xlim([time_axis[0], time_axis[-1]])\n",
    "    ax.set_ylabel('V2', fontsize=8)   \n",
    "    # ax.set_xlabel('Time [s]', fontsize=8)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Show instantaneous frequency\n",
    "    low_sigma_freq = 10\n",
    "    high_sigma_freq = 16\n",
    "    window_size = 101\n",
    "    \n",
    "    gs_idx = gs_idx + 1\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    name = 'F4-C4'\n",
    "    segment_fs = fs_dict[name]\n",
    "    segment_start = int(page_chosen * dataset.page_duration * segment_fs)\n",
    "    segment_end = int(segment_start + dataset.page_duration * segment_fs)\n",
    "    segment_signal = signal_dict[name][segment_start:segment_end]\n",
    "    segment_time_axis = np.arange(segment_start, segment_end) / segment_fs\n",
    "    \n",
    "    # Peak density\n",
    "    peak_border = int(5*fs)\n",
    "    segment_signal_for_peaks = signal_dict[name][segment_start-peak_border:segment_end+peak_border]\n",
    "    signal_for_peaks = np.zeros(segment_signal_for_peaks.shape)\n",
    "    filtered_for_peaks = utils.broad_filter(segment_signal_for_peaks, fs, lowcut=0.1, highcut=20)\n",
    "    signal_for_peaks[fs:-fs] = filtered_for_peaks[fs:-fs]\n",
    "    segment_peaks, _ = find_peaks(signal_for_peaks)\n",
    "    peaks_onehot = np.zeros(signal_for_peaks.shape)\n",
    "    peaks_onehot[segment_peaks] = 1\n",
    "    \n",
    "    kernel = np.ones(window_size)\n",
    "    peak_density = lfilter(kernel, 1.0, peaks_onehot) / (window_size / fs)\n",
    "    n_shift = (window_size-1) // 2\n",
    "    instantaneous_frequency = np.zeros(peak_density.shape)\n",
    "    instantaneous_frequency[:-n_shift] = peak_density[n_shift:]\n",
    "    \n",
    "    kernel = np.hanning(21)\n",
    "    kernel = kernel / kernel.sum()\n",
    "    instantaneous_frequency = lfilter(kernel, 1.0, instantaneous_frequency)\n",
    "    n_shift = (kernel.size-1) // 2\n",
    "    tmp = instantaneous_frequency\n",
    "    instantaneous_frequency = np.zeros(tmp.shape)\n",
    "    instantaneous_frequency[:-n_shift] = tmp[n_shift:]\n",
    "    \n",
    "    instantaneous_frequency = instantaneous_frequency[peak_border:-peak_border]\n",
    "    \n",
    "    print('V1')\n",
    "    for j, this_stamp in enumerate(segment_stamps_valid_1):\n",
    "        start_slice = max(this_stamp[0] - segment_start, 0)\n",
    "        end_slice = min(this_stamp[1] - segment_start + 1, segment_end)\n",
    "        snippet_f = instantaneous_frequency[start_slice:end_slice]\n",
    "        inside_samples = np.where((snippet_f<=high_sigma_freq) & (snippet_f>=low_sigma_freq))[0]\n",
    "        print(\n",
    "            'mean f %1.2f, dt %1.2f [s], dt inside band %1.2f' \n",
    "            % (snippet_f.mean(), snippet_f.size/fs, inside_samples.size/fs))\n",
    "    print('V2')\n",
    "    for j, this_stamp in enumerate(segment_stamps_valid_2):\n",
    "        start_slice = max(this_stamp[0] - segment_start, 0)\n",
    "        end_slice = min(this_stamp[1] - segment_start + 1, segment_end)\n",
    "        snippet_f = instantaneous_frequency[start_slice:end_slice]\n",
    "        inside_samples = np.where((snippet_f<=high_sigma_freq) & (snippet_f>=low_sigma_freq))[0]\n",
    "        print(\n",
    "            'mean f %1.2f, dt %1.2f [s], dt inside band %1.2f, %% inside band %1.2f' \n",
    "            % (snippet_f.mean(), snippet_f.size/fs, inside_samples.size/fs, 100*inside_samples.size/snippet_f.size))\n",
    "    \n",
    "    ax.plot(\n",
    "        segment_time_axis, instantaneous_frequency, linewidth=1, color=CUSTOM_COLOR['grey'])\n",
    "    ax.plot(\n",
    "        segment_time_axis, instantaneous_frequency_complete[segment_start:segment_end], linewidth=1, color=CUSTOM_COLOR['red'])\n",
    "    ax.plot([time_axis[0], time_axis[-1]], [low_sigma_freq, low_sigma_freq], 'k--', linewidth=1)\n",
    "    ax.plot([time_axis[0], time_axis[-1]], [high_sigma_freq, high_sigma_freq], 'k--', linewidth=1)\n",
    "    \n",
    "    ax.set_xticks(np.arange(time_axis[0], time_axis[-1], 0.5), minor=True)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_ylim([4, 20])\n",
    "    ax.set_xlim([time_axis[0], time_axis[-1]])\n",
    "    ax.set_ylabel('f [Hz]', fontsize=8)   \n",
    "    # ax.set_xlabel('Time [s]', fontsize=8)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    name = 'F4-C4'\n",
    "    segment_fs = fs_dict[name]\n",
    "    segment_start = int(page_chosen * dataset.page_duration * segment_fs)\n",
    "    segment_end = int(segment_start + dataset.page_duration * segment_fs)\n",
    "    segment_signal = signal_dict[name][segment_start:segment_end]\n",
    "    segment_time_axis = np.arange(segment_start, segment_end) / segment_fs\n",
    "    \n",
    "    ax.plot(\n",
    "        segment_time_axis, absolute_power[segment_start:segment_end], linewidth=1, color=CUSTOM_COLOR['grey'])\n",
    "    ax.plot([time_axis[0], time_axis[-1]], [abs_tol, abs_tol], 'k--', linewidth=1)\n",
    "    \n",
    "    ax.set_xticks(np.arange(time_axis[0], time_axis[-1], 0.5), minor=True)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([time_axis[0], time_axis[-1]])\n",
    "    ax.set_ylabel('AbsP', fontsize=8)   \n",
    "    ax.set_ylim([0, 1])\n",
    "    # ax.set_xlabel('Time [s]', fontsize=8)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    gs_idx = gs_idx + 1\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    ax.plot(\n",
    "        segment_time_axis, relative_power[segment_start:segment_end], linewidth=1, color=CUSTOM_COLOR['grey'])\n",
    "    ax.plot([time_axis[0], time_axis[-1]], [rel_tol, rel_tol], 'k--', linewidth=1)\n",
    "    ax.set_xticks(np.arange(time_axis[0], time_axis[-1], 0.5), minor=True)\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([time_axis[0], time_axis[-1]])\n",
    "    ax.set_ylabel('RelP', fontsize=8)   \n",
    "    ax.set_xlabel('Time [s]', fontsize=8)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    ax.set_ylim([0, 1])\n",
    "    \n",
    "    \n",
    "    # Signal\n",
    "    gs_idx = gs_idx + 1\n",
    "    y_max = 150\n",
    "    y_sep = 150\n",
    "    scale = 0.5\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    \n",
    "    for k, name in enumerate(to_show_names):\n",
    "        if name == 'F4-C4':\n",
    "            stamp_center = -y_sep*k\n",
    "        segment_fs = fs_dict[name]\n",
    "        segment_start = int(page_chosen * dataset.page_duration * segment_fs)\n",
    "        segment_end = int(segment_start + dataset.page_duration * segment_fs)\n",
    "        segment_signal = signal_dict[name][segment_start:segment_end]\n",
    "        segment_time_axis = np.arange(segment_start, segment_end) / segment_fs\n",
    "        ax.plot(\n",
    "            segment_time_axis, -y_sep*k + scale*segment_signal, linewidth=1, color=CUSTOM_COLOR['grey'])\n",
    "    \n",
    "    add_scalebar(ax, matchx=True, matchy=True, hidex=False, hidey=False)\n",
    "    model_shown = False\n",
    "    expert_shown = False\n",
    "    primitive_shown = False\n",
    "    for single_segment_model_stamps in segment_model_stamps:\n",
    "        for model_stamp in single_segment_model_stamps:\n",
    "            if not model_shown:\n",
    "                label = 'Model'\n",
    "            else:\n",
    "                label = None\n",
    "            ax.fill_between(\n",
    "                model_stamp / fs, 50+stamp_center, -50+stamp_center, \n",
    "                facecolor=model_stamps_color, alpha=0.5,  label=label)\n",
    "            model_shown = True\n",
    "    for expert_stamp in segment_stamps:\n",
    "        if not expert_shown:\n",
    "            label = 'Expert'\n",
    "        else:\n",
    "            label = None\n",
    "        ax.plot(\n",
    "            expert_stamp / fs, [stamp_center-50, stamp_center-50], \n",
    "            color=expert_stamps_color, linewidth=2, label=label)\n",
    "        expert_shown = True\n",
    "        \n",
    "    for primitive_stamp in segment_primitive:\n",
    "        if not primitive_shown:\n",
    "            label = 'Primitive'\n",
    "        else:\n",
    "            label = None\n",
    "        ax.plot(\n",
    "            primitive_stamp / fs, [stamp_center-30, stamp_center-30], \n",
    "            color=CUSTOM_COLOR['green'], linewidth=2, label=label)\n",
    "        primitive_shown = True\n",
    "    \n",
    "    ax.set_yticks([-y_sep*k for k in range(len(to_show_names))])\n",
    "    ax.set_yticklabels(to_show_names)\n",
    "    ax.set_xlim([time_axis[0], time_axis[-1]])\n",
    "    ax.set_ylim([-y_max -y_sep*(len(to_show_names)-1) - 30, y_max])\n",
    "    ax.set_title('Subject %d (%s INTA). Page in record: %d. (intervals of 0.5s are shown).' \n",
    "                 % (subject_id, NAMES[subject_id-1], page_chosen), fontsize=10)\n",
    "    ax.set_xticks(x_ticks)\n",
    "    ax.set_xticks(np.arange(time_axis[0], time_axis[-1], 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    ax.set_aspect(1/microvolt_per_second)\n",
    "    ax.set_xlabel('Time [s]', fontsize=8)\n",
    "\n",
    "    if model_shown or expert_shown:\n",
    "        lg = ax.legend(loc='upper right', fontsize=8)\n",
    "        for lh in lg.legendHandles:\n",
    "            lh.set_alpha(1.0)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Casos\n",
    "\n",
    "11: Peor performance\n",
    "\n",
    "- Consultas 1 vs 2, valid 2\n",
    "- Consultas delimitación de inicio y fin en mayores discordancias\n",
    "- ¿Utiliza actividad en canales vecinos para apoyar decisión y existencia y delimitación?\n",
    "- Tomar 0.5s como la separación mínima entre marcas o 0.3s?\n",
    "\n",
    "[O] Mostrar sin marca\n",
    "Desde índice 400 a índice 405\n",
    "Group size 4. Page idx: 400. Group: [205, 206, 207, 208] * \n",
    "401: (start xq v2>v1?; final xq?)\n",
    "Group size 4. Page idx: 402. Group: [217, 218, 219, 220] *  ¿Por qué no se marca el de al medio, es un artefacto?\n",
    "Group size 4. Page idx: 404. Group: [226, 227, 228, 229] * (al final)\n",
    "\n",
    "Mostrar con marca (16 ejemplos)\n",
    "\n",
    "Group size 4. Page idx: 348. Group: [113, 114, 115, 116] * \n",
    "Group size 4. Page idx: 393. Group: [180, 181, 182, 183] * \n",
    "Group size 4. Page idx: 394. Group: [184, 185, 186, 187] * \n",
    "Group size 4. Page idx: 411. Group: [263, 264, 265, 266] * (inicio y medio)\n",
    "Group size 4. Page idx: 413. Group: [275, 276, 277, 278] * (medio y final)\n",
    "Group size 4. Page idx: 414. Group: [286, 287, 288, 289] * \n",
    "Group size 4. Page idx: 424. Group: [324, 325, 326, 327] *\n",
    "\n",
    "Group size 5. Page idx: 203. Group: [21, 22, 23, 24, 25] * \n",
    "Group size 5. Page idx: 428. Group: [346, 347, 348, 349, 350] * \n",
    "Group size 5. Page idx: 438. Group: [384, 385, 386, 387, 388] *\n",
    "Group size 5. Page idx: 807. Group: [799, 800, 801, 802, 803] * [O]\n",
    "Group size 5. Page idx: 849. Group: [876, 877, 878, 879, 880] * \n",
    "Group size 5. Page idx: 1280. Group: [1007, 1008, 1009, 1010, 1011] * \n",
    "Group size 5. Page idx: 1305. Group: [1089, 1090, 1091, 1092, 1093] * \n",
    "\n",
    "Group size 6. Page idx: 596. Group: [477, 478, 479, 480, 481, 482] *\n",
    "Group size 6. Page idx: 751. Group: [619, 620, 621, 622, 623, 624] *\n",
    "\"\"\"\n",
    "\n",
    "start_page = 414\n",
    "# s11 393 muy rapido, 414 muy lento, 203\n",
    "# s4 61 288 363 407 615-616 624 639 846 863-864 878-879 922 938 1008\n",
    "show_model = False\n",
    "show_expert = True\n",
    "show_primitive = True\n",
    "\n",
    "style = {'description_width': 'initial'}\n",
    "layout= widgets.Layout(width='1000px')\n",
    "widgets.interact(\n",
    "    lambda page_idx: plot_page(page_idx, show_model, show_expert, show_primitive),\n",
    "    page_idx=widgets.IntSlider(\n",
    "        min=0, max=this_pages.shape[0]-1, step=1, value=start_page, \n",
    "        continuous_update=False,\n",
    "        style=style,\n",
    "        layout=layout\n",
    "    ));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx 393 segment\n",
    "segment_stamps = filter_stamps(this_stamps, 394, dataset.page_size)\n",
    "# single_stamp = segment_stamps[2, :]\n",
    "# Get signal\n",
    "# context = 15\n",
    "# start_sample = int(single_stamp.mean() - fs*context//2)\n",
    "# end_sample = int(single_stamp.mean() + fs*context//2)\n",
    "stamp_signal = signal_dict['F4-C4'][start_sample:end_sample]\n",
    "\n",
    "# Filter\n",
    "stamp_signal = utils.broad_filter(stamp_signal, fs, lowcut=1, highcut=25)\n",
    "stamp_signal = stamp_signal[fs:-fs]\n",
    "\n",
    "t = np.arange(stamp_signal.size) / fs\n",
    "analytic_signal = hilbert(stamp_signal)\n",
    "amplitude_envelope = np.abs(analytic_signal)\n",
    "instantaneous_phase = np.unwrap(np.angle(analytic_signal))\n",
    "kernel = np.hanning(21)\n",
    "kernel = kernel / kernel.sum()\n",
    "instantaneous_phase_filt = filtfilt(kernel, 1.0, instantaneous_phase)\n",
    "instantaneous_frequency = np.gradient(instantaneous_phase_filt) / (2*np.pi) * fs\n",
    "\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(8, 2))\n",
    "# plt.plot(t, np.imag(analytic_signal), linewidth=1)\n",
    "# plt.fill_between((single_stamp-start_sample)/fs, -50, 50, facecolor=CUSTOM_COLOR['red'], alpha=0.3)\n",
    "# plt.show()\n",
    "\n",
    "# plt.figure(figsize=(8, 2))\n",
    "# plt.plot(t, np.angle(analytic_signal), linewidth=1)\n",
    "# plt.show()\n",
    "# print(np.angle(analytic_signal).max(), np.angle(analytic_signal).min())\n",
    "\n",
    "fig, ax = plt.subplots(5, 1, figsize=(10, 10), sharex=True)\n",
    "ax[0].plot(t, np.real(analytic_signal), linewidth=1)\n",
    "ax[0].fill_between((single_stamp-start_sample)/fs, -50, 50, facecolor=CUSTOM_COLOR['red'], alpha=0.3)\n",
    "\n",
    "ax[1].plot(t, instantaneous_frequency, linewidth=1)\n",
    "ax[1].plot([t[0], t[-1]], [11, 11], 'k--')\n",
    "ax[1].plot([t[0], t[-1]], [15, 15], 'k--')\n",
    "\n",
    "segment_peaks, _ = find_peaks(stamp_signal)\n",
    "peaks_onehot = np.zeros(t.shape)\n",
    "peaks_onehot[segment_peaks] = 1\n",
    "window_size = 50\n",
    "kernel = np.kaiser(window_size, beta=1)\n",
    "peak_density = lfilter(kernel, 1.0, peaks_onehot) / (window_size / fs)\n",
    "\n",
    "ax[2].plot(t, peaks_onehot, linewidth=1)\n",
    "\n",
    "ax[3].plot(t, peak_density, linewidth=1)\n",
    "ax[3].plot([t[0], t[-1]], [11, 11], 'k--')\n",
    "ax[3].plot([t[0], t[-1]], [15, 15], 'k--')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S11 histogram of mean frequencies of raw marks\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
