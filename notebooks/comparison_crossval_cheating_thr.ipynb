{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, gridspec\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor\n",
    "project_root = '..'\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from sleeprnn.common import constants, pkeys, viz\n",
    "from sleeprnn.common.optimal_thresholds import OPTIMAL_THR_FOR_CKPT_DICT\n",
    "from sleeprnn.data import utils, stamp_correction\n",
    "from sleeprnn.detection.feeder_dataset import FeederDataset\n",
    "from sleeprnn.detection.postprocessor import PostProcessor\n",
    "from sleeprnn.detection import metrics\n",
    "from sleeprnn.helpers import reader, plotter, printer, misc, performer\n",
    "\n",
    "RESULTS_PATH = os.path.join(project_root, 'results')\n",
    "COMPARISON_PATH = os.path.join(project_root, 'resources', 'comparison_data')\n",
    "\n",
    "%matplotlib inline\n",
    "viz.notebook_full_width()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_dates = [20200724, None]\n",
    "printer.print_available_ckpt(OPTIMAL_THR_FOR_CKPT_DICT, filter_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = constants.MASS_SS_NAME\n",
    "which_expert = 1\n",
    "seed_id_list = [i for i in range(4)]\n",
    "task_mode = constants.N2_RECORD\n",
    "fs = 200\n",
    "set_list = [constants.VAL_SUBSET, constants.TRAIN_SUBSET]\n",
    "\n",
    "# Specify what to load\n",
    "comparison_runs_list = [\n",
    "    (\n",
    "        '20201024_combi_completa_n2_train_mass_ss/v19_noisy_waves1_ab0.0_focal0.25-0.25', \n",
    "        'RED-CWT-Focal-Noisy-Waves', 'v19-focal-noisy-waves'),\n",
    "    # ('20200724_reproduce_red_n2_train_mass_ss/v19_rep1', 'RED-CWT', 'v19'),\n",
    "    #('20191227_bsf_10runs_e1_n2_train_mass_ss/v11', 'RED-Time', 'v11'),\n",
    "    # ('20191227_bsf_10runs_e1_n2_train_mass_ss/v19', 'RED-CWT', 'v19'),\n",
    "    #('20191227_bsf_10runs_e2_n2_train_mass_ss/v11', 'RED-Time', 'v11'),\n",
    "    #('20191227_bsf_10runs_e2_n2_train_mass_ss/v19', 'RED-CWT', 'v19'),\n",
    "    #('20191227_bsf_10runs_e1_n2_train_mass_kc/v11', 'RED-Time', 'v11'),\n",
    "    #('20191227_bsf_10runs_e1_n2_train_mass_kc/v19', 'RED-CWT', 'v19'),\n",
    "]\n",
    "comparison_runs_list = [\n",
    "    (t_folder, t_label, t_code) \n",
    "    for (t_folder, t_label, t_code) in comparison_runs_list \n",
    "    if (dataset_name in t_folder)\n",
    "    # if (dataset_name in t_folder) and ('e%d' % which_expert) in t_folder\n",
    "]\n",
    "ckpt_folder_list = [t_folder for (t_folder, t_label, t_code) in comparison_runs_list]\n",
    "ckpt_folder_dict = {t_label: t_folder for (t_folder, t_label, t_code) in comparison_runs_list}\n",
    "ckpt_label_dict = {t_folder: t_label for (t_folder, t_label, t_code) in comparison_runs_list}\n",
    "ckpt_label_list = [t_label for (t_folder, t_label, t_code) in comparison_runs_list]\n",
    "ckpt_code_list = [t_code for (t_folder, t_label, t_code) in comparison_runs_list]\n",
    "\n",
    "# Load data\n",
    "n_cases = len(comparison_runs_list)\n",
    "dataset = reader.load_dataset(dataset_name, params={pkeys.FS: fs})\n",
    "ids_dict = {\n",
    "    constants.ALL_TRAIN_SUBSET: dataset.train_ids,\n",
    "    constants.TEST_SUBSET: dataset.test_ids}\n",
    "ids_dict.update(misc.get_splits_dict(dataset, seed_id_list))\n",
    "predictions_dict = {}\n",
    "for ckpt_folder in ckpt_folder_list:\n",
    "    predictions_dict[ckpt_folder] = reader.read_prediction_with_seeds(\n",
    "        ckpt_folder, dataset_name, task_mode, seed_id_list, set_list=set_list, parent_dataset=dataset)\n",
    "# useful for viz\n",
    "iou_hist_bins = np.linspace(0, 1, 21)\n",
    "iou_curve_axis = misc.custom_linspace(0.05, 0.95, 0.05)\n",
    "result_id = '%s-%s-E%d-%s' % (\n",
    "    dataset_name.split('_')[0].upper(), \n",
    "    dataset_name.split('_')[1].upper(), \n",
    "    which_expert,\n",
    "    task_mode.upper())\n",
    "expert_data_dict = reader.load_ss_expert_performance()\n",
    "exp_keys = list(expert_data_dict.keys())\n",
    "print('\\nAvailable data:')\n",
    "pprint(exp_keys)\n",
    "model_names = ckpt_label_list\n",
    "code_names = ckpt_code_list\n",
    "models = []\n",
    "for name, code_name in zip(model_names, code_names):\n",
    "    models.append({'name': name, 'ckpt': ckpt_folder_dict[name], 'code_name': code_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = False\n",
    "save_txt = False\n",
    "folder_name = 'cheating_%s_e%d' % (dataset_name, which_expert)\n",
    "os.makedirs(folder_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall Curve subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seeds_to_show = seed_id_list\n",
    "n_seeds = len(seeds_to_show)\n",
    "set_list = ['val']\n",
    "iou_to_show = 0.2\n",
    "dpi = 200\n",
    "res_thr = 0.01\n",
    "start_thr = 0.1\n",
    "end_thr = 0.95\n",
    "iou_idx = misc.closest_index(iou_to_show, iou_curve_axis) \n",
    "color_dict = {\n",
    "    'train': {i: viz.GREY_COLORS[4] for i in range(4)},\n",
    "    'val': {0: viz.PALETTE['red'], 1: viz.PALETTE['blue'], 2: viz.PALETTE['green'], 3: viz.PALETTE['dark']}\n",
    "}\n",
    "markersize_model = 6\n",
    "axis_markers = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "n_thr = int(np.floor((end_thr - start_thr) / res_thr + 1))\n",
    "thr_list = np.array([start_thr + res_thr * i for i in range(n_thr)])\n",
    "thr_list = np.round(thr_list, 2)\n",
    "if save_txt:\n",
    "    f = open(os.path.join(folder_name, 'cheating_metrics_xval.txt'), 'w')\n",
    "print('Thr grid search: %1.2f:%1.2f:%1.2f' % (start_thr, res_thr, end_thr))\n",
    "if save_txt:\n",
    "    print('Thr grid search: %1.2f:%1.2f:%1.2f' % (start_thr, res_thr, end_thr), file=f)\n",
    "for j_m, model in enumerate(models):\n",
    "    for cheating in [False, True]:\n",
    "        if cheating:\n",
    "            title = '%s (Cheating)\\n(%s) - ValSet IoU>%1.1f' % (model['name'], result_id, iou_to_show)\n",
    "        else:\n",
    "            title = '%s\\n(%s) - ValSet IoU>%1.1f' % (model['name'], result_id, iou_to_show)\n",
    "        print('\\n%s' % title)\n",
    "        if save_txt:\n",
    "            print('\\n%s' % title, file=f)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(3, 3), dpi=viz.DPI if dpi is None else dpi)\n",
    "        store_f1 = []\n",
    "        store_precision = []\n",
    "        store_recall = []\n",
    "        for k_ax, seed_id_for_f1vsiou in enumerate(seeds_to_show):\n",
    "            # ---------------- Compute performance\n",
    "            pre_vs_iou_subject_dict = {}\n",
    "            rec_vs_iou_subject_dict = {}\n",
    "            for set_name in set_list:\n",
    "                # print('Processing %s' % set_name, flush=True)\n",
    "                # Prepare expert labels\n",
    "                data_inference = FeederDataset(\n",
    "                    dataset, ids_dict[seed_id_for_f1vsiou][set_name], task_mode, which_expert)\n",
    "                this_ids = data_inference.get_ids()\n",
    "                this_events_list = data_inference.get_stamps()\n",
    "                # Prepare model predictions\n",
    "                prediction_obj = predictions_dict[model['ckpt']][seed_id_for_f1vsiou][set_name]\n",
    "                if cheating:\n",
    "                    for i, single_id in enumerate(this_ids):\n",
    "                        predictions_at_thr_list = []\n",
    "                        t_proba = prediction_obj.get_subject_probabilities(single_id)\n",
    "                        max_valid = t_proba.max() - 0.05\n",
    "                        thr_list_subject = thr_list[thr_list < max_valid]\n",
    "                        for thr in thr_list_subject:\n",
    "                            prediction_obj.set_probability_threshold(thr)\n",
    "                            this_detections = prediction_obj.get_subject_stamps(single_id)\n",
    "                            predictions_at_thr_list.append(this_detections)\n",
    "                        single_events = this_events_list[i]\n",
    "                        af1_list = Parallel(n_jobs=-1)(\n",
    "                            delayed(metrics.average_metric)(single_events, single_prediction, verbose=False)\n",
    "                            for single_prediction in predictions_at_thr_list)\n",
    "                        max_idx = np.argmax(af1_list).item()\n",
    "                        best_thr = thr_list_subject[max_idx]\n",
    "                        prediction_obj.set_probability_threshold(best_thr)\n",
    "                        single_detections = prediction_obj.get_subject_stamps(single_id)\n",
    "                        this_precision = metrics.metric_vs_iou(\n",
    "                            single_events, single_detections, iou_curve_axis, metric_name=constants.PRECISION)\n",
    "                        this_recall = metrics.metric_vs_iou(\n",
    "                            single_events, single_detections, iou_curve_axis, metric_name=constants.RECALL)\n",
    "                        this_f1 = 2 * this_precision * this_recall / (this_precision + this_recall)\n",
    "                        # Print performance\n",
    "                        print(\"S%02d (seed%d) F1: %1.1f -- Precision %1.1f -- Recall %1.1f  (thr %1.2f)\" % (\n",
    "                            single_id, \n",
    "                            seed_id_for_f1vsiou,\n",
    "                            100 * this_f1[iou_idx],\n",
    "                            100 * this_precision[iou_idx],\n",
    "                            100 * this_recall[iou_idx],\n",
    "                            best_thr\n",
    "                        ))\n",
    "                        if save_txt:\n",
    "                            print(\"S%02d (seed%d) F1: %1.1f -- Precision %1.1f -- Recall %1.1f  (thr %1.2f)\" % (\n",
    "                                single_id, \n",
    "                                seed_id_for_f1vsiou,\n",
    "                                100 * this_f1[iou_idx],\n",
    "                                100 * this_precision[iou_idx],\n",
    "                                100 * this_recall[iou_idx],\n",
    "                                best_thr\n",
    "                            ), file=f)\n",
    "                        store_f1.append(100 * this_f1[iou_idx])\n",
    "                        store_precision.append(100 * this_precision[iou_idx])\n",
    "                        store_recall.append(100 * this_recall[iou_idx])\n",
    "                        pre_vs_iou_subject_dict[single_id] = this_precision\n",
    "                        rec_vs_iou_subject_dict[single_id] = this_recall\n",
    "                else:\n",
    "                    prediction_obj.set_probability_threshold(OPTIMAL_THR_FOR_CKPT_DICT[model['ckpt']][seed_id_for_f1vsiou])\n",
    "                    this_detections_list = prediction_obj.get_stamps()\n",
    "                    for i, single_id in enumerate(this_ids):\n",
    "                        single_events = this_events_list[i]\n",
    "                        single_detections = this_detections_list[i]\n",
    "                        this_precision = metrics.metric_vs_iou(\n",
    "                            single_events, single_detections, iou_curve_axis, metric_name=constants.PRECISION)\n",
    "                        this_recall = metrics.metric_vs_iou(\n",
    "                            single_events, single_detections, iou_curve_axis, metric_name=constants.RECALL)\n",
    "                        this_f1 = 2 * this_precision * this_recall / (this_precision + this_recall)\n",
    "                        # Print performance\n",
    "                        print(\"S%02d (seed%d) F1: %1.1f -- Precision %1.1f -- Recall %1.1f  (thr %1.2f)\" % (\n",
    "                            single_id, \n",
    "                            seed_id_for_f1vsiou,\n",
    "                            100 * this_f1[iou_idx],\n",
    "                            100 * this_precision[iou_idx],\n",
    "                            100 * this_recall[iou_idx],\n",
    "                            OPTIMAL_THR_FOR_CKPT_DICT[model['ckpt']][seed_id_for_f1vsiou]\n",
    "                        ))\n",
    "                        if save_txt:\n",
    "                            print(\"S%02d (seed%d) F1: %1.1f -- Precision %1.1f -- Recall %1.1f  (thr %1.2f)\" % (\n",
    "                                single_id, \n",
    "                                seed_id_for_f1vsiou,\n",
    "                                100 * this_f1[iou_idx],\n",
    "                                100 * this_precision[iou_idx],\n",
    "                                100 * this_recall[iou_idx],\n",
    "                                OPTIMAL_THR_FOR_CKPT_DICT[model['ckpt']][seed_id_for_f1vsiou]\n",
    "                            ), file=f)\n",
    "                        store_f1.append(100 * this_f1[iou_idx])\n",
    "                        store_precision.append(100 * this_precision[iou_idx])\n",
    "                        store_recall.append(100 * this_recall[iou_idx])\n",
    "                        pre_vs_iou_subject_dict[single_id] = this_precision\n",
    "                        rec_vs_iou_subject_dict[single_id] = this_recall\n",
    "            # print('Done', flush=True)\n",
    "\n",
    "            # -------------------- P L O T ----------------------    \n",
    "\n",
    "            for set_name in set_list:\n",
    "                for i, single_id in enumerate(ids_dict[seed_id_for_f1vsiou][set_name]):\n",
    "                    if i == 0:\n",
    "                        label = 'Seed %d' % seed_id_for_f1vsiou\n",
    "                    else:\n",
    "                        label = None\n",
    "                    ax.plot(\n",
    "                        rec_vs_iou_subject_dict[single_id][iou_idx], \n",
    "                        pre_vs_iou_subject_dict[single_id][iou_idx],\n",
    "                        color=color_dict[set_name][k_ax], marker='o', \n",
    "                        markersize=markersize_model, label=label, linestyle = 'None'\n",
    "                    )\n",
    "        print(\"Avg F1: %1.1f \\u00B1 %1.1f -- Precision %1.1f \\u00B1 %1.1f -- Recall %1.1f \\u00B1 %1.1f\" % (\n",
    "            np.mean(store_f1), np.std(store_f1),\n",
    "            np.mean(store_precision), np.std(store_precision),\n",
    "            np.mean(store_recall), np.std(store_recall)\n",
    "        ))\n",
    "        if save_txt:\n",
    "            print(\"Avg F1: %1.1f \\u00B1 %1.1f -- Precision %1.1f \\u00B1 %1.1f -- Recall %1.1f \\u00B1 %1.1f\" % (\n",
    "                np.mean(store_f1), np.std(store_f1),\n",
    "                np.mean(store_precision), np.std(store_precision),\n",
    "                np.mean(store_recall), np.std(store_recall)\n",
    "            ), file=f)\n",
    "        ax.plot([0, 1], [0, 1], zorder=1, linewidth=1, color=viz.GREY_COLORS[4])\n",
    "        ax.set_title(title, fontsize=8)\n",
    "        ax.set_xlim([0, 1])\n",
    "        ax.set_ylim([0, 1])\n",
    "        ax.set_yticks(axis_markers)\n",
    "        ax.set_xticks(axis_markers)\n",
    "        ax.tick_params(labelsize=8) \n",
    "        ax.set_ylabel('Precision', fontsize=8)\n",
    "        ax.set_xlabel('Recall', fontsize=8)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.legend(loc='lower left', fontsize=8)\n",
    "        plt.tight_layout()\n",
    "        if save_figs:\n",
    "            if cheating:\n",
    "                fname = os.path.join(folder_name, \"pr_%s_seeds_cheating.png\" % model['code_name'])\n",
    "            else:\n",
    "                fname = os.path.join(folder_name, \"pr_%s_seeds.png\" % model['code_name'])\n",
    "            plt.savefig(fname, dpi=200, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "        plt.show()\n",
    "if save_txt:\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stuff as a function of thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seeds_to_show = seed_id_list\n",
    "res_thr = 0.01\n",
    "start_thr = 0.1\n",
    "end_thr = 0.95\n",
    "set_list = ['val']\n",
    "iou_to_show = 0.2\n",
    "\n",
    "n_thr = int(np.floor((end_thr - start_thr) / res_thr + 1))\n",
    "thr_list = np.array([start_thr + res_thr * i for i in range(n_thr)])\n",
    "thr_list = np.round(thr_list, 2)\n",
    "grid_result = {}\n",
    "for model in models:\n",
    "    ckpt_folder = model['ckpt']\n",
    "    grid_result[ckpt_folder] = {}\n",
    "    for seed_id in seeds_to_show:\n",
    "        print(\"Processing Seed %d\" % seed_id, flush=True)\n",
    "        grid_result[ckpt_folder][seed_id] = {}\n",
    "        for set_name in set_list:\n",
    "            print(\"Processing set %s\" % set_name, flush=True)\n",
    "            grid_result[ckpt_folder][seed_id][set_name] = {}\n",
    "            \n",
    "            data_inference = FeederDataset(dataset, ids_dict[seed_id][set_name], task_mode, which_expert)\n",
    "            this_events_list = data_inference.get_stamps()\n",
    "            this_ids = data_inference.get_ids()\n",
    "            prediction_obj = predictions_dict[ckpt_folder][seed_id][set_name]\n",
    "            \n",
    "            set_probas = prediction_obj.get_probabilities()\n",
    "            max_valid = np.max([t_proba.max() for t_proba in set_probas]) - 0.05\n",
    "            thr_list_seed = thr_list[thr_list < max_valid]\n",
    "            print(\"Evaluating %d thresholds\" % len(thr_list_seed), flush=True)\n",
    "            \n",
    "            detections_at_thr = []\n",
    "            for thr in thr_list_seed:\n",
    "                prediction_obj.set_probability_threshold(thr)\n",
    "                this_detections = prediction_obj.get_stamps()\n",
    "                detections_at_thr.append(this_detections)\n",
    "            \n",
    "            for i, single_events in enumerate(this_events_list):\n",
    "                grid_result[ckpt_folder][seed_id][set_name][this_ids[i]] = {}\n",
    "                single_detections_at_thr = [dets_at_single_thr[i] for dets_at_single_thr in detections_at_thr]\n",
    "                n_detections = [p.shape[0] for p in single_detections_at_thr]\n",
    "                \n",
    "                af1_thr_list = Parallel(n_jobs=-1)(\n",
    "                    delayed(metrics.average_metric)(single_events, single_prediction, verbose=False)\n",
    "                    for single_prediction in single_detections_at_thr)\n",
    "                prec_thr_list = Parallel(n_jobs=-1)(\n",
    "                    delayed(metrics.metric_vs_iou)(single_events, single_prediction, [iou_to_show], metric_name=constants.PRECISION)\n",
    "                    for single_prediction in single_detections_at_thr)\n",
    "                prec_thr_list = np.array([p[0] for p in prec_thr_list])\n",
    "                rec_thr_list = Parallel(n_jobs=-1)(\n",
    "                    delayed(metrics.metric_vs_iou)(single_events, single_prediction, [iou_to_show], metric_name=constants.RECALL)\n",
    "                    for single_prediction in single_detections_at_thr)\n",
    "                rec_thr_list = np.array([p[0] for p in rec_thr_list])\n",
    "                f1_thr_list = 2 * prec_thr_list * rec_thr_list / (prec_thr_list + rec_thr_list)\n",
    "                \n",
    "                grid_result[ckpt_folder][seed_id][set_name][this_ids[i]]['thr'] = np.array(thr_list_seed)\n",
    "                grid_result[ckpt_folder][seed_id][set_name][this_ids[i]]['af1'] = np.array(af1_thr_list)\n",
    "                grid_result[ckpt_folder][seed_id][set_name][this_ids[i]]['n_dets'] = np.array(n_detections)\n",
    "                grid_result[ckpt_folder][seed_id][set_name][this_ids[i]]['f1'] = f1_thr_list\n",
    "                grid_result[ckpt_folder][seed_id][set_name][this_ids[i]]['precision'] = prec_thr_list\n",
    "                grid_result[ckpt_folder][seed_id][set_name][this_ids[i]]['recall'] = rec_thr_list\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    print(\"Showing model %s in %s\" % (model['name'], model['ckpt']))\n",
    "    n_seeds = len(seeds_to_show)\n",
    "    fig, axes = plt.subplots(n_seeds, 3, figsize=(9, 3 * n_seeds), dpi=200)\n",
    "    for i, seed_id in enumerate(seeds_to_show):\n",
    "        for set_name in set_list:\n",
    "            for j, single_id in enumerate(ids_dict[seed_id][set_name]):\n",
    "                results = grid_result[ckpt_folder][seed_id][set_name][single_id]\n",
    "                ax = axes[i, j]\n",
    "                \n",
    "                ax.plot(results['thr'], results['af1'], label=\"AF1\")\n",
    "                ax.plot(results['thr'], results['f1'], label=\"F1-%1.1f\" % iou_to_show)\n",
    "                ax.plot(results['thr'], results['recall'], label=\"Recall-%1.1f\" % iou_to_show)\n",
    "                ax.plot(results['thr'], results['precision'], label=\"Precision-%1.1f\" % iou_to_show)\n",
    "                ax.plot(results['thr'], results['n_dets'] / results['n_dets'].max(), label=\"Detections (% of max)\")\n",
    "                \n",
    "                # print('af1', results['af1'])\n",
    "                # print('f1', results['f1'])\n",
    "                # print('recall', results['recall'])\n",
    "                # print('precision', results['precision'])\n",
    "                \n",
    "                max_af1 = np.argmax(results['af1'])\n",
    "                max_f1 = np.argmax(results['f1'])\n",
    "                min_gap = np.argmin(np.abs(results['recall'] - results['precision']))\n",
    "                ax.plot(results['thr'][max_af1], results['af1'][max_af1], marker='o', markersize=4, color=\"k\", zorder=30)\n",
    "                ax.plot(results['thr'][max_f1], results['f1'][max_f1], marker='o', markersize=4, color=\"k\", zorder=30)\n",
    "                ax.plot(results['thr'][min_gap], results['recall'][min_gap], marker='o', markersize=4, color=\"k\", zorder=30)\n",
    "                ax.axvline(results['thr'][max_af1], linestyle=\"--\", color=\"k\")\n",
    "                \n",
    "                ax.tick_params(labelsize=8)\n",
    "                ax.set_ylim([0, 1])\n",
    "                ax.set_xlim([0, 1])\n",
    "                ax.set_title(\"Seed %d - %s - S%02d\" % (seed_id, set_name, single_id), fontsize=10)\n",
    "                ax.set_xlabel(\"Threshold\", fontsize=8)\n",
    "            lg = ax.legend(loc=\"upper left\", bbox_to_anchor=(1, 1), frameon=False, fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"%s_thr_effect.pdf\" % model['code_name'], bbox_extra_artists=(lg,), bbox_inches=\"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
