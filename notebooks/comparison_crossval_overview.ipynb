{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import collections\n",
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "import itertools\n",
    "\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors, gridspec\n",
    "import numpy as np\n",
    "from scipy.stats import gaussian_kde\n",
    "from scipy.interpolate import interp1d\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor\n",
    "project_root = '..'\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from sleeprnn.common import constants, pkeys, viz\n",
    "from sleeprnn.common.optimal_thresholds import OPTIMAL_THR_FOR_CKPT_DICT\n",
    "from sleeprnn.data import utils, stamp_correction\n",
    "from sleeprnn.detection.feeder_dataset import FeederDataset\n",
    "from sleeprnn.detection.postprocessor import PostProcessor\n",
    "from sleeprnn.detection import metrics\n",
    "from sleeprnn.helpers import reader, plotter, printer, misc, performer\n",
    "\n",
    "RESULTS_PATH = os.path.join(project_root, 'results')\n",
    "COMPARISON_PATH = os.path.join(project_root, 'resources', 'comparison_data')\n",
    "\n",
    "%matplotlib inline\n",
    "viz.notebook_full_width()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filter_dates = [20201115, None]\n",
    "printer.print_available_ckpt(OPTIMAL_THR_FOR_CKPT_DICT, filter_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_of_interest = [\n",
    "    (\n",
    "        '20201028_combi_completa_batch_n2_train_mass_ss/%s_waves%d_ab0.0_focal%1.2f-%1.2f_batch%d' % (\n",
    "            model_version, wave_proba, focal_eps, focal_eps, batch_size\n",
    "        ),\n",
    "        'batch%02d_noise%d_waves%d_ab0_focal%d' % (\n",
    "            batch_size, model_version == \"v19_noisy\", wave_proba, focal_eps == 0.25\n",
    "        )\n",
    "    ) for model_version, wave_proba, focal_eps, batch_size in itertools.product(\n",
    "        ['v19', 'v19_noisy'], [0, 1], [1, 0.25], [8, 16, 32, 64]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataset_name = constants.MASS_SS_NAME\n",
    "fs = 200\n",
    "which_expert = 1\n",
    "task_mode = constants.N2_RECORD\n",
    "seed_id_list = [i for i in range(4)]\n",
    "set_list = [constants.VAL_SUBSET, constants.TRAIN_SUBSET]\n",
    "\n",
    "# Specify what to load\n",
    "comparison_runs_list = [\n",
    "    ('20200724_reproduce_red_n2_train_mass_ss/v19_rep1', 'RED-CWT'),\n",
    "    ('20200724_reproduce_red_n2_train_mass_ss/v11_rep1', 'RED-Time'),\n",
    "    ('20201006_noisy_cwt_n2_train_mass_ss/v19_noisy_intens0.05', 'RED-CWT-Noise0.05'),\n",
    "    ('20201201_logits_reg_cwt_n2_train_mass_ss/v19_1e-3_logits_reg_attractor',      'RED-CWT-1e-3_LReg_attractor'),\n",
    "    ('20201201_logits_reg_cwt_n2_train_mass_ss/v19_1e-3_logits_reg_attractor_sqrt', 'RED-CWT-1e-3_LReg_attractor_sqrt'),\n",
    "    ('20201201_logits_reg_cwt_n2_train_mass_ss/v19_1e-2_logits_reg_norm_sqrt',      'RED-CWT-1e-2_LReg_norm_sqrt'),\n",
    "    ('20201201_logits_reg_cwt_n2_train_mass_ss/v19_1e-3_logits_reg_norm',           'RED-CWT-1e-3_LReg_norm'),\n",
    "    ('20201201_logits_reg_cwt_n2_train_mass_ss/v19_1e-2_logits_reg_attractor_sqrt', 'RED-CWT-1e-2_LReg_attractor_sqrt'),\n",
    "    ('20201201_logits_reg_cwt_n2_train_mass_ss/v19_1e-3_logits_reg_norm_sqrt',      'RED-CWT-1e-3_LReg_norm_sqrt'),\n",
    "    ('20201201_logits_reg_cwt_n2_train_mass_ss/v19_1e-2_logits_reg_norm',           'RED-CWT-1e-2_LReg_norm'),\n",
    "    ('20201201_logits_reg_cwt_n2_train_mass_ss/v19_1e-2_logits_reg_attractor',      'RED-CWT-1e-2_LReg_attractor'),\n",
    "    ('20201201_logits_reg_cwt_n2_train_mass_ss/v19_1e-1_logits_reg_attractor',      'RED-CWT-1e-1_LReg_attractor'),\n",
    "    ('20201201_logits_reg_cwt_n2_train_mass_ss/v19_1e-1_logits_reg_norm_sqrt',      'RED-CWT-1e-1_LReg_norm_sqrt'),\n",
    "    ('20201201_logits_reg_cwt_n2_train_mass_ss/v19_1e-1_logits_reg_norm',           'RED-CWT-1e-1_LReg_norm'),\n",
    "    ('20201201_logits_reg_cwt_n2_train_mass_ss/v19_1e-1_logits_reg_attractor_sqrt', 'RED-CWT-1e-1_LReg_attractor_sqrt'),\n",
    "]\n",
    "comparison_runs_list = [\n",
    "    (t_folder, t_label) for (t_folder, t_label) in comparison_runs_list if dataset_name in t_folder\n",
    "]\n",
    "ckpt_folder_list = [t_folder for (t_folder, t_label) in comparison_runs_list]\n",
    "ckpt_folder_dict = {t_label: t_folder for (t_folder, t_label) in comparison_runs_list}\n",
    "ckpt_label_dict = {t_folder: t_label for (t_folder, t_label) in comparison_runs_list}\n",
    "\n",
    "# Load data\n",
    "n_cases = len(comparison_runs_list)\n",
    "dataset = reader.load_dataset(dataset_name, params={pkeys.FS: fs})\n",
    "ids_dict = {\n",
    "    constants.ALL_TRAIN_SUBSET: dataset.train_ids,\n",
    "    constants.TEST_SUBSET: dataset.test_ids}\n",
    "ids_dict.update(misc.get_splits_dict(dataset, seed_id_list))\n",
    "predictions_dict = {}\n",
    "for ckpt_folder in ckpt_folder_list:\n",
    "    predictions_dict[ckpt_folder] = reader.read_prediction_with_seeds(\n",
    "        ckpt_folder, dataset_name, task_mode, seed_id_list, set_list=set_list, parent_dataset=dataset)\n",
    "# useful for viz\n",
    "iou_hist_bins = np.linspace(0, 1, 21)\n",
    "iou_curve_axis = misc.custom_linspace(0.05, 0.95, 0.05)\n",
    "result_id = '%s-%s-E%d-%s' % (\n",
    "    dataset_name.split('_')[0].upper(), \n",
    "    dataset_name.split('_')[1].upper(), \n",
    "    which_expert,\n",
    "    task_mode.upper())\n",
    "expert_data_dict = reader.load_ss_expert_performance()\n",
    "exp_keys = list(expert_data_dict.keys())\n",
    "print('\\nAvailable data:')\n",
    "pprint(exp_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output values distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(0, 1, num=11)\n",
    "for ckpt_folder in ckpt_folder_list:\n",
    "    fig, ax = plt.subplots(len(dataset.train_ids), 5, figsize=(8, 8), dpi=120, sharex=True)\n",
    "    print(ckpt_folder)\n",
    "    ax[0, 0].set_title('True Positives (N2)', fontsize=9)\n",
    "    ax[0, 1].set_title('False Positives (N2)', fontsize=9)\n",
    "    ax[0, 2].set_title('False Negatives (N2)', fontsize=9)\n",
    "    ax[0, 3].set_title('TP+FP (N2)', fontsize=9)\n",
    "    ax[0, 4].set_title('TP+FN (N2)', fontsize=9)\n",
    "    subject_global_idx = 0\n",
    "    shown_subjects = []\n",
    "    for k in seed_id_list:\n",
    "        this_thr = OPTIMAL_THR_FOR_CKPT_DICT[ckpt_folder][k]\n",
    "        t_preds = predictions_dict[ckpt_folder][k][constants.VAL_SUBSET]\n",
    "        t_preds.set_probability_threshold(this_thr)\n",
    "        t_dets = t_preds.get_stamps()\n",
    "        t_probas = t_preds.get_probabilities()\n",
    "        this_ids = ids_dict[k][constants.VAL_SUBSET]\n",
    "        data_inference = FeederDataset(dataset, this_ids, task_mode, which_expert=which_expert)\n",
    "        this_events_list = data_inference.get_stamps()\n",
    "        this_pages_n2_list = data_inference.get_pages(pages_subset=constants.N2_RECORD)\n",
    "        for i, single_id in enumerate(this_ids):\n",
    "            if single_id in shown_subjects:\n",
    "                continue\n",
    "            shown_subjects.append(single_id)\n",
    "            proba = t_probas[i]\n",
    "            events = (this_events_list[i] / 8).astype(np.int32)\n",
    "            dets = (t_dets[i] / 8).astype(np.int32)\n",
    "            iou_matching, idx_matching = metrics.matching(events, dets)\n",
    "            # Find median probability inside detections\n",
    "            dets_median = [np.median(proba[t0:tf]) for (t0, tf) in dets]\n",
    "            dets_median = np.array(dets_median)\n",
    "            # Find median probability inside events\n",
    "            events_median = [np.median(proba[t0:tf]) for (t0, tf) in events]\n",
    "            events_median = np.array(events_median)\n",
    "            # TP indices\n",
    "            tp_idx = idx_matching[idx_matching != -1]\n",
    "            tp_median = dets_median[tp_idx]  # We use median on detections because of differences in Overlap\n",
    "            # FP indices\n",
    "            fp_idx = [i for i in range(dets.shape[0]) if i not in idx_matching]\n",
    "            fp_median = dets_median[fp_idx]\n",
    "            # FN indices\n",
    "            fn_idx = np.where(idx_matching == -1)[0]\n",
    "            fn_median = events_median[fn_idx]\n",
    "            # Now plot statistics\n",
    "            ax[subject_global_idx, 0].set_ylabel('S%02d' % single_id, fontsize=9)\n",
    "            \n",
    "            ax[subject_global_idx, 0].hist(tp_median, bins=bins)\n",
    "            n1, _, _ = ax[subject_global_idx, 1].hist(fp_median, bins=bins)\n",
    "            n2, _, _ = ax[subject_global_idx, 2].hist(fn_median, bins=bins)\n",
    "            \n",
    "            n = max(n1.max(), n2.max())\n",
    "            ax[subject_global_idx, 1].set_ylim([0, n])\n",
    "            ax[subject_global_idx, 2].set_ylim([0, n])\n",
    "            \n",
    "            tp_fp = np.concatenate([tp_median, fp_median])\n",
    "            ax[subject_global_idx, 3].hist(tp_fp, bins=bins)\n",
    "            tp_fn = np.concatenate([tp_median, fn_median])\n",
    "            ax[subject_global_idx, 4].hist(tp_fn, bins=bins)\n",
    "            \n",
    "            ax[subject_global_idx, 0].axvline(x=this_thr, color='k', linewidth=1)\n",
    "            ax[subject_global_idx, 1].axvline(x=this_thr, color='k', linewidth=1)\n",
    "            ax[subject_global_idx, 2].axvline(x=this_thr, color='k', linewidth=1)\n",
    "            ax[subject_global_idx, 3].axvline(x=this_thr, color='k', linewidth=1)\n",
    "            ax[subject_global_idx, 4].axvline(x=this_thr, color='k', linewidth=1)\n",
    "            \n",
    "            subject_global_idx += 1\n",
    "    for s_ax in ax.flatten():\n",
    "        s_ax.set_xlim([0, 1])\n",
    "        s_ax.tick_params(labelsize=7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General xVal Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance\n",
    "data_dict = {}\n",
    "for ckpt_folder in ckpt_folder_list:\n",
    "    print(ckpt_label_dict[ckpt_folder])\n",
    "    t_data_dict = performer.performance_vs_iou_with_seeds(\n",
    "        dataset,\n",
    "        predictions_dict[ckpt_folder],\n",
    "        OPTIMAL_THR_FOR_CKPT_DICT[ckpt_folder],\n",
    "        iou_curve_axis,\n",
    "        iou_hist_bins,\n",
    "        task_mode,\n",
    "        which_expert,\n",
    "        set_name=constants.VAL_SUBSET\n",
    "    )\n",
    "    \n",
    "    # Mean performance\n",
    "    print('Val AF1: %1.2f \\u00B1 %1.2f' % (\n",
    "        100 * t_data_dict[constants.MEAN_AF1].mean(), 100 * t_data_dict[constants.MEAN_AF1].std()\n",
    "    ))\n",
    "    print('Val Mean IoU at TP: %1.2f \\u00B1 %1.2f' % (\n",
    "        100 * t_data_dict[constants.MEAN_IOU].mean(), 100 * t_data_dict[constants.MEAN_IOU].std()\n",
    "    ))\n",
    "    \n",
    "    data_dict[ckpt_folder] = t_data_dict\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iou_thr = 0.2\n",
    "red_time_f1_score = 80\n",
    "red_time_iou_mean = 84.5\n",
    "fig, ax = plt.subplots(2, 1, figsize=(4, 4), dpi=200)\n",
    "ax[0].set_title(ckpt_label_dict[ckpt_folder_list[-1]][:5], fontsize=11)\n",
    "for s_ax in ax:\n",
    "    s_ax.tick_params(labelsize=8)\n",
    "    s_ax.set_ylim([75, 85])\n",
    "ax[0].set_ylabel(\"F1-score [%]\", fontsize=9)\n",
    "ax[1].set_ylabel(\"IoU [%]\", fontsize=9)\n",
    "ax[1].set_xlabel(\"Max Dilation (N)\", fontsize=9)\n",
    "n_blocks_list = []\n",
    "f1_score_list = []\n",
    "iou_mean_list = []\n",
    "iou_low_list = []\n",
    "iou_high_list = []\n",
    "for ckpt_folder in ckpt_folder_list:\n",
    "    performance_data_dict = data_dict[ckpt_folder]\n",
    "    iou_curve_axis = performance_data_dict[constants.IOU_CURVE_AXIS]\n",
    "    idx_to_show = misc.closest_index(iou_thr, iou_curve_axis)\n",
    "    f1_score = performance_data_dict[constants.F1_VS_IOU].mean(axis=0)[idx_to_show]\n",
    "    iou_mean = performance_data_dict[constants.MEAN_IOU].mean()\n",
    "    iou_iqr_low = performance_data_dict[constants.IQR_LOW_IOU].mean()\n",
    "    iou_iqr_high = performance_data_dict[constants.IQR_HIGH_IOU].mean()\n",
    "    n_blocks = ckpt_label_dict[ckpt_folder][-1]\n",
    "    n_blocks_list.append(n_blocks)\n",
    "    f1_score_list.append(100*f1_score)\n",
    "    iou_mean_list.append(100*iou_mean)\n",
    "    iou_low_list.append(100*iou_iqr_low)\n",
    "    iou_high_list.append(100*iou_iqr_high)\n",
    "ax[0].axhline(red_time_f1_score, linestyle=\"--\", color=viz.PALETTE['red'], label='RED reference')\n",
    "ax[0].plot(n_blocks_list, f1_score_list, marker='o', color=viz.PALETTE['blue'])\n",
    "ax[1].axhline(red_time_iou_mean, linestyle=\"--\", color=viz.PALETTE['red'], label='RED reference')\n",
    "ax[1].plot(n_blocks_list, iou_mean_list, marker='o', color=viz.PALETTE['blue'])\n",
    "ax[0].legend(fontsize=9, loc='upper left')\n",
    "ax[1].legend(fontsize=9, loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('metrics_xval.txt', 'w')\n",
    "color_list = [\n",
    "    viz.PALETTE['red'], \n",
    "    viz.PALETTE['green'], \n",
    "    #viz.GREY_COLORS[4],\n",
    "    # viz.GREY_COLORS[7],\n",
    "    viz.PALETTE['blue'], \n",
    "    viz.PALETTE['dark'],\n",
    "    # viz.PALETTE['cyan'],\n",
    "    viz.PALETTE['purple'],\n",
    "    \n",
    "]\n",
    "marker_list = n_cases * ['o']\n",
    "alpha_line_list = n_cases * [1]\n",
    "zorder_list = [30] + (n_cases-1) * [20]\n",
    "idx_to_remove = []\n",
    "# idx_to_remove = [0, 2, 4, 6]\n",
    "\n",
    "# Plot f1 vs iou specs\n",
    "smaller_plot = False\n",
    "zoom_plot = True\n",
    "zoom_f1 = [0.58, 0.83]\n",
    "external_legend = True\n",
    "show_seed_std = False\n",
    "print_formatted_table = True\n",
    "compare_expert = False\n",
    "alpha_seed_std = 0.4\n",
    "alpha_expert = 0.5\n",
    "iou_thr_to_show = 0.2\n",
    "figsize = (9 if zoom_plot else 4, 4)\n",
    "title = '%d-fold cross-val (%s)' % (len(seed_id_list), result_id)\n",
    "\n",
    "# -------------------- P L O T ----------------------  \n",
    "print('Database: %s, Expert: %d' % (dataset_name, which_expert))\n",
    "print('IoU to show: %1.1f' % iou_thr_to_show)\n",
    "print('Database: %s, Expert: %d' % (dataset_name, which_expert), file=f)\n",
    "print('IoU to show: %1.1f' % iou_thr_to_show, file=f)\n",
    "this_dpi = 100 if smaller_plot else viz.DPI\n",
    "fig, axs = plt.subplots(1, 2 if zoom_plot else 1, figsize=figsize, dpi=this_dpi)\n",
    "default_cmap = plt.get_cmap(\"tab10\")\n",
    "for k_ax, ax in enumerate(axs if type(axs) is np.ndarray else [axs]):\n",
    "    # Expert\n",
    "    if compare_expert and (dataset.event_name == constants.SPINDLE):\n",
    "        exp_mean_f1 = expert_data_dict['%s_mean' % constants.F1_VS_IOU]\n",
    "        exp_std_f1 = expert_data_dict['%s_std' % constants.F1_VS_IOU]\n",
    "        exp_iou_axis = expert_data_dict[constants.IOU_CURVE_AXIS]\n",
    "        min_border = exp_mean_f1 - exp_std_f1\n",
    "        max_border = exp_mean_f1 + exp_std_f1\n",
    "        denser_iou, max_border = plotter.densify_curve(exp_iou_axis, max_border)\n",
    "        denser_iou, min_border = plotter.densify_curve(exp_iou_axis, min_border)\n",
    "        ax.fill_between(\n",
    "            denser_iou, min_border, max_border, alpha=alpha_expert, facecolor=viz.GREY_COLORS[6], \n",
    "            label='Expert Performance\\nWarby et al. 2014\\nPrivate Dataset')\n",
    "\n",
    "    for i, ckpt_folder in enumerate(ckpt_folder_list):\n",
    "        if i in idx_to_remove:\n",
    "            continue\n",
    "        this_label = ckpt_label_dict[ckpt_folder]\n",
    "        this_marker = marker_list[i]\n",
    "        this_alpha = alpha_line_list[i]\n",
    "        if color_list is not None:\n",
    "            this_color = color_list[i]\n",
    "        else:\n",
    "            this_color = default_cmap(i)\n",
    "        this_zorder = zorder_list[i]\n",
    "        model_data_dict = data_dict[ckpt_folder]\n",
    "        mean_f1_vs_iou = model_data_dict[constants.F1_VS_IOU].mean(axis=0)\n",
    "        std_f1_vs_iou = model_data_dict[constants.F1_VS_IOU].std(axis=0)\n",
    "        ax.plot(\n",
    "            iou_curve_axis, mean_f1_vs_iou, linewidth=viz.LINEWIDTH, zorder=this_zorder, label=this_label,\n",
    "            markersize=viz.MARKERSIZE, markevery=(1, 2),\n",
    "            marker=this_marker, color=this_color, alpha=this_alpha\n",
    "        )\n",
    "        if show_seed_std:\n",
    "            ax.fill_between(\n",
    "                iou_curve_axis, mean_f1_vs_iou - std_f1_vs_iou, mean_f1_vs_iou + std_f1_vs_iou, \n",
    "                alpha=alpha_seed_std, facecolor=this_color, zorder=this_zorder)\n",
    "        if k_ax == 0:\n",
    "            printer.print_performance_at_iou(model_data_dict, iou_thr_to_show, this_label, file=f)\n",
    "\n",
    "    if print_formatted_table and k_ax == 0:\n",
    "        print(\"\")\n",
    "        print(\"\", file=f)\n",
    "        for i, ckpt_folder in enumerate(ckpt_folder_list):\n",
    "            printer.print_formatted_performance_at_iou(\n",
    "                data_dict[ckpt_folder], \n",
    "                iou_thr_to_show, \n",
    "                ckpt_label_dict[ckpt_folder], \n",
    "                print_header=(i==0), file=f)\n",
    "    if k_ax == 1:\n",
    "        title = 'ZOOM'\n",
    "    ax.set_title(title, fontsize=viz.FONTSIZE_TITLE, loc='center')\n",
    "    ax = plotter.format_metric_vs_iou_plot(ax, 'F1-score', iou_thr_to_show)\n",
    "    if k_ax == 1:\n",
    "        ax.set_ylim(zoom_f1)\n",
    "        ax.set_ylabel('')\n",
    "lg = plotter.format_legend(ax, external_legend, remove_alpha=(not compare_expert))\n",
    "f.close()\n",
    "if save_figs:\n",
    "    plt.savefig(\"f1_vs_iou_xval.png\", dpi=200, bbox_extra_artists=(lg,), bbox_inches=\"tight\", pad_inches=0.01)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_names = ['RED-Time', 'ATT4', 'ATT1']\n",
    "# code_names = ['v11', 'att4', 'att1']\n",
    "#model_names = ['xEnt-0.5', 'xEnt-0.01', 'xEntSmooth-0.1', 'xEntSmoothClip-0.1']\n",
    "#code_names = ['xent', 'xentB', 'xentBS', 'xentBSC']\n",
    "# model_names = ['RED-Time', 'RED-CWT']\n",
    "# code_names = ['v11', 'v19']\n",
    "#model_names = ['Regular xEnt', 'SumA4M2-C0.25', 'SumA4M2-C0.50', 'SumA4M2-C1.00', 'SumA4M2-C2.00']\n",
    "#code_names = ['xent', 'sum0.25', 'sum0.50', 'sum1.00', 'sum2.00']\n",
    "# model_names = ['regv4-3', 'regv4-2', 'regv4-1', 'regv4-0']\n",
    "# model_names = ['reg-6', 'reg-1', 'reg+0', 'reg+1']\n",
    "model_names = [ckpt_label_dict[key] for key in ckpt_label_dict.keys()] \n",
    "code_names = model_names \n",
    "\n",
    "models = []\n",
    "for name, code_name in zip(model_names, code_names):\n",
    "    models.append({'name': name, 'ckpt': ckpt_folder_dict[name], 'code_name': code_name})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric vs IoU Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seeds_to_show = [0, 1, 2, 3]\n",
    "n_seeds = len(seeds_to_show)\n",
    "set_list = ['train', 'val']\n",
    "\n",
    "color_dict = {\n",
    "    'train': {i: viz.GREY_COLORS[4] for i in range(4)},\n",
    "    'val': {0: viz.PALETTE['red'], 1: viz.PALETTE['blue'], 2: viz.PALETTE['green'], 3: viz.PALETTE['dark']}\n",
    "}\n",
    "\n",
    "marker_list = ['.', 's', '^', 'x', '*', 'd', 'v', 'p']\n",
    "linewidth_model = 1\n",
    "markersize_model = 5\n",
    "f1_markers_iou = [0.2, 0.4, 0.6, 0.8]\n",
    "idx_markers_iou = [\n",
    "    misc.closest_index(single_marker, iou_curve_axis) \n",
    "    for single_marker in f1_markers_iou]\n",
    "    \n",
    "for j_m, model in enumerate(models):\n",
    "    fig, ax = plt.subplots(3, n_seeds, figsize=(2*n_seeds, 5), dpi=viz.DPI)\n",
    "    for k_ax, seed_id_for_f1vsiou in enumerate(seeds_to_show):\n",
    "        # ---------------- Compute performance\n",
    "        f1_vs_iou_subject_dict = {}\n",
    "        pre_vs_iou_subject_dict = {}\n",
    "        rec_vs_iou_subject_dict = {}\n",
    "        for set_name in set_list:\n",
    "            print('Processing %s' % set_name, flush=True)\n",
    "            # Prepare expert labels\n",
    "            this_ids = ids_dict[seed_id_for_f1vsiou][set_name]\n",
    "            data_inference = FeederDataset(dataset, this_ids, task_mode, which_expert=which_expert)\n",
    "            this_events_list = data_inference.get_stamps()\n",
    "            # Prepare model predictions\n",
    "            prediction_obj = predictions_dict[model['ckpt']][seed_id_for_f1vsiou][set_name]\n",
    "            prediction_obj.set_probability_threshold(OPTIMAL_THR_FOR_CKPT_DICT[model['ckpt']][seed_id_for_f1vsiou])\n",
    "            this_detections_list = prediction_obj.get_stamps()\n",
    "            for i, single_id in enumerate(this_ids):\n",
    "                single_events = this_events_list[i]\n",
    "                single_detections = this_detections_list[i]\n",
    "                this_precision = metrics.metric_vs_iou(\n",
    "                    single_events, single_detections, iou_curve_axis, metric_name=constants.PRECISION)\n",
    "                this_recall = metrics.metric_vs_iou(\n",
    "                    single_events, single_detections, iou_curve_axis, metric_name=constants.RECALL)\n",
    "                this_f1 = 2 * this_precision * this_recall / (this_precision + this_recall + 1e-8)\n",
    "                pre_vs_iou_subject_dict[single_id] = this_precision\n",
    "                rec_vs_iou_subject_dict[single_id] = this_recall\n",
    "                f1_vs_iou_subject_dict[single_id] = this_f1\n",
    "        print('Done', flush=True)\n",
    "\n",
    "        # -------------------- P L O T ----------------------    \n",
    "\n",
    "        for set_name in set_list:\n",
    "            for i, single_id in enumerate(ids_dict[seed_id_for_f1vsiou][set_name]):\n",
    "                # F1-score\n",
    "                ax[0, k_ax].plot(iou_curve_axis, f1_vs_iou_subject_dict[single_id], \n",
    "                           linewidth=linewidth_model, markersize=markersize_model, marker=marker_list[i], \n",
    "                           label='S%02d' % single_id, color=color_dict[set_name][k_ax], markevery=idx_markers_iou)\n",
    "                # Precision\n",
    "                ax[1, k_ax].plot(iou_curve_axis, pre_vs_iou_subject_dict[single_id], \n",
    "                           linewidth=linewidth_model, markersize=markersize_model, marker=marker_list[i], \n",
    "                           label='S%02d' % single_id, color=color_dict[set_name][k_ax], markevery=idx_markers_iou)\n",
    "                # Recall\n",
    "                ax[2, k_ax].plot(iou_curve_axis, rec_vs_iou_subject_dict[single_id], \n",
    "                           linewidth=linewidth_model, markersize=markersize_model, marker=marker_list[i], \n",
    "                           label='S%02d' % single_id, color=color_dict[set_name][k_ax], markevery=idx_markers_iou)\n",
    "\n",
    "        ax[0, k_ax].set_title('seed %d' % (seed_id_for_f1vsiou), fontsize=9)\n",
    "    for s_ax in ax.flatten():\n",
    "        s_ax.set_xlim([0, 1])\n",
    "        s_ax.set_ylim([0, 1])\n",
    "        s_ax.set_yticks([0.1*i for i in range(2, 10, 2)])\n",
    "        s_ax.set_xticks([0.1*i for i in range(2, 10, 2)])\n",
    "        s_ax.set_xticklabels([])\n",
    "        s_ax.set_yticklabels([])\n",
    "        s_ax.tick_params(labelsize=8.5)\n",
    "        s_ax.yaxis.grid()       \n",
    "    ax[0, 0].set_ylabel('F1-score', fontsize=9)\n",
    "    ax[1, 0].set_ylabel('Precision', fontsize=9)\n",
    "    ax[2, 0].set_ylabel('Recall', fontsize=9)\n",
    "    for s_ax in ax[2, :]:\n",
    "        s_ax.set_xticks([0.1*i for i in range(2, 10, 2)])\n",
    "        s_ax.set_xlabel('IoU Threshold', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.text(\n",
    "        x=0.03, y=1.0, fontsize=9, \n",
    "        s='%s (%s)\\nValidation Set Highlighted' % (model['name'], result_id), \n",
    "        ha=\"left\", transform=fig.transFigure)\n",
    "    if save_figs:\n",
    "        plt.savefig(\"f1_vs_iou_%s_seeds.png\" % model['code_name'], dpi=200, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision-Recall Curve subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "show_subject_id = True\n",
    "show_grid = True\n",
    "show_desired_attractor = True\n",
    "show_mean = True\n",
    "show_quadrants = True\n",
    "skip_subjects = [] # [11, 14, 19]\n",
    "seeds_to_show = [0, 1, 2, 3]\n",
    "n_seeds = len(seeds_to_show)\n",
    "set_list = ['val']\n",
    "iou_to_show = 0.2\n",
    "iou_idx = misc.closest_index(iou_to_show, iou_curve_axis) \n",
    "color_dict = {\n",
    "    'train': {i: viz.GREY_COLORS[4] for i in range(4)},\n",
    "    'val': {0: viz.PALETTE['red'], 1: viz.PALETTE['blue'], 2: viz.PALETTE['green'], 3: viz.PALETTE['dark']}\n",
    "}\n",
    "markersize_model = 6\n",
    "axis_markers = np.arange(0, 1.1, 0.1) #[0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "\n",
    "for j_m, model in enumerate(models):\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=viz.DPI)\n",
    "    tmp_all_recall = []\n",
    "    tmp_all_precision = []\n",
    "    tmp_all_mean_iou = []\n",
    "    for k_ax, seed_id_for_f1vsiou in enumerate(seeds_to_show):\n",
    "        # ---------------- Compute performance\n",
    "        pre_vs_iou_subject_dict = {}\n",
    "        rec_vs_iou_subject_dict = {}\n",
    "        mean_iou_subject_dict = {}\n",
    "        for set_name in set_list:\n",
    "            print('Processing %s' % set_name, flush=True)\n",
    "            # Prepare expert labels\n",
    "            data_inference = FeederDataset(\n",
    "                dataset, ids_dict[seed_id_for_f1vsiou][set_name], task_mode, which_expert)\n",
    "            this_ids = data_inference.get_ids()\n",
    "            this_events_list = data_inference.get_stamps()\n",
    "            # Prepare model predictions\n",
    "            prediction_obj = predictions_dict[model['ckpt']][seed_id_for_f1vsiou][set_name]\n",
    "            prediction_obj.set_probability_threshold(OPTIMAL_THR_FOR_CKPT_DICT[model['ckpt']][seed_id_for_f1vsiou])\n",
    "            this_detections_list = prediction_obj.get_stamps()\n",
    "            for i, single_id in enumerate(this_ids):\n",
    "                single_events = this_events_list[i]\n",
    "                single_detections = this_detections_list[i]\n",
    "                this_iou_matching, _ = metrics.matching(single_events, single_detections)\n",
    "                this_mean_iou = np.mean(this_iou_matching[this_iou_matching > 0])\n",
    "                this_precision = metrics.metric_vs_iou(\n",
    "                    single_events, single_detections, iou_curve_axis, metric_name=constants.PRECISION, iou_matching=this_iou_matching)\n",
    "                this_recall = metrics.metric_vs_iou(\n",
    "                    single_events, single_detections, iou_curve_axis, metric_name=constants.RECALL, iou_matching=this_iou_matching)\n",
    "                pre_vs_iou_subject_dict[single_id] = this_precision\n",
    "                rec_vs_iou_subject_dict[single_id] = this_recall\n",
    "                mean_iou_subject_dict[single_id] = this_mean_iou\n",
    "        print('Done', flush=True)\n",
    "\n",
    "        # -------------------- P L O T ----------------------    \n",
    "\n",
    "        for set_name in set_list:\n",
    "            for i, single_id in enumerate(ids_dict[seed_id_for_f1vsiou][set_name]):\n",
    "                if single_id in skip_subjects:\n",
    "                    continue\n",
    "                this_rec = rec_vs_iou_subject_dict[single_id][iou_idx]\n",
    "                this_pre = pre_vs_iou_subject_dict[single_id][iou_idx]\n",
    "                this_iou = mean_iou_subject_dict[single_id]\n",
    "                tmp_all_recall.append(this_rec)\n",
    "                tmp_all_precision.append(this_pre)\n",
    "                tmp_all_mean_iou.append(this_iou)\n",
    "                if i == 0:\n",
    "                    label = 'Split %d' % seed_id_for_f1vsiou\n",
    "                else:\n",
    "                    label = None\n",
    "                ax.plot(\n",
    "                    this_rec, this_pre, color=color_dict[set_name][seed_id_for_f1vsiou], \n",
    "                    marker='o', markersize=markersize_model, label=label, linestyle='None')\n",
    "                if show_subject_id:\n",
    "                    ax.annotate(\n",
    "                        single_id, (this_rec, this_pre), \n",
    "                        horizontalalignment=\"center\", verticalalignment=\"center\", fontsize=4, color=\"w\")\n",
    "    tmp_all_precision = np.array(tmp_all_precision)\n",
    "    tmp_all_recall = np.array(tmp_all_recall)\n",
    "    tmp_all_f1_score = 2 * tmp_all_precision * tmp_all_recall / (tmp_all_precision + tmp_all_recall)\n",
    "    print(\"%s: Precision %1.1f \\u00B1 %1.1f -- Recall %1.1f \\u00B1 %1.1f -- F1-score %1.1f \\u00B1 %1.1f\" % (\n",
    "        model['name'], 100 * np.mean(tmp_all_precision), 100 * np.std(tmp_all_precision),\n",
    "        100 * np.mean(tmp_all_recall), 100 * np.std(tmp_all_recall),\n",
    "        100 * np.mean(tmp_all_f1_score), 100 * np.std(tmp_all_f1_score),\n",
    "    ))\n",
    "    \n",
    "    perf_str = \"F1: %1.1f\\u00B1%1.1f, IoU: %1.1f\\u00B1%1.1f\\nP: %1.1f\\u00B1%1.1f, R: %1.1f\\u00B1%1.1f\" % (\n",
    "        100 * np.mean(tmp_all_f1_score), 100 * np.std(tmp_all_f1_score),\n",
    "        100 * np.mean(tmp_all_mean_iou), 100 * np.std(tmp_all_mean_iou),\n",
    "        100 * np.mean(tmp_all_precision), 100 * np.std(tmp_all_precision),\n",
    "        100 * np.mean(tmp_all_recall), 100 * np.std(tmp_all_recall),\n",
    "        \n",
    "    )\n",
    "    ax.plot([0, 1], [0, 1], zorder=1, linewidth=1, color=viz.GREY_COLORS[4])\n",
    "    ax.set_title('%s\\nValidation, %s\\n%s' % (model['name'], result_id, perf_str), fontsize=9)\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_yticks(axis_markers)\n",
    "    ax.set_xticks(axis_markers)\n",
    "    if show_grid:\n",
    "        ax.set_xticks(np.arange(0, 1, 0.1), minor=True)\n",
    "        ax.set_yticks(np.arange(0, 1, 0.1), minor=True)\n",
    "        ax.grid(which=\"minor\")\n",
    "    if show_quadrants:\n",
    "        ax.axhline(0.5, color=viz.GREY_COLORS[5], linewidth=2)\n",
    "        ax.axvline(0.5, color=viz.GREY_COLORS[5], linewidth=2)\n",
    "    if show_desired_attractor:\n",
    "        ax.fill_between([0.80, 0.9], 0.8, 0.9, facecolor=viz.GREY_COLORS[2], zorder=1)\n",
    "    if show_mean:\n",
    "        ax.plot(\n",
    "            np.mean(tmp_all_recall), np.mean(tmp_all_precision), \n",
    "            marker='o', markersize=markersize_model/2, linestyle=\"None\",\n",
    "            color=viz.GREY_COLORS[6]\n",
    "        )\n",
    "    ax.tick_params(labelsize=8.5) \n",
    "    ax.set_ylabel('Precision (IoU>%1.1f)' % iou_to_show, fontsize=9)\n",
    "    ax.set_xlabel('Recall (IoU>%1.1f)' % iou_to_show, fontsize=9)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.legend(loc='lower left', fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    if save_figs:\n",
    "        plt.savefig(\"pr_%s_seeds.png\" % model['code_name'], dpi=200, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# more stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_seed = 3\n",
    "set_name = 'val'\n",
    "\n",
    "val_ids = ids_dict[chosen_seed][set_name]\n",
    "subset_data = FeederDataset(dataset, val_ids, task_mode, which_expert=which_expert)\n",
    "events = subset_data.get_stamps()\n",
    "signals = subset_data.get_signals(normalize_clip=False)\n",
    "\n",
    "cmp_opt_thr = []\n",
    "cmp_preds = []\n",
    "cmp_dets = []\n",
    "cmp_probas = []\n",
    "for model in models:\n",
    "    t_opt_thr = OPTIMAL_THR_FOR_CKPT_DICT[model['ckpt']][chosen_seed]\n",
    "    t_preds = predictions_dict[model['ckpt']][chosen_seed][set_name]\n",
    "    t_preds.set_probability_threshold(t_opt_thr)\n",
    "    t_dets = t_preds.get_stamps()\n",
    "    t_probas = t_preds.get_probabilities()\n",
    "    cmp_opt_thr.append(t_opt_thr)\n",
    "    cmp_preds.append(t_preds)\n",
    "    cmp_dets.append(t_dets)\n",
    "    cmp_probas.append(t_probas)\n",
    "\n",
    "matching_data_all = {}\n",
    "for i, single_id in enumerate(val_ids):  \n",
    "    # Matching with expert\n",
    "    for j, s_dets in enumerate(cmp_dets):\n",
    "        s_key = '%s_vs_exp' % models[j]['code_name']\n",
    "        if i == 0:\n",
    "            matching_data_all[s_key] = []\n",
    "        s_iou_matching, s_idx_matching = metrics.matching(events[i], s_dets[i])\n",
    "        matching_data_all[s_key].append({'iou': s_iou_matching, 'idx': s_idx_matching})\n",
    "    # Matching between models\n",
    "    for j_1, s_dets_1 in enumerate(cmp_dets):\n",
    "        for j_2, s_dets_2 in enumerate(cmp_dets):\n",
    "            if j_2<=j_1:\n",
    "                continue\n",
    "            s_key = '%s_vs_%s' % (models[j_2]['code_name'], models[j_1]['code_name'])\n",
    "            if i == 0:\n",
    "                matching_data_all[s_key] = []\n",
    "            s_iou_matching, s_idx_matching = metrics.matching(s_dets_1[i], s_dets_2[i])\n",
    "            matching_data_all[s_key].append({'iou': s_iou_matching, 'idx': s_idx_matching})\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Escalares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desempeño por sujeto a IoU 0.2\n",
    "iou_thr = 0.2\n",
    "f = open('metrics_seed%d.txt' % chosen_seed, 'w')\n",
    "print('Database: %s, Expert: %d' % (dataset_name, which_expert), file=f)\n",
    "print('Seed %d' % chosen_seed, file=f)\n",
    "for i, single_id in enumerate(val_ids):\n",
    "    n_events = events[i].shape[0]\n",
    "    print(\"\", file=f)\n",
    "    print('Subject %02d (%d events)' % (single_id, n_events), file=f)\n",
    "    for j, model in enumerate(models):\n",
    "        print(\"\", file=f)\n",
    "        print('Report for %s (IoU >= %1.1f)' % (model['name'], iou_thr), file=f)\n",
    "        n_detections = cmp_dets[j][i].shape[0]\n",
    "        s_key = '%s_vs_exp' % model['code_name']        \n",
    "        iou_match = matching_data_all[s_key][i]['iou'][matching_data_all[s_key][i]['idx'] != -1]    \n",
    "        tp = np.sum((iou_match >= iou_thr).astype(int))\n",
    "        fp = n_detections - tp\n",
    "        fn = n_events - tp\n",
    "        precision = 100 * tp / n_detections\n",
    "        recall = 100 * tp / n_events\n",
    "        f1_score = 100 * 2 * tp / (n_detections + n_events)\n",
    "        print('TP %03d - FP %03d - FN %03d' % (tp, fp, fn), file=f)\n",
    "        print('F1 %1.1f - Precision %1.1f - Recall %1.1f' % (f1_score, precision, recall), file=f)\n",
    "        mean_iou = 100 * iou_match.mean()\n",
    "        low_iqr = 100 * np.percentile(iou_match, 25)\n",
    "        high_iqr = 100 * np.percentile(iou_match, 75)\n",
    "        print('IoU of Matchings %1.1f [%1.1f - %1.1f]' % (mean_iou, low_iqr, high_iqr), file=f)\n",
    "f.close()\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_durations(data_x, data_y, idx_matching):\n",
    "    matched_real_idx = np.where(idx_matching > -1)[0]\n",
    "    matched_det_idx = idx_matching[idx_matching > -1]\n",
    "    matched_real_event = data_x[matched_real_idx]\n",
    "    matched_det_event = data_y[matched_det_idx]\n",
    "    matched_real_dur = matched_real_event[:, 1] - matched_real_event[:, 0]\n",
    "    matched_det_dur = matched_det_event[:, 1] - matched_det_event[:, 0]\n",
    "    return matched_real_dur, matched_det_dur\n",
    "\n",
    "def linear_regression(durations_x, durations_y, min_dur, max_dur, ax):\n",
    "    durations_x = durations_x.reshape(-1, 1)\n",
    "    # reg = LinearRegression().fit(durations_x, durations_y)\n",
    "    reg = HuberRegressor().fit(durations_x, durations_y)\n",
    "    r2_score = reg.score(durations_x, durations_y)\n",
    "    x_reg = np.array([min_dur, max_dur]).reshape(-1, 1)\n",
    "    y_reg = reg.predict(x_reg)\n",
    "    ax.plot(x_reg, y_reg, '--r', linewidth=1.1)\n",
    "    delta = 0.05 * (max_dur - min_dur)\n",
    "    ax.annotate(\n",
    "        'R2 = %1.2f' % r2_score, \n",
    "        xy=(min_dur + delta, max_dur - delta),  \n",
    "        textcoords='data',\n",
    "        horizontalalignment='left', verticalalignment='top', fontsize=8)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print('Database: %s, Expert: %d' % (dataset_name, which_expert))\n",
    "print('Seed %d' % chosen_seed)\n",
    "\n",
    "dpi = 120\n",
    "n_bins = 20\n",
    "min_dur = 0.3\n",
    "max_dur = 2.2\n",
    "alpha_scatter = 0.2\n",
    "ticks = [0.5, 1.0, 1.5, 2.0]\n",
    "size_marker = 10\n",
    "\n",
    "x_bins = np.linspace(min_dur, max_dur, n_bins, endpoint=True)\n",
    "y_bins = np.linspace(min_dur, max_dur, n_bins, endpoint=True)\n",
    "x_centers = x_bins[:-1] + x_bins[1]/2 - x_bins[0]/2\n",
    "y_centers = y_bins[:-1] + y_bins[1]/2 - y_bins[0]/2\n",
    "xv, yv = np.meshgrid(x_centers, y_centers)\n",
    "\n",
    "# Models versus expert: SCATTERPLOT\n",
    "n_models = len(models)\n",
    "fig, ax = plt.subplots(n_models, 3, figsize=(5, 2 + 1.5*(n_models-1)), dpi=dpi)\n",
    "for j, model in enumerate(models):\n",
    "    ax[j, 0].set_ylabel(model['name'], fontsize=viz.FONTSIZE_GENERAL)\n",
    "    for i, single_id in enumerate(val_ids):\n",
    "        ax[0, i].set_title('Subject %02d' % single_id, fontsize=10)\n",
    "        s_key = '%s_vs_exp' % model['code_name']\n",
    "        dur_x, dur_y = find_durations(events[i], cmp_dets[j][i], matching_data_all[s_key][i]['idx'])\n",
    "        dur_x, dur_y = dur_x / fs, dur_y / fs\n",
    "        ax[j, i].scatter(dur_x, dur_y, alpha=alpha_scatter, color=viz.PALETTE['blue'], s=size_marker)        \n",
    "        ax[j, i] = linear_regression(dur_x, dur_y, min_dur, max_dur, ax[j, i])\n",
    "        if i > 0:\n",
    "            ax[j, i].set_yticklabels([])\n",
    "        if j == n_models-1:\n",
    "            ax[j, i].set_xlabel('Expert', fontsize=viz.FONTSIZE_GENERAL)\n",
    "        else:\n",
    "            ax[j, i].set_xticklabels([])\n",
    "for s_ax in ax.flatten():   \n",
    "    s_ax.set_xlim([min_dur, max_dur])\n",
    "    s_ax.set_ylim([min_dur, max_dur])\n",
    "    s_ax.set_yticks(ticks)\n",
    "    s_ax.set_xticks(ticks)\n",
    "    s_ax.plot(\n",
    "        [min_dur, max_dur], [min_dur, max_dur],\n",
    "        linestyle='-', color=viz.GREY_COLORS[6], zorder=10, linewidth=1)\n",
    "    s_ax.tick_params(labelsize=viz.FONTSIZE_GENERAL)\n",
    "    s_ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.text(\n",
    "    x=0.03, y=1.0, fontsize=10, \n",
    "    s='Validation Set Seed %d (%s)' % (\n",
    "        chosen_seed, result_id), \n",
    "    ha=\"left\", transform=fig.transFigure)\n",
    "if save_figs:\n",
    "    plt.savefig(\"dur_all_vs_exp_seed%d_scat.png\" % (chosen_seed), dpi=200, bbox_inches=\"tight\", pad_inches=0.05)\n",
    "plt.show()\n",
    "\n",
    "# Models versus expert: HISTOGRAM\n",
    "n_models = len(models)\n",
    "fig, ax = plt.subplots(n_models, 3, figsize=(5, 2 + 1.5*(n_models-1)), dpi=dpi)\n",
    "for j, model in enumerate(models):\n",
    "    ax[j, 0].set_ylabel(model['name'], fontsize=viz.FONTSIZE_GENERAL)\n",
    "    s_key = '%s_vs_exp' % model['code_name']\n",
    "    for i, single_id in enumerate(val_ids):\n",
    "        ax[0, i].set_title('Subject %02d' % single_id, fontsize=10)\n",
    "        dur_x, dur_y = find_durations(events[i], cmp_dets[j][i], matching_data_all[s_key][i]['idx'])\n",
    "        dur_x, dur_y = dur_x / fs, dur_y / fs\n",
    "        hist, _, _ = np.histogram2d(dur_x, dur_y, bins=[x_bins, y_bins], density=True)\n",
    "        hist = hist.T\n",
    "        ax[j, i].hist2d(xv.flatten(), yv.flatten(), bins=[x_bins, y_bins], weights=hist.flatten(), cmap='viridis')\n",
    "        if i > 0:\n",
    "            ax[j, i].set_yticklabels([])\n",
    "        if j == n_models-1:\n",
    "            ax[j, i].set_xlabel('Expert', fontsize=viz.FONTSIZE_GENERAL)\n",
    "        else:\n",
    "            ax[j, i].set_xticklabels([])\n",
    "for s_ax in ax.flatten():   \n",
    "    s_ax.set_xlim([min_dur, max_dur])\n",
    "    s_ax.set_ylim([min_dur, max_dur])\n",
    "    s_ax.set_yticks(ticks)\n",
    "    s_ax.set_xticks(ticks)\n",
    "    s_ax.plot(\n",
    "        [min_dur, max_dur], [min_dur, max_dur],\n",
    "        linestyle='-', color=viz.GREY_COLORS[6], zorder=10, linewidth=1)\n",
    "    s_ax.tick_params(labelsize=viz.FONTSIZE_GENERAL)\n",
    "    s_ax.set_aspect('equal')\n",
    "plt.tight_layout()\n",
    "plt.text(\n",
    "    x=0.03, y=1.0, fontsize=10, \n",
    "    s='Validation Set Seed %d (%s)' % (\n",
    "        chosen_seed, result_id), \n",
    "    ha=\"left\", transform=fig.transFigure)\n",
    "if save_figs:\n",
    "    plt.savefig(\"dur_all_vs_exp_seed%d_hist.png\" % (chosen_seed), dpi=200, bbox_inches=\"tight\", pad_inches=0.05)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Models versus models: SCATTERPLOT\n",
    "for j_1, s_dets_1 in enumerate(cmp_dets):\n",
    "    for j_2, s_dets_2 in enumerate(cmp_dets):\n",
    "        if j_2<=j_1:\n",
    "            continue\n",
    "        s_key = '%s_vs_%s' % (models[j_2]['code_name'], models[j_1]['code_name'])\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(5, 2), dpi=dpi)\n",
    "        ax[0].set_ylabel(models[j_2]['name'], fontsize=viz.FONTSIZE_GENERAL)\n",
    "        for i, single_id in enumerate(val_ids):\n",
    "            ax[i].set_title('Subject %02d' % single_id, fontsize=10)\n",
    "            dur_x, dur_y = find_durations(s_dets_1[i], s_dets_2[i], matching_data_all[s_key][i]['idx'])\n",
    "            dur_x, dur_y = dur_x / fs, dur_y / fs\n",
    "            ax[i].scatter(dur_x, dur_y, alpha=alpha_scatter, color=viz.PALETTE['blue'], s=size_marker)\n",
    "            ax[i] = linear_regression(dur_x, dur_y, min_dur, max_dur, ax[i])\n",
    "            if i > 0:\n",
    "                ax[i].set_yticklabels([])\n",
    "            ax[i].set_xlabel(models[j_1]['name'], fontsize=viz.FONTSIZE_GENERAL)\n",
    "        for s_ax in ax.flatten():   \n",
    "            s_ax.set_xlim([min_dur, max_dur])\n",
    "            s_ax.set_ylim([min_dur, max_dur])\n",
    "            s_ax.set_yticks(ticks)\n",
    "            s_ax.set_xticks(ticks)\n",
    "            s_ax.plot(\n",
    "                [min_dur, max_dur], [min_dur, max_dur],\n",
    "                linestyle='-', color=viz.GREY_COLORS[6], zorder=10, linewidth=1)\n",
    "            s_ax.tick_params(labelsize=viz.FONTSIZE_GENERAL)\n",
    "            s_ax.set_aspect('equal')\n",
    "        plt.tight_layout()\n",
    "        plt.text(\n",
    "            x=0.03, y=1.0, fontsize=10, \n",
    "            s='Validation Set Seed %d (%s)' % (\n",
    "                chosen_seed, result_id), \n",
    "            ha=\"left\", transform=fig.transFigure)\n",
    "        if save_figs:\n",
    "            plt.savefig(\"dur_%s_vs_%s_seed%d_scat.png\" % (\n",
    "                    models[j_2]['code_name'], models[j_1]['code_name'], chosen_seed\n",
    "                ), dpi=200, bbox_inches=\"tight\", pad_inches=0.05)\n",
    "        plt.show()\n",
    "        \n",
    "# Models versus models: HISTOGRAM\n",
    "for j_1, s_dets_1 in enumerate(cmp_dets):\n",
    "    for j_2, s_dets_2 in enumerate(cmp_dets):\n",
    "        if j_2<=j_1:\n",
    "            continue\n",
    "        s_key = '%s_vs_%s' % (models[j_2]['code_name'], models[j_1]['code_name'])\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(5, 2), dpi=dpi)\n",
    "        ax[0].set_ylabel(models[j_2]['name'], fontsize=viz.FONTSIZE_GENERAL)\n",
    "        for i, single_id in enumerate(val_ids):\n",
    "            ax[i].set_title('Subject %02d' % single_id, fontsize=10)\n",
    "            dur_x, dur_y = find_durations(s_dets_1[i], s_dets_2[i], matching_data_all[s_key][i]['idx'])\n",
    "            dur_x, dur_y = dur_x / fs, dur_y / fs\n",
    "            hist, _, _ = np.histogram2d(dur_x, dur_y, bins=[x_bins, y_bins], density=True)\n",
    "            hist = hist.T\n",
    "            ax[i].hist2d(xv.flatten(), yv.flatten(), bins=[x_bins, y_bins], weights=hist.flatten(), cmap='viridis')\n",
    "            if i > 0:\n",
    "                ax[i].set_yticklabels([])\n",
    "            ax[i].set_xlabel(models[j_1]['name'], fontsize=viz.FONTSIZE_GENERAL)\n",
    "        for s_ax in ax.flatten():   \n",
    "            s_ax.set_xlim([min_dur, max_dur])\n",
    "            s_ax.set_ylim([min_dur, max_dur])\n",
    "            s_ax.set_yticks(ticks)\n",
    "            s_ax.set_xticks(ticks)\n",
    "            s_ax.plot(\n",
    "                [min_dur, max_dur], [min_dur, max_dur],\n",
    "                linestyle='-', color=viz.GREY_COLORS[6], zorder=10, linewidth=1)\n",
    "            s_ax.tick_params(labelsize=viz.FONTSIZE_GENERAL)\n",
    "            s_ax.set_aspect('equal')\n",
    "        plt.tight_layout()\n",
    "        plt.text(\n",
    "            x=0.03, y=1.0, fontsize=10, \n",
    "            s='Validation Set Seed %d (%s)' % (\n",
    "                chosen_seed, result_id), \n",
    "            ha=\"left\", transform=fig.transFigure)\n",
    "        if save_figs:\n",
    "            plt.savefig(\"dur_%s_vs_%s_seed%d_hist.png\" % (\n",
    "                    models[j_2]['code_name'], models[j_1]['code_name'], chosen_seed\n",
    "                ), dpi=200, bbox_inches=\"tight\", pad_inches=0.05)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance as a function of threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "color_list = [viz.PALETTE['red'], viz.PALETTE['blue'], viz.PALETTE['green'], viz.PALETTE['dark']]\n",
    "iou_to_show = 0.2\n",
    "n_points = 30\n",
    "min_proba_factor = 0.1\n",
    "max_proba_factor = 0.9\n",
    "\n",
    "# Plot f1 vs iou specs\n",
    "smaller_plot = False\n",
    "external_legend = True\n",
    "show_iou_iqr = True\n",
    "figsize = (4, 4)\n",
    "\n",
    "for j_m, model in enumerate(models):\n",
    "\n",
    "    title = '%s\\n(%s)-%s-Seed%d' % (model['name'], result_id, set_name.upper(), chosen_seed)\n",
    "\n",
    "    # -------------------- P L O T ----------------------  \n",
    "    print('Database: %s, Expert: %d' % (dataset_name, which_expert))\n",
    "    print(title)\n",
    "    this_dpi = 100 if smaller_plot else viz.DPI\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize, dpi=this_dpi)\n",
    "    probas = cmp_preds[j_m].get_probabilities()\n",
    "    max_valid = np.min([s_p.max() for s_p in probas])\n",
    "    min_valid = np.max([s_p[s_p>0].min() for s_p in probas])\n",
    "    min_proba = min_valid + min_proba_factor * (max_valid - min_valid)\n",
    "    max_proba = min_valid + max_proba_factor * (max_valid - min_valid)\n",
    "    dense_thr = np.linspace(max([min_proba, 0.01]), min([max_proba, 0.99]), n_points)\n",
    "    f1_evol = np.zeros((len(dense_thr), len(val_ids)))\n",
    "    prec_evol = np.zeros((len(dense_thr), len(val_ids)))\n",
    "    rec_evol = np.zeros((len(dense_thr), len(val_ids)))\n",
    "    iou_evol = np.zeros((len(dense_thr), len(val_ids)))\n",
    "    iou_evol_low_iqr = np.zeros((len(dense_thr), len(val_ids)))\n",
    "    iou_evol_high_iqr = np.zeros((len(dense_thr), len(val_ids)))\n",
    "    for j, s_thr in enumerate(dense_thr):\n",
    "        cmp_preds[j_m].set_probability_threshold(s_thr)\n",
    "        dets = cmp_preds[j_m].get_stamps()\n",
    "        for i, single_id in enumerate(val_ids):\n",
    "            s_events = events[i]\n",
    "            s_dets = dets[i]\n",
    "            s_iou_matching, s_idx_matching = metrics.matching(s_events, s_dets)\n",
    "            iou_matching = s_iou_matching[s_idx_matching != -1]\n",
    "            n_detections = s_dets.shape[0]\n",
    "            n_events = s_events.shape[0]\n",
    "            # Now, give credit only for iou >= iou_thr\n",
    "            tp = np.sum((iou_matching >= iou_to_show).astype(int))\n",
    "            fp = n_detections - tp\n",
    "            fn = n_events - tp\n",
    "            prec_evol[j, i] = tp / n_detections\n",
    "            rec_evol[j, i] = tp / n_events\n",
    "            f1_evol[j, i] = 2 * tp / (n_detections + n_events)\n",
    "            iou_evol[j, i] = np.mean(iou_matching)\n",
    "            iou_evol_low_iqr[j, i] = np.percentile(iou_matching, 25)\n",
    "            iou_evol_high_iqr[j, i] = np.percentile(iou_matching, 75)\n",
    "    # Mean set\n",
    "    f1_evol = f1_evol.mean(axis=1)\n",
    "    prec_evol = prec_evol.mean(axis=1)\n",
    "    rec_evol = rec_evol.mean(axis=1)\n",
    "    iou_evol = iou_evol.mean(axis=1)\n",
    "    iou_evol_low_iqr = iou_evol_low_iqr.mean(axis=1)\n",
    "    iou_evol_high_iqr = iou_evol_high_iqr.mean(axis=1)\n",
    "\n",
    "    # Plots\n",
    "    linewidth = 1.5\n",
    "    ax.plot(dense_thr, f1_evol, label='F1-score', linewidth=linewidth, color=color_list[0], zorder=20)\n",
    "    ax.plot(dense_thr, prec_evol, label='Precision', linewidth=linewidth, color=color_list[1], zorder=20)\n",
    "    ax.plot(dense_thr, rec_evol, label='Recall', linewidth=linewidth, color=color_list[2], zorder=20)\n",
    "    ax.plot(dense_thr, iou_evol, label='Mean IoU', linewidth=linewidth, color=color_list[3], zorder=20)\n",
    "    if show_iou_iqr:\n",
    "        ax.fill_between(\n",
    "            dense_thr,\n",
    "            iou_evol_low_iqr,\n",
    "            iou_evol_high_iqr,\n",
    "            facecolor=color_list[3], alpha=0.2\n",
    "        )\n",
    "\n",
    "    ax.set_title(title, fontsize=9, loc='center')\n",
    "\n",
    "    ax.axvline(\n",
    "        cmp_opt_thr[j_m],\n",
    "        linestyle='-',\n",
    "        color=viz.GREY_COLORS[4],\n",
    "        zorder=1,\n",
    "        linewidth=1)\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.0])\n",
    "    ax.set_xticks(np.linspace(0, 1, 6))\n",
    "    ax.set_xticks(np.linspace(0, 1, 11), minor=True)\n",
    "    ax.set_yticks(np.linspace(0.2, 1, 5))\n",
    "    ax.set_yticks(np.linspace(0, 1, 11), minor=True)\n",
    "    ax.tick_params(labelsize=viz.FONTSIZE_GENERAL)\n",
    "    ax.set_xlabel('Output Threshold', fontsize=viz.FONTSIZE_GENERAL)\n",
    "    ax.yaxis.grid(which='both')\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.tick_params(axis='y', which='both', length=0)\n",
    "    lg = plotter.format_legend(ax, external_legend)\n",
    "    lg.set_title(\"IoU > %1.2f\" % iou_to_show)\n",
    "    lg.get_title().set_fontsize('8')\n",
    "    if save_figs:\n",
    "        plt.savefig(\n",
    "            \"thr_effect_%s_seed%d.png\" % (model['code_name'], chosen_seed), \n",
    "            dpi=200, bbox_extra_artists=(lg,), bbox_inches=\"tight\", pad_inches=0.01)\n",
    "    plt.show()\n",
    "    cmp_preds[j_m].set_probability_threshold(cmp_opt_thr[j_m])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F1 vs IoU between models (agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f = open('agreement_seed%d.txt' % chosen_seed, 'w')\n",
    "color_list = [viz.PALETTE['red'], viz.PALETTE['blue'], viz.PALETTE['green']]\n",
    "\n",
    "# Plot f1 vs iou specs\n",
    "smaller_plot = False\n",
    "external_legend = True\n",
    "iou_thr_to_show = 0.2\n",
    "figsize = (4, 4)\n",
    "# -------------------- P L O T ----------------------  \n",
    "print('Database: %s, Expert: %d' % (dataset_name, which_expert), file=f)\n",
    "print('IoU to show: %1.1f' % iou_thr_to_show, file=f)\n",
    "this_dpi = 100 if smaller_plot else viz.DPI\n",
    "dense_iou = misc.custom_linspace(0.01, 0.99, 0.01)\n",
    "\n",
    "for j_1, s_dets_1 in enumerate(cmp_dets):\n",
    "    for j_2, s_dets_2 in enumerate(cmp_dets):\n",
    "        if j_2<=j_1:\n",
    "            continue\n",
    "        print(\"\", file=f)\n",
    "        title = '%s wrt %s (%s)' % (models[j_2]['name'], models[j_1]['name'], result_id)\n",
    "        print(title, file=f)\n",
    "        fig, ax = plt.subplots(1, 1, figsize=figsize, dpi=this_dpi)\n",
    "        s_key = '%s_vs_%s' % (models[j_2]['code_name'], models[j_1]['code_name'])\n",
    "        for i, single_id in enumerate(val_ids):\n",
    "            s_f1_curve = []\n",
    "            iou_matching = matching_data_all[s_key][i]['iou'][matching_data_all[s_key][i]['idx'] != -1]\n",
    "            n_detections = cmp_dets[j_2][i].shape[0]\n",
    "            n_events = cmp_dets[j_1][i].shape[0]\n",
    "            for single_iou in dense_iou:\n",
    "                # Now, give credit only for iou >= iou_thr\n",
    "                tp = np.sum((iou_matching >= single_iou).astype(int))\n",
    "                fp = n_detections - tp\n",
    "                fn = n_events - tp\n",
    "                precision = tp / n_detections\n",
    "                recall = tp / n_events\n",
    "                f1_score = 2 * tp / (n_detections + n_events)\n",
    "                s_f1_curve.append(f1_score)\n",
    "                if np.abs(single_iou - 0.2) <= 1e-4:\n",
    "                    print(\"\", file=f)\n",
    "                    print('Subject %02d at IoU >= 0.2' % single_id, file=f)\n",
    "                    print('F1 %1.1f - Precision %1.1f - Recall %1.1f' % (\n",
    "                        f1_score * 100, precision * 100, recall * 100\n",
    "                    ), file=f)\n",
    "                    mean_iou = 100 * iou_matching.mean()\n",
    "                    low_iqr = 100 * np.percentile(iou_matching, 25)\n",
    "                    high_iqr = 100 * np.percentile(iou_matching, 75)\n",
    "                    print('IoU of Matchings %1.1f [%1.1f - %1.1f]' % (mean_iou, low_iqr, high_iqr), file=f)\n",
    "                    print('Min IoU of matching: %1.1f' % (100 * np.min(iou_matching)), file=f)\n",
    "            this_color = color_list[i]\n",
    "            ax.plot(\n",
    "                dense_iou, s_f1_curve, linewidth=viz.LINEWIDTH, zorder=10, \n",
    "                label='Subject %02d' % single_id, color=this_color\n",
    "            )\n",
    "\n",
    "        ax.set_title(title, fontsize=viz.FONTSIZE_TITLE, loc='center')\n",
    "        ax = plotter.format_metric_vs_iou_plot(ax, 'F1-score', iou_thr_to_show)\n",
    "        lg = plotter.format_legend(ax, external_legend)\n",
    "        lg.set_title(\"Val Set\\nSeed %d\" % chosen_seed)\n",
    "        lg.get_title().set_fontsize('8')\n",
    "        if save_figs:\n",
    "            plt.savefig(\n",
    "                \"f1_agree_%s_vs_%s_seed%d.png\" % (models[j_2]['code_name'], models[j_1]['code_name'], chosen_seed), \n",
    "                dpi=200, bbox_extra_artists=(lg,), bbox_inches=\"tight\", pad_inches=0.01)\n",
    "        plt.show()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
