{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pyedflib\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_state = {\n",
    "    12: '/home/ntapia/projects/repos/sleep-rnn/resources/datasets/mass/label/state/01-02-0012 Base.edf',\n",
    "    13: '/home/ntapia/projects/repos/sleep-rnn/resources/datasets/mass/label/state/01-02-0013 Base.edf',\n",
    "    19: '/home/ntapia/projects/repos/sleep-rnn/resources/datasets/mass/label/state/01-02-0019 Base.edf',\n",
    "}\n",
    "filename_signal = {\n",
    "    12: '/home/ntapia/projects/repos/sleep-rnn/resources/datasets/mass/register/01-02-0012 PSG.edf',\n",
    "    13: '/home/ntapia/projects/repos/sleep-rnn/resources/datasets/mass/register/01-02-0013 PSG.edf',\n",
    "    19: '/home/ntapia/projects/repos/sleep-rnn/resources/datasets/mass/register/01-02-0019 PSG.edf',\n",
    "}\n",
    "\n",
    "fs = 200\n",
    "page_size = 4000\n",
    "page_duration = 20\n",
    "state_ids = np.array(['1', '2', '3', '4', 'R', 'W', '?'])\n",
    "unknown_id = '?'  # Character for unknown state in hypnogram\n",
    "n2_id = '2'  # Character for N2 identification in hypnogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = 19\n",
    "\n",
    "with pyedflib.EdfReader(filename_state[subject_id]) as file:\n",
    "    annotations = file.readAnnotations()\n",
    "with pyedflib.EdfReader(filename_signal[subject_id]) as file:\n",
    "    channel_names = file.getSignalLabels()\n",
    "    channel_to_extract = channel_names.index('EEG C3-CLE')\n",
    "    signal = file.readSignal(channel_to_extract)\n",
    "    signal_length = signal.size\n",
    "    signal_length = int(signal_length * fs / file.samplefrequency(channel_to_extract))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total pages not necessarily equal to total_annots\n",
    "total_pages = int(np.ceil(signal_length / page_size))\n",
    "\n",
    "onsets = np.array(annotations[0])\n",
    "durations = np.round(np.array(annotations[1]))\n",
    "stages_str = annotations[2]\n",
    "# keep only 20s durations\n",
    "valid_idx = (durations == page_duration)\n",
    "onsets = onsets[valid_idx]\n",
    "onsets_pages = np.floor(onsets / page_duration).astype(np.int32)\n",
    "stages_str = stages_str[valid_idx]\n",
    "stages_char = [single_annot[-1] for single_annot in stages_str]\n",
    "\n",
    "# Build complete hypnogram\n",
    "total_annots = len(stages_char)\n",
    "\n",
    "not_unkown_ids = [\n",
    "    state_id for state_id in state_ids\n",
    "    if state_id != unknown_id]\n",
    "not_unkown_state_dict = {}\n",
    "for state_id in not_unkown_ids:\n",
    "    state_idx = np.where(\n",
    "        [stages_char[i] == state_id for i in range(total_annots)])[0]\n",
    "    not_unkown_state_dict[state_id] = onsets_pages[state_idx]\n",
    "hypnogram = []\n",
    "for page in range(total_pages):\n",
    "    state_not_found = True\n",
    "    for state_id in not_unkown_ids:\n",
    "        if page in not_unkown_state_dict[state_id] and state_not_found:\n",
    "            hypnogram.append(state_id)\n",
    "            state_not_found = False\n",
    "    if state_not_found:\n",
    "        hypnogram.append(unknown_id)\n",
    "hypnogram = np.asarray(hypnogram)\n",
    "\n",
    "# Extract N2 pages\n",
    "n2_pages = np.where(hypnogram == n2_id)[0]\n",
    "# Drop first, last and second to last page of the whole registers\n",
    "# if they where selected.\n",
    "last_page = total_pages - 1\n",
    "n2_pages = n2_pages[\n",
    "    (n2_pages != 0)\n",
    "    & (n2_pages != last_page)\n",
    "    & (n2_pages != last_page - 1)]\n",
    "n2_pages = n2_pages.astype(np.int16)\n",
    "\n",
    "alternative_n2_pages = n2_pages\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# OLD CODE: (debuG)\n",
    "onsets = np.array(annotations[0])\n",
    "stages_str = annotations[2]\n",
    "stages_char = [single_annot[-1] for single_annot in stages_str]\n",
    "total_annots = len(stages_char)\n",
    "# Total pages not necessarily equal to total_annots\n",
    "total_pages = int(np.ceil(signal_length / page_size))\n",
    "n2_pages_onehot = np.zeros(total_pages, dtype=np.int32)\n",
    "for i in range(total_annots):\n",
    "    if stages_char[i] == n2_id:\n",
    "        page_idx = int(np.round(onsets[i] / page_duration))\n",
    "        if page_idx < total_pages:\n",
    "            n2_pages_onehot[page_idx] = 1\n",
    "n2_pages = np.where(n2_pages_onehot == 1)[0]\n",
    "# Drop first, last and second to last page of the whole registers\n",
    "# if they where selected.\n",
    "last_page = total_pages - 1\n",
    "n2_pages = n2_pages[\n",
    "    (n2_pages != 0)\n",
    "    & (n2_pages != last_page)\n",
    "    & (n2_pages != last_page - 1)]\n",
    "\n",
    "n2_pages = n2_pages.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63, 64, 65, 66, 67, 68, 76, 77, 78, 79])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(np.array(stages_char) == n2_id)[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stages_char[63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63.8544668"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onsets[63] / page_duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64, 65, 66, 67, 68, 69, 77, 78, 79, 80], dtype=int32)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n2_pages[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([63, 64, 65, 66, 67, 68, 76, 77, 78, 79], dtype=int16)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alternative_n2_pages[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
