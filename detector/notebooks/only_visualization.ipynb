{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import gridspec\n",
    "import pprint\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "detector_path = '..'\n",
    "results_path = os.path.join(detector_path, 'results')\n",
    "sys.path.append(detector_path)\n",
    "\n",
    "from utils import constants\n",
    "from utils import errors\n",
    "from sleep.mass import MASS\n",
    "from sleep.inta import INTA\n",
    "from sleep import postprocessing\n",
    "from sleep import data_ops\n",
    "from evaluation import metrics\n",
    "from evaluation import data_manipulation\n",
    "\n",
    "DPI = 100\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset mass with 15 patients.\n",
      "Train size: 11. Test size: 4\n",
      "Train subjects: \n",
      " [1, 3, 5, 7, 9, 10, 11, 14, 17, 18, 19]\n",
      "Test subjects: \n",
      " [2, 6, 12, 13]\n",
      "Loading from checkpoint... Loaded\n",
      "Loading train set and splitting train/val\n",
      "All Training set IDs: [1, 3, 5, 7, 9, 10, 11, 14, 17, 18, 19]\n",
      "Loading test set\n",
      "Testing set IDs: [2, 6, 12, 13]\n",
      "Loading signals and marks\n",
      "Loading pages\n",
      "Loading predictions from /home/ntapia/Projects/GitNico/ssdetection-rnn/detector/results/predictions_mass/20190408_bsf_train_mass/bsf/avg\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Best ones:\n",
    "# MASS: ckpt_folder = os.path.join('20190408_bsf_train_mass', 'bsf', 'avg'), thr=0.45\n",
    "# INTA: ckpt_folder = os.path.join('20190407_bsf_train_inta', 'bsf', 'avg'), thr=0.475\n",
    "\n",
    "# Select database\n",
    "dataset_name = constants.MASS_NAME\n",
    "# Select predictions ckpt folder\n",
    "ckpt_folder = os.path.join('20190408_bsf_train_mass', 'bsf', 'avg')\n",
    "thr = 0.45\n",
    "verbose = False\n",
    "\n",
    "# Load data\n",
    "\n",
    "# Marks are binary sequences for each page, 200 fs resolution\n",
    "errors.check_valid_value(\n",
    "    dataset_name, 'dataset_name',\n",
    "    [constants.MASS_NAME, constants.INTA_NAME])\n",
    "if dataset_name == constants.MASS_NAME:\n",
    "    dataset = MASS(load_checkpoint=True)\n",
    "else:\n",
    "    dataset = INTA(load_checkpoint=True)\n",
    "\n",
    "    # Get training set ids\n",
    "print('Loading train set and splitting train/val')\n",
    "all_train_ids = dataset.train_ids\n",
    "print('All Training set IDs:', all_train_ids)\n",
    "# Get test data\n",
    "print('Loading test set')\n",
    "test_ids = dataset.test_ids\n",
    "print('Testing set IDs:', test_ids)\n",
    "idx_dict = {'alltrain': train_ids, 'test': test_ids}\n",
    "\n",
    "# Get subjects data, with the expert used for training\n",
    "print('Loading signals and marks')\n",
    "# set_list = ['train', 'val', 'test']\n",
    "set_list = ['alltrain', 'test']\n",
    "x = {}\n",
    "y = {}\n",
    "pages = {}\n",
    "x['alltrain'], y['alltrain'] = dataset.get_subset_data(all_train_ids, which_expert=1, verbose=verbose)\n",
    "x['test'], y['test'] = dataset.get_subset_data(test_ids, which_expert=1, verbose=verbose)\n",
    "print('Loading pages')\n",
    "pages['alltrain'] = dataset.get_subset_pages(all_train_ids, verbose=verbose)\n",
    "pages['test'] = dataset.get_subset_pages(test_ids, verbose=verbose)\n",
    "\n",
    "# Load predictions (probability vectors for each page), 200/factor resolution (default factor 8)\n",
    "ckpt_path = os.path.abspath(os.path.join(results_path, 'predictions_%s' % dataset_name, ckpt_folder))\n",
    "print('Loading predictions from %s' % ckpt_path)\n",
    "y_pred = {}\n",
    "for set_name in set_list:\n",
    "    y_pred[set_name] = np.load(os.path.join(ckpt_path, 'y_pred_%s.npy' % set_name), allow_pickle=True)\n",
    "    # Keep only class 1 probability\n",
    "    y_pred[set_name] = [this_y_pred[..., 1] for this_y_pred in y_pred[set_name]]\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting ID 13, 818 N2 pages, Expert 2\n"
     ]
    }
   ],
   "source": [
    "subset_name = 'test'\n",
    "subject_id = 13\n",
    "\n",
    "# -----\n",
    "idx_subject = idx_dict[subset_name].index(subject_id)\n",
    "this_signal = x[subset_name][idx_subject]\n",
    "this_marks_1 = y[subset_name][idx_subject]\n",
    "this_n2_pages = pages[subset_name][idx_subject]\n",
    "this_prob = y_pred[subset_name][idx_subject]\n",
    "\n",
    "y_pred_thr = postprocessing.generate_mark_intervals(\n",
    "    y_pred[subset_name][idx_subject], pages[subset_name][idx_subject], 200//8, 200, thr=thr)\n",
    "y_pred_thr_seq = data_ops.inter2seq(y_pred_thr, 0, (pages[subset_name][idx_subject].max()+1)*200*20-1)\n",
    "# Now reshape into pages\n",
    "this_det = data_ops.extract_pages(y_pred_thr_seq, pages[subset_name][idx_subject], 200*20, border_size=0)\n",
    "\n",
    "if dataset_name == constants.MASS_NAME:\n",
    "    _, this_marks_2 = dataset.get_subject_data(subject_id, which_expert=2, verbose=True)\n",
    "    channel_name = 'C3-CLE'\n",
    "else:\n",
    "    channel_name = 'F4-C4'\n",
    "    \n",
    "# make a color map of fixed colors\n",
    "cmap = colors.ListedColormap(['white', '#c62828'])\n",
    "\n",
    "def plot_page(page_idx):\n",
    "    if dataset_name == constants.MASS_NAME:\n",
    "        fig = plt.figure(figsize=(10, 5), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(4, 1, height_ratios=[4, 1, 1, 1])\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(10, 4), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(3, 1, height_ratios=[4, 1, 1])\n",
    "    \n",
    "    page_idx = page_idx - 1\n",
    "    \n",
    "    segment_signal = this_signal[page_idx, :]\n",
    "    segment_marks_1 = this_marks_1[page_idx, :]\n",
    "    segment_prob = this_prob[page_idx, :]\n",
    "    segment_det = this_det[page_idx, :]\n",
    "    time_axis = np.arange(this_signal.shape[1]) / dataset.fs\n",
    "    \n",
    "    if dataset_name == constants.MASS_NAME:\n",
    "        segment_marks_2 = this_marks_2[page_idx, :]\n",
    "    \n",
    "    gs_idx = 0\n",
    "    \n",
    "    # Signal\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(time_axis, segment_signal, linewidth=1, color='#455a64')\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([0, 20])\n",
    "    ax.set_ylim([-8, 8])\n",
    "    ax.set_title('Subject %d (%s-%s). %s EEG channel. Page in record: %d (intervals of 0.5s are shown)' \n",
    "                 % (subject_id, dataset_name.upper(), subset_name.capitalize(), channel_name, this_n2_pages[page_idx]), fontsize=10)\n",
    "    ax.set_xticks([0, 5, 10, 15, 20])\n",
    "    ax.set_xticks(np.arange(0, 20, 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Expert mark\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.imshow(segment_marks_1[np.newaxis, :], interpolation=None, aspect='auto', cmap=cmap)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title('Expert ground truth (red indicates event)', fontsize=10)\n",
    "    \n",
    "    # Neural net\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(segment_prob, color='#c62828', linewidth=1.5)\n",
    "    ax.fill_between(np.arange(500), segment_det[::8], facecolor='k', alpha=0.3)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_ylim([-0.1, 1.1])\n",
    "    ax.set_xlim([0, 500])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticks([thr], minor=True)\n",
    "    ax.grid(b=True, axis='y', linewidth=1.5, which='minor')\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    ax.set_title('Model probability prediction (%1.2f threshold and postprocessed detections are shown)' % thr, fontsize=10)\n",
    "    \n",
    "    if dataset_name == constants.MASS_NAME:\n",
    "        ax = fig.add_subplot(gs[gs_idx])\n",
    "        ax.imshow(segment_marks_2[np.newaxis, :], interpolation=None, aspect='auto', cmap=cmap)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Second expert, not used for training (red indicates event)', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70fc33fe1b04e659ca13695f3dd0e11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, continuous_update=False, description='page_idx', max=818, min=1), Outâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.interact(\n",
    "    lambda page_idx: plot_page(page_idx),\n",
    "    page_idx=widgets.IntSlider(min=1,max=this_n2_pages.shape[0],step=1,value=1, continuous_update=False));"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
