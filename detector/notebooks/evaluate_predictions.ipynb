{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pprint\n",
    "import collections\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import gridspec\n",
    "import pprint\n",
    "from scipy.stats import gaussian_kde\n",
    "from tqdm import tqdm\n",
    "\n",
    "detector_path = '..'\n",
    "results_path = os.path.join(detector_path, 'results')\n",
    "sys.path.append(detector_path)\n",
    "\n",
    "from utils import constants\n",
    "from utils import errors\n",
    "from sleep.mass import MASS\n",
    "from sleep.mass_k import MASSK\n",
    "from sleep.inta import INTA\n",
    "from sleep import postprocessing\n",
    "from sleep import data_ops\n",
    "from evaluation import metrics\n",
    "from evaluation import data_manipulation\n",
    "\n",
    "SEED = 123\n",
    "DPI = 200\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load database and predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select database\n",
    "dataset_name = constants.MASSK_NAME\n",
    "# Select predictions ckpt folder\n",
    "\n",
    "# Best ones:\n",
    "# MASS: ckpt_folder = os.path.join('20190413_bsf_ss_using_angle_train_mass', 'bsf', 'avg'), thr 0.45\n",
    "# INTA: ckpt_folder = os.path.join('20190328_v2bn_fixed_inta_train_inta', 'bsf_avg'), thr 0.48\n",
    "# MASSK: ckpt_folder = os.path.join('20190413_bsf_kc_using_angle_train_massk', 'bsf', 'avg'), thr 0.48\n",
    "\n",
    "# ckpt_folder = os.path.join('20190414_bsf_kc_whole_night_train_massk', 'seed0')\n",
    "ckpt_folder = os.path.join('20190413_bsf_kc_using_angle_train_massk', 'bsf', 'avg')\n",
    "optimal_thr = 0.48\n",
    "whole_night = False\n",
    "verbose = False\n",
    "\n",
    "# Load data\n",
    "\n",
    "# Marks are binary sequences for each page, 200 fs resolution\n",
    "errors.check_valid_value(\n",
    "    dataset_name, 'dataset_name',\n",
    "    [constants.MASS_NAME, constants.INTA_NAME, constants.MASSK_NAME])\n",
    "if dataset_name == constants.MASS_NAME:\n",
    "    dataset = MASS(load_checkpoint=True)\n",
    "elif dataset_name == constants.INTA_NAME:\n",
    "    dataset = INTA(load_checkpoint=True)\n",
    "else:\n",
    "    dataset = MASSK(load_checkpoint=True)\n",
    "    \n",
    "    # Get training set ids\n",
    "print('Loading train set and splitting train/val')\n",
    "all_train_ids = dataset.train_ids\n",
    "# Split to form validation set\n",
    "train_ids, val_ids = data_manipulation.split_ids_list(\n",
    "    all_train_ids, seed=SEED)\n",
    "print('Training set IDs:', train_ids)\n",
    "print('Validation set IDs:', val_ids)\n",
    "# Get test data\n",
    "print('Loading test set')\n",
    "test_ids = dataset.test_ids\n",
    "print('Testing set IDs:', test_ids)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids, 'alltrain': all_train_ids}\n",
    "\n",
    "# Get subjects data, with the expert used for training\n",
    "print('Loading signals and marks')\n",
    "# set_list = ['train', 'val', 'test']\n",
    "set_list = ['alltrain', 'test']\n",
    "\n",
    "x = {}\n",
    "y = {}\n",
    "pages = {}\n",
    "x['alltrain'], y['alltrain'] = dataset.get_subset_data(all_train_ids, which_expert=1, verbose=verbose, whole_night=whole_night)\n",
    "x['train'], y['train'] = dataset.get_subset_data(train_ids, which_expert=1, verbose=verbose, whole_night=whole_night)\n",
    "x['val'], y['val'] = dataset.get_subset_data(val_ids, which_expert=1, verbose=verbose, whole_night=whole_night)\n",
    "x['test'], y['test'] = dataset.get_subset_data(test_ids, which_expert=1, verbose=verbose, whole_night=whole_night)\n",
    "print('Loading pages')\n",
    "pages['alltrain'] = dataset.get_subset_pages(all_train_ids, verbose=verbose, whole_night=whole_night)\n",
    "pages['train'] = dataset.get_subset_pages(train_ids, verbose=verbose, whole_night=whole_night)\n",
    "pages['val'] = dataset.get_subset_pages(val_ids, whole_night=whole_night)\n",
    "pages['test'] = dataset.get_subset_pages(test_ids, whole_night=whole_night)\n",
    "\n",
    "# Load predictions (probability vectors for each page), 200/factor resolution (default factor 8)\n",
    "ckpt_path = os.path.abspath(os.path.join(results_path, 'predictions_%s' % dataset_name, ckpt_folder))\n",
    "print('Loading predictions from %s' % ckpt_path)\n",
    "y_pred = {}\n",
    "\n",
    "if whole_night:\n",
    "    descriptor = '_whole_night_'\n",
    "else:\n",
    "    descriptor = '_'\n",
    "\n",
    "for set_name in set_list:\n",
    "    y_pred[set_name] = np.load(os.path.join(ckpt_path, 'y_pred%s%s.npy' % (descriptor, set_name)), allow_pickle=True)\n",
    "    # Keep only class 1 probability\n",
    "    y_pred[set_name] = [this_y_pred[..., 1] for this_y_pred in y_pred[set_name]]\n",
    "print('Done')\n",
    "\n",
    "if dataset_name == constants.MASSK_NAME:\n",
    "    # KC\n",
    "    min_separation = 0\n",
    "    min_duration = 0.3\n",
    "    max_duration = 4.0\n",
    "else:  \n",
    "    # SS\n",
    "    min_separation = 0.3\n",
    "    min_duration = 0.2\n",
    "    max_duration = 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare expert labels into marks\n",
    "print('Preparing labels... ', end='', flush=True)\n",
    "y_stamps = {}\n",
    "for set_name in set_list:\n",
    "    y_stamps[set_name] = postprocessing.generate_mark_intervals_with_list(\n",
    "        y[set_name], pages[set_name], 200, 200, thr=None, postprocess=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load second expert in mass\n",
    "y2 = {}\n",
    "if dataset_name == constants.MASS_NAME:\n",
    "    _, y2['train'] = dataset.get_subset_data(train_ids, which_expert=2, verbose=verbose)\n",
    "    _, y2['val'] = dataset.get_subset_data(val_ids, which_expert=2, verbose=verbose)\n",
    "    _, y2['test'] = dataset.get_subset_data(test_ids, which_expert=2, verbose=verbose)\n",
    "print('Preparing labels of E2... ', end='', flush=True)\n",
    "y2_stamps = {}\n",
    "for set_name in set_list:\n",
    "    y2_stamps[set_name] = postprocessing.generate_mark_intervals_with_list(\n",
    "        y2[set_name], pages[set_name], 200, 200, thr=None, postprocess=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cheating performance: Looking for Individualized thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance settings\n",
    "res_thr = 0.02\n",
    "start_thr = 0.1\n",
    "end_thr = 0.9\n",
    "n_thr = int(np.round((end_thr - start_thr) / res_thr + 1))\n",
    "thr_list = [start_thr + res_thr * i for i in range(n_thr)]\n",
    "# print(thr_list)\n",
    "print('Number of thresholds to be evaluated: %d' % len(thr_list))\n",
    "\n",
    "# ---------------- Compute performance\n",
    "af1 = {}\n",
    "# Go through several IoU values\n",
    "first_iou = 0\n",
    "last_iou = 1\n",
    "res_iou = 0.01\n",
    "n_points = int(np.round((last_iou - first_iou) / res_iou))\n",
    "full_iou_list = np.arange(n_points + 1) * res_iou + first_iou\n",
    "\n",
    "for set_name in set_list:\n",
    "    af1[set_name] = []\n",
    "    n_subjects = len(y_pred[set_name])\n",
    "    for _ in range(n_subjects):\n",
    "        af1[set_name].append([])\n",
    "    my_it = tqdm(thr_list)\n",
    "    for thr in my_it:\n",
    "        my_it.set_description('Processing %s set, threshold %1.3f' % (set_name, thr))\n",
    "        # Prepare model predictions\n",
    "        # print('Preparing predictions', flush=True)\n",
    "        y_pred_thr = postprocessing.generate_mark_intervals_with_list(\n",
    "            y_pred[set_name], pages[set_name], \n",
    "            fs_input = 200//8, fs_output=200, thr=thr, postprocess=True,\n",
    "            min_separation=min_separation, min_duration=min_duration,\n",
    "            max_duration=max_duration)\n",
    "        # Go through several IoU values\n",
    "        # print('Computing F1 Curve... ', flush=True, end='')\n",
    "        all_f1_list = [metrics.f1_vs_iou(this_y, this_y_pred, full_iou_list) \n",
    "                       for (this_y, this_y_pred) \n",
    "                       in zip(y_stamps[set_name], y_pred_thr)]\n",
    "        all_af1 = [this_result.mean() for this_result in all_f1_list]\n",
    "        for j in range(n_subjects):\n",
    "            af1[set_name][j].append(all_af1[j])\n",
    "\n",
    "# Find optimal thresholds for each subjects\n",
    "optimal_thr_dict = {}\n",
    "for set_name in set_list:\n",
    "    print('\\nSubset %s' % set_name)\n",
    "    optimal_thr_dict[set_name] = []\n",
    "    n_subjects = len(y_pred[set_name])\n",
    "    for j in range(n_subjects):\n",
    "        subject_idx = idx_dict[set_name][j]\n",
    "        max_idx = np.argmax(af1[set_name][j])\n",
    "        this_optimal = thr_list[max_idx]\n",
    "        optimal_thr_dict[set_name].append(this_optimal)\n",
    "        print('Optimal for S%02d: %1.4f' % (subject_idx, optimal_thr_dict[set_name][j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: F1 vs IoU curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Performance settings\n",
    "chosen_set = 'test'\n",
    "thr = optimal_thr_dict\n",
    "\n",
    "# ---------------- Compute performance\n",
    "\n",
    "# Prepare expert labels into marks\n",
    "y_thr = y_stamps[chosen_set]\n",
    "\n",
    "# Prepare model predictions\n",
    "print('Preparing predictions', flush=True)\n",
    "n_subjects = len(y_thr)\n",
    "if isinstance(thr, collections.Mapping):\n",
    "    print('Using thr dictionary and %s set' % (chosen_set))\n",
    "    y_pred_thr = []\n",
    "    for j in range(n_subjects):\n",
    "        this_pred_thr = postprocessing.generate_mark_intervals(\n",
    "            y_pred[chosen_set][j], pages[chosen_set][j], 200//8, 200, thr=thr[chosen_set][j],\n",
    "            min_separation=min_separation, min_duration=min_duration, max_duration=max_duration)\n",
    "        y_pred_thr.append(this_pred_thr)\n",
    "else:\n",
    "    print('Using thr %1.4f and %s set' % (thr, chosen_set))\n",
    "    y_pred_thr = postprocessing.generate_mark_intervals_with_list(\n",
    "        y_pred[chosen_set], pages[chosen_set], 200//8, 200, thr=thr,\n",
    "        min_separation=min_separation, min_duration=min_duration, max_duration=max_duration)\n",
    "\n",
    "\n",
    "# Go through several IoU values\n",
    "print('Computing F1 Curve', flush=True)\n",
    "first_iou = 0\n",
    "last_iou = 1\n",
    "res_iou = 0.01\n",
    "n_points = int(np.round((last_iou - first_iou) / res_iou))\n",
    "full_iou_list = np.arange(n_points + 1) * res_iou + first_iou\n",
    "short_iou_list = np.arange(11) * 0.1\n",
    "\n",
    "# Full\n",
    "all_f1_list = [metrics.f1_vs_iou(this_y, this_y_pred, full_iou_list) \n",
    "               for (this_y, this_y_pred) \n",
    "               in zip(y_thr, y_pred_thr)]\n",
    "all_f1_list = np.stack(all_f1_list, axis=1)\n",
    "mean_f1 = np.mean(all_f1_list, axis=1)\n",
    "std_f1 = np.std(all_f1_list, axis=1)\n",
    "model_f1_mean = np.stack([full_iou_list, mean_f1], axis=1)\n",
    "model_f1_std = np.stack([full_iou_list, std_f1], axis=1)\n",
    "\n",
    "# Short\n",
    "all_f1_list = [metrics.f1_vs_iou(this_y, this_y_pred, short_iou_list) \n",
    "               for (this_y, this_y_pred) \n",
    "               in zip(y_thr, y_pred_thr)]\n",
    "all_f1_list = np.stack(all_f1_list, axis=1)\n",
    "mean_f1 = np.mean(all_f1_list, axis=1)\n",
    "std_f1 = np.std(all_f1_list, axis=1)\n",
    "short_model_f1_mean = np.stack([short_iou_list, mean_f1], axis=1)\n",
    "short_model_f1_std = np.stack([short_iou_list, std_f1], axis=1)\n",
    "\n",
    "\n",
    "print('Mean F1')\n",
    "pprint.pprint(short_model_f1_mean)\n",
    "print('Std F1')\n",
    "pprint.pprint(short_model_f1_std)\n",
    "print('%s AF1: %1.4f' % (chosen_set.capitalize(), model_f1_mean[:, 1].mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single metric: average F1 on validation set\n",
    "chosen_set_af1 = 'alltrain'\n",
    "validation_af1 = metrics.average_f1_with_list(\n",
    "    y[chosen_set_af1], y_pred[chosen_set_af1], pages[chosen_set_af1], thr=thr, \n",
    "    min_separation=min_separation, min_duration=min_duration, max_duration=max_duration)\n",
    "print('%s AF1: %1.4f' % (chosen_set_af1.capitalize(), validation_af1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving settings\n",
    "save_f1_iou_result = False\n",
    "ckpt_id = ''\n",
    "\n",
    "# Comparison settings\n",
    "comparison_folder = 'comparison_data'\n",
    "compare_expert = True\n",
    "compare_chambon = True\n",
    "show_set_std = False\n",
    "alpha = 0.2\n",
    "color_list = {'model': '#c62828', 'expert': '#455a64', 'chambon': '#0277bd'} \n",
    "zoom_xlim = [0.1, 0.7]\n",
    "zoom_ylim = [0.6, 0.85]\n",
    "linewidth_model = 2\n",
    "markersize_model = 10\n",
    "linewidth_others = 1.3\n",
    "markersize_others = 6\n",
    "\n",
    "# --------------- Optional: Save F1 data\n",
    "if save_f1_iou_result:\n",
    "    filename = os.path.join('comparison_data', '%s_f1_vs_iou_model_%s.csv' % (dataset_name, ckpt_id))\n",
    "    np.savetxt(filename, model_f1_mean, delimiter=\",\")\n",
    "\n",
    "\n",
    "# -------------------- P L O T ----------------------    \n",
    "# Comparison data\n",
    "if compare_expert and (dataset_name == constants.MASS_NAME or dataset_name == constants.INTA_NAME):\n",
    "    expert_f1_curve_mean = np.loadtxt(os.path.join(comparison_folder, 'f1_vs_iou_expert_mean.csv'), delimiter=',')\n",
    "    expert_f1_curve_std = np.loadtxt(os.path.join(comparison_folder, 'f1_vs_iou_expert_std.csv'), delimiter=',')\n",
    "if compare_chambon and dataset_name == constants.MASS_NAME:\n",
    "    # chambon_f1_curve_1 = np.loadtxt(os.path.join(comparison_folder, 'mass_f1_vs_iou_Chambon_jointly.csv'), delimiter=',')\n",
    "    chambon_f1_curve_2 = np.loadtxt(os.path.join(comparison_folder, 'mass_f1_vs_iou_Chambon_separately.csv'), delimiter=',')\n",
    "    # chambon_f1_curve = np.stack([chambon_f1_curve_1, chambon_f1_curve_2], axis=2).max(axis=2)\n",
    "    chambon_f1_curve = chambon_f1_curve_2\n",
    "if compare_chambon and dataset_name == constants.MASSK_NAME:\n",
    "    # chambon_f1_curve_1 = np.loadtxt(os.path.join(comparison_folder, 'massk_f1_vs_iou_Chambon_jointly.csv'), delimiter=',')\n",
    "    chambon_f1_curve_2 = np.loadtxt(os.path.join(comparison_folder, 'massk_f1_vs_iou_Chambon_separately.csv'), delimiter=',')\n",
    "    # chambon_f1_curve = np.stack([chambon_f1_curve_1, chambon_f1_curve_2], axis=2).max(axis=2)\n",
    "    chambon_f1_curve = chambon_f1_curve_2\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "\n",
    "# Complete plot\n",
    "if compare_expert and (dataset_name == constants.MASS_NAME or dataset_name == constants.INTA_NAME):\n",
    "    ax.plot(expert_f1_curve_mean[:, 0], expert_f1_curve_mean[:, 1], linewidth=linewidth_others, \n",
    "               markersize=markersize_others, marker='.', \n",
    "               label='Expert Performance\\nPrivate Database\\nWarby et al. 2014', color=color_list['expert'])\n",
    "    ax.fill_between(\n",
    "        expert_f1_curve_mean[:, 0], \n",
    "        expert_f1_curve_mean[:, 1] - expert_f1_curve_std[:, 1], \n",
    "        expert_f1_curve_mean[:, 1] + expert_f1_curve_std[:, 1], \n",
    "        alpha=alpha, facecolor=color_list['expert'])\n",
    "if compare_chambon and (dataset_name == constants.MASS_NAME or dataset_name == constants.MASSK_NAME):\n",
    "    ax.plot(chambon_f1_curve[:, 0], chambon_f1_curve[:, 1], linewidth=linewidth_others, \n",
    "               markersize=markersize_others, marker='.', \n",
    "               label='DOSED (ConvNet)\\nChambon et al. 2018', color=color_list['chambon'])\n",
    "ax.plot(model_f1_mean[:, 0], model_f1_mean[:, 1], \n",
    "           linewidth=linewidth_model, # markersize=markersize_model, marker='.', \n",
    "           label='Proposed Model\\n%s Database' % dataset_name.upper(), color=color_list['model'])\n",
    "ax.plot(short_model_f1_mean[:, 0], short_model_f1_mean[:, 1], \n",
    "           linestyle='none', markersize=markersize_model, marker='.', color=color_list['model'])\n",
    "if show_set_std:\n",
    "    ax.fill_between(\n",
    "            model_f1_mean[:, 0], \n",
    "            model_f1_mean[:, 1] - model_f1_std[:, 1], \n",
    "            model_f1_mean[:, 1] + model_f1_std[:, 1], \n",
    "            alpha=alpha, facecolor=color_list['model'])\n",
    "if isinstance(thr, collections.Mapping):\n",
    "    ax.set_title('Performance with individualized $\\mu$ (%s)' % (chosen_set.capitalize()), fontsize=11)\n",
    "else:\n",
    "    ax.set_title('Performance with $\\mu=%1.3f$ (%s)' % (thr, chosen_set.capitalize()), fontsize=11)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax.set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax.set_ylabel('F1-score', fontsize=8.5)\n",
    "ax.grid()\n",
    "\n",
    "ax.legend(loc='lower left', bbox_to_anchor=(1.05, 0.15), labelspacing=3, fontsize=7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: Precision-Recall plot, separated subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = optimal_thr_dict\n",
    "\n",
    "iou_thr = 0.3\n",
    "\n",
    "# Prepare model predictions\n",
    "be_stats = {}\n",
    "for set_name in set_list:\n",
    "    print('Preparing predictions for %s set' % set_name, flush=True) \n",
    "    n_subjects = len(y_pred[set_name])\n",
    "    if isinstance(thr, collections.Mapping):\n",
    "        print('Using thr dictionary and %s set' % (chosen_set))\n",
    "        y_pred_thr = []\n",
    "        for j in range(n_subjects):\n",
    "            this_pred_thr = postprocessing.generate_mark_intervals(\n",
    "                y_pred[set_name][j], pages[set_name][j], 200//8, 200, thr=thr[set_name][j],\n",
    "                min_separation=min_separation, min_duration=min_duration, max_duration=max_duration)\n",
    "            y_pred_thr.append(this_pred_thr)\n",
    "    else:\n",
    "        print('Using thr %1.4f and %s set' % (thr, chosen_set))\n",
    "        y_pred_thr = postprocessing.generate_mark_intervals_with_list(\n",
    "            y_pred[set_name], pages[set_name], 200//8, 200, thr=thr,\n",
    "            min_separation=min_separation, min_duration=min_duration, max_duration=max_duration)    \n",
    "    be_stats[set_name] = [metrics.by_event_confusion(this_y, this_y_pred, iou_thr=iou_thr) \n",
    "                for (this_y, this_y_pred) in zip(y_stamps[set_name], y_pred_thr)]\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "text_space = 0.01\n",
    "markersize = 20\n",
    "\n",
    "compare_chambon = True\n",
    "\n",
    "if compare_chambon and dataset_name == constants.MASS_NAME:\n",
    "    chambon_f1_curve_joint = np.loadtxt(os.path.join(comparison_folder, 'mass_pr_Chambon_jointly.csv'), delimiter=',')\n",
    "    chambon_f1_curve_sepa = np.loadtxt(os.path.join(comparison_folder, 'mass_pr_Chambon_separately.csv'), delimiter=',')\n",
    "if compare_chambon and dataset_name == constants.MASSK_NAME:\n",
    "    chambon_f1_curve_joint = np.loadtxt(os.path.join(comparison_folder, 'massk_pr_Chambon_jointly.csv'), delimiter=',')\n",
    "    chambon_f1_curve_sepa = np.loadtxt(os.path.join(comparison_folder, 'massk_pr_Chambon_separately.csv'), delimiter=',')\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=[0.6, 0.7, 0.8, 0.9])\n",
    "ax.clabel(CS, fontsize=7.5, fmt='%1.2f')\n",
    "\n",
    "# Scatter plots of each subject\n",
    "color_list = {'train':'#43a047', 'val':'#0288d1', 'test': '#c62828', 'alltrain':'#43a047'}\n",
    "for set_name in set_list:\n",
    "    for i, stats in enumerate(be_stats[set_name]):\n",
    "        if i==0:\n",
    "            ax.scatter(stats['recall'], stats['precision'], c=color_list[set_name], label='Proposed (%s)' % set_name.capitalize(), s=markersize, zorder=10)\n",
    "        else:\n",
    "            ax.scatter(stats['recall'], stats['precision'], c=color_list[set_name], s=markersize, zorder=10)\n",
    "        ax.annotate(idx_dict[set_name][i], (stats['recall']+text_space, stats['precision']+text_space), fontsize=7, color='#1b2631', zorder=20)  \n",
    "if compare_chambon and (dataset_name == constants.MASSK_NAME or dataset_name == constants.MASS_NAME):\n",
    "    ax.scatter(chambon_f1_curve_joint[0], chambon_f1_curve_joint[1], \n",
    "               c='#455a64', label='DOSED Jointly', s=markersize, zorder=10, marker='s')\n",
    "    ax.scatter(chambon_f1_curve_sepa[0], chambon_f1_curve_sepa[1], \n",
    "               c='#455a64', label='DOSED Separately', s=markersize, zorder=10, marker='o')\n",
    "if isinstance(thr, collections.Mapping):\n",
    "    ax.set_title('Test PR with individualized $\\mu$ and IoU$>$%1.1f (%s)' % (iou_thr, dataset_name.upper()), fontsize=10)\n",
    "else:\n",
    "    ax.set_title('Test PR with $\\mu=%1.3f$ and IoU$>$%1.1f (%s)' % (thr, iou_thr, dataset_name.upper()), fontsize=10)\n",
    "        \n",
    "\n",
    "ax.set_xlabel('Recall', fontsize=8.5)\n",
    "ax.set_ylabel('Precision', fontsize=8.5)\n",
    "ax.set_xlim([0.4, 1])\n",
    "ax.set_ylim([0.4, 1])\n",
    "ax.legend(loc='lower left', fontsize=6.5)\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: Precision-Recall curve, separated subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mean of each set is drawn, for several thr\n",
    "\n",
    "iou_thr = 0.3\n",
    "this_thr = optimal_thr_dict\n",
    "\n",
    "res_thr = 0.02\n",
    "start_thr = 0.1\n",
    "end_thr = 0.9\n",
    "n_thr = int(np.round((end_thr - start_thr) / res_thr))\n",
    "thr_list = np.arange(n_thr+1) * res_thr + start_thr\n",
    "\n",
    "# Prepare model predictions\n",
    "pr_curve = {}\n",
    "n_thr = len(thr_list)\n",
    "for set_name in set_list:\n",
    "    n_subjects = len(y_pred[set_name])\n",
    "    pr_curve[set_name] = []\n",
    "    for _ in range(n_subjects):\n",
    "        pr_curve[set_name].append(np.zeros((n_thr, 2)))   # Columns are [x: recall, y: precision]\n",
    "    my_it = tqdm(enumerate(thr_list))\n",
    "    for i, thr in my_it:\n",
    "        my_it.set_description('Processing %s set, threshold %1.2f' % (set_name, thr))\n",
    "        y_pred_thr = postprocessing.generate_mark_intervals_with_list(\n",
    "            y_pred[set_name], pages[set_name], 200//8, 200, thr=thr,\n",
    "            min_separation=min_separation, min_duration=min_duration, max_duration=max_duration\n",
    "        )\n",
    "        \n",
    "        this_stats = [metrics.by_event_confusion(this_y, this_y_pred, iou_thr=iou_thr) \n",
    "                     for (this_y, this_y_pred) in zip(y_stamps[set_name], y_pred_thr)]\n",
    "        for j in range(n_subjects):\n",
    "            pr_curve[set_name][j][i, 0] = this_stats[j]['recall']\n",
    "            pr_curve[set_name][j][i, 1] = this_stats[j]['precision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "show_train = True\n",
    "show_val = True\n",
    "\n",
    "thr_to_show = this_thr\n",
    "\n",
    "subjects_to_show = None\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "markersize = 30\n",
    "text_space = 0.01\n",
    "alpha=0.8\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=[0.6, 0.7, 0.8, 0.9])\n",
    "ax.clabel(CS, fontsize=7.5, fmt='%1.2f')\n",
    "\n",
    "set_list_aux = []\n",
    "if show_train and ('alltrain' in set_list):\n",
    "    set_list_aux.append('alltrain')\n",
    "if show_train and ('train' in set_list):\n",
    "    set_list_aux.append('train')\n",
    "if show_val and ('val' in set_list):\n",
    "    set_list_aux.append('val')\n",
    "set_list_aux.append('test')\n",
    "\n",
    "# Scatter plots of each subset\n",
    "\n",
    "color_list = {'train':'#43a047', 'val':'#0288d1', 'test': '#c62828', 'alltrain':'#43a047'}\n",
    "for i, set_name in enumerate(set_list_aux):\n",
    "    n_subjects = len(y_pred[set_name])\n",
    "    first_time = True\n",
    "    for j in range(n_subjects):\n",
    "        subject_id = idx_dict[set_name][j]\n",
    "        if (subjects_to_show is None) or (subject_id in subjects_to_show):\n",
    "            if first_time:\n",
    "                ax.plot(pr_curve[set_name][j][:, 0], pr_curve[set_name][j][:, 1], \n",
    "                        label=set_name.capitalize(), alpha=alpha,\n",
    "                        linewidth=1, color=color_list[set_name], zorder=10*(i+1))\n",
    "                first_time = False\n",
    "            else:\n",
    "                ax.plot(pr_curve[set_name][j][:, 0], pr_curve[set_name][j][:, 1], alpha=alpha,\n",
    "                        linewidth=1, color=color_list[set_name], zorder=10*(i+1))\n",
    "# Highlight threshold=0.5\n",
    "for i, set_name in enumerate(set_list_aux):\n",
    "    n_subjects = len(y_pred[set_name])\n",
    "    for j in range(n_subjects):\n",
    "        subject_id = idx_dict[set_name][j]\n",
    "        if (subjects_to_show is None) or (subject_id in subjects_to_show):\n",
    "            if isinstance(thr_to_show, collections.Mapping):\n",
    "                this_thr_to_show = thr_to_show[set_name][j]\n",
    "                half_thr_idx = np.where(np.isclose(thr_list, this_thr_to_show))[0]\n",
    "            else:\n",
    "                half_thr_idx = np.where(np.isclose(thr_list, thr_to_show))[0]\n",
    "            ax.scatter(pr_curve[set_name][j][half_thr_idx, 0], pr_curve[set_name][j][half_thr_idx, 1], \n",
    "                       s=markersize, c=color_list[set_name], zorder=10*(i+1))\n",
    "\n",
    "            ax.annotate(subject_id, (pr_curve[set_name][j][half_thr_idx, 0] + text_space, pr_curve[set_name][j][half_thr_idx, 1] + text_space), \n",
    "                        fontsize=7, color='#1b2631', zorder=20)  \n",
    "\n",
    "ax.set_title('Performance with IoU$>$%1.1f (%s)' % (iou_thr, dataset_name.upper()), fontsize=11)\n",
    "ax.set_xlabel('Recall', fontsize=8.5)\n",
    "ax.set_ylabel('Precision', fontsize=8.5)\n",
    "ax.set_xlim([0.5, 1])\n",
    "ax.set_ylim([0.5, 1])\n",
    "ax.legend(loc='lower left', fontsize=8.5)\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: Precision-Recall curve, average per set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The mean of each set is drawn, for several thr\n",
    "\n",
    "iou_thr = 0.3\n",
    "this_thr = optimal_thr\n",
    "\n",
    "res_thr = 0.02\n",
    "start_thr = 0.1\n",
    "end_thr = 0.9\n",
    "n_thr = int(np.round((end_thr - start_thr) / res_thr))\n",
    "thr_list = np.arange(n_thr+1) * res_thr + start_thr\n",
    "\n",
    "# Prepare model predictions\n",
    "pr_curve = {}\n",
    "n_thr = len(thr_list)\n",
    "for set_name in set_list:\n",
    "    pr_curve[set_name] = np.zeros((n_thr, 2))   # Columns are [x: recall, y: precision]\n",
    "    my_it = tqdm(enumerate(thr_list))\n",
    "    for i, thr in my_it:\n",
    "        my_it.set_description('Processing %s set, threshold %1.2f' % (set_name, thr))\n",
    "        y_pred_thr = postprocessing.generate_mark_intervals_with_list(\n",
    "            y_pred[set_name], pages[set_name], 200//8, 200, thr=thr,\n",
    "            min_separation=min_separation, min_duration=min_duration, max_duration=max_duration\n",
    "        )\n",
    "        this_stats = [metrics.by_event_confusion(this_y, this_y_pred, iou_thr=iou_thr) \n",
    "                    for (this_y, this_y_pred) in zip(y_stamps[set_name], y_pred_thr)]\n",
    "        this_recall = np.mean([m['recall'] for m in this_stats])\n",
    "        this_precision = np.mean([m['precision'] for m in this_stats])\n",
    "        pr_curve[set_name][i, 0] = this_recall\n",
    "        pr_curve[set_name][i, 1] = this_precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "show_train = True\n",
    "show_val = True\n",
    "\n",
    "thr_to_show = 0.3\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "markersize = 8\n",
    "text_space = 0.01\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=[0.6, 0.7, 0.8, 0.9])\n",
    "ax.clabel(CS, fontsize=7.5, fmt='%1.2f')\n",
    "\n",
    "set_list_aux = []\n",
    "if show_train and ('alltrain' in set_list):\n",
    "    set_list_aux.append('alltrain')\n",
    "if show_train and ('train' in set_list):\n",
    "    set_list_aux.append('train')\n",
    "if show_val and ('val' in set_list):\n",
    "    set_list_aux.append('val')\n",
    "set_list_aux.append('test')\n",
    "\n",
    "# Scatter plots of each subset\n",
    "half_thr_idx = np.where(np.isclose(thr_list, thr_to_show))[0]\n",
    "color_list = {'train':'#43a047', 'val':'#0288d1', 'test': '#c62828', 'alltrain':'#43a047'}\n",
    "for i, set_name in enumerate(set_list_aux):\n",
    "    ax.plot(pr_curve[set_name][:, 0], pr_curve[set_name][:, 1], \n",
    "            label=set_name.capitalize(), # markersize=markersize, marker='.', \n",
    "            linewidth=1.5, color=color_list[set_name], zorder=10*(i+1))\n",
    "# Highlight threshold=0.5\n",
    "for i, set_name in enumerate(set_list_aux):\n",
    "    ax.scatter(pr_curve[set_name][half_thr_idx, 0], pr_curve[set_name][half_thr_idx, 1], \n",
    "               s=100, c=color_list[set_name], zorder=10*(i+1))\n",
    "    ax.annotate('$\\mu$=%1.3f' % thr_to_show, \n",
    "                (pr_curve[set_name][half_thr_idx, 0] + text_space*2, pr_curve[set_name][half_thr_idx, 1] + text_space), \n",
    "                fontsize=7, color='#1b2631', zorder=20)  \n",
    "\n",
    "ax.set_title('Performance with IoU$>$%1.1f (%s)' % (iou_thr, dataset_name.upper()), fontsize=11)\n",
    "ax.set_xlabel('Recall', fontsize=8.5)\n",
    "ax.set_ylabel('Precision', fontsize=8.5)\n",
    "ax.set_xlim([0.5, 1])\n",
    "ax.set_ylim([0.5, 1])\n",
    "ax.legend(loc='lower left', fontsize=8.5)\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = optimal_thr\n",
    "\n",
    "subset_name = 'alltrain'\n",
    "subject_id = 19\n",
    "\n",
    "# -----\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids, 'alltrain': all_train_ids}\n",
    "idx_subject = idx_dict[subset_name].index(subject_id)\n",
    "this_signal = x[subset_name][idx_subject]\n",
    "this_marks_1 = y[subset_name][idx_subject]\n",
    "this_n2_pages = pages[subset_name][idx_subject]\n",
    "this_prob = y_pred[subset_name][idx_subject]\n",
    "if dataset_name == constants.MASS_NAME:\n",
    "    _, this_marks_2 = dataset.get_subject_data(subject_id, which_expert=2, verbose=True)\n",
    "    channel_name = 'C3-CLE'\n",
    "    event_name = 'Sleep Spindle'\n",
    "elif dataset_name == constants.INTA_NAME:\n",
    "    channel_name = 'F4-C4'\n",
    "    event_name = 'Sleep Spindle'\n",
    "else:\n",
    "    channel_name = 'C3-CLE'\n",
    "    event_name = 'K Complex'\n",
    "    \n",
    "y_pred_thr = postprocessing.generate_mark_intervals(\n",
    "    y_pred[subset_name][idx_subject], pages[subset_name][idx_subject], 200//8, 200, thr=thr,\n",
    "    min_separation=min_separation, min_duration=min_duration, max_duration=max_duration\n",
    ")\n",
    "y_pred_thr_seq = data_ops.inter2seq(y_pred_thr, 0, (pages[subset_name][idx_subject].max()+1)*200*20-1)\n",
    "# Now reshape into pages\n",
    "this_det = data_ops.extract_pages(y_pred_thr_seq, pages[subset_name][idx_subject], 200*20, border_size=0)\n",
    "    \n",
    "# make a color map of fixed colors\n",
    "cmap = colors.ListedColormap(['white', '#c62828'])\n",
    "\n",
    "def plot_page(page_idx):\n",
    "    if dataset_name == constants.MASS_NAME:\n",
    "        fig = plt.figure(figsize=(15, 4), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(3, 1, height_ratios=[4, 1, 1])\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(15, 3), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(2, 1, height_ratios=[4, 1])\n",
    "    \n",
    "    page_idx = page_idx - 1\n",
    "    \n",
    "    segment_signal = this_signal[page_idx, :]\n",
    "    segment_marks_1 = this_marks_1[page_idx, :]\n",
    "    segment_prob = this_prob[page_idx, :]\n",
    "    segment_det = this_det[page_idx, :]\n",
    "    time_axis = np.arange(this_signal.shape[1]) / dataset.fs\n",
    "    \n",
    "    if dataset_name == constants.MASS_NAME:\n",
    "        segment_marks_2 = this_marks_2[page_idx, :]\n",
    "    \n",
    "    gs_idx = 0\n",
    "    \n",
    "    # Signal\n",
    "    y_max = 10\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(time_axis, segment_signal, linewidth=1, color='#455a64', label='EEG %s' % channel_name)\n",
    "    ax.fill_between(time_axis, y_max * segment_marks_1, -y_max * segment_marks_1, facecolor='#c62828', alpha=0.3, label=event_name)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([0, 20])\n",
    "    ax.set_ylim([-y_max, y_max])\n",
    "    ax.set_title('Subject %d (%s-%s). Page in record: %d (intervals of 0.5s are shown).' \n",
    "                 % (subject_id, dataset_name.upper(), subset_name.capitalize(), this_n2_pages[page_idx]), fontsize=10)\n",
    "    ax.set_xticks([0, 5, 10, 15, 20])\n",
    "    ax.set_xticks(np.arange(0, 20, 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    lg = ax.legend(loc='upper right', fontsize=8.5)\n",
    "    # lh = lg.legendHandles[1]\n",
    "    # lh.set_facecolor(lh.get_facecolor())\n",
    "    # lh.set_alpha(1.0)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Neural net\n",
    "    delta_y = 0.1\n",
    "    time_axis_short = time_axis[::8]\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(time_axis_short, segment_prob, color='#c62828', linewidth=1.5, zorder=7)\n",
    "    ax.fill_between(time_axis, (1+delta_y)*segment_det, (-delta_y)*segment_det, facecolor='grey', zorder=6)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_ylim([-delta_y, 1+delta_y])\n",
    "    ax.set_xlim([0, 20])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticks([thr], minor=True)\n",
    "    ax.grid(b=True, axis='y', linewidth=1.5, which='minor', zorder=5)\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    ax.set_title('Model probability prediction (%1.2f threshold and postprocessed detections are shown)' % thr, fontsize=10)\n",
    "    \n",
    "    if dataset_name == constants.MASS_NAME:\n",
    "        ax = fig.add_subplot(gs[gs_idx])\n",
    "        ax.imshow(segment_marks_2[np.newaxis, :], interpolation=None, aspect='auto', cmap=cmap)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Second expert, not used for training (red indicates event)', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(\n",
    "    lambda page_idx: plot_page(page_idx),\n",
    "    page_idx=widgets.IntSlider(min=1,max=this_n2_pages.shape[0],step=1,value=1, continuous_update=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_set_error = 'test'\n",
    "thr = optimal_thr\n",
    "\n",
    "y_thr = y_stamps[chosen_set_error]\n",
    "\n",
    "# Prepare model predictions\n",
    "n_subjects = len(y_thr)\n",
    "pred_stamps = []\n",
    "for i in range(n_subjects):\n",
    "    print('Processing subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    # Binarize\n",
    "    this_y_pred_thr = (y_pred[chosen_set_error][i] >= thr).astype(np.int32)\n",
    "    # Transform to intervals\n",
    "    this_y_pred_thr = data_ops.seq2inter_with_pages(\n",
    "        this_y_pred_thr, pages[chosen_set_error][i]\n",
    "    )\n",
    "    pred_stamps.append(this_y_pred_thr)\n",
    "fs_pred = 200 // 8 \n",
    "fs_real = 200\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Compute spacing ----------------------\n",
    "combine_thr = 0.3\n",
    "\n",
    "spacing = []\n",
    "spacing_expert = []\n",
    "for i in range(n_subjects):\n",
    "    print('Spacing for subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    this_spacing = (pred_stamps[i][1:, 0] - pred_stamps[i][:-1, 1]) / fs_pred\n",
    "    this_spacing_expert = (y_stamps[chosen_set_error][i][1:, 0] - y_stamps[chosen_set_error][i][:-1, 1]) / fs_real\n",
    "    # Only consider for this analysis, spacing less than one second\n",
    "    this_spacing = this_spacing[this_spacing < 1]\n",
    "    this_spacing_expert = this_spacing_expert[this_spacing_expert < 1]\n",
    "    spacing.append(this_spacing)\n",
    "    spacing_expert.append(this_spacing_expert)\n",
    "print('Done')\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Spacing between nearby expert marks', fontsize=10)\n",
    "ax[0, 1].set_title('Spacing between nearby detections', fontsize=10)\n",
    "y_max = 0\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Real\n",
    "    n_real, _, _ = ax[i, 0].hist(spacing_expert[i], bins=[k*0.1 for k in range(11)], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].set_xticks([k*0.2 for k in range(6)])\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "    # Predicted\n",
    "    n_pred, _, _ = ax[i, 1].hist(spacing[i], bins=[k*0.1 for k in range(11)], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].set_xticks([k*0.2 for k in range(6)])\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "    max_y = max(np.max(n_real), np.max(n_pred))\n",
    "    ax[i, 0].plot([combine_thr, combine_thr], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    ax[i, 1].plot([combine_thr, combine_thr], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    # y_max = max(max_y, y_max)\n",
    "# for i in range(n_subjects):\n",
    "#     ax[i, 0].plot([combine_thr, combine_thr], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "#     ax[i, 1].plot([combine_thr, combine_thr], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "ax[-1, 0].set_xlabel('Spacing [s]', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Spacing [s]', fontsize=8.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Durations\n",
    "\n",
    "if dataset_name == constants.MASSK_NAME:\n",
    "    postprocess_predicted = False\n",
    "else:\n",
    "    postprocess_predicted = True\n",
    "\n",
    "durations = []\n",
    "durations_expert = []\n",
    "for i in range(n_subjects):\n",
    "    print('Durations for subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    # First, combine close marks\n",
    "    if dataset_name == constants.MASSK_NAME:\n",
    "        this_pred_stamps = pred_stamps[i]\n",
    "    else:\n",
    "        this_pred_stamps = postprocessing.combine_close_marks(pred_stamps[i], fs_pred, combine_thr)\n",
    "    # Now compute durations\n",
    "    this_durations = (this_pred_stamps[:, 1] - this_pred_stamps[:, 0]) / fs_pred\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    # Only consider for this analysis, spacing less than one second\n",
    "    durations.append(this_durations)\n",
    "    durations_expert.append(this_durations_expert)\n",
    "print('Done')\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Duration of expert marks', fontsize=10)\n",
    "ax[0, 1].set_title('Duration of detections', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "y_max = 0\n",
    "min_duration = 0.3  \n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Real\n",
    "    n_real, _, _ = ax[i, 0].hist(durations_expert[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "    # Predicted\n",
    "    n_pred, _, _ = ax[i, 1].hist(durations[i], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "    max_y = max(np.max(n_real), np.max(n_pred))\n",
    "    ax[i, 0].plot([min_duration, min_duration], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    ax[i, 1].plot([min_duration, min_duration], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    y_max = max(max_y, y_max)\n",
    "    print(durations[i].max())\n",
    "    \n",
    "#for i in range(n_subjects):\n",
    "#    ax[i, 0].plot([min_duration, min_duration], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "#    ax[i, 1].plot([min_duration, min_duration], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "\n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location of Falses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset_name == constants.MASSK_NAME:\n",
    "    min_separation = 0\n",
    "    min_duration = 0.3\n",
    "    max_duration = 4.0\n",
    "else:\n",
    "    min_separation = 0.3\n",
    "    min_duration = 0.2\n",
    "    max_duration = 4.0\n",
    "\n",
    "iou_array = []\n",
    "idx_array = []\n",
    "y_pred_thr = []\n",
    "for i in range(n_subjects):\n",
    "    print('Processing subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    events = y_stamps[chosen_set_error][i]\n",
    "    detections = postprocessing.generate_mark_intervals(\n",
    "        y_pred[chosen_set_error][i], pages[chosen_set_error][i], 200//8, 200, thr=thr, \n",
    "        min_separation=min_separation, min_duration=min_duration, max_duration=max_duration)\n",
    "    print(events.shape, detections.shape)\n",
    "    this_iou_array, this_idx_array = metrics.matching(events, detections)\n",
    "    iou_array.append(this_iou_array)\n",
    "    idx_array.append(this_idx_array)\n",
    "    y_pred_thr.append(detections)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- False negatives\n",
    "iou_thr = 0.3\n",
    "\n",
    "fn_center = []\n",
    "for i in range(n_subjects):\n",
    "    idx_fn = iou_array[i] < iou_thr\n",
    "    fn_stamps = y_stamps[chosen_set_error][i][idx_fn]\n",
    "    this_fn_center = np.mean(fn_stamps, axis=1).astype(np.int32)\n",
    "    fn_center.append(this_fn_center)\n",
    "    \n",
    "# --- False positives\n",
    "fp_center = []\n",
    "for i in range(n_subjects):\n",
    "    # matched detections:\n",
    "    idx_fp_1 = iou_array[i] < iou_thr\n",
    "    idx_fp_1 = idx_array[i][idx_fp_1]\n",
    "    idx_fp_1 = [idx for idx in idx_fp_1 if idx != -1]\n",
    "    # Unmatched events\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    idx_fp = idx_fp_1 + idx_fp_2\n",
    "    fp_stamps = y_pred_thr[i][idx_fp]\n",
    "    this_fp_center = np.mean(fp_stamps, axis=1).astype(np.int32)\n",
    "    fp_center.append(this_fp_center)\n",
    "\n",
    "    \n",
    "# --- Histogram of IoU values across real events\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(3.5, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0].set_title('IoU values on expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].hist(iou_array[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), bins=[0.05*i for i in range(21)])\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "    ax[i].legend(fontsize=8.5, loc='upper center')\n",
    "    ax[i].set_xticks([0.2*i for i in range(6)])\n",
    "ax[-1].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "plt.show()\n",
    "    \n",
    "# --- Location in page\n",
    "fn_loc_page = [np.mod(this_fn_center, 20*fs_real) for this_fn_center in fn_center]\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Location of expert marks with IoU < %1.2f' % (iou_thr), fontsize=11)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 0].hist(fn_loc_page[i] / fs_real, bins=[i*4 for i in range(6)], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5, loc='upper center')\n",
    "ax[-1, 0].set_xticks([i*4 for i in range(6)])\n",
    "ax[-1, 0].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "\n",
    "fp_loc_page = [np.mod(this_fp_center, 20*fs_real) for this_fp_center in fp_center]\n",
    "\n",
    "ax[0, 1].set_title('Location of detections with IoU < %1.2f' % (iou_thr), fontsize=10)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 1].hist(fp_loc_page[i] / fs_real, bins=[i*4 for i in range(6)], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5, loc='upper center')\n",
    "ax[-1, 1].set_xticks([i*4 for i in range(6)])\n",
    "ax[-1, 1].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --- Location in register\n",
    "\n",
    "fn_loc_register = [np.floor_divide(this_fn_center, 20*fs_real) for this_fn_center in fn_center]\n",
    "max_page_array = [np.max(pages[chosen_set_error][i]) for i in range(n_subjects)]\n",
    "\n",
    "max_of_all = np.max(max_page_array)\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Location in register of expert marks with IoU < %1.1f' % (iou_thr), fontsize=10)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 0].hist(fn_loc_register[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "ax[-1, 0].set_xlim([0, max_of_all+10])\n",
    "ax[-1, 0].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "fp_loc_register = [np.floor_divide(this_fp_center, 20*fs_real) for this_fp_center in fp_center]\n",
    "max_page_array = [np.max(pages[chosen_set_error][i]) for i in range(n_subjects)]\n",
    "\n",
    "max_of_all = np.max(max_page_array)\n",
    "\n",
    "ax[0, 1].set_title('Location in register of detections with IoU < %1.1f' % (iou_thr), fontsize=11)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 1].hist(fp_loc_register[i], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "ax[-1, 1].set_xlim([0, max_of_all+10])\n",
    "ax[-1, 1].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ----- N2 pages\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(3.5, 1*n_subjects), dpi=DPI, sharex=True, sharey=True)\n",
    "ax[0].set_title('Location in register of N2 pages (%s)' % (chosen_set_error.capitalize()), fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].hist(pages[chosen_set_error][i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "    ax[i].legend(fontsize=8.5)\n",
    "ax[-1].set_xlim([0, max_of_all+10])\n",
    "ax[-1].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IoU vs Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- Scatter of IoU values and duration of real and detected events\n",
    "alpha = 0.2\n",
    "markersize=10\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(7, 1*n_subjects), dpi=DPI, sharex=True, sharey=True)\n",
    "ax[0, 0].set_title('IoU vs duration of expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    ax[i, 0].scatter(this_durations_expert, iou_array[i], label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#455a64', alpha=alpha, s=markersize)\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 0].legend(fontsize=7, loc='upper right')\n",
    "    for lh in lg.legendHandles:\n",
    "        lh.set_facecolor(lh.get_facecolor())\n",
    "        lh.set_edgecolor(lh.get_edgecolor())\n",
    "        lh.set_alpha(1.0)\n",
    "    ax[i, 0].set_ylabel('IoU', fontsize=8.5)\n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('IoU vs duration of detections', fontsize=10)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations for IoU > 0 \n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    this_iou_1 = iou_array[i][idx_valid]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    this_durations_1 = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    # Now durations for IoU = 0\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_fp_2]\n",
    "    this_durations_2 = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    this_iou_2 = np.zeros(this_durations_2.shape[0])\n",
    "    # Concatenation\n",
    "    this_durations = np.concatenate([this_durations_1, this_durations_2])\n",
    "    this_iou = np.concatenate([this_iou_1, this_iou_2])\n",
    "    ax[i, 1].scatter(this_durations, this_iou, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#c62828', alpha=alpha, s=markersize)\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 1].legend(fontsize=7, loc='upper right')\n",
    "    for lh in lg.legendHandles:\n",
    "        lh.set_facecolor(lh.get_facecolor())\n",
    "        lh.set_edgecolor(lh.get_edgecolor())\n",
    "        lh.set_alpha(1.0)\n",
    "    # ax[i, 1].set_ylabel('IoU', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Histogram of duration for IoU == 0\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Duration of unpaired expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    idx_zero = (iou_array[i] == 0)\n",
    "    this_durations_expert_fn = this_durations_expert[idx_zero]\n",
    "    ax[i, 0].hist(this_durations_expert_fn, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#455a64')\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 0].legend(fontsize=8.5, loc='upper right')\n",
    "    \n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('Duration of unpaired detections', fontsize=10)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_fp_2]\n",
    "    this_durations_fp = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    ax[i, 1].hist(this_durations_fp, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#c62828')\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5, loc='upper right')\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration of events and matched detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(5, 5), dpi=DPI, sharex=False, sharey=False)\n",
    "# plt.suptitle('Duration of matched events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    # Now compute durations for real\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    this_durations_expert = this_durations_expert[idx_valid]\n",
    "    # Now compute durations for matched detections\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    this_durations_det = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    if i<2:\n",
    "        ax[0, i].scatter(this_durations_expert, this_durations_det, label='S%02d' % subject_idx, color='#455a64', alpha=alpha)\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "        lg = ax[0, i].legend(fontsize=7)\n",
    "        for lh in lg.legendHandles:\n",
    "            lh.set_facecolor(lh.get_facecolor())\n",
    "            lh.set_edgecolor(lh.get_edgecolor())\n",
    "            lh.set_alpha(1.0)\n",
    "        max_dur = max(this_durations_expert.max(), this_durations_det.max())\n",
    "        ax[0, i].set_xlim([0, max_dur + 0.1])\n",
    "        ax[0, i].set_ylim([0, max_dur + 0.1])\n",
    "        if i == 0 :\n",
    "            ax[0, i].set_ylabel('Detected duration [s]', fontsize=8.5)\n",
    "        # ax[0, i].set_xlabel('Duration Real [s]', fontsize=8.5)\n",
    "        ax[0, i].plot([0.3, 2.0], [0.3, 2.0], '--k', alpha=0.6)\n",
    "    else:\n",
    "        ax[1, i-2].scatter(this_durations_expert, this_durations_det, label='S%02d' % subject_idx, color='#455a64', alpha=alpha)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "        lg = ax[1, i-2].legend(fontsize=7)\n",
    "        for lh in lg.legendHandles:\n",
    "            lh.set_facecolor(lh.get_facecolor())\n",
    "            lh.set_edgecolor(lh.get_edgecolor())\n",
    "            lh.set_alpha(1.0)\n",
    "        max_dur = max(this_durations_expert.max(), this_durations_det.max())\n",
    "        ax[1, i-2].set_xlim([0, max_dur + 0.1])\n",
    "        ax[1, i-2].set_ylim([0, max_dur + 0.1])\n",
    "        if i == 2:\n",
    "            ax[1, i-2].set_ylabel('Detected duration [s]', fontsize=8.5)\n",
    "        ax[1, i-2].set_xlabel('Real duration [s]', fontsize=8.5)\n",
    "        ax[1, i-2].plot([0.3, 2.0], [0.3, 2.0], '--k', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted probability to matched and unmatched events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare probabilities\n",
    "whole_y_proba = []\n",
    "for i in range(n_subjects):\n",
    "    this_proba = y_pred[chosen_set_error][i]\n",
    "    this_pages = pages[chosen_set_error][i]\n",
    "    page_size = this_proba.shape[1]\n",
    "    max_page = np.max(this_pages)\n",
    "    max_size = (max_page + 1) * page_size\n",
    "    whole_y_proba.append(np.zeros(max_size, dtype=np.float32))\n",
    "    for k, page in enumerate(this_pages):\n",
    "        sample_start = page * page_size\n",
    "        sample_end = (page + 1) * page_size\n",
    "        whole_y_proba[i][sample_start:sample_end] = this_proba[k, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching probabilities (Candidates for TP according to IoU)\n",
    "# It is expected that they have more than 0.5 since that is the threshold used for detection\n",
    "print('Processing probability for matched events', flush=True)\n",
    "matching_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for the valid detections stamps \n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    y_pred_stamps = y_pred_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in y_pred_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    matching_proba.append(mean_proba_list)\n",
    "    \n",
    "# Unmatched real events (FN)\n",
    "# It is expected that they have less than 0.5 since they were missed by the tresholding\n",
    "print('Processing probability for unmatched real events', flush=True)\n",
    "unmatching_fn_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for the missed real events \n",
    "    idx_valid = (idx_array[i] == -1)\n",
    "    fn_stamps = y_stamps[chosen_set_error][i][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    fn_stamps = fn_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in fn_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    unmatching_fn_proba.append(mean_proba_list)\n",
    "    \n",
    "# Unmatched detected events (FP)\n",
    "# It is expected that they have more than 0.5 since they were detected\n",
    "print('Processing probability for unmatched detected events', flush=True)\n",
    "unmatching_fp_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for detected events with no match \n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_valid = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    fp_stamps = y_pred_thr[i][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    fp_stamps = fp_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in fp_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    unmatching_fp_proba.append(mean_proba_list)\n",
    "    \n",
    "\n",
    "# Probability for real events\n",
    "print('Processing probability for real events', flush=True)\n",
    "real_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    y_pred_stamps = y_stamps[chosen_set_error][i] // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in y_pred_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    real_proba.append(mean_proba_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 3, figsize=(14, 3*n_subjects), dpi=100, sharex=True)\n",
    "\n",
    "ax[0, 0].set_title('Model output on matched events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 0].hist(matching_proba[i], label='S%02d' % subject_idx, color='#43a047')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 0].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "ax[-1, 0].set_xlim([0, 1])\n",
    "ax[-1, 0].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('Probability on unmatched real events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 1].hist(unmatching_fn_proba[i], label='S%02d' % subject_idx, color='#455a64')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 1].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "ax[-1, 1].set_xlim([0, 1])\n",
    "ax[-1, 1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "ax[0, 2].set_title('Probability on unmatched detections (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 2].hist(unmatching_fp_proba[i], label='S%02d' % subject_idx, color='#c62828')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 2].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 2].tick_params(labelsize=8.5)\n",
    "    ax[i, 2].legend(fontsize=8.5)\n",
    "ax[-1, 2].set_xlim([0, 1])\n",
    "ax[-1, 2].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(6, 5*n_subjects), dpi=100, sharex=True)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].set_title('Predicted probability for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=11)\n",
    "\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "max_n = 0\n",
    "for i in range(n_subjects):\n",
    "    \n",
    "    n, _, _ = ax[i].hist(\n",
    "        matching_proba[i], label='Matched real', color='#43a047', alpha=0.4, density=True,\n",
    "        bins = [i*0.05 for i in range(21)])\n",
    "    kernel = gaussian_kde(matching_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    ax[i].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "ax[-1].set_xlim([0, 1])\n",
    "ax[-1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "# for i in range(n_subjects):\n",
    "#     subject_idx = idx_dict[chosen_set_error][i]\n",
    "#     n, _, _ = ax[i].hist(\n",
    "#         unmatching_fn_proba[i], label='Unmatched real', color='#455a64', alpha=0.4, density=True,\n",
    "#         bins = [i*0.05 for i in range(21)])\n",
    "#     kernel = gaussian_kde(unmatching_fn_proba[i])\n",
    "#     y_kde = kernel(x_points)\n",
    "#     ax[i].plot(x_points, y_kde, color='#455a64', linewidth=2)\n",
    "#     max_n = max(np.max(n), max_n)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i].hist(\n",
    "        unmatching_fp_proba[i], label='Unmatched detection', color='#c62828', alpha=0.4, density=True,\n",
    "        bins = [i*0.05 for i in range(21)])\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    ax[i].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i].legend(fontsize=8.5, loc='upper left')\n",
    "    ax[i].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(6, 5), dpi=DPI, sharex=True)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    if i < 2:\n",
    "        ax[0, i].set_title('Model Output for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=10)\n",
    "    else:\n",
    "        ax[1, i-2].set_title('Model Output for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=10)\n",
    "\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "max_n = 0\n",
    "for i in range(n_subjects):\n",
    "    if i < 2:\n",
    "        n, _, _ = ax[0, i].hist(\n",
    "            real_proba[i], label='Expert marks', color='#43a047', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "    else:\n",
    "        n, _, _ = ax[1, i-2].hist(\n",
    "            real_proba[i], label='Real events\\n(Expert marks)', color='#43a047', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "    kernel = gaussian_kde(real_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    if i<2:\n",
    "        ax[0, i].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "        ax[0, i].set_xlim([0, 1])\n",
    "    else:\n",
    "        ax[1, i-2].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "        ax[1, i-2].set_xlim([0, 1])\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    \n",
    "\n",
    "# ax[-1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    if i<2:\n",
    "        n, _, _ = ax[0, i].hist(\n",
    "            unmatching_fp_proba[i], label='Unpaired detections ($\\mu$=0.1)', color='#c62828', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "        ax[0, i].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "        # ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "        # lg = ax[0, i].legend(fontsize=8.5, loc='upper center', bbox_to_anchor=(1.05, 0.15))\n",
    "        # for lh in lg.legendHandles:\n",
    "        #     lh.set_facecolor(lh.get_facecolor())\n",
    "        #     lh.set_alpha(1.0)\n",
    "        ax[0, i].set_yticks([])\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "    else:\n",
    "        n, _, _ = ax[1, i-2].hist(\n",
    "            unmatching_fp_proba[i], label='False events\\n(Unpaired detections\\ngenerated with $\\mu$=0.1)', color='#c62828', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "        ax[1, i-2].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "        # ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "        ax[1, i-2].set_yticks([])\n",
    "        ax[1, i-2].set_xlabel('Class assignment', fontsize=8.5)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "lg = ax[1, 1].legend(fontsize=9, loc='upper left', bbox_to_anchor=(1.05, 1.35), labelspacing=3)\n",
    "for lh in lg.legendHandles:\n",
    "    lh.set_facecolor(lh.get_facecolor())\n",
    "    lh.set_alpha(1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Avg distributions over set\n",
    "\n",
    "\n",
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5), dpi=100, sharex=True)\n",
    "\n",
    "ax.set_title('Predicted probability. Average for %s set' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "\n",
    "y_kde_list = []\n",
    "for i in range(n_subjects):\n",
    "    kernel = gaussian_kde(matching_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    y_kde_list.append(y_kde)\n",
    "y_kde_avg_real = np.stack(y_kde_list, axis=1).mean(axis=1)\n",
    "ax.plot(x_points, y_kde_avg_real, color='#43a047', linewidth=2, label='Real event')\n",
    "ax.fill_between(x_points, y_kde_avg_real, 0*y_kde_avg_real, color='#43a047', alpha=0.4)\n",
    "\n",
    "y_kde_list = []\n",
    "for i in range(n_subjects):\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    y_kde_list.append(y_kde)\n",
    "y_kde_avg_false = np.stack(y_kde_list, axis=1).mean(axis=1)\n",
    "ax.plot(x_points, y_kde_avg_false, color='#c62828', linewidth=2, label='False event')\n",
    "ax.fill_between(x_points, y_kde_avg_false, 0*y_kde_avg_false, color='#c62828', alpha=0.4)\n",
    "\n",
    "max_y = max(np.max(y_kde_avg_real), np.max(y_kde_avg_false))\n",
    "\n",
    "# Find optimal threshold\n",
    "difference = y_kde_avg_false - y_kde_avg_real\n",
    "idx_thr = np.where(np.signbit(difference))[0][0]\n",
    "x_thr = x_points[idx_thr]\n",
    "print('Optimal Threshold: %1.4f' % x_thr)\n",
    "ax.plot([x_thr, x_thr], [0, max_y], '--', color='k', linewidth=1.5, alpha=0.6, label='Optimal Threshold')\n",
    "\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, max_y])\n",
    "ax.set_yticks([])\n",
    "ax.legend(fontsize=8.5, loc='upper left')\n",
    "ax.set_xlabel('Probability', fontsize=8.5)\n",
    "ax.set_xticks([i*0.1 for i in range(11)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of FP that are TP-E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unmatched events according to E1\n",
    "unmatched_stamps = []\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    # Unmatched detections\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    fp_stamps = y_pred_thr[i][idx_fp]\n",
    "    print('\\n%d / %d (%1.2f %%) unmatched detections with E1 for S%02d' % (fp_stamps.shape[0], n_detections, 100*fp_stamps.shape[0]/n_detections, subject_idx))\n",
    "    unmatched_stamps.append(fp_stamps)\n",
    "    # Now match with E2\n",
    "    events = y2_stamps[chosen_set_error][i]\n",
    "    detections = fp_stamps\n",
    "    n_detections = fp_stamps.shape[0]\n",
    "    this_iou_array, this_idx_array = metrics.matching(events, detections)\n",
    "    matched_2 =  (this_idx_array > -1).sum()\n",
    "    print('%d were matched with E2 (%1.2f%% of previously unmatched detections)' % (matched_2, 100*matched_2 / fp_stamps.shape[0]))\n",
    "    # print(fp_stamps[this_idx_array[this_idx_array > -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
