{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import gridspec\n",
    "import pprint\n",
    "\n",
    "detector_path = '..'\n",
    "results_path = os.path.join(detector_path, 'results')\n",
    "sys.path.append(detector_path)\n",
    "\n",
    "from utils import constants\n",
    "from utils import errors\n",
    "from sleep.mass import MASS\n",
    "from sleep.inta import INTA\n",
    "from sleep import postprocessing\n",
    "from evaluation import metrics\n",
    "from evaluation import data_manipulation\n",
    "\n",
    "SEED = 123\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load database and predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select database\n",
    "dataset_name = constants.INTA_NAME\n",
    "# Select predictions ckpt folder\n",
    "\n",
    "# Best ones:\n",
    "# MASS: ckpt_folder = os.path.join('20190325_v2bn_fixed_loading_train_mass', 'bsf_avg')\n",
    "# INTA: ckpt_folder = os.path.join('20190328_v2bn_fixed_inta_train_inta', 'bsf_avg')\n",
    "ckpt_folder = os.path.join('20190328_v2bn_fixed_inta_train_inta', 'bsf_avg')\n",
    "verbose = False\n",
    "\n",
    "# Load data\n",
    "\n",
    "# Marks are binary sequences for each page, 200 fs resolution\n",
    "errors.check_valid_value(\n",
    "    dataset_name, 'dataset_name',\n",
    "    [constants.MASS_NAME, constants.INTA_NAME])\n",
    "if dataset_name == constants.MASS_NAME:\n",
    "    dataset = MASS(load_checkpoint=True)\n",
    "else:\n",
    "    dataset = INTA(load_checkpoint=True)\n",
    "\n",
    "    # Get training set ids\n",
    "print('Loading train set and splitting train/val')\n",
    "all_train_ids = dataset.train_ids\n",
    "# Split to form validation set\n",
    "train_ids, val_ids = data_manipulation.split_ids_list(\n",
    "    all_train_ids, seed=SEED)\n",
    "print('Training set IDs:', train_ids)\n",
    "print('Validation set IDs:', val_ids)\n",
    "# Get test data\n",
    "print('Loading test set')\n",
    "test_ids = dataset.test_ids\n",
    "print('Testing set IDs:', test_ids)\n",
    "\n",
    "# Get subjects data, with the expert used for training\n",
    "print('Loading signals and marks')\n",
    "set_list = ['train', 'val', 'test']\n",
    "x = {}\n",
    "y = {}\n",
    "pages = {}\n",
    "x['train'], y['train'] = dataset.get_subset_data(train_ids, which_expert=1, verbose=verbose)\n",
    "x['val'], y['val'] = dataset.get_subset_data(val_ids, which_expert=1, verbose=verbose)\n",
    "x['test'], y['test'] = dataset.get_subset_data(test_ids, which_expert=1, verbose=verbose)\n",
    "print('Loading pages')\n",
    "pages['train'] = dataset.get_subset_pages(train_ids, verbose=verbose)\n",
    "pages['val'] = dataset.get_subset_pages(val_ids, verbose=verbose)\n",
    "pages['test'] = dataset.get_subset_pages(test_ids, verbose=verbose)\n",
    "\n",
    "# Prepare expert labels into marks\n",
    "print('Preparing labels', flush=True)\n",
    "y_stamps = {}\n",
    "for set_name in set_list:\n",
    "    y_stamps[set_name] = postprocessing.generate_mark_intervals_with_list(\n",
    "        y[set_name], pages[set_name], 200, 200, thr=None, postprocess=False)\n",
    "\n",
    "# Load predictions (probability vectors for each page), 200/factor resolution (default factor 8)\n",
    "ckpt_path = os.path.abspath(os.path.join(results_path, 'predictions_%s' % dataset_name, ckpt_folder))\n",
    "print('Loading predictions from %s' % ckpt_path)\n",
    "y_pred = {}\n",
    "for set_name in set_list:\n",
    "    y_pred[set_name] = np.load(os.path.join(ckpt_path, 'y_pred_%s.npy' % set_name), allow_pickle=True)\n",
    "    # Keep only class 1 probability\n",
    "    y_pred[set_name] = [this_y_pred[..., 1] for this_y_pred in y_pred[set_name]]\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: F1 vs IoU curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Performance settings\n",
    "chosen_set = 'test'\n",
    "thr = 0.5\n",
    "\n",
    "# ---------------- Compute performance\n",
    "print('Using thr %1.4f and %s set' % (thr, chosen_set))\n",
    "\n",
    "# Prepare expert labels into marks\n",
    "y_thr = y_stamps[chosen_set]\n",
    "\n",
    "# Prepare model predictions\n",
    "print('Preparing predictions', flush=True)\n",
    "y_pred_thr = postprocessing.generate_mark_intervals_with_list(\n",
    "    y_pred[chosen_set], pages[chosen_set], 200//8, 200, thr=thr)\n",
    "n_subjects = len(y_thr)\n",
    "\n",
    "# Go through several IoU values\n",
    "print('Computing F1 Curve', flush=True)\n",
    "iou_list = np.arange(1, 10) * 0.1\n",
    "all_f1_list = [metrics.f1_vs_iou(this_y, this_y_pred, iou_list) \n",
    "               for (this_y, this_y_pred) \n",
    "               in zip(y_thr, y_pred_thr)]\n",
    "all_f1_list = np.stack(all_f1_list, axis=1)\n",
    "mean_f1 = np.mean(all_f1_list, axis=1)\n",
    "std_f1 = np.std(all_f1_list, axis=1)\n",
    "    \n",
    "model_f1_mean = np.stack([iou_list, mean_f1], axis=1)\n",
    "model_f1_std = np.stack([iou_list, std_f1], axis=1)\n",
    "print('Mean F1')\n",
    "pprint.pprint(model_f1_mean)\n",
    "print('Std F1')\n",
    "pprint.pprint(model_f1_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving settings\n",
    "save_f1_iou_result = False\n",
    "ckpt_id = 'avg_2019mar'\n",
    "\n",
    "# Comparison settings\n",
    "comparison_folder = 'comparison_data'\n",
    "compare_expert = True\n",
    "compare_chambon = True\n",
    "show_set_std = False\n",
    "alpha = 0.2\n",
    "colors = {'model': '#c62828', 'expert': '#455a64', 'chambon': '#0277bd'} \n",
    "zoom_xlim = [0.1, 0.7]\n",
    "zoom_ylim = [0.6, 0.85]\n",
    "linewidth_model = 2.5\n",
    "markersize_model = 12\n",
    "linewidth_others = 1.5\n",
    "markersize_others = 8\n",
    "\n",
    "# --------------- Optional: Save F1 data\n",
    "if save_f1_iou_result:\n",
    "    filename = os.path.join('comparison_data', '%s_f1_vs_iou_model_%s.csv' % (dataset_name, ckpt_id))\n",
    "    np.savetxt(filename, model_f1_mean, delimiter=\",\")\n",
    "\n",
    "\n",
    "# -------------------- P L O T ----------------------    \n",
    "# Comparison data\n",
    "if compare_expert:\n",
    "    expert_f1_curve_mean = np.loadtxt(os.path.join(comparison_folder, 'f1_vs_iou_expert_mean.csv'), delimiter=',')\n",
    "    expert_f1_curve_std = np.loadtxt(os.path.join(comparison_folder, 'f1_vs_iou_expert_std.csv'), delimiter=',')\n",
    "if compare_chambon:\n",
    "    chambon_f1_curve = np.loadtxt(os.path.join(comparison_folder, 'mass_f1_vs_iou_Chambon.csv'), delimiter=',')\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(9, 4), dpi=150)\n",
    "\n",
    "# Complete plot\n",
    "if compare_expert:\n",
    "    ax[0].plot(expert_f1_curve_mean[1:, 0], expert_f1_curve_mean[1:, 1], linewidth=linewidth_others, \n",
    "               markersize=markersize_others, marker='.', \n",
    "               label='Expert Performance', color=colors['expert'])\n",
    "    ax[0].fill_between(\n",
    "        expert_f1_curve_mean[1:, 0], \n",
    "        expert_f1_curve_mean[1:, 1] - expert_f1_curve_std[1:, 1], \n",
    "        expert_f1_curve_mean[1:, 1] + expert_f1_curve_std[1:, 1], \n",
    "        alpha=alpha, facecolor=colors['expert'])\n",
    "if compare_chambon:\n",
    "    ax[0].plot(chambon_f1_curve[:, 0], chambon_f1_curve[:, 1], linewidth=linewidth_others, \n",
    "               markersize=markersize_others, marker='.', \n",
    "               label='Chambon et al.', color=colors['chambon'])\n",
    "ax[0].plot(model_f1_mean[:, 0], model_f1_mean[:, 1], \n",
    "           linewidth=linewidth_model, markersize=markersize_model, marker='.', \n",
    "           label='Proposed Model', color=colors['model'])\n",
    "if show_set_std:\n",
    "    ax[0].fill_between(\n",
    "            model_f1_mean[:, 0], \n",
    "            model_f1_mean[:, 1] - model_f1_std[:, 1], \n",
    "            model_f1_mean[:, 1] + model_f1_std[:, 1], \n",
    "            alpha=alpha, facecolor=colors['model'])\n",
    "ax[0].set_title('Performance with $\\mu=%1.1f$ (%s)' % (thr, chosen_set), fontsize=11)\n",
    "ax[0].set_xlim([0, 1])\n",
    "ax[0].set_ylim([0, 1])\n",
    "ax[0].set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax[0].set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax[0].tick_params(labelsize=8.5)\n",
    "ax[0].set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax[0].set_ylabel('F1-score', fontsize=8.5)\n",
    "ax[0].grid()\n",
    "\n",
    "# Zoom plot\n",
    "if compare_expert:\n",
    "    ax[1].plot(expert_f1_curve_mean[1:, 0], expert_f1_curve_mean[1:, 1], \n",
    "               linewidth=linewidth_others, markersize=markersize_others, marker='.', \n",
    "               label='Expert Performance\\nPrivate Database\\nWarby et al. 2014', color=colors['expert'])\n",
    "    ax[1].fill_between(\n",
    "        expert_f1_curve_mean[1:, 0], \n",
    "        expert_f1_curve_mean[1:, 1] - expert_f1_curve_std[1:, 1], \n",
    "        expert_f1_curve_mean[1:, 1] + expert_f1_curve_std[1:, 1], \n",
    "        alpha=alpha, facecolor=colors['expert'])\n",
    "if compare_chambon:\n",
    "    ax[1].plot(chambon_f1_curve[:, 0], chambon_f1_curve[:, 1], \n",
    "               linewidth=linewidth_others, markersize=markersize_others, marker='.', \n",
    "               label='ConvNet\\nMASS Database\\nChambon et al. 2018', color=colors['chambon'])\n",
    "ax[1].plot(model_f1_mean[:, 0], model_f1_mean[:, 1], \n",
    "           linewidth=linewidth_model, markersize=markersize_model, marker='.', \n",
    "           label='Proposed Model\\n%s Database' % dataset_name.upper(), color=colors['model'])\n",
    "if show_set_std:\n",
    "    ax[1].fill_between(\n",
    "            model_f1_mean[:, 0], \n",
    "            model_f1_mean[:, 1] - model_f1_std[:, 1], \n",
    "            model_f1_mean[:, 1] + model_f1_std[:, 1], \n",
    "            alpha=alpha, facecolor=colors['model'])\n",
    "ax[1].set_title('Zoom in', fontsize=11)\n",
    "ax[1].set_xlim(zoom_xlim)\n",
    "ax[1].set_ylim(zoom_ylim)\n",
    "ax[1].set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "# ax[1].set_ylabel('F1-score')\n",
    "ax[1].tick_params(labelsize=8.5)\n",
    "ax[1].legend(loc='lower left', bbox_to_anchor=(1.05, 0.15), labelspacing=3, fontsize=8.5)\n",
    "ax[1].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: Precision-Recall plot, separated subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.5\n",
    "\n",
    "iou_thr = 0.3\n",
    "\n",
    "# Prepare model predictions\n",
    "be_stats = {}\n",
    "for set_name in set_list:\n",
    "    print('Preparing predictions for %s set' % set_name, flush=True)\n",
    "    y_pred_thr = postprocessing.generate_mark_intervals_with_list(\n",
    "        y_pred[set_name], pages[set_name], 200//8, 200, thr=thr)\n",
    "    be_stats[set_name] = [metrics.by_event_confusion(this_y, this_y_pred, iou_thr=iou_thr) \n",
    "                for (this_y, this_y_pred) in zip(y_stamps[set_name], y_pred_thr)]\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=150)\n",
    "text_space = 0.01\n",
    "markersize = 15\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=[0.6, 0.7, 0.8, 0.9])\n",
    "ax.clabel(CS, fontsize=7.5, fmt='%1.2f')\n",
    "\n",
    "# Scatter plots of each subject\n",
    "color_list = {'train':'#43a047', 'val':'#0288d1', 'test': '#c62828'}\n",
    "for set_name in set_list:\n",
    "    for i, stats in enumerate(be_stats[set_name]):\n",
    "        if i==0:\n",
    "            ax.scatter(stats['recall'], stats['precision'], c=color_list[set_name], label=set_name.capitalize(), s=markersize, zorder=10)\n",
    "        else:\n",
    "            ax.scatter(stats['recall'], stats['precision'], c=color_list[set_name], s=markersize, zorder=10)\n",
    "        ax.annotate(train_ids[i], (stats['recall']+text_space, stats['precision']+text_space), fontsize=7, color='#1b2631', zorder=20)  \n",
    "\n",
    "ax.set_title('Performance with $\\mu=%1.1f$ and IoU$>$%1.1f' % (thr, iou_thr), fontsize=11)\n",
    "ax.set_xlabel('Recall', fontsize=8.5)\n",
    "ax.set_ylabel('Precision', fontsize=8.5)\n",
    "ax.set_xlim([0.5, 1])\n",
    "ax.set_ylim([0.5, 1])\n",
    "ax.legend(loc='lower left', fontsize=8.5)\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: Precision-Recall curve, average per set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The mean of each set is drawn, for several thr\n",
    "\n",
    "iou_thr = 0.3\n",
    "thr_list = [0.05, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95]\n",
    "\n",
    "# Prepare model predictions\n",
    "pr_curve = {}\n",
    "n_thr = len(thr_list)\n",
    "for set_name in set_list:\n",
    "    print('Processing %s set' % set_name, flush=True)\n",
    "    pr_curve[set_name] = np.zeros((n_thr, 2))   # Columns are [x: recall, y: precision]\n",
    "    for i, thr in enumerate(thr_list):\n",
    "        print('Processing threshold %1.2f' % thr, flush=True)\n",
    "        y_pred_thr = postprocessing.generate_mark_intervals_with_list(\n",
    "            y_pred[set_name], pages[set_name], 200//8, 200, thr=thr)\n",
    "        this_stats = [metrics.by_event_confusion(this_y, this_y_pred, iou_thr=iou_thr) \n",
    "                    for (this_y, this_y_pred) in zip(y_stamps[set_name], y_pred_thr)]\n",
    "        this_recall = np.mean([m['recall'] for m in this_stats])\n",
    "        this_precision = np.mean([m['precision'] for m in this_stats])\n",
    "        pr_curve[set_name][i, 0] = this_recall\n",
    "        pr_curve[set_name][i, 1] = this_precision\n",
    "    print('Done', flush=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=150)\n",
    "markersize = 8\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=[0.6, 0.7, 0.8, 0.9])\n",
    "ax.clabel(CS, fontsize=7.5, fmt='%1.2f')\n",
    "\n",
    "# Scatter plots of each subset\n",
    "half_thr_idx = thr_list.index(0.5)\n",
    "color_list = {'train':'#43a047', 'val':'#0288d1', 'test': '#c62828'}\n",
    "for i, set_name in enumerate(set_list):\n",
    "    ax.plot(pr_curve[set_name][:, 0], pr_curve[set_name][:, 1], \n",
    "            label=set_name.capitalize(), markersize=markersize, marker='.', \n",
    "            linewidth=1.5, color=color_list[set_name], zorder=10*(i+1))\n",
    "# Highlight threshold=0.5\n",
    "for i, set_name in enumerate(set_list):\n",
    "    ax.scatter(pr_curve[set_name][half_thr_idx, 0], pr_curve[set_name][half_thr_idx, 1], \n",
    "               s=100, c=color_list[set_name], zorder=10*(i+1))\n",
    "\n",
    "ax.set_title('Performance with IoU$>$%1.1f' % iou_thr, fontsize=11)\n",
    "ax.set_xlabel('Recall', fontsize=8.5)\n",
    "ax.set_ylabel('Precision', fontsize=8.5)\n",
    "ax.set_xlim([0.5, 1])\n",
    "ax.set_ylim([0.5, 1])\n",
    "ax.legend(loc='lower left', fontsize=8.5)\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = 'train'\n",
    "subject_id = 10\n",
    "\n",
    "# -----\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "idx_subject = idx_dict[subset_name].index(subject_id)\n",
    "this_signal = x[subset_name][idx_subject]\n",
    "this_marks_1 = y[subset_name][idx_subject]\n",
    "this_n2_pages = pages[subset_name][idx_subject]\n",
    "this_prob = y_pred[subset_name][idx_subject]\n",
    "if dataset_name == constants.MASS_NAME:\n",
    "    _, this_marks_2 = dataset.get_subject_data(subject_id, which_expert=2, verbose=True)\n",
    "    channel_name = 'C3-CLE'\n",
    "else:\n",
    "    channel_name = 'F4-C4'\n",
    "    \n",
    "# make a color map of fixed colors\n",
    "cmap = colors.ListedColormap(['white', '#c62828'])\n",
    "\n",
    "def plot_page(page_idx):\n",
    "    if dataset_name == constants.MASS_NAME:\n",
    "        fig = plt.figure(figsize=(10, 5), dpi=150)\n",
    "        gs = gridspec.GridSpec(4, 1, height_ratios=[4, 1, 1, 1])\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(10, 4), dpi=150)\n",
    "        gs = gridspec.GridSpec(3, 1, height_ratios=[4, 1, 1])\n",
    "    \n",
    "    page_idx = page_idx - 1\n",
    "    \n",
    "    segment_signal = this_signal[page_idx, :]\n",
    "    segment_marks_1 = this_marks_1[page_idx, :]\n",
    "    segment_prob = this_prob[page_idx, :]\n",
    "    time_axis = np.arange(this_signal.shape[1]) / dataset.fs\n",
    "    \n",
    "    if dataset_name == constants.MASS_NAME:\n",
    "        segment_marks_2 = this_marks_2[page_idx, :]\n",
    "    \n",
    "    gs_idx = 0\n",
    "    \n",
    "    # Signal\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(time_axis, segment_signal, linewidth=1, color='#455a64')\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([0, 20])\n",
    "    ax.set_ylim([-10, 10])\n",
    "    ax.set_title('Subject %d (%s-%s). %s EEG channel. Page in record: %d (intervals of 0.5s are shown)' \n",
    "                 % (subject_id, dataset_name.upper(), subset_name.capitalize(), channel_name, this_n2_pages[page_idx]), fontsize=10)\n",
    "    ax.set_xticks([0, 5, 10, 15, 20])\n",
    "    ax.set_xticks(np.arange(0, 20, 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Expert mark\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.imshow(segment_marks_1[np.newaxis, :], interpolation=None, aspect='auto', cmap=cmap)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title('Expert ground truth (red indicates event)', fontsize=10)\n",
    "    \n",
    "    # Neural net\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(segment_prob, linewidth=1.5, color='#c62828')\n",
    "    ax.set_xticks([])\n",
    "    ax.set_ylim([-0.1, 1.1])\n",
    "    ax.set_xlim([0, 500])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticks([0.5], minor=True)\n",
    "    ax.grid(b=True, axis='y', which='minor')\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    ax.set_title('Model probability prediction (0.5 threshold is shown)', fontsize=10)\n",
    "    \n",
    "    if dataset_name == constants.MASS_NAME:\n",
    "        ax = fig.add_subplot(gs[gs_idx])\n",
    "        ax.imshow(segment_marks_2[np.newaxis, :], interpolation=None, aspect='auto', cmap=cmap)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Second expert, not used for training (red indicates event)', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(\n",
    "    lambda page_idx: plot_page(page_idx),\n",
    "    page_idx=widgets.IntSlider(min=1,max=this_n2_pages.shape[0],step=1,value=1, continuous_update=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
