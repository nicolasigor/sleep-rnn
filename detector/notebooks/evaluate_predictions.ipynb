{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import gridspec\n",
    "import pprint\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "detector_path = '..'\n",
    "results_path = os.path.join(detector_path, 'results')\n",
    "sys.path.append(detector_path)\n",
    "\n",
    "from utils import constants\n",
    "from utils import errors\n",
    "from sleep.mass import MASS\n",
    "from sleep.inta import INTA\n",
    "from sleep import postprocessing\n",
    "from sleep import data_ops\n",
    "from evaluation import metrics\n",
    "from evaluation import data_manipulation\n",
    "\n",
    "SEED = 123\n",
    "DPI = 200\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "The raw code for this IPython notebook is by default hidden for easier reading.\n",
    "To toggle on/off the raw code, click <a href=\"javascript:code_toggle()\">here</a>.''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load database and predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset mass with 15 patients.\n",
      "Train size: 11. Test size: 4\n",
      "Train subjects: \n",
      " [1, 3, 5, 7, 9, 10, 11, 14, 17, 18, 19]\n",
      "Test subjects: \n",
      " [2, 6, 12, 13]\n",
      "Loading from checkpoint... Loaded\n",
      "Loading train set and splitting train/val\n",
      "Split IDs: Total 11 -- Training 8\n",
      "Training set IDs: [1, 9, 10, 14, 17, 18, 7, 3]\n",
      "Validation set IDs: [11, 19, 5]\n",
      "Loading test set\n",
      "Testing set IDs: [2, 6, 12, 13]\n",
      "Loading signals and marks\n",
      "Loading pages\n",
      "Loading predictions from /home/ntapia/Projects/GitNico/ssdetection-rnn/detector/results/predictions_mass/20190408_bsf_train_mass/bsf/avg\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# Select database\n",
    "dataset_name = constants.MASS_NAME\n",
    "# Select predictions ckpt folder\n",
    "\n",
    "# Best ones:\n",
    "# MASS: ckpt_folder = os.path.join('20190325_v2bn_fixed_loading_train_mass', 'bsf_avg')\n",
    "# INTA: ckpt_folder = os.path.join('20190328_v2bn_fixed_inta_train_inta', 'bsf_avg')\n",
    "ckpt_folder = os.path.join('20190408_bsf_train_mass', 'bsf', 'avg')\n",
    "verbose = False\n",
    "\n",
    "# Load data\n",
    "\n",
    "# Marks are binary sequences for each page, 200 fs resolution\n",
    "errors.check_valid_value(\n",
    "    dataset_name, 'dataset_name',\n",
    "    [constants.MASS_NAME, constants.INTA_NAME])\n",
    "if dataset_name == constants.MASS_NAME:\n",
    "    dataset = MASS(load_checkpoint=True)\n",
    "else:\n",
    "    dataset = INTA(load_checkpoint=True)\n",
    "\n",
    "    # Get training set ids\n",
    "print('Loading train set and splitting train/val')\n",
    "all_train_ids = dataset.train_ids\n",
    "# Split to form validation set\n",
    "train_ids, val_ids = data_manipulation.split_ids_list(\n",
    "    all_train_ids, seed=SEED)\n",
    "print('Training set IDs:', train_ids)\n",
    "print('Validation set IDs:', val_ids)\n",
    "# Get test data\n",
    "print('Loading test set')\n",
    "test_ids = dataset.test_ids\n",
    "print('Testing set IDs:', test_ids)\n",
    "\n",
    "# Get subjects data, with the expert used for training\n",
    "print('Loading signals and marks')\n",
    "# set_list = ['train', 'val', 'test']\n",
    "set_list = ['test']\n",
    "x = {}\n",
    "y = {}\n",
    "pages = {}\n",
    "x['train'], y['train'] = dataset.get_subset_data(train_ids, which_expert=1, verbose=verbose)\n",
    "x['val'], y['val'] = dataset.get_subset_data(val_ids, which_expert=1, verbose=verbose)\n",
    "x['test'], y['test'] = dataset.get_subset_data(test_ids, which_expert=1, verbose=verbose)\n",
    "print('Loading pages')\n",
    "pages['train'] = dataset.get_subset_pages(train_ids, verbose=verbose)\n",
    "pages['val'] = dataset.get_subset_pages(val_ids, verbose=verbose)\n",
    "pages['test'] = dataset.get_subset_pages(test_ids, verbose=verbose)\n",
    "\n",
    "# Load predictions (probability vectors for each page), 200/factor resolution (default factor 8)\n",
    "ckpt_path = os.path.abspath(os.path.join(results_path, 'predictions_%s' % dataset_name, ckpt_folder))\n",
    "print('Loading predictions from %s' % ckpt_path)\n",
    "y_pred = {}\n",
    "for set_name in set_list:\n",
    "    y_pred[set_name] = np.load(os.path.join(ckpt_path, 'y_pred_%s.npy' % set_name), allow_pickle=True)\n",
    "    # Keep only class 1 probability\n",
    "    y_pred[set_name] = [this_y_pred[..., 1] for this_y_pred in y_pred[set_name]]\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing labels... Done\n"
     ]
    }
   ],
   "source": [
    "# Prepare expert labels into marks\n",
    "print('Preparing labels... ', end='', flush=True)\n",
    "y_stamps = {}\n",
    "for set_name in set_list:\n",
    "    y_stamps[set_name] = postprocessing.generate_mark_intervals_with_list(\n",
    "        y[set_name], pages[set_name], 200, 200, thr=None, postprocess=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing labels of E2... Done\n"
     ]
    }
   ],
   "source": [
    "# Load second expert in mass\n",
    "y2 = {}\n",
    "if dataset_name == constants.MASS_NAME:\n",
    "    _, y2['train'] = dataset.get_subset_data(train_ids, which_expert=2, verbose=verbose)\n",
    "    _, y2['val'] = dataset.get_subset_data(val_ids, which_expert=2, verbose=verbose)\n",
    "    _, y2['test'] = dataset.get_subset_data(test_ids, which_expert=2, verbose=verbose)\n",
    "print('Preparing labels of E2... ', end='', flush=True)\n",
    "y2_stamps = {}\n",
    "for set_name in set_list:\n",
    "    y2_stamps[set_name] = postprocessing.generate_mark_intervals_with_list(\n",
    "        y2[set_name], pages[set_name], 200, 200, thr=None, postprocess=False)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: F1 vs IoU curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Performance settings\n",
    "chosen_set = 'test'\n",
    "thr = 0.45\n",
    "\n",
    "# ---------------- Compute performance\n",
    "print('Using thr %1.4f and %s set' % (thr, chosen_set))\n",
    "\n",
    "# Prepare expert labels into marks\n",
    "y_thr = y_stamps[chosen_set]\n",
    "\n",
    "# Prepare model predictions\n",
    "print('Preparing predictions', flush=True)\n",
    "y_pred_thr = postprocessing.generate_mark_intervals_with_list(\n",
    "    y_pred[chosen_set], pages[chosen_set], 200//8, 200, thr=thr)\n",
    "n_subjects = len(y_thr)\n",
    "\n",
    "# Go through several IoU values\n",
    "print('Computing F1 Curve', flush=True)\n",
    "iou_list = np.arange(1, 10) * 0.1\n",
    "all_f1_list = [metrics.f1_vs_iou(this_y, this_y_pred, iou_list) \n",
    "               for (this_y, this_y_pred) \n",
    "               in zip(y_thr, y_pred_thr)]\n",
    "all_f1_list = np.stack(all_f1_list, axis=1)\n",
    "mean_f1 = np.mean(all_f1_list, axis=1)\n",
    "std_f1 = np.std(all_f1_list, axis=1)\n",
    "    \n",
    "model_f1_mean = np.stack([iou_list, mean_f1], axis=1)\n",
    "model_f1_std = np.stack([iou_list, std_f1], axis=1)\n",
    "print('Mean F1')\n",
    "pprint.pprint(model_f1_mean)\n",
    "print('Std F1')\n",
    "pprint.pprint(model_f1_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single metric: average F1 on validation set at threshold 0.5\n",
    "chosen_set_af1 = 'val'\n",
    "validation_af1 = metrics.average_f1_with_list(\n",
    "    y[chosen_set_af1], y_pred[chosen_set_af1], pages[chosen_set_af1])\n",
    "print('%s AF1: %1.4f' % (chosen_set_af1.capitalize(), validation_af1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving settings\n",
    "save_f1_iou_result = False\n",
    "ckpt_id = ''\n",
    "\n",
    "# Comparison settings\n",
    "comparison_folder = 'comparison_data'\n",
    "compare_expert = True\n",
    "compare_chambon = False\n",
    "show_set_std = False\n",
    "alpha = 0.2\n",
    "color_list = {'model': '#c62828', 'expert': '#455a64', 'chambon': '#0277bd'} \n",
    "zoom_xlim = [0.1, 0.7]\n",
    "zoom_ylim = [0.6, 0.85]\n",
    "linewidth_model = 2.5\n",
    "markersize_model = 12\n",
    "linewidth_others = 1.5\n",
    "markersize_others = 8\n",
    "\n",
    "# --------------- Optional: Save F1 data\n",
    "if save_f1_iou_result:\n",
    "    filename = os.path.join('comparison_data', '%s_f1_vs_iou_model_%s.csv' % (dataset_name, ckpt_id))\n",
    "    np.savetxt(filename, model_f1_mean, delimiter=\",\")\n",
    "\n",
    "\n",
    "# -------------------- P L O T ----------------------    \n",
    "# Comparison data\n",
    "if compare_expert:\n",
    "    expert_f1_curve_mean = np.loadtxt(os.path.join(comparison_folder, 'f1_vs_iou_expert_mean.csv'), delimiter=',')\n",
    "    expert_f1_curve_std = np.loadtxt(os.path.join(comparison_folder, 'f1_vs_iou_expert_std.csv'), delimiter=',')\n",
    "if compare_chambon:\n",
    "    chambon_f1_curve = np.loadtxt(os.path.join(comparison_folder, 'mass_f1_vs_iou_Chambon.csv'), delimiter=',')\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "\n",
    "# Complete plot\n",
    "if compare_expert:\n",
    "    ax.plot(expert_f1_curve_mean[1:, 0], expert_f1_curve_mean[1:, 1], linewidth=linewidth_others, \n",
    "               markersize=markersize_others, marker='.', \n",
    "               label='Expert Performance\\nPrivate Database\\nWarby et al. 2014', color=color_list['expert'])\n",
    "    ax.fill_between(\n",
    "        expert_f1_curve_mean[1:, 0], \n",
    "        expert_f1_curve_mean[1:, 1] - expert_f1_curve_std[1:, 1], \n",
    "        expert_f1_curve_mean[1:, 1] + expert_f1_curve_std[1:, 1], \n",
    "        alpha=alpha, facecolor=color_list['expert'])\n",
    "if compare_chambon:\n",
    "    ax.plot(chambon_f1_curve[:, 0], chambon_f1_curve[:, 1], linewidth=linewidth_others, \n",
    "               markersize=markersize_others, marker='.', \n",
    "               label='DOSED (ConvNet)\\nMASS Database\\nChambon et al. 2018', color=color_list['chambon'])\n",
    "ax.plot(model_f1_mean[:, 0], model_f1_mean[:, 1], \n",
    "           linewidth=linewidth_model, markersize=markersize_model, marker='.', \n",
    "           label='Proposed Model\\n%s Database' % dataset_name.upper(), color=color_list['model'])\n",
    "if show_set_std:\n",
    "    ax.fill_between(\n",
    "            model_f1_mean[:, 0], \n",
    "            model_f1_mean[:, 1] - model_f1_std[:, 1], \n",
    "            model_f1_mean[:, 1] + model_f1_std[:, 1], \n",
    "            alpha=alpha, facecolor=color_list['model'])\n",
    "ax.set_title('Performance with $\\mu=%1.3f$ (%s)' % (thr, chosen_set.capitalize()), fontsize=11)\n",
    "ax.set_xlim([0.08, 0.92])\n",
    "ax.set_ylim([0.08, 0.92])\n",
    "ax.set_yticks([0.1*i for i in range(1, 10)])\n",
    "ax.set_xticks([0.1*i for i in range(1, 10)])\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "ax.set_ylabel('F1-score', fontsize=8.5)\n",
    "ax.grid()\n",
    "\n",
    "# # Zoom plot\n",
    "# if compare_expert:\n",
    "#     ax[1].plot(expert_f1_curve_mean[1:, 0], expert_f1_curve_mean[1:, 1], \n",
    "#                linewidth=linewidth_others, markersize=markersize_others, marker='.', \n",
    "#                label='Expert Performance\\nPrivate Database\\nWarby et al. 2014', \n",
    "#                color=color_list['expert'])\n",
    "#     ax[1].fill_between(\n",
    "#         expert_f1_curve_mean[1:, 0], \n",
    "#         expert_f1_curve_mean[1:, 1] - expert_f1_curve_std[1:, 1], \n",
    "#         expert_f1_curve_mean[1:, 1] + expert_f1_curve_std[1:, 1], \n",
    "#         alpha=alpha, facecolor=color_list['expert'])\n",
    "# if compare_chambon:\n",
    "#     ax[1].plot(chambon_f1_curve[:, 0], chambon_f1_curve[:, 1], \n",
    "#                linewidth=linewidth_others, markersize=markersize_others, marker='.', \n",
    "#                label='DOSED (ConvNet)\\nMASS Database\\nChambon et al. 2018', color=color_list['chambon'])\n",
    "# ax[1].plot(model_f1_mean[:, 0], model_f1_mean[:, 1], \n",
    "#            linewidth=linewidth_model, markersize=markersize_model, marker='.', \n",
    "#            label='Proposed Model\\n%s Database' % dataset_name.upper(), color=color_list['model'])\n",
    "# if show_set_std:\n",
    "#     ax[1].fill_between(\n",
    "#             model_f1_mean[:, 0], \n",
    "#             model_f1_mean[:, 1] - model_f1_std[:, 1], \n",
    "#             model_f1_mean[:, 1] + model_f1_std[:, 1], \n",
    "#             alpha=alpha, facecolor=color_list['model'])\n",
    "# ax[1].set_title('Zoom in', fontsize=11)\n",
    "# ax[1].set_xlim(zoom_xlim)\n",
    "# ax[1].set_ylim(zoom_ylim)\n",
    "# ax[1].set_xlabel('IoU Threshold', fontsize=8.5)\n",
    "# # ax[1].set_ylabel('F1-score')\n",
    "# ax[1].tick_params(labelsize=8.5)\n",
    "# ax[1].legend(loc='lower left', bbox_to_anchor=(1.05, 0.15), labelspacing=3, fontsize=8.5)\n",
    "# ax[1].grid()\n",
    "\n",
    "ax.legend(loc='lower left', bbox_to_anchor=(1.05, 0.15), labelspacing=3, fontsize=7)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: Precision-Recall plot, separated subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = 0.45\n",
    "\n",
    "iou_thr = 0.3\n",
    "\n",
    "# Prepare model predictions\n",
    "be_stats = {}\n",
    "for set_name in set_list:\n",
    "    print('Preparing predictions for %s set' % set_name, flush=True)\n",
    "    y_pred_thr = postprocessing.generate_mark_intervals_with_list(\n",
    "        y_pred[set_name], pages[set_name], 200//8, 200, thr=thr)\n",
    "    be_stats[set_name] = [metrics.by_event_confusion(this_y, this_y_pred, iou_thr=iou_thr) \n",
    "                for (this_y, this_y_pred) in zip(y_stamps[set_name], y_pred_thr)]\n",
    "    print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "text_space = 0.01\n",
    "markersize = 20\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=[0.6, 0.7, 0.8, 0.9])\n",
    "ax.clabel(CS, fontsize=7.5, fmt='%1.2f')\n",
    "\n",
    "# Scatter plots of each subject\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "color_list = {'train':'#43a047', 'val':'#0288d1', 'test': '#c62828'}\n",
    "for set_name in set_list:\n",
    "    for i, stats in enumerate(be_stats[set_name]):\n",
    "        if i==0:\n",
    "            ax.scatter(stats['recall'], stats['precision'], c=color_list[set_name], label='Proposed (Ensemble of 4 runs)', s=markersize, zorder=10)\n",
    "        else:\n",
    "            ax.scatter(stats['recall'], stats['precision'], c=color_list[set_name], s=markersize, zorder=10)\n",
    "        ax.annotate(idx_dict[set_name][i], (stats['recall']+text_space, stats['precision']+text_space), fontsize=7, color='#1b2631', zorder=20)  \n",
    "\n",
    "ax.set_title('Test PR with $\\mu=%1.3f$ and IoU$>$%1.1f (%s)' % (thr, iou_thr, dataset_name.upper()), fontsize=10)\n",
    "ax.set_xlabel('Recall', fontsize=8.5)\n",
    "ax.set_ylabel('Precision', fontsize=8.5)\n",
    "ax.set_xlim([0.5, 1])\n",
    "ax.set_ylim([0.5, 1])\n",
    "ax.legend(loc='lower left', fontsize=6.5)\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance: Precision-Recall curve, average per set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# The mean of each set is drawn, for several thr\n",
    "\n",
    "iou_thr = 0.3\n",
    "thr_list = [0.1, 0.2, 0.3, 0.4, 0.475, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "# thr_list = [0.05*i for i in range(1, 20)]\n",
    "\n",
    "# Prepare model predictions\n",
    "pr_curve = {}\n",
    "n_thr = len(thr_list)\n",
    "for set_name in set_list:\n",
    "    print('Processing %s set' % set_name, flush=True)\n",
    "    pr_curve[set_name] = np.zeros((n_thr, 2))   # Columns are [x: recall, y: precision]\n",
    "    for i, thr in enumerate(thr_list):\n",
    "        print('Processing threshold %1.2f' % thr, flush=True)\n",
    "        y_pred_thr = postprocessing.generate_mark_intervals_with_list(\n",
    "            y_pred[set_name], pages[set_name], 200//8, 200, thr=thr)\n",
    "        this_stats = [metrics.by_event_confusion(this_y, this_y_pred, iou_thr=iou_thr) \n",
    "                    for (this_y, this_y_pred) in zip(y_stamps[set_name], y_pred_thr)]\n",
    "        this_recall = np.mean([m['recall'] for m in this_stats])\n",
    "        this_precision = np.mean([m['precision'] for m in this_stats])\n",
    "        pr_curve[set_name][i, 0] = this_recall\n",
    "        pr_curve[set_name][i, 1] = this_precision\n",
    "    print('Done', flush=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot settings\n",
    "show_train = False\n",
    "show_val = False\n",
    "\n",
    "thr_to_show = 0.475\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "fig, ax = plt.subplots(1, 1, figsize=(4, 4), dpi=DPI)\n",
    "markersize = 8\n",
    "\n",
    "# F1 score levels\n",
    "delta = 0.01 \n",
    "x_ = np.arange(1, 100) * delta \n",
    "y_ = np.arange(1, 100) * delta \n",
    "X, Y = np.meshgrid(x_, y_)\n",
    "Z = 2 * X * Y / (X + Y)\n",
    "CS = ax.contour(X, Y, Z, colors='k', alpha=0.3, levels=[0.6, 0.7, 0.8, 0.9])\n",
    "ax.clabel(CS, fontsize=7.5, fmt='%1.2f')\n",
    "\n",
    "set_list_aux = []\n",
    "if show_train:\n",
    "    set_list_aux.append('train')\n",
    "if show_val:\n",
    "    set_list_aux.append('val')\n",
    "set_list_aux.append('test')\n",
    "\n",
    "# Scatter plots of each subset\n",
    "half_thr_idx = thr_list.index(thr_to_show)\n",
    "color_list = {'train':'#43a047', 'val':'#0288d1', 'test': '#c62828'}\n",
    "for i, set_name in enumerate(set_list_aux):\n",
    "    ax.plot(pr_curve[set_name][:, 0], pr_curve[set_name][:, 1], \n",
    "            label=set_name.capitalize(), markersize=markersize, marker='.', \n",
    "            linewidth=1.5, color=color_list[set_name], zorder=10*(i+1))\n",
    "# Highlight threshold=0.5\n",
    "for i, set_name in enumerate(set_list_aux):\n",
    "    ax.scatter(pr_curve[set_name][half_thr_idx, 0], pr_curve[set_name][half_thr_idx, 1], \n",
    "               s=100, c=color_list[set_name], zorder=10*(i+1))\n",
    "    ax.annotate('$\\mu$=%1.3f' % thr_to_show, (pr_curve[set_name][half_thr_idx, 0] + text_space*2, pr_curve[set_name][half_thr_idx, 1] + text_space), fontsize=7, color='#1b2631', zorder=20)  \n",
    "\n",
    "ax.set_title('Performance with IoU$>$%1.1f (%s)' % (iou_thr, dataset_name.upper()), fontsize=11)\n",
    "ax.set_xlabel('Recall', fontsize=8.5)\n",
    "ax.set_ylabel('Precision', fontsize=8.5)\n",
    "ax.set_xlim([0.5, 1])\n",
    "ax.set_ylim([0.5, 1])\n",
    "ax.legend(loc='lower left', fontsize=8.5)\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_name = 'test'\n",
    "subject_id = 13\n",
    "\n",
    "# -----\n",
    "y_pred_thr = postprocessing.generate_mark_intervals(\n",
    "    y_pred[subset_name][idx_subject], pages[subset_name][idx_subject], 200//8, 200, thr=thr)\n",
    "y_pred_thr_seq = data_ops.inter2seq(y_pred_thr, 0, (pages[subset_name][idx_subject].max()+1)*200*20-1)\n",
    "# Now reshape into pages\n",
    "this_det = data_ops.extract_pages(y_pred_thr_seq, pages[subset_name][idx_subject], 200*20, border_size=0)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "idx_subject = idx_dict[subset_name].index(subject_id)\n",
    "this_signal = x[subset_name][idx_subject]\n",
    "this_marks_1 = y[subset_name][idx_subject]\n",
    "this_n2_pages = pages[subset_name][idx_subject]\n",
    "this_prob = y_pred[subset_name][idx_subject]\n",
    "if dataset_name == constants.MASS_NAME:\n",
    "    _, this_marks_2 = dataset.get_subject_data(subject_id, which_expert=2, verbose=True)\n",
    "    channel_name = 'C3-CLE'\n",
    "else:\n",
    "    channel_name = 'F4-C4'\n",
    "    \n",
    "# make a color map of fixed colors\n",
    "cmap = colors.ListedColormap(['white', '#c62828'])\n",
    "\n",
    "def plot_page(page_idx):\n",
    "    if dataset_name == constants.MASS_NAME:\n",
    "        fig = plt.figure(figsize=(10, 5), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(4, 1, height_ratios=[4, 1, 1, 1])\n",
    "    else:\n",
    "        fig = plt.figure(figsize=(10, 4), dpi=DPI)\n",
    "        gs = gridspec.GridSpec(3, 1, height_ratios=[4, 1, 1])\n",
    "    \n",
    "    page_idx = page_idx - 1\n",
    "    \n",
    "    segment_signal = this_signal[page_idx, :]\n",
    "    segment_marks_1 = this_marks_1[page_idx, :]\n",
    "    segment_prob = this_prob[page_idx, :]\n",
    "    segment_det = this_det[page_idx, :]\n",
    "    time_axis = np.arange(this_signal.shape[1]) / dataset.fs\n",
    "    \n",
    "    if dataset_name == constants.MASS_NAME:\n",
    "        segment_marks_2 = this_marks_2[page_idx, :]\n",
    "    \n",
    "    gs_idx = 0\n",
    "    \n",
    "    # Signal\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(time_axis, segment_signal, linewidth=1, color='#455a64')\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlim([0, 20])\n",
    "    ax.set_ylim([-8, 8])\n",
    "    ax.set_title('Subject %d (%s-%s). %s EEG channel. Page in record: %d (intervals of 0.5s are shown)' \n",
    "                 % (subject_id, dataset_name.upper(), subset_name.capitalize(), channel_name, this_n2_pages[page_idx]), fontsize=10)\n",
    "    ax.set_xticks([0, 5, 10, 15, 20])\n",
    "    ax.set_xticks(np.arange(0, 20, 0.5), minor=True)\n",
    "    ax.grid(b=True, axis='x', which='minor')\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    \n",
    "    # Expert mark\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.imshow(segment_marks_1[np.newaxis, :], interpolation=None, aspect='auto', cmap=cmap)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_title('Expert ground truth (red indicates event)', fontsize=10)\n",
    "    \n",
    "    # Neural net\n",
    "    ax = fig.add_subplot(gs[gs_idx])\n",
    "    gs_idx = gs_idx + 1\n",
    "    ax.plot(segment_prob, color='#c62828', linewidth=1.5)\n",
    "    ax.fill_between(np.arange(500), segment_det[::8], facecolor='k', alpha=0.3)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_ylim([-0.1, 1.1])\n",
    "    ax.set_xlim([0, 500])\n",
    "    ax.set_yticks([0, 1])\n",
    "    ax.set_yticks([thr], minor=True)\n",
    "    ax.grid(b=True, axis='y', linewidth=1.5, which='minor')\n",
    "    ax.tick_params(labelsize=8.5)\n",
    "    ax.set_title('Model probability prediction (%1.2f threshold and postprocessed detections are shown)' % thr, fontsize=10)\n",
    "    \n",
    "    if dataset_name == constants.MASS_NAME:\n",
    "        ax = fig.add_subplot(gs[gs_idx])\n",
    "        ax.imshow(segment_marks_2[np.newaxis, :], interpolation=None, aspect='auto', cmap=cmap)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_title('Second expert, not used for training (red indicates event)', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widgets.interact(\n",
    "    lambda page_idx: plot_page(page_idx),\n",
    "    page_idx=widgets.IntSlider(min=1,max=this_n2_pages.shape[0],step=1,value=1, continuous_update=False));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Postprocessing sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject 1/4\n",
      "Processing subject 2/4\n",
      "Processing subject 3/4\n",
      "Processing subject 4/4\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "chosen_set_error = 'test'\n",
    "thr = 0.45\n",
    "\n",
    "y_thr = y_stamps[chosen_set_error]\n",
    "\n",
    "# Prepare model predictions\n",
    "n_subjects = len(y_thr)\n",
    "pred_stamps = []\n",
    "for i in range(n_subjects):\n",
    "    print('Processing subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    # Binarize\n",
    "    this_y_pred_thr = (y_pred[chosen_set_error][i] >= thr).astype(np.int32)\n",
    "    # Transform to intervals\n",
    "    this_y_pred_thr = data_ops.seq2inter_with_pages(\n",
    "        this_y_pred_thr, pages[chosen_set_error][i]\n",
    "    )\n",
    "    pred_stamps.append(this_y_pred_thr)\n",
    "fs_pred = 200 // 8 \n",
    "fs_real = 200\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- Compute spacing ----------------------\n",
    "combine_thr = 0.3\n",
    "\n",
    "spacing = []\n",
    "spacing_expert = []\n",
    "for i in range(n_subjects):\n",
    "    print('Spacing for subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    this_spacing = (pred_stamps[i][1:, 0] - pred_stamps[i][:-1, 1]) / fs_pred\n",
    "    this_spacing_expert = (y_stamps[chosen_set_error][i][1:, 0] - y_stamps[chosen_set_error][i][:-1, 1]) / fs_real\n",
    "    # Only consider for this analysis, spacing less than one second\n",
    "    this_spacing = this_spacing[this_spacing < 1]\n",
    "    this_spacing_expert = this_spacing_expert[this_spacing_expert < 1]\n",
    "    spacing.append(this_spacing)\n",
    "    spacing_expert.append(this_spacing_expert)\n",
    "print('Done')\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Spacing between nearby expert marks', fontsize=10)\n",
    "ax[0, 1].set_title('Spacing between nearby detections', fontsize=10)\n",
    "y_max = 0\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Real\n",
    "    n_real, _, _ = ax[i, 0].hist(spacing_expert[i], bins=[k*0.1 for k in range(11)], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].set_xticks([k*0.2 for k in range(6)])\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "    # Predicted\n",
    "    n_pred, _, _ = ax[i, 1].hist(spacing[i], bins=[k*0.1 for k in range(11)], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].set_xticks([k*0.2 for k in range(6)])\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "    max_y = max(np.max(n_real), np.max(n_pred))\n",
    "    ax[i, 0].plot([combine_thr, combine_thr], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    ax[i, 1].plot([combine_thr, combine_thr], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    # y_max = max(max_y, y_max)\n",
    "# for i in range(n_subjects):\n",
    "#     ax[i, 0].plot([combine_thr, combine_thr], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "#     ax[i, 1].plot([combine_thr, combine_thr], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "ax[-1, 0].set_xlabel('Spacing [s]', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Spacing [s]', fontsize=8.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------- Durations\n",
    "\n",
    "durations = []\n",
    "durations_expert = []\n",
    "for i in range(n_subjects):\n",
    "    print('Durations for subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    # First, combine close marks\n",
    "    this_pred_stamps = postprocessing.combine_close_marks(pred_stamps[i], fs_pred, combine_thr)\n",
    "    # Now compute durations\n",
    "    this_durations = (this_pred_stamps[:, 1] - this_pred_stamps[:, 0]) / fs_pred\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    # Only consider for this analysis, spacing less than one second\n",
    "    durations.append(this_durations)\n",
    "    durations_expert.append(this_durations_expert)\n",
    "print('Done')\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Duration of expert marks', fontsize=10)\n",
    "ax[0, 1].set_title('Duration of detections', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "y_max = 0\n",
    "min_duration = 0.3  \n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Real\n",
    "    n_real, _, _ = ax[i, 0].hist(durations_expert[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "    # Predicted\n",
    "    n_pred, _, _ = ax[i, 1].hist(durations[i], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "    max_y = max(np.max(n_real), np.max(n_pred))\n",
    "    ax[i, 0].plot([min_duration, min_duration], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    ax[i, 1].plot([min_duration, min_duration], [0, max_y], '--', color='k', linewidth=2, alpha=0.6)\n",
    "    y_max = max(max_y, y_max)\n",
    "    \n",
    "#for i in range(n_subjects):\n",
    "#    ax[i, 0].plot([min_duration, min_duration], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "#    ax[i, 1].plot([min_duration, min_duration], [0, y_max], '--', color='k', linewidth=2, alpha=0.6)\n",
    "\n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Location of Falses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing subject 1/4\n",
      "(1139, 2) (1153, 2)\n",
      "Processing subject 2/4\n",
      "(150, 2) (134, 2)\n",
      "Processing subject 3/4\n",
      "(706, 2) (622, 2)\n",
      "Processing subject 4/4\n",
      "(691, 2) (976, 2)\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "iou_array = []\n",
    "idx_array = []\n",
    "y_pred_thr = []\n",
    "for i in range(n_subjects):\n",
    "    print('Processing subject %d/%d' % (i+1, n_subjects), flush=True)\n",
    "    events = y_stamps[chosen_set_error][i]\n",
    "    detections = postprocessing.generate_mark_intervals(\n",
    "        y_pred[chosen_set_error][i], pages[chosen_set_error][i], 200//8, 200, thr=thr)\n",
    "    print(events.shape, detections.shape)\n",
    "    this_iou_array, this_idx_array = metrics.matching(events, detections)\n",
    "    iou_array.append(this_iou_array)\n",
    "    idx_array.append(this_idx_array)\n",
    "    y_pred_thr.append(detections)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- False negatives\n",
    "iou_thr = 0.3\n",
    "\n",
    "fn_center = []\n",
    "for i in range(n_subjects):\n",
    "    idx_fn = iou_array[i] < iou_thr\n",
    "    fn_stamps = y_stamps[chosen_set_error][i][idx_fn]\n",
    "    this_fn_center = np.mean(fn_stamps, axis=1).astype(np.int32)\n",
    "    fn_center.append(this_fn_center)\n",
    "    \n",
    "# --- False positives\n",
    "fp_center = []\n",
    "for i in range(n_subjects):\n",
    "    # matched detections:\n",
    "    idx_fp_1 = iou_array[i] < iou_thr\n",
    "    idx_fp_1 = idx_array[i][idx_fp_1]\n",
    "    idx_fp_1 = [idx for idx in idx_fp_1 if idx != -1]\n",
    "    # Unmatched events\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    idx_fp = idx_fp_1 + idx_fp_2\n",
    "    fp_stamps = y_pred_thr[i][idx_fp]\n",
    "    this_fp_center = np.mean(fp_stamps, axis=1).astype(np.int32)\n",
    "    fp_center.append(this_fp_center)\n",
    "\n",
    "    \n",
    "# --- Histogram of IoU values across real events\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(3.5, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0].set_title('IoU values on expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].hist(iou_array[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), bins=[0.05*i for i in range(21)])\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "    ax[i].legend(fontsize=8.5, loc='upper center')\n",
    "    ax[i].set_xticks([0.2*i for i in range(6)])\n",
    "ax[-1].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "plt.show()\n",
    "    \n",
    "# --- Location in page\n",
    "fn_loc_page = [np.mod(this_fn_center, 20*fs_real) for this_fn_center in fn_center]\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Location of expert marks with IoU < %1.2f' % (iou_thr), fontsize=11)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 0].hist(fn_loc_page[i] / fs_real, bins=[i*4 for i in range(6)], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5, loc='upper center')\n",
    "ax[-1, 0].set_xticks([i*4 for i in range(6)])\n",
    "ax[-1, 0].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "\n",
    "fp_loc_page = [np.mod(this_fp_center, 20*fs_real) for this_fp_center in fp_center]\n",
    "\n",
    "ax[0, 1].set_title('Location of detections with IoU < %1.2f' % (iou_thr), fontsize=10)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 1].hist(fp_loc_page[i] / fs_real, bins=[i*4 for i in range(6)], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5, loc='upper center')\n",
    "ax[-1, 1].set_xticks([i*4 for i in range(6)])\n",
    "ax[-1, 1].set_xlabel('Time within page [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# --- Location in register\n",
    "\n",
    "fn_loc_register = [np.floor_divide(this_fn_center, 20*fs_real) for this_fn_center in fn_center]\n",
    "max_page_array = [np.max(pages[chosen_set_error][i]) for i in range(n_subjects)]\n",
    "\n",
    "max_of_all = np.max(max_page_array)\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Location in register of expert marks with IoU < %1.1f' % (iou_thr), fontsize=10)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 0].hist(fn_loc_register[i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "ax[-1, 0].set_xlim([0, max_of_all+10])\n",
    "ax[-1, 0].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "fp_loc_register = [np.floor_divide(this_fp_center, 20*fs_real) for this_fp_center in fp_center]\n",
    "max_page_array = [np.max(pages[chosen_set_error][i]) for i in range(n_subjects)]\n",
    "\n",
    "max_of_all = np.max(max_page_array)\n",
    "\n",
    "ax[0, 1].set_title('Location in register of detections with IoU < %1.1f' % (iou_thr), fontsize=11)\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i, 1].hist(fp_loc_register[i], color='#c62828', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "ax[-1, 1].set_xlim([0, max_of_all+10])\n",
    "ax[-1, 1].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ----- N2 pages\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(3.5, 1*n_subjects), dpi=DPI, sharex=True, sharey=True)\n",
    "ax[0].set_title('Location in register of N2 pages (%s)' % (chosen_set_error.capitalize()), fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].hist(pages[chosen_set_error][i], color='#455a64', label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()))\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "    ax[i].legend(fontsize=8.5)\n",
    "ax[-1].set_xlim([0, max_of_all+10])\n",
    "ax[-1].set_xlabel('Page within register', fontsize=8.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IoU vs Duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- Scatter of IoU values and duration of real and detected events\n",
    "alpha = 0.2\n",
    "markersize=10\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(7, 1*n_subjects), dpi=DPI, sharex=True, sharey=True)\n",
    "ax[0, 0].set_title('IoU vs duration of expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    ax[i, 0].scatter(this_durations_expert, iou_array[i], label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#455a64', alpha=alpha, s=markersize)\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 0].legend(fontsize=7, loc='lower right')\n",
    "    for lh in lg.legendHandles:\n",
    "        lh.set_facecolor(lh.get_facecolor())\n",
    "        lh.set_edgecolor(lh.get_edgecolor())\n",
    "        lh.set_alpha(1.0)\n",
    "    ax[i, 0].set_ylabel('IoU', fontsize=8.5)\n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('IoU vs duration of detections', fontsize=10)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations for IoU > 0 \n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    this_iou_1 = iou_array[i][idx_valid]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    this_durations_1 = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    # Now durations for IoU = 0\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_fp_2]\n",
    "    this_durations_2 = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    this_iou_2 = np.zeros(this_durations_2.shape[0])\n",
    "    # Concatenation\n",
    "    this_durations = np.concatenate([this_durations_1, this_durations_2])\n",
    "    this_iou = np.concatenate([this_iou_1, this_iou_2])\n",
    "    ax[i, 1].scatter(this_durations, this_iou, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#c62828', alpha=alpha, s=markersize)\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 1].legend(fontsize=7, loc='lower right')\n",
    "    for lh in lg.legendHandles:\n",
    "        lh.set_facecolor(lh.get_facecolor())\n",
    "        lh.set_edgecolor(lh.get_edgecolor())\n",
    "        lh.set_alpha(1.0)\n",
    "    # ax[i, 1].set_ylabel('IoU', fontsize=8.5)\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- Histogram of duration for IoU == 0\n",
    "fig, ax = plt.subplots(n_subjects, 2, figsize=(8, 1*n_subjects), dpi=DPI, sharex=True, sharey=False)\n",
    "ax[0, 0].set_title('Duration of unpaired expert marks', fontsize=10)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # Now compute durations\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    idx_zero = (iou_array[i] == 0)\n",
    "    this_durations_expert_fn = this_durations_expert[idx_zero]\n",
    "    ax[i, 0].hist(this_durations_expert_fn, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#455a64')\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    lg = ax[i, 0].legend(fontsize=8.5, loc='upper right')\n",
    "    \n",
    "ax[-1, 0].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('Duration of unpaired detections', fontsize=10)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp_2 = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    y_pred_stamps = y_pred_thr[i][idx_fp_2]\n",
    "    this_durations_fp = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    ax[i, 1].hist(this_durations_fp, label='S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), color='#c62828')\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5, loc='upper right')\n",
    "ax[-1, 1].set_xlabel('Duration [s]', fontsize=8.5)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration of events and matched detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "alpha = 0.2\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(5, 5), dpi=DPI, sharex=True, sharey=True)\n",
    "# plt.suptitle('Duration of matched events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    # Now compute durations for real\n",
    "    this_durations_expert = (y_stamps[chosen_set_error][i][:, 1] - y_stamps[chosen_set_error][i][:, 0]) / fs_real\n",
    "    this_durations_expert = this_durations_expert[idx_valid]\n",
    "    # Now compute durations for matched detections\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    this_durations_det = (y_pred_stamps[:, 1] - y_pred_stamps[:, 0]) / fs_real\n",
    "    if i<2:\n",
    "        ax[0, i].scatter(this_durations_expert, this_durations_det, label='S%02d' % subject_idx, color='#455a64', alpha=alpha)\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "        lg = ax[0, i].legend(fontsize=7)\n",
    "        for lh in lg.legendHandles:\n",
    "            lh.set_facecolor(lh.get_facecolor())\n",
    "            lh.set_edgecolor(lh.get_edgecolor())\n",
    "            lh.set_alpha(1.0)\n",
    "        max_dur = max(this_durations_expert.max(), this_durations_det.max())\n",
    "        ax[0, i].set_xlim([0, max_dur + 0.1])\n",
    "        ax[0, i].set_ylim([0, max_dur + 0.1])\n",
    "        if i == 0 :\n",
    "            ax[0, i].set_ylabel('Detected duration [s]', fontsize=8.5)\n",
    "        # ax[0, i].set_xlabel('Duration Real [s]', fontsize=8.5)\n",
    "        ax[0, i].plot([0.3, 2.0], [0.3, 2.0], '--k', alpha=0.6)\n",
    "    else:\n",
    "        ax[1, i-2].scatter(this_durations_expert, this_durations_det, label='S%02d' % subject_idx, color='#455a64', alpha=alpha)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "        lg = ax[1, i-2].legend(fontsize=7)\n",
    "        for lh in lg.legendHandles:\n",
    "            lh.set_facecolor(lh.get_facecolor())\n",
    "            lh.set_edgecolor(lh.get_edgecolor())\n",
    "            lh.set_alpha(1.0)\n",
    "        max_dur = max(this_durations_expert.max(), this_durations_det.max())\n",
    "        ax[1, i-2].set_xlim([0, max_dur + 0.1])\n",
    "        ax[1, i-2].set_ylim([0, max_dur + 0.1])\n",
    "        if i == 2:\n",
    "            ax[1, i-2].set_ylabel('Detected duration [s]', fontsize=8.5)\n",
    "        ax[1, i-2].set_xlabel('Real duration [s]', fontsize=8.5)\n",
    "        ax[1, i-2].plot([0.3, 2.0], [0.3, 2.0], '--k', alpha=0.6)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted probability to matched and unmatched events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare probabilities\n",
    "whole_y_proba = []\n",
    "for i in range(n_subjects):\n",
    "    this_proba = y_pred[chosen_set_error][i]\n",
    "    this_pages = pages[chosen_set_error][i]\n",
    "    page_size = this_proba.shape[1]\n",
    "    max_page = np.max(this_pages)\n",
    "    max_size = (max_page + 1) * page_size\n",
    "    whole_y_proba.append(np.zeros(max_size, dtype=np.float32))\n",
    "    for k, page in enumerate(this_pages):\n",
    "        sample_start = page * page_size\n",
    "        sample_end = (page + 1) * page_size\n",
    "        whole_y_proba[i][sample_start:sample_end] = this_proba[k, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching probabilities (Candidates for TP according to IoU)\n",
    "# It is expected that they have more than 0.5 since that is the threshold used for detection\n",
    "print('Processing probability for matched events', flush=True)\n",
    "matching_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for the valid detections stamps \n",
    "    idx_valid = (idx_array[i] > -1)\n",
    "    y_pred_stamps = y_pred_thr[i][idx_array[i]][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    y_pred_stamps = y_pred_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in y_pred_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    matching_proba.append(mean_proba_list)\n",
    "    \n",
    "# Unmatched real events (FN)\n",
    "# It is expected that they have less than 0.5 since they were missed by the tresholding\n",
    "print('Processing probability for unmatched real events', flush=True)\n",
    "unmatching_fn_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for the missed real events \n",
    "    idx_valid = (idx_array[i] == -1)\n",
    "    fn_stamps = y_stamps[chosen_set_error][i][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    fn_stamps = fn_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in fn_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    unmatching_fn_proba.append(mean_proba_list)\n",
    "    \n",
    "# Unmatched detected events (FP)\n",
    "# It is expected that they have more than 0.5 since they were detected\n",
    "print('Processing probability for unmatched detected events', flush=True)\n",
    "unmatching_fp_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # In this case, we look for detected events with no match \n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_valid = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    fp_stamps = y_pred_thr[i][idx_valid]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    fp_stamps = fp_stamps // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in fp_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    unmatching_fp_proba.append(mean_proba_list)\n",
    "    \n",
    "\n",
    "# Probability for real events\n",
    "print('Processing probability for real events', flush=True)\n",
    "real_proba = []\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    # And now we need to get the probabilities inside those stamps\n",
    "    # First, we downsample the stamps\n",
    "    y_pred_stamps = y_stamps[chosen_set_error][i] // 8\n",
    "    # Now, we get the mean probability between stamps\n",
    "    mean_proba_list = []\n",
    "    for stamp in y_pred_stamps:\n",
    "        proba_inside = whole_y_proba[i][stamp[0]:(stamp[1]+1)]\n",
    "        mean_proba_inside = proba_inside.mean()\n",
    "        mean_proba_list.append(mean_proba_inside)\n",
    "    mean_proba_list = np.array(mean_proba_list)\n",
    "    print('Mean probability for S%02d: %1.4f' % (subject_idx, mean_proba_list.mean()))\n",
    "    real_proba.append(mean_proba_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 3, figsize=(14, 3*n_subjects), dpi=100, sharex=True)\n",
    "\n",
    "ax[0, 0].set_title('Model output on matched events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 0].hist(matching_proba[i], label='S%02d' % subject_idx, color='#43a047')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 0].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 0].tick_params(labelsize=8.5)\n",
    "    ax[i, 0].legend(fontsize=8.5)\n",
    "ax[-1, 0].set_xlim([0, 1])\n",
    "ax[-1, 0].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "ax[0, 1].set_title('Probability on unmatched real events (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 1].hist(unmatching_fn_proba[i], label='S%02d' % subject_idx, color='#455a64')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 1].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 1].tick_params(labelsize=8.5)\n",
    "    ax[i, 1].legend(fontsize=8.5)\n",
    "ax[-1, 1].set_xlim([0, 1])\n",
    "ax[-1, 1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "ax[0, 2].set_title('Probability on unmatched detections (%s)' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i, 2].hist(unmatching_fp_proba[i], label='S%02d' % subject_idx, color='#c62828')\n",
    "    max_n = np.max(n)\n",
    "    ax[i, 2].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i, 2].tick_params(labelsize=8.5)\n",
    "    ax[i, 2].legend(fontsize=8.5)\n",
    "ax[-1, 2].set_xlim([0, 1])\n",
    "ax[-1, 2].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(n_subjects, 1, figsize=(6, 5*n_subjects), dpi=100, sharex=True)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    ax[i].set_title('Predicted probability for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=11)\n",
    "\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "max_n = 0\n",
    "for i in range(n_subjects):\n",
    "    \n",
    "    n, _, _ = ax[i].hist(\n",
    "        matching_proba[i], label='Matched real', color='#43a047', alpha=0.4, density=True,\n",
    "        bins = [i*0.05 for i in range(21)])\n",
    "    kernel = gaussian_kde(matching_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    ax[i].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    ax[i].tick_params(labelsize=8.5)\n",
    "ax[-1].set_xlim([0, 1])\n",
    "ax[-1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "# for i in range(n_subjects):\n",
    "#     subject_idx = idx_dict[chosen_set_error][i]\n",
    "#     n, _, _ = ax[i].hist(\n",
    "#         unmatching_fn_proba[i], label='Unmatched real', color='#455a64', alpha=0.4, density=True,\n",
    "#         bins = [i*0.05 for i in range(21)])\n",
    "#     kernel = gaussian_kde(unmatching_fn_proba[i])\n",
    "#     y_kde = kernel(x_points)\n",
    "#     ax[i].plot(x_points, y_kde, color='#455a64', linewidth=2)\n",
    "#     max_n = max(np.max(n), max_n)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n, _, _ = ax[i].hist(\n",
    "        unmatching_fp_proba[i], label='Unmatched detection', color='#c62828', alpha=0.4, density=True,\n",
    "        bins = [i*0.05 for i in range(21)])\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    ax[i].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "    ax[i].legend(fontsize=8.5, loc='upper left')\n",
    "    ax[i].set_yticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(2, 2, figsize=(6, 5), dpi=DPI, sharex=True)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    if i < 2:\n",
    "        ax[0, i].set_title('Model Output for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=10)\n",
    "    else:\n",
    "        ax[1, i-2].set_title('Model Output for S%02d (%s)' % (subject_idx, chosen_set_error.capitalize()), fontsize=10)\n",
    "\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "max_n = 0\n",
    "for i in range(n_subjects):\n",
    "    if i < 2:\n",
    "        n, _, _ = ax[0, i].hist(\n",
    "            real_proba[i], label='Expert marks', color='#43a047', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "    else:\n",
    "        n, _, _ = ax[1, i-2].hist(\n",
    "            real_proba[i], label='Real events\\n(Expert marks)', color='#43a047', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "    kernel = gaussian_kde(real_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    if i<2:\n",
    "        ax[0, i].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "        ax[0, i].set_xlim([0, 1])\n",
    "    else:\n",
    "        ax[1, i-2].plot(x_points, y_kde, color='#43a047', linewidth=2)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "        ax[1, i-2].set_xlim([0, 1])\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    \n",
    "\n",
    "# ax[-1].set_xlabel('Probability', fontsize=8.5)\n",
    "\n",
    "for i in range(n_subjects):\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    max_n = max(np.max(n), max_n)\n",
    "    if i<2:\n",
    "        n, _, _ = ax[0, i].hist(\n",
    "            unmatching_fp_proba[i], label='Unpaired detections ($\\mu$=0.1)', color='#c62828', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "        ax[0, i].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "        # ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "        # lg = ax[0, i].legend(fontsize=8.5, loc='upper center', bbox_to_anchor=(1.05, 0.15))\n",
    "        # for lh in lg.legendHandles:\n",
    "        #     lh.set_facecolor(lh.get_facecolor())\n",
    "        #     lh.set_alpha(1.0)\n",
    "        ax[0, i].set_yticks([])\n",
    "        ax[0, i].tick_params(labelsize=8.5)\n",
    "    else:\n",
    "        n, _, _ = ax[1, i-2].hist(\n",
    "            unmatching_fp_proba[i], label='False events\\n(Unpaired detections\\ngenerated with $\\mu$=0.1)', color='#c62828', alpha=0.4, density=True,\n",
    "            bins = [k*0.05 for k in range(21)])\n",
    "        ax[1, i-2].plot(x_points, y_kde, color='#c62828', linewidth=2)\n",
    "        # ax[i].plot([thr, thr], [0, max_n], '--', color='k', linewidth=1.5, alpha=0.6, label='thr')\n",
    "        ax[1, i-2].set_yticks([])\n",
    "        ax[1, i-2].set_xlabel('Class assignment', fontsize=8.5)\n",
    "        ax[1, i-2].tick_params(labelsize=8.5)\n",
    "lg = ax[1, 1].legend(fontsize=9, loc='upper left', bbox_to_anchor=(1.05, 1.35), labelspacing=3)\n",
    "for lh in lg.legendHandles:\n",
    "    lh.set_facecolor(lh.get_facecolor())\n",
    "    lh.set_alpha(1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Avg distributions over set\n",
    "\n",
    "\n",
    "# --- Histogram of probabilities\n",
    "\n",
    "n_points = 100\n",
    "x_points =np.arange(n_points + 1) / n_points\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(7, 5), dpi=100, sharex=True)\n",
    "\n",
    "ax.set_title('Predicted probability. Average for %s set' % (chosen_set_error.capitalize()), fontsize=11)\n",
    "\n",
    "y_kde_list = []\n",
    "for i in range(n_subjects):\n",
    "    kernel = gaussian_kde(matching_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    y_kde_list.append(y_kde)\n",
    "y_kde_avg_real = np.stack(y_kde_list, axis=1).mean(axis=1)\n",
    "ax.plot(x_points, y_kde_avg_real, color='#43a047', linewidth=2, label='Real event')\n",
    "ax.fill_between(x_points, y_kde_avg_real, 0*y_kde_avg_real, color='#43a047', alpha=0.4)\n",
    "\n",
    "y_kde_list = []\n",
    "for i in range(n_subjects):\n",
    "    kernel = gaussian_kde(unmatching_fp_proba[i])\n",
    "    y_kde = kernel(x_points)\n",
    "    y_kde_list.append(y_kde)\n",
    "y_kde_avg_false = np.stack(y_kde_list, axis=1).mean(axis=1)\n",
    "ax.plot(x_points, y_kde_avg_false, color='#c62828', linewidth=2, label='False event')\n",
    "ax.fill_between(x_points, y_kde_avg_false, 0*y_kde_avg_false, color='#c62828', alpha=0.4)\n",
    "\n",
    "max_y = max(np.max(y_kde_avg_real), np.max(y_kde_avg_false))\n",
    "\n",
    "# Find optimal threshold\n",
    "difference = y_kde_avg_false - y_kde_avg_real\n",
    "idx_thr = np.where(np.signbit(difference))[0][0]\n",
    "x_thr = x_points[idx_thr]\n",
    "print('Optimal Threshold: %1.4f' % x_thr)\n",
    "ax.plot([x_thr, x_thr], [0, max_y], '--', color='k', linewidth=1.5, alpha=0.6, label='Optimal Threshold')\n",
    "\n",
    "ax.tick_params(labelsize=8.5)\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, max_y])\n",
    "ax.set_yticks([])\n",
    "ax.legend(fontsize=8.5, loc='upper left')\n",
    "ax.set_xlabel('Probability', fontsize=8.5)\n",
    "ax.set_xticks([i*0.1 for i in range(11)])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of FP that are TP-E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "183 / 1153 (15.87 %) unmatched detections with E1 for S02\n",
      "176 were matched with E2 (96.17% of previously unmatched detections)\n",
      "\n",
      "28 / 134 (20.90 %) unmatched detections with E1 for S06\n",
      "27 were matched with E2 (96.43% of previously unmatched detections)\n",
      "\n",
      "67 / 622 (10.77 %) unmatched detections with E1 for S12\n",
      "65 were matched with E2 (97.01% of previously unmatched detections)\n",
      "\n",
      "328 / 976 (33.61 %) unmatched detections with E1 for S13\n",
      "292 were matched with E2 (89.02% of previously unmatched detections)\n"
     ]
    }
   ],
   "source": [
    "# Find unmatched events according to E1\n",
    "unmatched_stamps = []\n",
    "\n",
    "idx_dict = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n",
    "for i in range(n_subjects):\n",
    "    # Unmatched detections\n",
    "    subject_idx = idx_dict[chosen_set_error][i]\n",
    "    n_detections = y_pred_thr[i].shape[0]\n",
    "    idx_fp = [idx for idx in range(n_detections) if (idx not in idx_array[i])]\n",
    "    fp_stamps = y_pred_thr[i][idx_fp]\n",
    "    print('\\n%d / %d (%1.2f %%) unmatched detections with E1 for S%02d' % (fp_stamps.shape[0], n_detections, 100*fp_stamps.shape[0]/n_detections, subject_idx))\n",
    "    unmatched_stamps.append(fp_stamps)\n",
    "    # Now match with E2\n",
    "    events = y2_stamps[chosen_set_error][i]\n",
    "    detections = fp_stamps\n",
    "    n_detections = fp_stamps.shape[0]\n",
    "    this_iou_array, this_idx_array = metrics.matching(events, detections)\n",
    "    matched_2 =  (this_idx_array > -1).sum()\n",
    "    print('%d were matched with E2 (%1.2f%% of previously unmatched detections)' % (matched_2, 100*matched_2 / fp_stamps.shape[0]))\n",
    "    # print(fp_stamps[this_idx_array[this_idx_array > -1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
