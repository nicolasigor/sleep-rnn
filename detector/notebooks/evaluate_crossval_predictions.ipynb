{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from matplotlib import gridspec\n",
    "import pprint\n",
    "\n",
    "detector_path = '..'\n",
    "results_path = os.path.join(detector_path, 'results')\n",
    "sys.path.append(detector_path)\n",
    "\n",
    "from utils import constants\n",
    "from utils import errors\n",
    "from sleep.mass import MASS\n",
    "from sleep.inta import INTA\n",
    "from sleep import postprocessing\n",
    "from sleep import data_ops\n",
    "from evaluation import metrics\n",
    "from evaluation import data_manipulation\n",
    "\n",
    "SEED = 123\n",
    "DPI = 200\n",
    "\n",
    "%matplotlib inline\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load database and predicted probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 1. cargar las predicciones para todas las semillas, evaluar la curva para cada semilla en VAL,\n",
    "# mostrar todas las curvas superpuestas y ademas el promedio, y mostrar el PR de cada semilla.\n",
    "\n",
    "\n",
    "\n",
    "# Select database\n",
    "dataset_name = constants.MASS_NAME\n",
    "# Select predictions ckpt folder\n",
    "\n",
    "# Best ones:\n",
    "# MASS: ckpt_folder = os.path.join('20190325_v2bn_fixed_loading_train_mass', 'bsf_avg')\n",
    "# INTA: ckpt_folder = os.path.join('20190328_v2bn_fixed_inta_train_inta', 'bsf_avg')\n",
    "ckpt_folder = os.path.join('20190325_v2bn_fixed_loading_train_mass', 'bsf_avg')\n",
    "verbose = False\n",
    "\n",
    "# Load data\n",
    "\n",
    "# Marks are binary sequences for each page, 200 fs resolution\n",
    "errors.check_valid_value(\n",
    "    dataset_name, 'dataset_name',\n",
    "    [constants.MASS_NAME, constants.INTA_NAME])\n",
    "if dataset_name == constants.MASS_NAME:\n",
    "    dataset = MASS(load_checkpoint=True)\n",
    "else:\n",
    "    dataset = INTA(load_checkpoint=True)\n",
    "\n",
    "    # Get training set ids\n",
    "print('Loading train set and splitting train/val')\n",
    "all_train_ids = dataset.train_ids\n",
    "# Split to form validation set\n",
    "train_ids, val_ids = data_manipulation.split_ids_list(\n",
    "    all_train_ids, seed=SEED)\n",
    "print('Training set IDs:', train_ids)\n",
    "print('Validation set IDs:', val_ids)\n",
    "# Get test data\n",
    "print('Loading test set')\n",
    "test_ids = dataset.test_ids\n",
    "print('Testing set IDs:', test_ids)\n",
    "\n",
    "# Get subjects data, with the expert used for training\n",
    "print('Loading signals and marks')\n",
    "set_list = ['train', 'val', 'test']\n",
    "x = {}\n",
    "y = {}\n",
    "pages = {}\n",
    "x['train'], y['train'] = dataset.get_subset_data(train_ids, which_expert=1, verbose=verbose)\n",
    "x['val'], y['val'] = dataset.get_subset_data(val_ids, which_expert=1, verbose=verbose)\n",
    "x['test'], y['test'] = dataset.get_subset_data(test_ids, which_expert=1, verbose=verbose)\n",
    "print('Loading pages')\n",
    "pages['train'] = dataset.get_subset_pages(train_ids, verbose=verbose)\n",
    "pages['val'] = dataset.get_subset_pages(val_ids, verbose=verbose)\n",
    "pages['test'] = dataset.get_subset_pages(test_ids, verbose=verbose)\n",
    "\n",
    "# Load predictions (probability vectors for each page), 200/factor resolution (default factor 8)\n",
    "ckpt_path = os.path.abspath(os.path.join(results_path, 'predictions_%s' % dataset_name, ckpt_folder))\n",
    "print('Loading predictions from %s' % ckpt_path)\n",
    "y_pred = {}\n",
    "for set_name in set_list:\n",
    "    y_pred[set_name] = np.load(os.path.join(ckpt_path, 'y_pred_%s.npy' % set_name), allow_pickle=True)\n",
    "    # Keep only class 1 probability\n",
    "    y_pred[set_name] = [this_y_pred[..., 1] for this_y_pred in y_pred[set_name]]\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
