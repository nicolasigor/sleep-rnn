2019:

(Borrar marcados con X luego de armar ppt)

Idea para ajustar threshold (otro hiperparametro mas)
- 1. evaluar en varios val set por crossvalidation, y en cada uno calcular la distribucion de probabilidad de la salida de la red para reales (experto) y falsos, definiendo falsos como las detecciones no pareadas con experto usando thr=0.1 a la salida (i.e. sin importar el iou minimo). Luego promediar todas estas distribuciones para una estimacion robusta de como se verian en el test set, y ahi seleccionar el umbral que esta en el punto de igualdad. Ventaja: muy rapido, pero quizas no directamente relacionado con metrica final de interes (por el hecho de inventar qué es falso)
- 2. evaluar en varios val set por cross validation, y en cada uno calcular el f1 score con iou=0.3, para un arreglo de umbrales, por ejemplo 0.05:0.05:0.95, y promediar todas las corridas, de modo que se tiene una estimacion robusta de la  curva f1score vs thr. Seleccionar el que maximiza f1. Ventaja: metrica final de interes, pero demasiado lento.

[X] Reparación lectura MASS
[X] Reparación marcas INTA
[X] Implementación eficiente curva f1 vs IoU
[x] Upsampling de 25 a 200 Hz de las predicciones
[X] Implementación de curva PR con varios umbrales de probabilidad
[X] Mejoramiento estetico de graficos de evaluacion y visualizacion
[X] Implementacion de metrica escalar de validacion (Average F1)
[X] Reentrenamiento y guardar evaluacion de mejor modelo en MASS e INTA luego de reparaciones

[ ] Decidir por cross-validation mirando AF1 en validacion:
a.x BN o BRN (después del cambio de bn sobre el espectrograma)
b. Etapa convnet: resnet v2, o no residual.
c. Numero de unidades en LSTM.
d. Numero de unidades FC hidden (o bien sin esta capa)
e. Uso o no de logaritmo en espectrograma.

[ ] Analisis de error:
a.x Sensibilidad al postprocessing
b.x Localizacion de falsos a lo largo de las paginas (bordes?)
c.x IoU segun duracion de eventos reales
d.x IoU segun duracion de eventos detectados

[ ] Desempeño segun el numero de registros en train 


