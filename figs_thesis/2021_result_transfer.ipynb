{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05cb67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "project_root = '..'\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from sleeprnn.common import viz, constants\n",
    "from sleeprnn.helpers import reader, plotter, misc, performer\n",
    "from sleeprnn.detection import metrics, det_utils, ensemble\n",
    "from figs_thesis import fig_utils\n",
    "from baselines_scripts.butils import get_partitions\n",
    "from sleeprnn.detection.feeder_dataset import FeederDataset\n",
    "from sleeprnn.data import utils\n",
    "\n",
    "RESULTS_PATH = os.path.join(project_root, 'results')\n",
    "BASELINES_PATH = os.path.join(project_root, 'resources', 'comparison_data', 'baselines_2021')\n",
    "\n",
    "%matplotlib inline\n",
    "viz.notebook_full_width()\n",
    "\n",
    "param_filtering_fn = fig_utils.get_filtered_signal_for_event\n",
    "param_frequency_fn = fig_utils.get_frequency_by_fft\n",
    "param_amplitude_fn = fig_utils.get_amplitude_event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc881dd",
   "metadata": {},
   "source": [
    "# Mismo criterio de anotación (test subjects in-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17feb8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT',\n",
    "}\n",
    "print_dataset_names = {\n",
    "    (constants.MASS_SS_NAME, 1): \"MASS-SS2-E1SS\",\n",
    "    (constants.MASS_SS_NAME, 2): \"MASS-SS2-E2SS\",\n",
    "    (constants.MODA_SS_NAME, 1): \"MASS-MODA\",\n",
    "    (constants.INTA_SS_NAME, 1): \"INTA-UCH\",\n",
    "}\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=2, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.INTA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e83e4e",
   "metadata": {},
   "source": [
    "### PR by-subject, cheating\n",
    "\n",
    "```\n",
    "MASS-SS2-E1SS REDv2-Time (umbral original) F1-score 80.8670 ± 3.5689\n",
    "MASS-SS2-E1SS REDv2-CWT (umbral original) F1-score 80.9078 ± 3.3566\n",
    "\n",
    "MASS-SS2-E1SS REDv2-Time (umbral oráculo) F1-score 82.7517 ± 3.0363\n",
    "MASS-SS2-E1SS REDv2-CWT (umbral oráculo) F1-score 82.8609 ± 2.8293\n",
    "\n",
    "\n",
    "\n",
    "MASS-SS2-E2SS REDv2-Time (umbral original) F1-score 86.1270 ± 3.3854\n",
    "MASS-SS2-E2SS REDv2-CWT (umbral original) F1-score 86.1067 ± 3.4184\n",
    "\n",
    "MASS-SS2-E2SS REDv2-Time (umbral oráculo) F1-score 87.0420 ± 2.9517\n",
    "MASS-SS2-E2SS REDv2-CWT (umbral oráculo) F1-score 87.1587 ± 2.8882\n",
    "\n",
    "\n",
    "\n",
    "MASS-MODA REDv2-Time (umbral original) F1-score 78.5749 ± 7.0126\n",
    "MASS-MODA REDv2-CWT (umbral original) F1-score 78.4800 ± 6.9449\n",
    "\n",
    "MASS-MODA REDv2-Time (umbral oráculo) F1-score 80.9279 ± 5.8059\n",
    "MASS-MODA REDv2-CWT (umbral oráculo) F1-score 80.8579 ± 6.0169\n",
    "\n",
    "\n",
    "\n",
    "INTA-UCH REDv2-Time (umbral original) F1-score 83.8991 ± 4.7945\n",
    "INTA-UCH REDv2-CWT (umbral original) F1-score 83.5663 ± 5.2646\n",
    "\n",
    "INTA-UCH REDv2-Time (umbral oráculo) F1-score 84.4179 ± 4.3854\n",
    "INTA-UCH REDv2-CWT (umbral oráculo) F1-score 84.0723 ± 4.6876\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9e95a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_list = []\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        tmp_dict = fig_utils.get_red_predictions(model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        # Retrieve only predictions, same format as baselines\n",
    "        pred_dict[model_version] = {}\n",
    "        for k in tmp_dict.keys():\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "            pred_dict[model_version][k] = {s: pred for s, pred in zip(fold_subjects, fold_predictions)}\n",
    "    \n",
    "    # Measure performance by subject\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    table = {'Detector': [], 'F1-score': [], 'Recall': [], 'Precision': [], 'mIoU': [], 'Subject': [], 'Fold': []}\n",
    "    \n",
    "    # In MODA, only some subjects are used (N=28)\n",
    "    if config[\"dataset_name\"] == constants.MODA_SS_NAME:\n",
    "        valid_subjects = [\n",
    "            sub_id for sub_id in dataset.all_ids\n",
    "            if (dataset.data[sub_id]['n_blocks'] == 10)\n",
    "               and (sub_id not in ['01-01-0012', '01-01-0022'])\n",
    "        ]\n",
    "        print(\"moda, using n=\", len(valid_subjects))\n",
    "    else:\n",
    "        valid_subjects = dataset.all_ids\n",
    "    \n",
    "    for model_name in models:\n",
    "        for k in range(n_folds):\n",
    "            subject_ids = test_ids_list[k]\n",
    "            subject_ids = [s for s in subject_ids if s in valid_subjects]\n",
    "            feed_d = FeederDataset(dataset, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "            events_list = feed_d.get_stamps()\n",
    "            detections_list = [pred_dict[model_name][k][subject_id] for subject_id in subject_ids]\n",
    "            performance = fig_utils.compute_subject_performance(events_list, detections_list)\n",
    "            for i, subject_id in enumerate(subject_ids):\n",
    "                if subject_id in valid_subjects:\n",
    "                    table['Detector'].append(model_name)\n",
    "                    table['F1-score'].append(performance['F1-score'][i])\n",
    "                    table['Recall'].append(performance['Recall'][i])\n",
    "                    table['Precision'].append(performance['Precision'][i])\n",
    "                    table['mIoU'].append(performance['mIoU'][i])\n",
    "                    table['Subject'].append(subject_id)\n",
    "                    table['Fold'].append(k)\n",
    "    table = pd.DataFrame.from_dict(table)\n",
    "    metrics_list.append(table)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b184e853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheating performance\n",
    "cheat_thr_df = pd.read_csv('cheating_thresholds.csv')\n",
    "\n",
    "def get_cheat_thr(dataset_str, model_version, fold_id, subject_id):\n",
    "    subject_id = str(subject_id)\n",
    "    row = cheat_thr_df[\n",
    "        (cheat_thr_df.dataset == dataset_str) \n",
    "        & (cheat_thr_df.model == model_version)\n",
    "        & (cheat_thr_df.fold == fold_id)\n",
    "        & (cheat_thr_df.subject == subject_id)\n",
    "    ]\n",
    "    this_cheat_thr = row.cheat_thr.values.item()\n",
    "    return this_cheat_thr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7ec38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_cheat_list = []\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    dataset_str = print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])]\n",
    "    # In MODA, only some subjects are used (N=28)\n",
    "    if config[\"dataset_name\"] == constants.MODA_SS_NAME:\n",
    "        valid_subjects = [\n",
    "            sub_id for sub_id in dataset.all_ids\n",
    "            if (dataset.data[sub_id]['n_blocks'] == 10)\n",
    "               and (sub_id not in ['01-01-0012', '01-01-0022'])\n",
    "        ]\n",
    "        print(\"moda, using n=\", len(valid_subjects))\n",
    "    else:\n",
    "        valid_subjects = dataset.all_ids\n",
    "    \n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        tmp_dict = fig_utils.get_red_predictions(model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        # Retrieve only predictions, same format as baselines\n",
    "        pred_dict[model_version] = {}\n",
    "        for k in tmp_dict.keys():\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            pred_dict[model_version][k] = {}\n",
    "            for subject_id in fold_subjects:\n",
    "                if subject_id not in valid_subjects:\n",
    "                    continue\n",
    "                subject_cheat_thr = get_cheat_thr(dataset_str, model_version, k, subject_id)\n",
    "                tmp_dict[k][constants.TEST_SUBSET].set_probability_threshold(subject_cheat_thr)\n",
    "                subject_predictions = tmp_dict[k][constants.TEST_SUBSET].get_subject_stamps(subject_id)\n",
    "                pred_dict[model_version][k][subject_id] = subject_predictions\n",
    "    \n",
    "    # Measure performance by subject\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    table = {'Detector': [], 'F1-score': [], 'Recall': [], 'Precision': [], 'mIoU': [], 'Subject': [], 'Fold': []}\n",
    "    \n",
    "    for model_name in models:\n",
    "        for k in range(n_folds):\n",
    "            subject_ids = test_ids_list[k]\n",
    "            subject_ids = [s for s in subject_ids if s in valid_subjects]\n",
    "            feed_d = FeederDataset(dataset, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "            events_list = feed_d.get_stamps()\n",
    "            detections_list = [pred_dict[model_name][k][subject_id] for subject_id in subject_ids]\n",
    "            performance = fig_utils.compute_subject_performance(events_list, detections_list)\n",
    "            for i, subject_id in enumerate(subject_ids):\n",
    "                if subject_id in valid_subjects:\n",
    "                    table['Detector'].append(model_name)\n",
    "                    table['F1-score'].append(performance['F1-score'][i])\n",
    "                    table['Recall'].append(performance['Recall'][i])\n",
    "                    table['Precision'].append(performance['Precision'][i])\n",
    "                    table['mIoU'].append(performance['mIoU'][i])\n",
    "                    table['Subject'].append(subject_id)\n",
    "                    table['Fold'].append(k)\n",
    "    table = pd.DataFrame.from_dict(table)\n",
    "    metrics_cheat_list.append(table)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04dde908",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PR by-subject\n",
    "save_figure = True\n",
    "\n",
    "colors = {constants.V2_TIME: viz.PALETTE['blue'], constants.V2_CWT1D: viz.PALETTE['red']}\n",
    "marker_size = 5\n",
    "marker_alpha = 0.5\n",
    "letters = [\n",
    "    ['A', 'B', 'C', 'D'], \n",
    "    ['E', 'F', 'G', 'H'],\n",
    "    ['I', 'J', 'K', 'L'], \n",
    "    ['M', 'N', 'O', 'P'],\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(8, 7.2), dpi=200, sharex=True, sharey=True)\n",
    "\n",
    "for i_config, config in enumerate(eval_configs):\n",
    "    for i_cheat, m_list in enumerate([metrics_list, metrics_cheat_list]):\n",
    "        for j, model_version in enumerate(models):\n",
    "            row_value = j + i_cheat * 2\n",
    "            col_value = i_config\n",
    "            ax = axes[row_value, col_value]\n",
    "            table = m_list[i_config]\n",
    "            \n",
    "            model_str = print_model_names[model_version]\n",
    "            dataset_str = print_dataset_names[(config['dataset_name'], config['expert'])]\n",
    "            \n",
    "            # Form by-subject metrics \n",
    "            table_subject = table.drop(columns=[\"Fold\"]).groupby(by=[\"Detector\", \"Subject\"]).mean().reset_index()  # subject avg\n",
    "\n",
    "            table_model = table_subject[table_subject['Detector'] == model_version]\n",
    "            subjects = table_model['Subject'].values\n",
    "            recalls = table_model['Recall'].values\n",
    "            precisions = table_model['Precision'].values\n",
    "            \n",
    "            if config['dataset_name'] == constants.MODA_SS_NAME:\n",
    "                moda = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "                phases = [moda.data[sub_id]['phase'] for sub_id in subjects]\n",
    "                del moda\n",
    "            else:\n",
    "                phases = [1 for sub_id in subjects]\n",
    "\n",
    "            # Draw\n",
    "            marker_by_phase = {1: 'o', 2: 's'}\n",
    "            for r, p, ph in zip(recalls, precisions, phases):\n",
    "                ax.plot(\n",
    "                    r, p, color=colors[model_version], linestyle='None', alpha=marker_alpha,\n",
    "                    markeredgewidth=0.0, marker=marker_by_phase[ph], markersize=marker_size)\n",
    "            ax.plot(\n",
    "                [], [], color=colors[constants.V2_TIME], linestyle='None', alpha=1.0,\n",
    "                markeredgewidth=0.0, marker='o', markersize=marker_size, label=print_model_names[constants.V2_TIME])\n",
    "            ax.plot(\n",
    "                [], [], color=colors[constants.V2_CWT1D], linestyle='None', alpha=1.0,\n",
    "                markeredgewidth=0.0, marker='o', markersize=marker_size, label=print_model_names[constants.V2_CWT1D])\n",
    "            \n",
    "            cheat_str = '(umbral original)' if i_cheat == 0 else '(umbral oráculo)'\n",
    "            \n",
    "            f1_scores = 2 * recalls * precisions / (recalls + precisions)\n",
    "            f1_mean = np.mean(f1_scores)\n",
    "            f1_std = np.std(f1_scores)\n",
    "            f1_str = '%1.1f\\u00B1%1.1f' % (100 * f1_mean, 100 * f1_std)\n",
    "            \n",
    "            f1_str_to_plots = 'F1-score %1.4f \\u00B1 %1.4f' % (100 * f1_mean, 100 * f1_std)\n",
    "            print(dataset_str, model_str, cheat_str, f1_str_to_plots)\n",
    "            \n",
    "            \n",
    "            ax.set_title('%s\\n%s' % (dataset_str, cheat_str), fontsize=8, loc=\"left\")\n",
    "            \n",
    "            ax.text(x=0.51, y=0.51, fontsize=8, s='F1-score %s%%' % f1_str, ha='left', va='bottom')\n",
    "            \n",
    "            #ax.set_title('%s en %s' % (model_str, dataset_str), fontsize=8, loc=\"left\")\n",
    "\n",
    "            if False:\n",
    "                subjects = table_model['Subject'].values\n",
    "                print(\"\\n\", dataset_str, model_str, cheat_str)\n",
    "                sorted_locs = np.argsort(precisions)\n",
    "                for loc in sorted_locs:\n",
    "                    this_rec = recalls[loc]\n",
    "                    this_prec = precisions[loc]\n",
    "                    this_subject = subjects[loc]\n",
    "                    if this_prec < 0.71 or this_rec < 0.71:\n",
    "                        if config['dataset_name'] == constants.MODA_SS_NAME:\n",
    "                            this_phase = phases[loc]\n",
    "                        else:\n",
    "                            this_phase = -1\n",
    "                        print(\"Subject %s (%d), Recall %1.1f, Precision %1.1f\" % (this_subject, this_phase, this_rec * 100, this_prec * 100))\n",
    "\n",
    "            ax.text(\n",
    "                x=-0.12, y=1.08, fontsize=14, s=r\"$\\bf{%s}$\" % letters[row_value][col_value],\n",
    "                ha=\"center\", transform=ax.transAxes)\n",
    "\n",
    "        \n",
    "for ax in axes.flatten():\n",
    "    plotter.format_precision_recall_plot_simple(\n",
    "        ax, axis_range=(0.5, 1.0), \n",
    "        show_quadrants=False, show_grid=True, \n",
    "        axis_markers=[0.5, 1], minor_axis_markers=np.arange(0.5, 1 + 0.001, 0.1))\n",
    "    ax.tick_params(labelsize=8)\n",
    "    # Get labels closer to axis\n",
    "    ax.xaxis.labelpad = -8\n",
    "    ax.yaxis.labelpad = -8\n",
    "\n",
    "for ax in axes[:, 0]:\n",
    "    ax.set_ylabel(\"Precision\", fontsize=8)\n",
    "for ax in axes[-1, :]:\n",
    "    ax.set_xlabel(\"Recall\", fontsize=8)\n",
    "    \n",
    "\n",
    "axes[0, -1].legend(loc='upper left', bbox_to_anchor=(0.95, 1), fontsize=8, frameon=False, handletextpad=0.05)\n",
    "    \n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figure:\n",
    "    # Save figure\n",
    "    fname_prefix = \"result_transfer_indata_cheat_pr\"\n",
    "    plt.savefig(\"%s.pdf\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.png\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.svg\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ee0340",
   "metadata": {},
   "source": [
    "### Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58007581",
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers_dataset = {\n",
    "    (constants.MASS_SS_NAME, 1): [14],\n",
    "    (constants.MASS_SS_NAME, 2): [6, 18],\n",
    "    (constants.MODA_SS_NAME, 1): [\n",
    "        '01-01-0021', \n",
    "        # '01-01-0016', \n",
    "        # '01-05-0010', \n",
    "        '01-01-0013', \n",
    "        # '01-05-0004', \n",
    "        '01-01-0017'\n",
    "    ],\n",
    "    (constants.INTA_SS_NAME, 1): [3, 10],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748eec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier subjects' spectrum in N2\n",
    "freq_axis = None\n",
    "spectrums_list = []\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    dataset_str = print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])]\n",
    "    \n",
    "    # In MODA, only some subjects are used (N=28)\n",
    "    if config[\"dataset_name\"] == constants.MODA_SS_NAME:\n",
    "        valid_subjects = [\n",
    "            sub_id for sub_id in dataset.all_ids\n",
    "            if (dataset.data[sub_id]['n_blocks'] == 10)\n",
    "               and (sub_id not in ['01-01-0012', '01-01-0022'])\n",
    "        ]\n",
    "        print(\"moda, using n=\", len(valid_subjects))\n",
    "    else:\n",
    "        valid_subjects = dataset.all_ids\n",
    "    \n",
    "    spectrums = {}\n",
    "    for subject_id in valid_subjects:\n",
    "        signal = dataset.get_subject_signal(subject_id, normalize_clip=False, which_expert=config[\"expert\"])\n",
    "        n2_pages = dataset.get_subject_pages(subject_id, pages_subset='n2')\n",
    "        signal_valid = signal.reshape(-1, dataset.page_size)[n2_pages].flatten()\n",
    "        freq_axis, amp_axis = utils.power_spectrum_by_sliding_window(signal_valid, dataset.fs)\n",
    "        spectrums[subject_id] = amp_axis\n",
    "    spectrums_list.append(spectrums)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce7bccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_data_by_band(f, y, f_min=0, f_max=100):\n",
    "    locs = np.where((f >= f_min) & (f <= f_max))[0]\n",
    "    f = f[locs]\n",
    "    y = y[locs]\n",
    "    return f, y\n",
    "\n",
    "\n",
    "def get_original_id(dataset_name, custom_id):\n",
    "    \n",
    "    NAMES = [\n",
    "        'ADGU',\n",
    "        'ALUR',\n",
    "        'BECA',\n",
    "        'BRCA',\n",
    "        'BRLO',\n",
    "        'BTOL',\n",
    "        'CAPO',\n",
    "        'CRCA',\n",
    "        'ESCI',\n",
    "        'TAGO'\n",
    "    ]\n",
    "    \n",
    "    if dataset_name == constants.MODA_SS_NAME:\n",
    "        return custom_id\n",
    "    elif dataset_name == constants.MASS_SS_NAME:\n",
    "        return '01-02-%04d' % custom_id\n",
    "    else:\n",
    "        return NAMES[custom_id-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9dcc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figure = True\n",
    "\n",
    "f_min = 4\n",
    "f_max = 20\n",
    "color_series = ['blue', 'red', 'green']\n",
    "letters = ['A', 'B', 'C', 'D']\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(8, 3), dpi=200, sharey=True)\n",
    "max_y = 0\n",
    "for i_config, config in enumerate(eval_configs):\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    dataset_str = print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])]\n",
    "    \n",
    "    # In MODA, only some subjects are used (N=28)\n",
    "    if config[\"dataset_name\"] == constants.MODA_SS_NAME:\n",
    "        valid_subjects = [\n",
    "            sub_id for sub_id in dataset.all_ids\n",
    "            if (dataset.data[sub_id]['n_blocks'] == 10)\n",
    "               and (sub_id not in ['01-01-0012', '01-01-0022'])\n",
    "        ]\n",
    "        print(\"moda, using n=\", len(valid_subjects))\n",
    "    else:\n",
    "        valid_subjects = dataset.all_ids\n",
    "        \n",
    "    spectrums = spectrums_list[i_config]\n",
    "    this_outliers = outliers_dataset[(config[\"dataset_name\"], config[\"expert\"])]\n",
    "    \n",
    "    ax = axes[i_config]\n",
    "    highlight_count = 0\n",
    "    for subject_id in valid_subjects:\n",
    "        s = spectrums[subject_id]\n",
    "        f, s = reduce_data_by_band(freq_axis, s, f_min=f_min, f_max=f_max)\n",
    "        max_y = max(max_y, s.max())\n",
    "        if subject_id not in this_outliers:\n",
    "            ax.plot(f, s, linewidth=0.8, alpha=0.3, color=viz.GREY_COLORS[5], zorder=10)\n",
    "    \n",
    "    for i_high, subject_id in enumerate(this_outliers):\n",
    "        \n",
    "        # find number of annotations\n",
    "        events = dataset.get_subject_stamps(subject_id, which_expert=config['expert'], pages_subset='n2')\n",
    "        n2_pages = dataset.get_subject_pages(subject_id, pages_subset='n2')\n",
    "        subject_event_count = events.shape[0]\n",
    "        subject_density = subject_event_count / (n2_pages.size * dataset.page_duration / 60)\n",
    "        print(\"Subject %s, Dataset %s, Events %d, Density %1.2f\" % (subject_id, dataset_str, subject_event_count, subject_density))\n",
    "        \n",
    "        s = spectrums[subject_id]\n",
    "        f, s = reduce_data_by_band(freq_axis, s, f_min=f_min, f_max=f_max)\n",
    "        \n",
    "        # Here change ids to original (needed for MASS (01-02-etc) and INTA (BECA, TAGO etc))\n",
    "        subject_id_original = get_original_id(config[\"dataset_name\"], subject_id)\n",
    "        \n",
    "        ax.plot(\n",
    "            f, s, linewidth=1.5, alpha=0.8, zorder=20, color=viz.PALETTE[color_series[i_high]], \n",
    "            label=\"ID %s (%1.1f epm)\" % (subject_id_original, subject_density))\n",
    "\n",
    "    ax.legend(loc=\"upper right\", fontsize=7, handlelength=0.4)\n",
    "    \n",
    "    ax.tick_params(labelsize=8)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(\"Frecuencia (Hz)\", fontsize=8)\n",
    "    \n",
    "    title_str = '%s' % dataset_str\n",
    "    ax.set_title(title_str, fontsize=8, loc=\"center\")\n",
    "    \n",
    "    ax.text(\n",
    "        x=-0.01, y=1.03, fontsize=14, s=r\"$\\bf{%s}$\" % letters[i_config],\n",
    "        ha=\"left\", transform=ax.transAxes)\n",
    "    \n",
    "for ax in axes.flatten():\n",
    "    ax.set_ylim([0, max_y])\n",
    "    ax.set_xticks(np.arange(4, 20 + 0.001, 4))\n",
    "    ax.set_xticks(np.arange(4, 20 + 0.001, 2), minor=True)\n",
    "    ax.set_xlim([4, 20])\n",
    "    ax.grid(axis=\"x\", which=\"minor\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figure:\n",
    "    # Save figure\n",
    "    fname_prefix = \"result_transfer_indata_spectra\"\n",
    "    plt.savefig(\"%s.pdf\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.png\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.svg\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ae5cd",
   "metadata": {},
   "source": [
    "### Fracciones de sujetos válidas\n",
    "Con al menos un evento, también buscar sujeto más corto. En evernote:\n",
    "\n",
    "Preparar evolución F1-score: Estudiar si \"rho\" es % de páginas N2 (relativo a cada sujeto) o número de páginas N2 /minutos (absoluto). Ojalá minutos, para ello hay que estudiar los largos de los sujetos de las bases de interés y cuánto es el mínimo número de minutos para tener algún evento disponible (sobre todo en MASS-SS2-E1SS). Si es %, llegar solo hasta 50%, si es absoluto entonces seria llegar al 50% del sujeto más corto en cada dataset de forma independiente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846a7905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find shortest duration \n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    dataset_str = print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])]\n",
    "    \n",
    "    # In MODA, only some subjects are used (N=28)\n",
    "    if config[\"dataset_name\"] == constants.MODA_SS_NAME:\n",
    "        valid_subjects = [\n",
    "            sub_id for sub_id in dataset.all_ids\n",
    "            if (dataset.data[sub_id]['n_blocks'] == 10)\n",
    "               and (sub_id not in ['01-01-0012', '01-01-0022'])\n",
    "        ]\n",
    "        print(\"moda, using n=\", len(valid_subjects))\n",
    "    else:\n",
    "        valid_subjects = dataset.all_ids\n",
    "    \n",
    "    min_pages = 1e5\n",
    "    for subject_id in valid_subjects:\n",
    "        this_pages = dataset.get_subject_pages(subject_id, pages_subset='n2')\n",
    "        this_data_available = this_pages.size\n",
    "        min_pages = min(min_pages, this_data_available)\n",
    "    print(\"%s: shortest subject has %d N2 pages\" % (dataset_str, min_pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f09cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find cumulative distribution of events\n",
    "fig, axes = plt.subplots(2,2, figsize=(8, 6), dpi=200)\n",
    "axes = axes.flatten()\n",
    "for i_config, config in enumerate(eval_configs):\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    dataset_str = print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])]\n",
    "    \n",
    "    # In MODA, only some subjects are used (N=28)\n",
    "    if config[\"dataset_name\"] == constants.MODA_SS_NAME:\n",
    "        valid_subjects = [\n",
    "            sub_id for sub_id in dataset.all_ids\n",
    "            if (dataset.data[sub_id]['n_blocks'] == 10)\n",
    "               and (sub_id not in ['01-01-0012', '01-01-0022'])\n",
    "        ]\n",
    "        print(\"moda, using n=\", len(valid_subjects))\n",
    "    else:\n",
    "        valid_subjects = dataset.all_ids\n",
    "    \n",
    "    min_pages = 1e5\n",
    "    for subject_id in valid_subjects:\n",
    "        this_pages = dataset.get_subject_pages(subject_id, pages_subset='n2')\n",
    "        this_data_available = this_pages.size\n",
    "        min_pages = min(min_pages, this_data_available)\n",
    "    print(\"%s: shortest subject has %d N2 pages\" % (dataset_str, min_pages))\n",
    "    \n",
    "    maximum_to_try = min_pages // 2\n",
    "    \n",
    "    print(\"max number of N2 pages to try: %d (%1.2f minutes)\" % (maximum_to_try, maximum_to_try * dataset.page_duration / 60))\n",
    "    \n",
    "    p_possible = np.arange(1, maximum_to_try + 1)\n",
    "    all_cumulatives = []\n",
    "    for subject_id in valid_subjects:\n",
    "        this_events = dataset.get_subject_stamps(subject_id, which_expert=config['expert'], pages_subset='n2')\n",
    "        this_pages = dataset.get_subject_pages(subject_id, pages_subset='n2')\n",
    "        subject_cumulative_events = []\n",
    "        for p in p_possible:\n",
    "            subset_pages = this_pages[:p]\n",
    "            subset_events = utils.extract_pages_for_stamps(this_events, subset_pages, dataset.page_size)\n",
    "            n_events = subset_events.shape[0]\n",
    "            subject_cumulative_events.append(n_events)\n",
    "        subject_cumulative_events = np.array(subject_cumulative_events)\n",
    "        all_cumulatives.append(subject_cumulative_events)\n",
    "    \n",
    "    # now plot\n",
    "    p_possible_in_min = p_possible * dataset.page_duration / 60\n",
    "    ax = axes[i_config]\n",
    "    for subject_cumulative_events in all_cumulatives:\n",
    "        ax.plot(p_possible_in_min, subject_cumulative_events, linewidth=0.8, marker='o', markersize=3, alpha=0.8, color=viz.PALETTE['blue'])\n",
    "    ax.set_ylim([-0.2, 10])\n",
    "    ax.set_xlim([0, 15])\n",
    "    ax.set_xticks(np.arange(0, 15.5, 1))\n",
    "    ax.set_xlabel(\"N2 minutes\", fontsize=8)\n",
    "    ax.set_ylabel(\"Acc events\", fontsize=8)\n",
    "    ax.set_title(\"%s\\nmax to try %1.2f N2 min\" % (dataset_str, maximum_to_try * dataset.page_duration / 60), fontsize=8)\n",
    "    ax.tick_params(labelsize=8)\n",
    "    ax.grid()\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"acc_events_by_n2_minutes_per_subject.pdf\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ba6400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2740b6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c082f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6320114b",
   "metadata": {},
   "source": [
    "# Distinto criterio de anotacion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7d8c0a",
   "metadata": {},
   "source": [
    "### By-event SS params, different experts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be24c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_dataset_names = {\n",
    "    (constants.MASS_SS_NAME, 1): \"MASS-SS2-E1SS\",\n",
    "    (constants.MASS_SS_NAME, 2): \"MASS-SS2-E2SS\",\n",
    "    (constants.MASS_KC_NAME, 1): \"MASS-SS2-KC\",\n",
    "    (constants.MODA_SS_NAME, 1): \"MASS-MODA\",\n",
    "    (constants.INTA_SS_NAME, 1): \"INTA-UCH\",\n",
    "}\n",
    "\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=2, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.INTA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "\n",
    "table = {\n",
    "    'Detector': [],\n",
    "    'Duration': [], \n",
    "    'AmplitudePP': [],\n",
    "    'Frequency': [],\n",
    "}\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    if config[\"dataset_name\"] == constants.MODA_SS_NAME:\n",
    "        # process each phase independently\n",
    "        dataset_str_base = print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])]\n",
    "        dataset_str_list = [\n",
    "            '%s-Fase1' %  dataset_str_base,\n",
    "            '%s-Fase2' %  dataset_str_base,\n",
    "        ]\n",
    "        valid_subjects_list = [\n",
    "            [sub_id for sub_id in dataset.all_ids if dataset.data[sub_id]['phase'] == 1],\n",
    "            [sub_id for sub_id in dataset.all_ids if dataset.data[sub_id]['phase'] == 2],\n",
    "        ]\n",
    "    else:\n",
    "        dataset_str_list = [print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])]]\n",
    "        valid_subjects_list = [dataset.all_ids]\n",
    "    for dataset_str, valid_subjects in zip(dataset_str_list, valid_subjects_list):\n",
    "        # Retrieve parameters, all events together\n",
    "        tmp_table = {\n",
    "            'Duration': [], \n",
    "            'AmplitudePP': [],\n",
    "            'Frequency': [],\n",
    "        }\n",
    "        for subject_id in valid_subjects:\n",
    "            events = dataset.get_subject_stamps(\n",
    "                subject_id, which_expert=config['expert'], pages_subset=constants.N2_RECORD)\n",
    "            if events.size == 0:\n",
    "                continue\n",
    "            # Duration\n",
    "            duration = (events[:, 1] - events[:, 0] + 1) / dataset.fs\n",
    "            tmp_table['Duration'].append(duration)\n",
    "            # Amplitude\n",
    "            signal = dataset.get_subject_signal(\n",
    "                subject_id, normalize_clip=False, which_expert=config['expert'])\n",
    "            event_name = 'spindle'\n",
    "            filt_signal = param_filtering_fn(signal, dataset.fs, event_name)\n",
    "            signal_events = [filt_signal[e[0]:e[1]+1] for e in events]\n",
    "            amplitude = np.array([param_amplitude_fn(s, dataset.fs, event_name) for s in signal_events])\n",
    "            tmp_table['AmplitudePP'].append(amplitude)\n",
    "            # Frequency\n",
    "            freq_central = np.array([param_frequency_fn(s, dataset.fs) for s in signal_events])\n",
    "            tmp_table['Frequency'].append(freq_central)\n",
    "        table['Detector'].append(dataset_str)\n",
    "        for key in tmp_table.keys():\n",
    "            table[key].append(np.concatenate(tmp_table[key]))\n",
    "print(\"Metrics computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figure = False\n",
    "\n",
    "print_parameter = {\n",
    "    'Duration': 'Duración (s)', 'AmplitudePP': 'Amplitud PP ($\\mu$V)', 'Frequency': 'Frecuencia (Hz)'\n",
    "}\n",
    "\n",
    "min_values_forced = [0, 0, 9]\n",
    "max_values_forced = [3, 150, 17]\n",
    "major_ticks_forced = [[0, 1, 2, 3], [0, 50, 100, 150], [9, 11, 13, 15, 17]]\n",
    "minor_ticks_step_forced = [0.5, 25, 1]\n",
    "\n",
    "markersize = 8\n",
    "baseline_color = \"k\" # viz.GREY_COLORS[6]\n",
    "experts_specs = {\n",
    "    \"MASS-SS2-E1SS\": dict(marker='o', color=baseline_color),\n",
    "    \"MASS-SS2-E2SS\": dict(marker='s', color=baseline_color),\n",
    "    \"MASS-MODA-Fase1\": dict(marker='^', color=baseline_color),\n",
    "    \"MASS-MODA-Fase2\": dict(marker='v', color=baseline_color),\n",
    "    \"INTA-UCH\": dict(marker='p', color=baseline_color),\n",
    "}\n",
    "letters = ['A', 'B', 'C']\n",
    "fig, axes = plt.subplots(1, 3, figsize=(8, 3), dpi=200)\n",
    "\n",
    "param_names = ['Duration', 'AmplitudePP', 'Frequency']\n",
    "for i_p, param_name in enumerate(param_names):\n",
    "    ax = axes[i_p]\n",
    "    model_to_data = {m: d for m, d in zip(table['Detector'], table[param_name])}\n",
    "    this_order = table['Detector'][::-1]\n",
    "    x_data_list = [model_to_data[model_name] for model_name in this_order]\n",
    "    positions = np.arange(len(x_data_list))\n",
    "    parts = ax.violinplot(\n",
    "        x_data_list, vert=False, showextrema=False, positions=positions, widths=0.8\n",
    "    )\n",
    "    \n",
    "    for i_pc, pc in enumerate(parts['bodies']):\n",
    "        pc.set_facecolor(viz.GREY_COLORS[3])\n",
    "        pc.set_edgecolor(experts_specs[this_order[i_pc]][\"color\"])\n",
    "        pc.set_linewidth(0.7)\n",
    "        pc.set_alpha(1.0)\n",
    "        pc.set_zorder(20)\n",
    "    \n",
    "    for i_data, x_data in enumerate(x_data_list):\n",
    "        mean_val = x_data.mean()\n",
    "        model_name = this_order[i_data]\n",
    "        ax.plot(\n",
    "            mean_val, i_data, marker=\"x\",#model_specs[model_name][\"marker\"], \n",
    "            color=experts_specs[model_name][\"color\"], linestyle=\"None\", zorder=30,\n",
    "            markersize=4)\n",
    "        low_iqr, high_iqr = np.percentile(x_data, (25, 75))\n",
    "        ax.plot(\n",
    "            [low_iqr, high_iqr], [i_data, i_data], linewidth=0.8, zorder=30,\n",
    "            color=experts_specs[model_name][\"color\"])\n",
    "\n",
    "    min_pos_true = min_values_forced[i_p]\n",
    "    max_pos_true = max_values_forced[i_p]\n",
    "    for i_model, model_name in enumerate(this_order):\n",
    "        ax.plot(\n",
    "            min_pos_true - 0.1 * (max_pos_true - min_pos_true), i_model, \n",
    "            markersize=markersize, color=experts_specs[model_name][\"color\"], zorder=30, markeredgewidth=0.0,\n",
    "            label=model_name,\n",
    "            marker=experts_specs[model_name][\"marker\"], linestyle=\"None\")\n",
    "    min_pos_lim = min_pos_true - 0.2 * (max_pos_true - min_pos_true)\n",
    "    ax.set_xlim([min_pos_lim, max_pos_true])\n",
    "    ax.set_xticks(major_ticks_forced[i_p])\n",
    "    ax.set_xticks(\n",
    "        np.arange(\n",
    "            major_ticks_forced[i_p][0], \n",
    "            major_ticks_forced[i_p][-1]+0.001, \n",
    "            minor_ticks_step_forced[i_p]\n",
    "        ), minor=True)\n",
    "    # ax.set_title(\"hola\", fontsize=8, loc=\"left\")\n",
    "    ax.tick_params(labelsize=8)\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel(print_parameter[param_name], fontsize=8)\n",
    "    ax.text(\n",
    "        x=-0.01, y=1.02, fontsize=16, s=r\"$\\bf{%s}$\" % letters[i_p],\n",
    "        ha=\"left\", transform=ax.transAxes)\n",
    "    ax.xaxis.set_label_coords(0.6, -0.12)\n",
    "    ax.grid(axis=\"x\", which=\"minor\")\n",
    "        \n",
    "plt.tight_layout()\n",
    "\n",
    "# Get legend methods\n",
    "labels_to_lines_dict = {}\n",
    "for ax in axes:\n",
    "    t_lines, t_labels = ax.get_legend_handles_labels()\n",
    "    for lbl, lin in zip(t_labels, t_lines):\n",
    "        labels_to_lines_dict[lbl] = lin\n",
    "labels = [\n",
    "    'MASS-SS2-E1SS',\n",
    "    'MASS-SS2-E2SS',\n",
    "    'MASS-MODA-Fase1',\n",
    "    'MASS-MODA-Fase2',\n",
    "    'INTA-UCH']\n",
    "lines = [labels_to_lines_dict[lbl] for lbl in labels]\n",
    "lg1 = fig.legend(\n",
    "    lines, labels, fontsize=8, loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.5, 0.05), \n",
    "    ncol=len(labels), frameon=False, handletextpad=0.5)\n",
    "\n",
    "if save_figure:\n",
    "    # Save figure\n",
    "    fname_prefix = \"result_transfer_byevent_params\"\n",
    "    plt.savefig(\"%s.pdf\" % fname_prefix, bbox_extra_artists=(lg1,), bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.png\" % fname_prefix, bbox_extra_artists=(lg1,), bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.svg\" % fname_prefix, bbox_extra_artists=(lg1,), bbox_inches=\"tight\", pad_inches=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ae4f4f",
   "metadata": {},
   "source": [
    "### Efecto fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b518e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT',\n",
    "}\n",
    "print_dataset_names = {\n",
    "    (constants.MASS_SS_NAME, 1): \"MASS-SS2-E1SS\",\n",
    "    (constants.MASS_SS_NAME, 2): \"MASS-SS2-E2SS\",\n",
    "    (constants.MODA_SS_NAME, 1): \"MASS-MODA\",\n",
    "    (constants.INTA_SS_NAME, 1): \"INTA-UCH\",\n",
    "    (constants.CAP_SS_NAME, 1): \"CAP-A7\",\n",
    "}\n",
    "\n",
    "target_config = dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3)\n",
    "source_configs = [\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.CAP_SS_NAME, expert=1, strategy='5cv', seeds=1),\n",
    "]\n",
    "\n",
    "print(\"\\nLoading target:\", target_config)\n",
    "dataset = reader.load_dataset(target_config[\"dataset_name\"], verbose=False)\n",
    "average_mode = constants.MICRO_AVERAGE if (target_config[\"dataset_name\"] == constants.MODA_SS_NAME) else constants.MACRO_AVERAGE\n",
    "\n",
    "metrics_list = []\n",
    "for source_config in source_configs:\n",
    "    print(\"\\nLoading source:\", source_config)\n",
    "\n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        pred_dict[model_version] = {}\n",
    "        tmp_sizes_dict = fig_utils.get_red_predictions_for_moda_sizes(\n",
    "            model_version,\n",
    "            dataset,\n",
    "            source_dataset_name=source_config['dataset_name'],\n",
    "            source_expert=source_config['expert'],\n",
    "            overwrite_thr_with_constant=True,\n",
    "            verbose=True)\n",
    "        for size in tmp_sizes_dict.keys():\n",
    "            pred_dict[model_version][size] = {}\n",
    "            tmp_dict = tmp_sizes_dict[size]\n",
    "            # Retrieve only predictions, same format as baselines\n",
    "            for k in tmp_dict.keys():\n",
    "                fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "                fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "                pred_dict[model_version][size][k] = {s: pred for s, pred in zip(fold_subjects, fold_predictions)}\n",
    "\n",
    "    # Measure performance by subject (note that, independent from fraction, test sets are always complete)\n",
    "    _, _, test_ids_list = get_partitions(dataset, target_config[\"strategy\"], target_config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    table = {'Detector': [], 'Fracción': [], 'F1-score': [], 'Recall': [], 'Precision': [], 'mIoU': [], 'Fold': []}\n",
    "    for k in range(n_folds):\n",
    "        subject_ids = test_ids_list[k]\n",
    "        feed_d = FeederDataset(dataset, subject_ids, constants.N2_RECORD, which_expert=target_config[\"expert\"])\n",
    "        events_list = feed_d.get_stamps()\n",
    "        for model_version in models:\n",
    "            for size in tmp_sizes_dict.keys():\n",
    "                detections_list = [pred_dict[model_version][size][k][subject_id] for subject_id in subject_ids]\n",
    "                performance = fig_utils.compute_fold_performance(events_list, detections_list, average_mode)\n",
    "                table['Detector'].append(model_version)\n",
    "                table['Fracción'].append(size)\n",
    "                table['F1-score'].append(performance['F1-score'])\n",
    "                table['Recall'].append(performance['Recall'])\n",
    "                table['Precision'].append(performance['Precision'])\n",
    "                table['mIoU'].append(performance['mIoU'])\n",
    "                table['Fold'].append(k)\n",
    "    table = pd.DataFrame.from_dict(table)\n",
    "    metrics_list.append(table)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef465836",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = metrics_list[0]\n",
    "table.groupby(by=[\"Detector\", \"Fracción\"]).mean().drop(columns=[\"Fold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0dc3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = metrics_list[1]\n",
    "table.groupby(by=[\"Detector\", \"Fracción\"]).mean().drop(columns=[\"Fold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4776a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = metrics_list[2]\n",
    "table.groupby(by=[\"Detector\", \"Fracción\"]).mean().drop(columns=[\"Fold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baae56fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw\n",
    "save_figure = False\n",
    "\n",
    "letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H']\n",
    "colors_dict = {\n",
    "    constants.MODA_SS_NAME: 'blue',\n",
    "    constants.MASS_SS_NAME: 'red',\n",
    "    constants.CAP_SS_NAME: 'green'\n",
    "}\n",
    "show_std = False\n",
    "std_is_bar = False\n",
    "show_dosed_baseline = True\n",
    "dosed_metrics_reference = {'F1-score': (77.5,1.7), 'Recall': (76.4, 2.8), 'Precision': (78.9, 3.0), 'mIoU': (71.4, 1.1)}\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(8, 4), dpi=200, sharex=True, sharey=True)\n",
    "metric_order = ['F1-score', 'Recall', 'Precision', 'mIoU']\n",
    "for i_model, model_version in enumerate(models):\n",
    "    for i_m, metric_name in enumerate(metric_order):\n",
    "        ax = axes[i_model, i_m]\n",
    "        for i_config, source_config in enumerate(source_configs):\n",
    "            table = metrics_list[i_config]\n",
    "            table = table[table['Detector'] == model_version]\n",
    "            table = table[['Fracción', metric_name, 'Fold']]\n",
    "            table_mean = table.groupby(by=['Fracción']).mean().reset_index().to_dict(orient='list')\n",
    "            table_std = table.groupby(by=['Fracción']).std(ddof=0).reset_index().to_dict(orient='list')\n",
    "            sizes_list = table_mean['Fracción']\n",
    "            sizes_list = np.array([float(s) for s in sizes_list])\n",
    "            sorted_locs = np.argsort(sizes_list)\n",
    "            sizes_list = sizes_list[sorted_locs] / 100\n",
    "            mean_list = np.array(table_mean[metric_name])[sorted_locs]\n",
    "            std_list = np.array(table_std[metric_name])[sorted_locs]\n",
    "            \n",
    "            dataset_str = print_dataset_names[(source_config['dataset_name'], source_config['expert'])]\n",
    "            if dataset_str == 'MASS-MODA':\n",
    "                label_str = 'Sin pre-entrenamiento'\n",
    "            else:\n",
    "                label_str = 'Pre-entrenado en %s' % dataset_str\n",
    "            this_color_str = colors_dict[source_config['dataset_name']]\n",
    "            \n",
    "            if show_std and std_is_bar:\n",
    "                ax.errorbar(\n",
    "                    sizes_list, mean_list, yerr=std_list, label=label_str, \n",
    "                    linewidth=1, marker='o', markersize=3, \n",
    "                    color=viz.PALETTE[this_color_str],\n",
    "                    capsize=1.5, alpha=.8, zorder=20,\n",
    "                )\n",
    "            elif show_std and not std_is_bar:\n",
    "                ax.plot(\n",
    "                    sizes_list, mean_list, \n",
    "                    label=label_str,\n",
    "                    linewidth=1, marker='o', markersize=3, \n",
    "                    color=viz.PALETTE[this_color_str],\n",
    "                    alpha=.8, zorder=20,\n",
    "                )\n",
    "                ax.fill_between(\n",
    "                    sizes_list, \n",
    "                    mean_list + std_list,\n",
    "                    mean_list - std_list,\n",
    "                    facecolor=viz.PALETTE[this_color_str], alpha=0.4, zorder=20,\n",
    "                )\n",
    "            else:\n",
    "                ax.plot(\n",
    "                    sizes_list, mean_list, \n",
    "                    label=label_str,\n",
    "                    linewidth=1, marker='o', markersize=3, \n",
    "                    color=viz.PALETTE[this_color_str],\n",
    "                    alpha=.8, zorder=20,\n",
    "                )\n",
    "        if show_dosed_baseline:\n",
    "            metric_tuple = dosed_metrics_reference[metric_name]\n",
    "            dosed_mean = metric_tuple[0] / 100\n",
    "            ax.axhline(dosed_mean, linewidth=.8, linestyle=\"--\", color=\"k\", label=\"DOSED\", zorder=5)\n",
    "\n",
    "        model_str = print_model_names[model_version]\n",
    "        ax.set_title('%s, %s' % (model_str, metric_name), fontsize=8, loc=\"left\")\n",
    "\n",
    "y_max = 0.9\n",
    "y_min = 0.7\n",
    "        \n",
    "for i_ax, ax in enumerate(axes.flatten()):\n",
    "    # ax.legend(loc=\"lower right\", fontsize=8)\n",
    "    ax.tick_params(labelsize=8)\n",
    "    ax.set_xlim([-0.05, 1.05])\n",
    "    ax.set_xticks([0, 0.5, 1])\n",
    "    ax.set_xticks(np.arange(0, 1+0.001, 0.1), minor=True)\n",
    "    \n",
    "    ax.set_ylim([y_min, y_max])\n",
    "    ax.set_yticks(np.arange(y_min, y_max+0.001, 0.1))\n",
    "    ax.set_yticks(np.arange(y_min, y_max+0.001, 0.05), minor=True)\n",
    "    \n",
    "    ax.grid(which=\"minor\")\n",
    "    \n",
    "    if i_ax >= 4:\n",
    "        ax.set_xlabel(\"Fracción de señales\", fontsize=8)\n",
    "    \n",
    "    ax.text(\n",
    "        x=-0.08, y=1.05, fontsize=16, s=r\"$\\bf{%s}$\" % letters[i_ax],\n",
    "        ha=\"center\", transform=ax.transAxes)\n",
    "\n",
    "# outside legend, bottom, center\n",
    "# Get legend methods\n",
    "labels_to_lines_dict = {}\n",
    "for ax in axes.flatten():\n",
    "    t_lines, t_labels = ax.get_legend_handles_labels()\n",
    "    for lbl, lin in zip(t_labels, t_lines):\n",
    "        lin.set_alpha(1.0)\n",
    "        labels_to_lines_dict[lbl] = lin\n",
    "labels = list(labels_to_lines_dict.keys())\n",
    "lines = [labels_to_lines_dict[lbl] for lbl in labels]\n",
    "lg1 = fig.legend(\n",
    "    lines, labels, fontsize=8, loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.5, 0.03), ncol=len(labels), frameon=False, handletextpad=0.5)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figure:\n",
    "    # Save figure\n",
    "    fname_prefix = \"result_transfer_finetune_sizes\"\n",
    "    plt.savefig(\"%s.pdf\" % fname_prefix, bbox_extra_artists=(lg1,), bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.png\" % fname_prefix, bbox_extra_artists=(lg1,), bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.svg\" % fname_prefix, bbox_extra_artists=(lg1,), bbox_inches=\"tight\", pad_inches=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a529bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table for latex, only F1-score\n",
    "metric_name = 'F1-score'\n",
    "\n",
    "print(\"Fracción de    & Datos de          & \\multicolumn{2}{c}{F1-score (\\%)} \\\\\\\\\")\n",
    "print(\"señales (\\%)  & pre-entrenamiento & REDv2-Time & REDv2-CWT           \\\\\\\\\")\n",
    "\n",
    "rows_list = []\n",
    "for i_config, source_config in enumerate(source_configs):\n",
    "    dataset_str = print_dataset_names[(source_config['dataset_name'], source_config['expert'])]\n",
    "    \n",
    "    metrics_by_model = {}\n",
    "    for i_model, model_version in enumerate(models):\n",
    "        table = metrics_list[i_config]\n",
    "        table = table[table['Detector'] == model_version]\n",
    "        table = table[['Fracción', metric_name, 'Fold']]\n",
    "        table_mean = table.groupby(by=['Fracción']).mean().reset_index().to_dict(orient='list')\n",
    "        table_std = table.groupby(by=['Fracción']).std(ddof=0).reset_index().to_dict(orient='list')\n",
    "        sizes_list = table_mean['Fracción']\n",
    "        sizes_list = np.array([float(s) for s in sizes_list])\n",
    "        sorted_locs = np.argsort(sizes_list)\n",
    "        sizes_list = sizes_list[sorted_locs] / 100\n",
    "        mean_list = np.array(table_mean[metric_name])[sorted_locs]\n",
    "        std_list = np.array(table_std[metric_name])[sorted_locs]\n",
    "        metric_str_list = ['$%1.1f\\pm %1.1f$' % (100 * t_mean, 100 * t_std) for t_mean, t_std in zip(mean_list, std_list)]\n",
    "        metrics_by_model[model_version] = metric_str_list\n",
    "        \n",
    "    n_sizes = len(sizes_list)\n",
    "    for i_size in range(n_sizes):\n",
    "        pretrain_str = '-' if dataset_str == 'MASS-MODA' else dataset_str\n",
    "        row_str = '%d & %s & %s & %s \\\\\\\\' % (\n",
    "            100 * sizes_list[i_size], pretrain_str.ljust(15), \n",
    "            metrics_by_model[constants.V2_TIME][i_size], \n",
    "            metrics_by_model[constants.V2_CWT1D][i_size])\n",
    "        rows_list.append(row_str)\n",
    "    \n",
    "rows_list = np.sort(rows_list)\n",
    "for row in rows_list:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e2b2946",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
