{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "project_root = '..'\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from sleeprnn.common import viz, constants\n",
    "from sleeprnn.helpers import reader\n",
    "from sleeprnn.detection import metrics\n",
    "from figs_thesis import fig_utils\n",
    "from baselines_scripts.butils import get_partitions\n",
    "from sleeprnn.detection.feeder_dataset import FeederDataset\n",
    "\n",
    "RESULTS_PATH = os.path.join(project_root, 'results')\n",
    "BASELINES_PATH = os.path.join(project_root, 'resources', 'comparison_data', 'baselines_2021')\n",
    "\n",
    "%matplotlib inline\n",
    "viz.notebook_full_width()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379e1f62",
   "metadata": {},
   "source": [
    "# Tabla de desempeño (by-fold)\n",
    "Comparación con la literatura en desempeño in-dataset.\n",
    "Todos los P-value de REDv2-CWT son mayores a 0.05.\n",
    "Todos los P-value de baselines son menor a 0.001 excepto en INTA-UCH.\n",
    "Print esperado:\n",
    "```\n",
    "Detector & F1-score (\\%) & Recall (\\%) & Precision (\\%) & mIoU (\\%) \\\\\n",
    "\n",
    "MASS-SS2-E1SS (Fixed)\n",
    "REDv2-Time & $81.0\\pm 0.4$ & $83.7\\pm 1.2$ & $79.3\\pm 1.0$ & $84.8\\pm 0.2$ \\\\\n",
    "REDv2-CWT  & $80.7\\pm 0.5$ & $83.1\\pm 1.7$ & $79.4\\pm 2.1$ & $84.5\\pm 0.4$ \\\\\n",
    "DOSED      & $78.0\\pm 0.5$ & $77.7\\pm 2.4$ & $79.8\\pm 2.0$ & $75.3\\pm 1.3$ \\\\\n",
    "A7         & $69.7\\pm 0.4$ & $82.7\\pm 1.9$ & $61.2\\pm 1.5$ & $74.9\\pm 0.2$ \\\\\n",
    "\n",
    "MASS-SS2-E2SS (Fixed)\n",
    "REDv2-Time & $85.1\\pm 0.5$ & $84.5\\pm 1.0$ & $86.5\\pm 1.8$ & $77.8\\pm 0.2$ \\\\\n",
    "REDv2-CWT  & $85.0\\pm 0.4$ & $85.0\\pm 0.8$ & $86.0\\pm 1.4$ & $77.9\\pm 0.2$ \\\\\n",
    "DOSED      & $81.8\\pm 0.7$ & $79.7\\pm 1.4$ & $85.0\\pm 1.4$ & $73.8\\pm 0.5$ \\\\\n",
    "A7         & $73.4\\pm 0.1$ & $82.8\\pm 0.0$ & $66.4\\pm 0.2$ & $74.8\\pm 0.0$ \\\\\n",
    "\n",
    "MASS-SS2-KC (Fixed)\n",
    "REDv2-Time & $83.3\\pm 0.4$ & $82.4\\pm 1.0$ & $85.0\\pm 0.8$ & $90.5\\pm 0.2$ \\\\\n",
    "REDv2-CWT  & $83.4\\pm 0.5$ & $82.1\\pm 1.1$ & $85.7\\pm 0.8$ & $90.3\\pm 0.3$ \\\\\n",
    "DOSED      & $77.5\\pm 1.0$ & $76.5\\pm 1.9$ & $79.5\\pm 2.0$ & $72.2\\pm 1.3$ \\\\\n",
    "Spinky     & $65.7\\pm 0.2$ & $65.0\\pm 1.8$ & $67.7\\pm 2.2$ & $42.3\\pm 0.1$ \\\\\n",
    "\n",
    "MASS-MODA (5CV)\n",
    "REDv2-Time & $81.8\\pm 1.4$ & $83.5\\pm 2.5$ & $80.3\\pm 2.3$ & $83.1\\pm 0.5$ \\\\\n",
    "REDv2-CWT  & $81.5\\pm 1.2$ & $82.8\\pm 2.5$ & $80.3\\pm 2.4$ & $83.1\\pm 0.6$ \\\\\n",
    "DOSED      & $77.5\\pm 1.7$ & $76.4\\pm 2.8$ & $78.9\\pm 3.0$ & $71.4\\pm 1.1$ \\\\\n",
    "A7         & $73.3\\pm 1.9$ & $74.1\\pm 2.1$ & $72.8\\pm 3.6$ & $71.0\\pm 0.9$ \\\\\n",
    "\n",
    "INTA-UCH (5CV)\n",
    "REDv2-Time & $83.2\\pm 4.8$ & $85.0\\pm 5.4$ & $82.7\\pm 8.5$ & $75.8\\pm 2.7$ \\\\\n",
    "REDv2-CWT  & $83.2\\pm 4.7$ & $85.2\\pm 5.9$ & $82.7\\pm 8.1$ & $76.0\\pm 2.5$ \\\\\n",
    "DOSED      & $77.2\\pm 7.2$ & $78.0\\pm 12.6$ & $79.7\\pm 8.0$ & $68.7\\pm 3.9$ \\\\\n",
    "A7         & $77.6\\pm 5.4$ & $78.2\\pm 7.0$ & $79.9\\pm 10.8$ & $70.3\\pm 2.7$ \\\\\n",
    "\n",
    "MASS-SS2-E1SS (5CV)\n",
    "REDv2-Time & $80.8\\pm 2.1$ & $84.4\\pm 4.0$ & $78.9\\pm 5.4$ & $84.4\\pm 1.1$ \\\\\n",
    "REDv2-CWT  & $80.8\\pm 2.0$ & $84.9\\pm 4.3$ & $78.5\\pm 5.5$ & $84.3\\pm 1.2$ \\\\\n",
    "DOSED      & $76.8\\pm 2.9$ & $79.7\\pm 5.9$ & $77.5\\pm 7.8$ & $74.7\\pm 2.1$ \\\\\n",
    "A7         & $73.0\\pm 3.4$ & $80.1\\pm 4.0$ & $68.1\\pm 5.5$ & $73.9\\pm 1.0$ \\\\\n",
    "\n",
    "MASS-SS2-E2SS (5CV)\n",
    "REDv2-Time & $86.1\\pm 2.0$ & $87.0\\pm 3.7$ & $86.0\\pm 3.7$ & $78.5\\pm 1.1$ \\\\\n",
    "REDv2-CWT  & $86.0\\pm 2.2$ & $87.2\\pm 4.1$ & $85.7\\pm 4.3$ & $78.5\\pm 1.1$ \\\\\n",
    "DOSED      & $82.5\\pm 2.5$ & $84.0\\pm 5.0$ & $82.5\\pm 4.9$ & $73.1\\pm 1.1$ \\\\\n",
    "A7         & $74.9\\pm 2.8$ & $81.5\\pm 3.1$ & $70.0\\pm 4.3$ & $74.7\\pm 1.1$ \\\\\n",
    "\n",
    "MASS-SS2-KC (5CV)\n",
    "REDv2-Time & $83.6\\pm 1.5$ & $85.2\\pm 3.4$ & $82.9\\pm 3.2$ & $90.5\\pm 0.6$ \\\\\n",
    "REDv2-CWT  & $83.8\\pm 1.4$ & $85.0\\pm 2.4$ & $83.3\\pm 2.5$ & $90.4\\pm 0.5$ \\\\\n",
    "DOSED      & $77.5\\pm 2.4$ & $79.2\\pm 3.7$ & $76.5\\pm 3.6$ & $72.3\\pm 1.4$ \\\\\n",
    "Spinky     & $63.1\\pm 3.8$ & $61.6\\pm 3.5$ & $65.6\\pm 6.3$ & $41.2\\pm 1.6$ \\\\\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd28eabd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "baselines_ss = ['dosed', 'a7']\n",
    "baselines_kc = ['dosed', 'spinky']\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT',\n",
    "    'dosed': 'DOSED',\n",
    "    'a7': 'A7',\n",
    "    'spinky': 'Spinky'\n",
    "}\n",
    "\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=1, strategy='fixed', seeds=11),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=2, strategy='fixed', seeds=11),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='fixed', seeds=11),\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.INTA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=2, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    baselines = baselines_ss if dataset.event_name == constants.SPINDLE else baselines_kc\n",
    "    \n",
    "    # Collect predictions\n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        tmp_dict = fig_utils.get_red_predictions(model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        # Retrieve only predictions, same format as baselines\n",
    "        pred_dict[model_version] = {}\n",
    "        for k in tmp_dict.keys():\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "            pred_dict[model_version][k] = {s: pred for s, pred in zip(fold_subjects, fold_predictions)}\n",
    "    for baseline_name in baselines:\n",
    "        pred_dict[baseline_name] = fig_utils.get_baseline_predictions(baseline_name, config[\"strategy\"], config[\"dataset_name\"], config[\"expert\"])\n",
    "    # print(\"Loaded models:\", pred_dict.keys())\n",
    "    \n",
    "    # Measure performance byfold\n",
    "    average_mode = constants.MICRO_AVERAGE if (config[\"dataset_name\"] == constants.MODA_SS_NAME) else constants.MACRO_AVERAGE\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    table = {'Detector': [], 'F1-score': [], 'Recall': [], 'Precision': [], 'mIoU': [], 'Fold': []}\n",
    "    for model_name in pred_dict.keys():\n",
    "        for k in range(n_folds):\n",
    "            subject_ids = test_ids_list[k]\n",
    "            feed_d = FeederDataset(dataset, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "            events_list = feed_d.get_stamps()\n",
    "            detections_list = [pred_dict[model_name][k][subject_id] for subject_id in subject_ids]\n",
    "            performance = fig_utils.compute_fold_performance(events_list, detections_list, average_mode)\n",
    "            table['Detector'].append(model_name)\n",
    "            table['F1-score'].append(performance['F1-score'])\n",
    "            table['Recall'].append(performance['Recall'])\n",
    "            table['Precision'].append(performance['Precision'])\n",
    "            table['mIoU'].append(performance['mIoU'])\n",
    "            table['Fold'].append(k)\n",
    "    table = pd.DataFrame.from_dict(table)\n",
    "    print(\"By-fold statistics\")\n",
    "    metric_mean = table.groupby(by=[\"Detector\"]).mean().drop(columns=[\"Fold\"])\n",
    "    metric_std = table.groupby(by=[\"Detector\"]).std(ddof=0).drop(columns=[\"Fold\"])\n",
    "    print(\"Detector & F1-score (\\%) & Recall (\\%) & Precision (\\%) & mIoU (\\%) \\\\\\\\\")\n",
    "    for model_name in pred_dict.keys():\n",
    "        print(\"%s & %s & %s & %s & %s \\\\\\\\\" % (\n",
    "            print_model_names[model_name].ljust(10),\n",
    "            fig_utils.format_metric(metric_mean.at[model_name, \"F1-score\"], metric_std.at[model_name, \"F1-score\"]),\n",
    "            fig_utils.format_metric(metric_mean.at[model_name, \"Recall\"], metric_std.at[model_name, \"Recall\"]),\n",
    "            fig_utils.format_metric(metric_mean.at[model_name, \"Precision\"], metric_std.at[model_name, \"Precision\"]),\n",
    "            fig_utils.format_metric(metric_mean.at[model_name, \"mIoU\"], metric_std.at[model_name, \"mIoU\"]),\n",
    "        ))\n",
    "    # Statistical tests\n",
    "    reference_model_name = constants.V2_TIME\n",
    "    print(\"P-value test against %s\" % reference_model_name)\n",
    "    for model_name in pred_dict.keys():\n",
    "        model_metrics = table[table[\"Detector\"] == model_name][\"F1-score\"].values\n",
    "        reference_metrics = table[table[\"Detector\"] == reference_model_name][\"F1-score\"].values\n",
    "        pvalue = stats.ttest_ind(model_metrics, reference_metrics, equal_var=False)[1]\n",
    "        print(\"%s: P %1.4f\" % (print_model_names[model_name].ljust(10), pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d5003",
   "metadata": {},
   "source": [
    "# Dispersion by-subject\n",
    "5CV solamente por brevedad, ya que ya se vio que es similar el desempeño y permite tener todos los sujetos en MASS-SS2.\n",
    "\n",
    "Datos cuantitativos de dispersión entre sujetos (print esperado):\n",
    "```\n",
    "Dataset: MASS-SS2-E1SS\n",
    "          F1-score    Recall  Precision      mIoU\n",
    "Detector                                         \n",
    "a7        5.034115  6.698362   8.493331  2.332143\n",
    "dosed     5.065436  9.265257  13.893792  3.502857\n",
    "v2_cwt1d  3.443896  7.987251   8.489591  2.374149\n",
    "v2_time   3.575472  8.186777   8.515364  2.323281\n",
    "\n",
    "Dataset: MASS-SS2-E2SS\n",
    "          F1-score    Recall  Precision      mIoU\n",
    "Detector                                         \n",
    "a7        4.330717  5.803320   7.882029  1.664745\n",
    "dosed     4.163007  7.523092   8.901198  2.268538\n",
    "v2_cwt1d  3.483713  6.769644   6.658597  2.219977\n",
    "v2_time   3.329545  6.479800   6.366437  2.186028\n",
    "\n",
    "Dataset: MASS-SS2-KC\n",
    "          F1-score    Recall  Precision      mIoU\n",
    "Detector                                         \n",
    "dosed     3.960219  6.606413   6.062948  1.775579\n",
    "spinky    7.243040  6.883243  10.711108  2.448843\n",
    "v2_cwt1d  3.070712  6.027732   5.488672  0.810547\n",
    "v2_time   3.233140  6.605095   5.811940  0.966797\n",
    "\n",
    "Dataset: MASS-MODA\n",
    "           F1-score     Recall  Precision      mIoU\n",
    "Detector                                           \n",
    "a7        18.773054  22.023236  14.032634  6.618863\n",
    "dosed     13.233049  14.972821  13.520275  3.533990\n",
    "v2_cwt1d  10.929555  14.090439  10.262946  2.774643\n",
    "v2_time   11.000109  14.058725   9.195598  2.723617\n",
    "\n",
    "Dataset: INTA-UCH\n",
    "          F1-score     Recall  Precision      mIoU\n",
    "Detector                                          \n",
    "a7        7.567395   9.741852  13.076641  4.286478\n",
    "dosed     8.210749  13.977135   9.195159  4.280485\n",
    "v2_cwt1d  5.872097   8.169621   9.838274  3.862264\n",
    "v2_time   6.009940   7.387042  10.281951  4.194361\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "baselines_ss = ['dosed', 'a7']\n",
    "baselines_kc = ['dosed', 'spinky']\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT',\n",
    "    'dosed': 'DOSED',\n",
    "    'a7': 'A7',\n",
    "    'spinky': 'Spinky'\n",
    "}\n",
    "print_dataset_names = {\n",
    "    (constants.MASS_SS_NAME, 1): \"MASS-SS2-E1SS\",\n",
    "    (constants.MASS_SS_NAME, 2): \"MASS-SS2-E2SS\",\n",
    "    (constants.MASS_KC_NAME, 1): \"MASS-SS2-KC\",\n",
    "    (constants.MODA_SS_NAME, 1): \"MASS-MODA\",\n",
    "    (constants.INTA_SS_NAME, 1): \"INTA-UCH\",\n",
    "}\n",
    "\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=2, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.INTA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "dispersions_list = []\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    baselines = baselines_ss if dataset.event_name == constants.SPINDLE else baselines_kc\n",
    "    # Collect predictions\n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        tmp_dict = fig_utils.get_red_predictions(model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        # Retrieve only predictions, same format as baselines\n",
    "        pred_dict[model_version] = {}\n",
    "        for k in tmp_dict.keys():\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "            pred_dict[model_version][k] = {s: pred for s, pred in zip(fold_subjects, fold_predictions)}\n",
    "    for baseline_name in baselines:\n",
    "        pred_dict[baseline_name] = fig_utils.get_baseline_predictions(baseline_name, config[\"strategy\"], config[\"dataset_name\"], config[\"expert\"])\n",
    "    # Measure performance by subject\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    table = {'Detector': [], 'F1-score': [], 'Recall': [], 'Precision': [], 'mIoU': [], 'Subject': [], 'Fold': []}\n",
    "    if config[\"dataset_name\"] == constants.MODA_SS_NAME:\n",
    "        valid_subjects = [sub_id for sub_id in dataset.all_ids if dataset.data[sub_id]['n_blocks'] == 10]\n",
    "    else:\n",
    "        valid_subjects = dataset.all_ids\n",
    "    for model_name in pred_dict.keys():\n",
    "        for k in range(n_folds):\n",
    "            subject_ids = test_ids_list[k]\n",
    "            feed_d = FeederDataset(dataset, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "            events_list = feed_d.get_stamps()\n",
    "            detections_list = [pred_dict[model_name][k][subject_id] for subject_id in subject_ids]\n",
    "            performance = fig_utils.compute_subject_performance(events_list, detections_list)\n",
    "            for i, subject_id in enumerate(subject_ids):\n",
    "                if subject_id in valid_subjects:\n",
    "                    table['Detector'].append(model_name)\n",
    "                    table['F1-score'].append(performance['F1-score'][i])\n",
    "                    table['Recall'].append(performance['Recall'][i])\n",
    "                    table['Precision'].append(performance['Precision'][i])\n",
    "                    table['mIoU'].append(performance['mIoU'][i])\n",
    "                    table['Subject'].append(subject_id)\n",
    "                    table['Fold'].append(k)\n",
    "    table = pd.DataFrame.from_dict(table)\n",
    "    bysubject_dispersions = 100 * table.groupby([\"Detector\", \"Subject\"]).mean().drop(columns=[\"Fold\"]).groupby(\"Detector\").std(ddof=0)\n",
    "    dispersions_list.append(bysubject_dispersions)\n",
    "print(\"Dispersions computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c68727",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, config in enumerate(eval_configs):\n",
    "    print(\"\\nDataset: %s\" % print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])])\n",
    "    print(dispersions_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82f8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figure = False\n",
    "\n",
    "letters = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "fig, axes = plt.subplots(1, 5, figsize=(8, 3), dpi=200, sharex=True)\n",
    "for i, config in enumerate(eval_configs):\n",
    "    ax = axes[i]\n",
    "    disp_table = dispersions_list[i]\n",
    "    if config[\"dataset_name\"] == constants.MASS_KC_NAME:\n",
    "        extra_row = pd.DataFrame([[\"a7\", 0, 0, 0, 0]], columns=[\"Detector\", \"F1-score\", \"Recall\", \"Precision\", \"mIoU\"])\n",
    "        extra_row = extra_row.set_index(\"Detector\")\n",
    "        disp_table_mod = disp_table.append(extra_row).reindex([\"spinky\", \"a7\", \"dosed\", constants.V2_CWT1D, constants.V2_TIME])\n",
    "    else:\n",
    "        extra_row = pd.DataFrame([[\"spinky\", 0, 0, 0, 0]], columns=[\"Detector\", \"F1-score\", \"Recall\", \"Precision\", \"mIoU\"])\n",
    "        extra_row = extra_row.set_index(\"Detector\")\n",
    "        disp_table_mod = disp_table.append(extra_row).reindex([\"spinky\", \"a7\", \"dosed\", constants.V2_CWT1D, constants.V2_TIME])\n",
    "    \n",
    "    ax = disp_table_mod.plot.barh(y=[\"F1-score\", \"Recall\", \"Precision\"], ax=ax, fontsize=8, legend=False)\n",
    "    ax.set_title(print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])], loc=\"left\", fontsize=8)\n",
    "    \n",
    "    yticklabels = ax.get_yticklabels()\n",
    "    ax.set_yticklabels([print_model_names[yt.get_text()] for yt in yticklabels])\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_xlabel(\"$\\sigma_\\mathrm{subjects}$\", fontsize=8)\n",
    "    ax.tick_params(labelsize=8)\n",
    "    if i > 0:\n",
    "        ax.set_yticklabels([])\n",
    "    ax.set_xlim([0, 25])\n",
    "    ax.set_xticks([0, 10, 20])\n",
    "    ax.set_xticks([0, 2.5, 5, 7.5, 10, 12.5, 15, 17.5, 20, 22.5, 25], minor=True)\n",
    "    ax.grid(axis=\"x\", which=\"minor\")\n",
    "    ax.text(\n",
    "        x=-0.01, y=1.15, fontsize=16, s=r\"$\\bf{%s}$\" % letters[i],\n",
    "        ha=\"left\", transform=ax.transAxes)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Get legend\n",
    "lines_labels = [axes[0].get_legend_handles_labels()]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "# plt.subplots_adjust(bottom=0.9)\n",
    "lg = fig.legend(\n",
    "    lines, labels, fontsize=8, loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.5, 0.02), ncol=3, frameon=False, handletextpad=0.5)\n",
    "\n",
    "if save_figure:\n",
    "    # Save figure\n",
    "    fname_prefix = \"result_comparison_bysubject_std\"\n",
    "    plt.savefig(\"%s.pdf\" % fname_prefix, bbox_extra_artists=(lg,), bbox_inches=\"tight\", pad_inches=0.3)\n",
    "    plt.savefig(\"%s.png\" % fname_prefix, bbox_extra_artists=(lg,), bbox_inches=\"tight\", pad_inches=0.3)\n",
    "    plt.savefig(\"%s.svg\" % fname_prefix, bbox_extra_artists=(lg,), bbox_inches=\"tight\", pad_inches=0.3)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
