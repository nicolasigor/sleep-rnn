{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "948d6fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "project_root = '..'\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from sleeprnn.common import viz, constants\n",
    "from sleeprnn.helpers import reader, plotter, misc, performer\n",
    "from sleeprnn.detection import metrics\n",
    "from figs_thesis import fig_utils\n",
    "from baselines_scripts.butils import get_partitions\n",
    "from sleeprnn.detection.feeder_dataset import FeederDataset\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor\n",
    "from sleeprnn.data import utils\n",
    "\n",
    "RESULTS_PATH = os.path.join(project_root, 'results')\n",
    "BASELINES_PATH = os.path.join(project_root, 'resources', 'comparison_data', 'baselines_2021')\n",
    "\n",
    "%matplotlib inline\n",
    "viz.notebook_full_width()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac9e2f",
   "metadata": {},
   "source": [
    "# Comparación E1 y E2 en MASS-SS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518e7777",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_marks(dataset_name, expert):\n",
    "    dataset = reader.load_dataset(dataset_name, verbose=False)\n",
    "    marks_list = dataset.get_stamps(pages_subset=constants.N2_RECORD, which_expert=expert)\n",
    "    return marks_list\n",
    "\n",
    "\n",
    "events_list = get_marks(constants.MASS_SS_NAME, 1)\n",
    "detections_list = get_marks(constants.MASS_SS_NAME, 2)\n",
    "performance = fig_utils.compute_fold_performance(events_list, detections_list, constants.MACRO_AVERAGE)\n",
    "for metric_name in performance.keys():\n",
    "    print('%s: %1.1f%%' % (metric_name.ljust(10), 100 * performance[metric_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379e1f62",
   "metadata": {},
   "source": [
    "# Tabla de desempeño (by-fold)\n",
    "Comparación con la literatura en desempeño in-dataset.\n",
    "Todos los P-value de REDv2-CWT son mayores a 0.05.\n",
    "Todos los P-value de baselines son menor a 0.001 excepto en INTA-UCH.\n",
    "Print esperado:\n",
    "```\n",
    "Detector & F1-score (\\%) & Recall (\\%) & Precision (\\%) & mIoU (\\%) \\\\\n",
    "\n",
    "MASS-SS2-E1SS (Fixed)\n",
    "REDv2-Time & $81.0\\pm 0.4$ & $83.7\\pm 1.2$ & $79.3\\pm 1.0$ & $84.8\\pm 0.2$ \\\\\n",
    "REDv2-CWT  & $80.7\\pm 0.5$ & $83.1\\pm 1.7$ & $79.4\\pm 2.1$ & $84.5\\pm 0.4$ \\\\\n",
    "DOSED      & $78.0\\pm 0.5$ & $77.7\\pm 2.4$ & $79.8\\pm 2.0$ & $75.3\\pm 1.3$ \\\\\n",
    "A7         & $69.7\\pm 0.4$ & $82.7\\pm 1.9$ & $61.2\\pm 1.5$ & $74.9\\pm 0.2$ \\\\\n",
    "\n",
    "MASS-SS2-E2SS (Fixed)\n",
    "REDv2-Time & $85.1\\pm 0.5$ & $84.5\\pm 1.0$ & $86.5\\pm 1.8$ & $77.8\\pm 0.2$ \\\\\n",
    "REDv2-CWT  & $85.0\\pm 0.4$ & $85.0\\pm 0.8$ & $86.0\\pm 1.4$ & $77.9\\pm 0.2$ \\\\\n",
    "DOSED      & $81.8\\pm 0.7$ & $79.7\\pm 1.4$ & $85.0\\pm 1.4$ & $73.8\\pm 0.5$ \\\\\n",
    "A7         & $73.4\\pm 0.1$ & $82.8\\pm 0.0$ & $66.4\\pm 0.2$ & $74.8\\pm 0.0$ \\\\\n",
    "\n",
    "MASS-SS2-KC (Fixed)\n",
    "REDv2-Time & $83.3\\pm 0.4$ & $82.4\\pm 1.0$ & $85.0\\pm 0.8$ & $90.5\\pm 0.2$ \\\\\n",
    "REDv2-CWT  & $83.4\\pm 0.5$ & $82.1\\pm 1.1$ & $85.7\\pm 0.8$ & $90.3\\pm 0.3$ \\\\\n",
    "DOSED      & $77.5\\pm 1.0$ & $76.5\\pm 1.9$ & $79.5\\pm 2.0$ & $72.2\\pm 1.3$ \\\\\n",
    "Spinky     & $65.7\\pm 0.2$ & $65.0\\pm 1.8$ & $67.7\\pm 2.2$ & $42.3\\pm 0.1$ \\\\\n",
    "\n",
    "MASS-MODA (5CV)\n",
    "REDv2-Time & $81.8\\pm 1.4$ & $83.5\\pm 2.5$ & $80.3\\pm 2.3$ & $83.1\\pm 0.5$ \\\\\n",
    "REDv2-CWT  & $81.5\\pm 1.2$ & $82.8\\pm 2.5$ & $80.3\\pm 2.4$ & $83.1\\pm 0.6$ \\\\\n",
    "DOSED      & $77.5\\pm 1.7$ & $76.4\\pm 2.8$ & $78.9\\pm 3.0$ & $71.4\\pm 1.1$ \\\\\n",
    "A7         & $73.3\\pm 1.9$ & $74.1\\pm 2.1$ & $72.8\\pm 3.6$ & $71.0\\pm 0.9$ \\\\\n",
    "\n",
    "INTA-UCH (5CV)\n",
    "REDv2-Time & $83.2\\pm 4.8$ & $85.0\\pm 5.4$ & $82.7\\pm 8.5$ & $75.8\\pm 2.7$ \\\\\n",
    "REDv2-CWT  & $83.2\\pm 4.7$ & $85.2\\pm 5.9$ & $82.7\\pm 8.1$ & $76.0\\pm 2.5$ \\\\\n",
    "DOSED      & $77.2\\pm 7.2$ & $78.0\\pm 12.6$ & $79.7\\pm 8.0$ & $68.7\\pm 3.9$ \\\\\n",
    "A7         & $77.6\\pm 5.4$ & $78.2\\pm 7.0$ & $79.9\\pm 10.8$ & $70.3\\pm 2.7$ \\\\\n",
    "\n",
    "MASS-SS2-E1SS (5CV)\n",
    "REDv2-Time & $80.8\\pm 2.1$ & $84.4\\pm 4.0$ & $78.9\\pm 5.4$ & $84.4\\pm 1.1$ \\\\\n",
    "REDv2-CWT  & $80.8\\pm 2.0$ & $84.9\\pm 4.3$ & $78.5\\pm 5.5$ & $84.3\\pm 1.2$ \\\\\n",
    "DOSED      & $76.8\\pm 2.9$ & $79.7\\pm 5.9$ & $77.5\\pm 7.8$ & $74.7\\pm 2.1$ \\\\\n",
    "A7         & $73.0\\pm 3.4$ & $80.1\\pm 4.0$ & $68.1\\pm 5.5$ & $73.9\\pm 1.0$ \\\\\n",
    "\n",
    "MASS-SS2-E2SS (5CV)\n",
    "REDv2-Time & $86.1\\pm 2.0$ & $87.0\\pm 3.7$ & $86.0\\pm 3.7$ & $78.5\\pm 1.1$ \\\\\n",
    "REDv2-CWT  & $86.0\\pm 2.2$ & $87.2\\pm 4.1$ & $85.7\\pm 4.3$ & $78.5\\pm 1.1$ \\\\\n",
    "DOSED      & $82.5\\pm 2.5$ & $84.0\\pm 5.0$ & $82.5\\pm 4.9$ & $73.1\\pm 1.1$ \\\\\n",
    "A7         & $74.9\\pm 2.8$ & $81.5\\pm 3.1$ & $70.0\\pm 4.3$ & $74.7\\pm 1.1$ \\\\\n",
    "\n",
    "MASS-SS2-KC (5CV)\n",
    "REDv2-Time & $83.6\\pm 1.5$ & $85.2\\pm 3.4$ & $82.9\\pm 3.2$ & $90.5\\pm 0.6$ \\\\\n",
    "REDv2-CWT  & $83.8\\pm 1.4$ & $85.0\\pm 2.4$ & $83.3\\pm 2.5$ & $90.4\\pm 0.5$ \\\\\n",
    "DOSED      & $77.5\\pm 2.4$ & $79.2\\pm 3.7$ & $76.5\\pm 3.6$ & $72.3\\pm 1.4$ \\\\\n",
    "Spinky     & $63.1\\pm 3.8$ & $61.6\\pm 3.5$ & $65.6\\pm 6.3$ & $41.2\\pm 1.6$ \\\\\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd28eabd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "baselines_ss = ['dosed', 'a7']\n",
    "baselines_kc = ['dosed', 'spinky']\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT',\n",
    "    'dosed': 'DOSED',\n",
    "    'a7': 'A7',\n",
    "    'spinky': 'Spinky'\n",
    "}\n",
    "\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=1, strategy='fixed', seeds=11),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=2, strategy='fixed', seeds=11),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='fixed', seeds=11),\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.INTA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=2, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    baselines = baselines_ss if dataset.event_name == constants.SPINDLE else baselines_kc\n",
    "    \n",
    "    # Collect predictions\n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        tmp_dict = fig_utils.get_red_predictions(model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        # Retrieve only predictions, same format as baselines\n",
    "        pred_dict[model_version] = {}\n",
    "        for k in tmp_dict.keys():\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "            pred_dict[model_version][k] = {s: pred for s, pred in zip(fold_subjects, fold_predictions)}\n",
    "    for baseline_name in baselines:\n",
    "        pred_dict[baseline_name] = fig_utils.get_baseline_predictions(baseline_name, config[\"strategy\"], config[\"dataset_name\"], config[\"expert\"])\n",
    "    # print(\"Loaded models:\", pred_dict.keys())\n",
    "    \n",
    "    # Measure performance byfold\n",
    "    average_mode = constants.MICRO_AVERAGE if (config[\"dataset_name\"] == constants.MODA_SS_NAME) else constants.MACRO_AVERAGE\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    table = {'Detector': [], 'F1-score': [], 'Recall': [], 'Precision': [], 'mIoU': [], 'Fold': []}\n",
    "    for model_name in pred_dict.keys():\n",
    "        for k in range(n_folds):\n",
    "            subject_ids = test_ids_list[k]\n",
    "            feed_d = FeederDataset(dataset, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "            events_list = feed_d.get_stamps()\n",
    "            detections_list = [pred_dict[model_name][k][subject_id] for subject_id in subject_ids]\n",
    "            performance = fig_utils.compute_fold_performance(events_list, detections_list, average_mode)\n",
    "            table['Detector'].append(model_name)\n",
    "            table['F1-score'].append(performance['F1-score'])\n",
    "            table['Recall'].append(performance['Recall'])\n",
    "            table['Precision'].append(performance['Precision'])\n",
    "            table['mIoU'].append(performance['mIoU'])\n",
    "            table['Fold'].append(k)\n",
    "    table = pd.DataFrame.from_dict(table)\n",
    "    print(\"By-fold statistics\")\n",
    "    metric_mean = table.groupby(by=[\"Detector\"]).mean().drop(columns=[\"Fold\"])\n",
    "    metric_std = table.groupby(by=[\"Detector\"]).std(ddof=0).drop(columns=[\"Fold\"])\n",
    "    print(\"Detector & F1-score (\\%) & Recall (\\%) & Precision (\\%) & mIoU (\\%) \\\\\\\\\")\n",
    "    for model_name in pred_dict.keys():\n",
    "        print(\"%s & %s & %s & %s & %s \\\\\\\\\" % (\n",
    "            print_model_names[model_name].ljust(10),\n",
    "            fig_utils.format_metric(metric_mean.at[model_name, \"F1-score\"], metric_std.at[model_name, \"F1-score\"]),\n",
    "            fig_utils.format_metric(metric_mean.at[model_name, \"Recall\"], metric_std.at[model_name, \"Recall\"]),\n",
    "            fig_utils.format_metric(metric_mean.at[model_name, \"Precision\"], metric_std.at[model_name, \"Precision\"]),\n",
    "            fig_utils.format_metric(metric_mean.at[model_name, \"mIoU\"], metric_std.at[model_name, \"mIoU\"]),\n",
    "        ))\n",
    "    # Statistical tests\n",
    "    reference_model_name = constants.V2_TIME\n",
    "    print(\"P-value test against %s\" % reference_model_name)\n",
    "    for model_name in pred_dict.keys():\n",
    "        model_metrics = table[table[\"Detector\"] == model_name][\"F1-score\"].values\n",
    "        reference_metrics = table[table[\"Detector\"] == reference_model_name][\"F1-score\"].values\n",
    "        pvalue = stats.ttest_ind(model_metrics, reference_metrics, equal_var=False)[1]\n",
    "        print(\"%s: P %1.4f\" % (print_model_names[model_name].ljust(10), pvalue))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "901d5003",
   "metadata": {},
   "source": [
    "# Dispersion by-subject\n",
    "5CV solamente por brevedad, ya que ya se vio que es similar el desempeño y permite tener todos los sujetos en MASS-SS2.\n",
    "\n",
    "Datos cuantitativos de dispersión entre sujetos (print esperado):\n",
    "```\n",
    "Dataset: MASS-SS2-E1SS\n",
    "          F1-score    Recall  Precision      mIoU\n",
    "Detector                                         \n",
    "a7        5.034115  6.698362   8.493331  2.332143\n",
    "dosed     5.065436  9.265257  13.893792  3.502857\n",
    "v2_cwt1d  3.443896  7.987251   8.489591  2.374149\n",
    "v2_time   3.575472  8.186777   8.515364  2.323281\n",
    "\n",
    "Dataset: MASS-SS2-E2SS\n",
    "          F1-score    Recall  Precision      mIoU\n",
    "Detector                                         \n",
    "a7        4.330717  5.803320   7.882029  1.664745\n",
    "dosed     4.163007  7.523092   8.901198  2.268538\n",
    "v2_cwt1d  3.483713  6.769644   6.658597  2.219977\n",
    "v2_time   3.329545  6.479800   6.366437  2.186028\n",
    "\n",
    "Dataset: MASS-SS2-KC\n",
    "          F1-score    Recall  Precision      mIoU\n",
    "Detector                                         \n",
    "dosed     3.960219  6.606413   6.062948  1.775579\n",
    "spinky    7.243040  6.883243  10.711108  2.448843\n",
    "v2_cwt1d  3.070712  6.027732   5.488672  0.810547\n",
    "v2_time   3.233140  6.605095   5.811940  0.966797\n",
    "\n",
    "Dataset: MASS-MODA\n",
    "           F1-score     Recall  Precision      mIoU\n",
    "Detector                                           \n",
    "a7        18.773054  22.023236  14.032634  6.618863\n",
    "dosed     13.233049  14.972821  13.520275  3.533990\n",
    "v2_cwt1d  10.929555  14.090439  10.262946  2.774643\n",
    "v2_time   11.000109  14.058725   9.195598  2.723617\n",
    "\n",
    "Dataset: INTA-UCH\n",
    "          F1-score     Recall  Precision      mIoU\n",
    "Detector                                          \n",
    "a7        7.567395   9.741852  13.076641  4.286478\n",
    "dosed     8.210749  13.977135   9.195159  4.280485\n",
    "v2_cwt1d  5.872097   8.169621   9.838274  3.862264\n",
    "v2_time   6.009940   7.387042  10.281951  4.194361\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeef8e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "baselines_ss = ['dosed', 'a7']\n",
    "baselines_kc = ['dosed', 'spinky']\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT',\n",
    "    'dosed': 'DOSED',\n",
    "    'a7': 'A7',\n",
    "    'spinky': 'Spinky'\n",
    "}\n",
    "print_dataset_names = {\n",
    "    (constants.MASS_SS_NAME, 1): \"MASS-SS2-E1SS\",\n",
    "    (constants.MASS_SS_NAME, 2): \"MASS-SS2-E2SS\",\n",
    "    (constants.MASS_KC_NAME, 1): \"MASS-SS2-KC\",\n",
    "    (constants.MODA_SS_NAME, 1): \"MASS-MODA\",\n",
    "    (constants.INTA_SS_NAME, 1): \"INTA-UCH\",\n",
    "}\n",
    "\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=2, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.INTA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "dispersions_list = []\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    baselines = baselines_ss if dataset.event_name == constants.SPINDLE else baselines_kc\n",
    "    # Collect predictions\n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        tmp_dict = fig_utils.get_red_predictions(model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        # Retrieve only predictions, same format as baselines\n",
    "        pred_dict[model_version] = {}\n",
    "        for k in tmp_dict.keys():\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "            pred_dict[model_version][k] = {s: pred for s, pred in zip(fold_subjects, fold_predictions)}\n",
    "    for baseline_name in baselines:\n",
    "        pred_dict[baseline_name] = fig_utils.get_baseline_predictions(baseline_name, config[\"strategy\"], config[\"dataset_name\"], config[\"expert\"])\n",
    "    # Measure performance by subject\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    table = {'Detector': [], 'F1-score': [], 'Recall': [], 'Precision': [], 'mIoU': [], 'Subject': [], 'Fold': []}\n",
    "    if config[\"dataset_name\"] == constants.MODA_SS_NAME:\n",
    "        valid_subjects = [sub_id for sub_id in dataset.all_ids if dataset.data[sub_id]['n_blocks'] == 10]\n",
    "    else:\n",
    "        valid_subjects = dataset.all_ids\n",
    "    for model_name in pred_dict.keys():\n",
    "        for k in range(n_folds):\n",
    "            subject_ids = test_ids_list[k]\n",
    "            feed_d = FeederDataset(dataset, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "            events_list = feed_d.get_stamps()\n",
    "            detections_list = [pred_dict[model_name][k][subject_id] for subject_id in subject_ids]\n",
    "            performance = fig_utils.compute_subject_performance(events_list, detections_list)\n",
    "            for i, subject_id in enumerate(subject_ids):\n",
    "                if subject_id in valid_subjects:\n",
    "                    table['Detector'].append(model_name)\n",
    "                    table['F1-score'].append(performance['F1-score'][i])\n",
    "                    table['Recall'].append(performance['Recall'][i])\n",
    "                    table['Precision'].append(performance['Precision'][i])\n",
    "                    table['mIoU'].append(performance['mIoU'][i])\n",
    "                    table['Subject'].append(subject_id)\n",
    "                    table['Fold'].append(k)\n",
    "    table = pd.DataFrame.from_dict(table)\n",
    "    bysubject_dispersions = 100 * table.groupby([\"Detector\", \"Subject\"]).mean().drop(columns=[\"Fold\"]).groupby(\"Detector\").std(ddof=0)\n",
    "    dispersions_list.append(bysubject_dispersions)\n",
    "print(\"Dispersions computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c68727",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, config in enumerate(eval_configs):\n",
    "    print(\"\\nDataset: %s\" % print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])])\n",
    "    print(dispersions_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82f8dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figure = False\n",
    "\n",
    "letters = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "fig, axes = plt.subplots(1, 5, figsize=(8, 3), dpi=200, sharex=True)\n",
    "for i, config in enumerate(eval_configs):\n",
    "    ax = axes[i]\n",
    "    disp_table = dispersions_list[i]\n",
    "    if config[\"dataset_name\"] == constants.MASS_KC_NAME:\n",
    "        extra_row = pd.DataFrame([[\"a7\", 0, 0, 0, 0]], columns=[\"Detector\", \"F1-score\", \"Recall\", \"Precision\", \"mIoU\"])\n",
    "        extra_row = extra_row.set_index(\"Detector\")\n",
    "        disp_table_mod = disp_table.append(extra_row).reindex([\"spinky\", \"a7\", \"dosed\", constants.V2_CWT1D, constants.V2_TIME])\n",
    "    else:\n",
    "        extra_row = pd.DataFrame([[\"spinky\", 0, 0, 0, 0]], columns=[\"Detector\", \"F1-score\", \"Recall\", \"Precision\", \"mIoU\"])\n",
    "        extra_row = extra_row.set_index(\"Detector\")\n",
    "        disp_table_mod = disp_table.append(extra_row).reindex([\"spinky\", \"a7\", \"dosed\", constants.V2_CWT1D, constants.V2_TIME])\n",
    "    \n",
    "    ax = disp_table_mod.plot.barh(y=[\"F1-score\", \"Recall\", \"Precision\"], ax=ax, fontsize=8, legend=False)\n",
    "    ax.set_title(print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])], loc=\"left\", fontsize=8)\n",
    "    \n",
    "    yticklabels = ax.get_yticklabels()\n",
    "    ax.set_yticklabels([print_model_names[yt.get_text()] for yt in yticklabels])\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_xlabel(\"$\\sigma_\\mathrm{subjects}$ (%)\", fontsize=8)\n",
    "    ax.tick_params(labelsize=8)\n",
    "    if i > 0:\n",
    "        ax.set_yticklabels([])\n",
    "    ax.set_xlim([0, 25])\n",
    "    ax.set_xticks([0, 10, 20])\n",
    "    ax.set_xticks([0, 2.5, 5, 7.5, 10, 12.5, 15, 17.5, 20, 22.5, 25], minor=True)\n",
    "    ax.grid(axis=\"x\", which=\"minor\")\n",
    "    ax.text(\n",
    "        x=-0.01, y=1.15, fontsize=16, s=r\"$\\bf{%s}$\" % letters[i],\n",
    "        ha=\"left\", transform=ax.transAxes)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Get legend\n",
    "lines_labels = [axes[0].get_legend_handles_labels()]\n",
    "lines, labels = [sum(lol, []) for lol in zip(*lines_labels)]\n",
    "# plt.subplots_adjust(bottom=0.9)\n",
    "lg = fig.legend(\n",
    "    lines, labels, fontsize=8, loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.5, 0.02), ncol=3, frameon=False, handletextpad=0.5)\n",
    "\n",
    "if save_figure:\n",
    "    # Save figure\n",
    "    fname_prefix = \"result_comparison_bysubject_std\"\n",
    "    plt.savefig(\"%s.pdf\" % fname_prefix, bbox_extra_artists=(lg,), bbox_inches=\"tight\", pad_inches=0.3)\n",
    "    plt.savefig(\"%s.png\" % fname_prefix, bbox_extra_artists=(lg,), bbox_inches=\"tight\", pad_inches=0.3)\n",
    "    plt.savefig(\"%s.svg\" % fname_prefix, bbox_extra_artists=(lg,), bbox_inches=\"tight\", pad_inches=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba9be6a",
   "metadata": {},
   "source": [
    "# Efecto umbral probabilidad: curva PR y métricas vs umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98317e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "baselines_ss = ['dosed', 'a7']\n",
    "baselines_kc = ['dosed', 'spinky']\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT',\n",
    "    'dosed': 'DOSED',\n",
    "    'a7': 'A7',\n",
    "    'spinky': 'Spinky'\n",
    "}\n",
    "print_dataset_names = {\n",
    "    (constants.MASS_SS_NAME, 1): \"MASS-SS2-E1SS\",\n",
    "    (constants.MASS_SS_NAME, 2): \"MASS-SS2-E2SS\",\n",
    "    (constants.MASS_KC_NAME, 1): \"MASS-SS2-KC\",\n",
    "    (constants.MODA_SS_NAME, 1): \"MASS-MODA\",\n",
    "    (constants.INTA_SS_NAME, 1): \"INTA-UCH\",\n",
    "}\n",
    "\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=2, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.INTA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "metrics_list = []\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    baselines = baselines_ss if dataset.event_name == constants.SPINDLE else baselines_kc\n",
    "    \n",
    "    # Collect predictions\n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        tmp_dict = fig_utils.get_red_predictions(model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        # Retrieve only predictions, same format as baselines\n",
    "        pred_dict[model_version] = {}\n",
    "        for k in tmp_dict.keys():\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "            pred_dict[model_version][k] = {s: pred for s, pred in zip(fold_subjects, fold_predictions)}\n",
    "    for baseline_name in baselines:\n",
    "        pred_dict[baseline_name] = fig_utils.get_baseline_predictions(baseline_name, config[\"strategy\"], config[\"dataset_name\"], config[\"expert\"])\n",
    "    # print(\"Loaded models:\", pred_dict.keys())\n",
    "    \n",
    "    # Measure performance byfold\n",
    "    average_mode = constants.MICRO_AVERAGE if (config[\"dataset_name\"] == constants.MODA_SS_NAME) else constants.MACRO_AVERAGE\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    table = {'Detector': [], 'F1-score': [], 'Recall': [], 'Precision': [], 'mIoU': [], 'Fold': []}\n",
    "    for model_name in pred_dict.keys():\n",
    "        for k in range(n_folds):\n",
    "            subject_ids = test_ids_list[k]\n",
    "            feed_d = FeederDataset(dataset, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "            events_list = feed_d.get_stamps()\n",
    "            detections_list = [pred_dict[model_name][k][subject_id] for subject_id in subject_ids]\n",
    "            performance = fig_utils.compute_fold_performance(events_list, detections_list, average_mode)\n",
    "            table['Detector'].append(model_name)\n",
    "            table['F1-score'].append(performance['F1-score'])\n",
    "            table['Recall'].append(performance['Recall'])\n",
    "            table['Precision'].append(performance['Precision'])\n",
    "            table['mIoU'].append(performance['mIoU'])\n",
    "            table['Fold'].append(k)\n",
    "    table = pd.DataFrame.from_dict(table)\n",
    "    print(\"By-fold statistics\")\n",
    "    metric_mean = table.groupby(by=[\"Detector\"]).mean().drop(columns=[\"Fold\"])\n",
    "    metrics_list.append(metric_mean)\n",
    "print(\"Metrics computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaa45a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compute change due to threshold\n",
    "adjusted_thr_list = np.arange(0.05, 0.95 + 0.001, 0.05)\n",
    "metrics_curve_list = []  # [loc in config][model_name][fold_id][metric_name][loc in thr]\n",
    "for config in eval_configs:\n",
    "    average_mode = constants.MICRO_AVERAGE if (config[\"dataset_name\"] == constants.MODA_SS_NAME) else constants.MACRO_AVERAGE\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    baselines = baselines_ss if dataset.event_name == constants.SPINDLE else baselines_kc\n",
    "    metrics_curve = {}\n",
    "    for model_version in models:\n",
    "        metrics_curve[model_version] = {}\n",
    "        tmp_dict = fig_utils.get_red_predictions(model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        for k in tmp_dict.keys():\n",
    "            optimal_thr = tmp_dict[k][constants.TEST_SUBSET].probability_threshold\n",
    "            # print(\"Fold %d, optimal thr %1.3f\" % (k, optimal_thr))\n",
    "            # Get events\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            feed_d = FeederDataset(dataset, fold_subjects, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "            events_list = feed_d.get_stamps()\n",
    "            # Get predictions\n",
    "            tmp_metric_dict_list = []\n",
    "            for adjusted_thr in adjusted_thr_list:\n",
    "                tmp_dict[k][constants.TEST_SUBSET].set_probability_threshold(adjusted_thr, adjusted_by_threshold=optimal_thr, verbose=False)\n",
    "                detections_list = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "                performance = fig_utils.compute_fold_performance(events_list, detections_list, average_mode)\n",
    "                tmp_metric_dict_list.append(performance)\n",
    "            # list of dict -> dict of list\n",
    "            dict_of_list = {}\n",
    "            for metric_key in tmp_metric_dict_list[0].keys():\n",
    "                dict_of_list[metric_key] = np.array([tmp_metric_dict_list[thr_idx][metric_key] for thr_idx in range(len(adjusted_thr_list))])\n",
    "            metrics_curve[model_version][k] = dict_of_list\n",
    "    metrics_curve_list.append(metrics_curve)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8f1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pr_ckpt_action = \"load\"\n",
    "fname = 'pr_curve_ckpt.pkl'\n",
    "adjusted_thr_list = np.arange(0.05, 0.95 + 0.001, 0.05)\n",
    "if pr_ckpt_action == \"save\":\n",
    "    # save checkpoint\n",
    "    with open(fname, 'wb') as handle:\n",
    "        pickle.dump(metrics_curve_list, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "elif pr_ckpt_action == \"load\":\n",
    "    # load checkpoint\n",
    "    with open(fname, 'rb') as handle:\n",
    "        metrics_curve_list = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3119454",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figure = False\n",
    "markersize = 5\n",
    "red_alpha = 0.6\n",
    "pr_alpha_curve = 0.5\n",
    "thr_alpha_curve = 1.0\n",
    "baseline_color = viz.GREY_COLORS[9]\n",
    "letters = ['A', 'B', 'C', 'D', 'E']\n",
    "letters2 = ['F', 'G', 'H', 'I', 'J']\n",
    "model_specs = {\n",
    "    constants.V2_TIME: dict(marker='o', color=viz.PALETTE['blue']),\n",
    "    constants.V2_CWT1D: dict(marker='o', color=viz.PALETTE['red']),\n",
    "    'dosed': dict(marker='s', color=baseline_color),\n",
    "    'a7': dict(marker='^', color=baseline_color),\n",
    "    'spinky': dict(marker='v', color=baseline_color),\n",
    "}\n",
    "spindle_net = dict(metrics={\"F1-score\": .83, \"Recall\": .852, \"Precision\": .81}, marker='<', color=baseline_color)\n",
    "dkl_kc = dict(metrics={\"F1-score\": .78, \"Recall\": .80, \"Precision\": .77}, marker='>', color=baseline_color)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(8, 4), dpi=200)\n",
    "for i, config in enumerate(eval_configs):\n",
    "    # PR PLOT\n",
    "    ax = axes[0, i]\n",
    "    metric_dict = metrics_list[i].to_dict('index')\n",
    "    for model_name in metric_dict.keys():\n",
    "        ax.plot(\n",
    "            metric_dict[model_name][\"Recall\"], \n",
    "            metric_dict[model_name][\"Precision\"],\n",
    "            linestyle=\"None\",\n",
    "            alpha=red_alpha,\n",
    "            marker=model_specs[model_name][\"marker\"],\n",
    "            markersize=markersize,\n",
    "            markeredgewidth=0.0, zorder=20,\n",
    "            color=model_specs[model_name][\"color\"],\n",
    "            label=print_model_names[model_name])\n",
    "    ax.set_title(print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])], loc=\"left\", fontsize=8)\n",
    "    plotter.format_precision_recall_plot_simple(\n",
    "        ax, axis_range=(0.5, 1), show_quadrants=False, show_grid=True,\n",
    "        axis_markers=np.arange(0.5, 1 + 0.001, 0.5), minor_axis_markers=np.arange(0.5, 1 + 0.001, 0.1))\n",
    "    ax.tick_params(labelsize=8)\n",
    "    ax.set_xlabel(\"Recall\", fontsize=8)\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Precision\", fontsize=8) \n",
    "    else:\n",
    "        ax.set_yticks([])\n",
    "    # Get labels closer to axis\n",
    "    ax.xaxis.labelpad = -8\n",
    "    ax.yaxis.labelpad = -8\n",
    "    # Add PR curve\n",
    "    # [loc in config][model_name][fold_id][metric_name][loc in thr]\n",
    "    pr_curve_data = metrics_curve_list[i]\n",
    "    for model_name in pr_curve_data.keys():\n",
    "        n_folds = len(pr_curve_data[model_name].keys())\n",
    "        seeds_recall = [pr_curve_data[model_name][k][\"Recall\"] for k in range(n_folds)]\n",
    "        seeds_precision = [pr_curve_data[model_name][k][\"Precision\"] for k in range(n_folds)]\n",
    "        mean_recall_curve, mean_precision_curve = plotter.average_curves(seeds_recall, seeds_precision)\n",
    "        ax.plot(\n",
    "            mean_recall_curve, mean_precision_curve,\n",
    "            linewidth=1.0, color=model_specs[model_name][\"color\"], zorder=10, alpha=pr_alpha_curve)\n",
    "\n",
    "    if print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])] == print_dataset_names[(constants.MASS_SS_NAME, 2)]:\n",
    "        ax.plot(\n",
    "            spindle_net[\"metrics\"][\"Recall\"], \n",
    "            spindle_net[\"metrics\"][\"Precision\"],\n",
    "            linestyle=\"None\",\n",
    "            alpha=red_alpha,\n",
    "            marker=spindle_net[\"marker\"],\n",
    "            markersize=markersize,\n",
    "            markeredgewidth=0.0, zorder=20,\n",
    "            color=spindle_net[\"color\"],\n",
    "            label=\"SpindleNet\")\n",
    "    if print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])] == print_dataset_names[(constants.MASS_KC_NAME, 1)]:\n",
    "        ax.plot(\n",
    "            dkl_kc[\"metrics\"][\"Recall\"], \n",
    "            dkl_kc[\"metrics\"][\"Precision\"],\n",
    "            linestyle=\"None\",\n",
    "            alpha=red_alpha,\n",
    "            marker=dkl_kc[\"marker\"],\n",
    "            markersize=markersize,\n",
    "            markeredgewidth=0.0, zorder=20,\n",
    "            color=dkl_kc[\"color\"],\n",
    "            label=\"DKL-KC\")\n",
    "    \n",
    "    ax.text(\n",
    "        x=-0.01, y=1.2, fontsize=16, s=r\"$\\bf{%s}$\" % letters[i],\n",
    "        ha=\"left\", transform=ax.transAxes)\n",
    "    \n",
    "    # CHANGE DUE TO THR\n",
    "    ax = axes[1, i]\n",
    "    model_name = \"v2_time\"\n",
    "    # for model_name in pr_curve_data.keys():\n",
    "    \n",
    "    n_folds = len(pr_curve_data[model_name].keys())\n",
    "    seeds_metric = {\n",
    "        metric_name: np.stack([pr_curve_data[model_name][k][metric_name] for k in range(n_folds)], axis=0)\n",
    "        for metric_name in [\"F1-score\", \"Recall\", \"Precision\", \"mIoU\"]\n",
    "    }\n",
    "    for metric_name in [\"F1-score\", \"Recall\", \"Precision\", \"mIoU\"]:\n",
    "        ax.plot(\n",
    "            adjusted_thr_list, seeds_metric[metric_name].mean(axis=0), \n",
    "            linewidth=1.0, zorder=10, alpha=thr_alpha_curve, label=metric_name)\n",
    "        ax.fill_between(\n",
    "            adjusted_thr_list, \n",
    "            seeds_metric[metric_name].mean(axis=0) + seeds_metric[metric_name].std(axis=0), \n",
    "            seeds_metric[metric_name].mean(axis=0) - seeds_metric[metric_name].std(axis=0), \n",
    "            linewidth=1.0, zorder=10, alpha=0.2)\n",
    "    ax.axvline(0.5, color=\"k\", linewidth=1.5, zorder=30)\n",
    "    ax.tick_params(labelsize=8)\n",
    "    ax.set_xlabel(\"Umbral prob.\", fontsize=8)\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0.5, 1.0])\n",
    "    ax.set_xticks([0, 1.0])\n",
    "    ax.set_xticks(np.arange(0, 1 + 0.001, 0.1), minor=True)\n",
    "    ax.set_yticks([0.5, 1.0])\n",
    "    ax.set_yticks(np.arange(0.5, 1 + 0.001, 0.1), minor=True)\n",
    "    ax.grid(which=\"minor\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Métrica\", fontsize=8) \n",
    "    else:\n",
    "        ax.set_yticks([])\n",
    "    ax.xaxis.labelpad = -8\n",
    "    ax.yaxis.labelpad = -8\n",
    "    ax.set_aspect(2)\n",
    "    \n",
    "    ax.text(\n",
    "        x=-0.01, y=1.05, fontsize=16, s=r\"$\\bf{%s}$\" % letters2[i],\n",
    "        ha=\"left\", transform=ax.transAxes)\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# Get legend methods\n",
    "labels_to_lines_dict = {}\n",
    "for ax in axes[0, :]:\n",
    "    t_lines, t_labels = ax.get_legend_handles_labels()\n",
    "    for lbl, lin in zip(t_labels, t_lines):\n",
    "        labels_to_lines_dict[lbl] = lin\n",
    "labels = [\"REDv2-Time\", \"REDv2-CWT\", \"DOSED\", \"A7\", \"Spinky\", \"SpindleNet\", \"DKL-KC\"]\n",
    "lines = [labels_to_lines_dict[lbl] for lbl in labels]\n",
    "lg1 = fig.legend(\n",
    "    lines, labels, fontsize=7, loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.5, 0.49), ncol=len(labels), frameon=False, handletextpad=0.5)\n",
    "\n",
    "# Get legend metrics\n",
    "labels_to_lines_dict = {}\n",
    "for ax in axes[1, :]:\n",
    "    t_lines, t_labels = ax.get_legend_handles_labels()\n",
    "    for lbl, lin in zip(t_labels, t_lines):\n",
    "        labels_to_lines_dict[lbl] = lin\n",
    "labels = [\"F1-score\", \"Recall\", \"Precision\", \"mIoU\"]\n",
    "lines = [labels_to_lines_dict[lbl] for lbl in labels]\n",
    "lg2 = fig.legend(\n",
    "    lines, labels, fontsize=7, loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.5, 0.02), ncol=len(labels), frameon=False, handletextpad=0.5)\n",
    "\n",
    "if save_figure:\n",
    "    # Save figure\n",
    "    fname_prefix = \"result_comparison_pr_thr\"\n",
    "    plt.savefig(\"%s.pdf\" % fname_prefix, bbox_extra_artists=(lg1, lg2), bbox_inches=\"tight\", pad_inches=0.3)\n",
    "    plt.savefig(\"%s.png\" % fname_prefix, bbox_extra_artists=(lg1, lg2), bbox_inches=\"tight\", pad_inches=0.3)\n",
    "    plt.savefig(\"%s.svg\" % fname_prefix, bbox_extra_artists=(lg1, lg2), bbox_inches=\"tight\", pad_inches=0.3)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44dc812e",
   "metadata": {},
   "source": [
    "# Efecto umbral IoU: F1 vs IoU, Histograma IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff62da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "baselines_ss = ['dosed', 'a7']\n",
    "baselines_kc = ['dosed', 'spinky']\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT',\n",
    "    'dosed': 'DOSED',\n",
    "    'a7': 'A7',\n",
    "    'spinky': 'Spinky'\n",
    "}\n",
    "print_dataset_names = {\n",
    "    (constants.MASS_SS_NAME, 1): \"MASS-SS2-E1SS\",\n",
    "    (constants.MASS_SS_NAME, 2): \"MASS-SS2-E2SS\",\n",
    "    (constants.MASS_KC_NAME, 1): \"MASS-SS2-KC\",\n",
    "    (constants.MODA_SS_NAME, 1): \"MASS-MODA\",\n",
    "    (constants.INTA_SS_NAME, 1): \"INTA-UCH\",\n",
    "}\n",
    "\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=2, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.INTA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "\n",
    "iou_curve_axis = np.arange(0.05, 0.95 + 0.001, 0.05)\n",
    "iou_hist_bins = np.linspace(0, 1, 21)\n",
    "\n",
    "metrics_list = []\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    baselines = baselines_ss if dataset.event_name == constants.SPINDLE else baselines_kc\n",
    "    \n",
    "    # Collect predictions\n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        tmp_dict = fig_utils.get_red_predictions(model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        # Retrieve only predictions, same format as baselines\n",
    "        pred_dict[model_version] = {}\n",
    "        for k in tmp_dict.keys():\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "            pred_dict[model_version][k] = {s: pred for s, pred in zip(fold_subjects, fold_predictions)}\n",
    "    for baseline_name in baselines:\n",
    "        pred_dict[baseline_name] = fig_utils.get_baseline_predictions(baseline_name, config[\"strategy\"], config[\"dataset_name\"], config[\"expert\"])\n",
    "    # print(\"Loaded models:\", pred_dict.keys())\n",
    "    \n",
    "    # Measure performance byfold\n",
    "    average_mode = constants.MICRO_AVERAGE if (config[\"dataset_name\"] == constants.MODA_SS_NAME) else constants.MACRO_AVERAGE\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    table = {'Detector': [], 'F1-score_vs_iou': [], 'IoU_hist': [], 'mIoU': [], 'Fold': []}\n",
    "    for model_name in pred_dict.keys():\n",
    "        for k in range(n_folds):\n",
    "            subject_ids = test_ids_list[k]\n",
    "            feed_d = FeederDataset(dataset, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "            events_list = feed_d.get_stamps()\n",
    "            detections_list = [pred_dict[model_name][k][subject_id] for subject_id in subject_ids]\n",
    "            performance = fig_utils.compute_fold_performance_vs_iou(\n",
    "                events_list, detections_list, average_mode, iou_curve_axis)\n",
    "            iou_mean, iou_hist_values = fig_utils.compute_iou_histogram(\n",
    "                performance['nonzero_IoU'], average_mode, iou_hist_bins)\n",
    "            table['Detector'].append(model_name)\n",
    "            table['F1-score_vs_iou'].append(performance['F1-score_vs_iou'])\n",
    "            table['IoU_hist'].append(iou_hist_values)\n",
    "            table['mIoU'].append(iou_mean)\n",
    "            table['Fold'].append(k)\n",
    "    table = pd.DataFrame.from_dict(table)\n",
    "    print(\"By-fold statistics\")\n",
    "    metric_mean = table.groupby(by=[\"Detector\"]).apply(np.mean).drop(columns=[\"Fold\"])\n",
    "    metrics_list.append(metric_mean)\n",
    "print(\"Metrics computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b496b8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figure = False\n",
    "markersize = 4\n",
    "f1_alpha_curve = 1.0\n",
    "iou_thr_reported = 0.2\n",
    "f1_markers_iou = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "idx_markers_iou = [\n",
    "    misc.closest_index(single_marker, iou_curve_axis) \n",
    "    for single_marker in f1_markers_iou]\n",
    "\n",
    "baseline_color = viz.GREY_COLORS[8]\n",
    "letters = ['A', 'B', 'C', 'D', 'E']\n",
    "letters2 = ['F', 'G', 'H', 'I', 'J']\n",
    "model_specs = {\n",
    "    constants.V2_TIME: dict(marker='o', color=viz.PALETTE['blue']),\n",
    "    constants.V2_CWT1D: dict(marker='o', color=viz.PALETTE['red']),\n",
    "    'dosed': dict(marker='s', color=baseline_color),\n",
    "    'a7': dict(marker='^', color=baseline_color),\n",
    "    'spinky': dict(marker='v', color=baseline_color),\n",
    "}\n",
    "spindle_net = dict(metrics={\"F1-score\": .83, \"Recall\": .852, \"Precision\": .81}, marker='<', color=baseline_color)\n",
    "dkl_kc = dict(metrics={\"F1-score\": .78, \"Recall\": .80, \"Precision\": .77}, marker='>', color=baseline_color)\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(8, 4.5), dpi=200)\n",
    "for i, config in enumerate(eval_configs):\n",
    "    # F1-score vs IoU\n",
    "    ax = axes[0, i]\n",
    "    metric_dict = metrics_list[i].to_dict('index')\n",
    "    for model_name in metric_dict.keys():\n",
    "        ax.plot(\n",
    "            iou_curve_axis, \n",
    "            metric_dict[model_name][\"F1-score_vs_iou\"],\n",
    "            linewidth=1,\n",
    "            marker=model_specs[model_name][\"marker\"],\n",
    "            markersize=markersize,\n",
    "            alpha=f1_alpha_curve,\n",
    "            markeredgewidth=0.0, zorder=20,\n",
    "            color=model_specs[model_name][\"color\"],\n",
    "            label=print_model_names[model_name],\n",
    "            markevery=idx_markers_iou)\n",
    "    ax.set_title(print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])], loc=\"left\", fontsize=8)\n",
    "    # ax.axvline(iou_thr_reported, color=\"k\", linewidth=1.5, zorder=5, alpha=0.5)\n",
    "    ax.tick_params(labelsize=8)\n",
    "    ax.set_xlabel(\"Umbral IoU\", fontsize=8)\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_xticks([0, 1.0])\n",
    "    ax.set_xticks(np.arange(0, 1 + 0.001, 0.1), minor=True)\n",
    "    ax.set_yticks([0, 1.0])\n",
    "    ax.set_yticks(np.arange(0, 1 + 0.001, 0.1), minor=True)\n",
    "    ax.grid(which=\"minor\")\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"F1-score\", fontsize=8) \n",
    "    else:\n",
    "        ax.set_yticks([])\n",
    "    ax.xaxis.labelpad = -8\n",
    "    ax.yaxis.labelpad = -8\n",
    "    ax.set_aspect(\"equal\")\n",
    "    \n",
    "    ax.text(\n",
    "        x=-0.01, y=1.2, fontsize=16, s=r\"$\\bf{%s}$\" % letters[i],\n",
    "        ha=\"left\", transform=ax.transAxes)\n",
    "    \n",
    "    # IoU Hist\n",
    "    ax = axes[1, i]\n",
    "    max_value = 0\n",
    "    for model_name in metric_dict.keys():\n",
    "        max_value = max(metric_dict[model_name][\"IoU_hist\"].max(), max_value)\n",
    "    max_value = max_value * 1.3\n",
    "    n_cases = len(metric_dict.keys())\n",
    "    y_sep = 1 / n_cases\n",
    "    this_center = 1 - y_sep\n",
    "    \n",
    "    model_names = list(metric_dict.keys())\n",
    "    reference_order = [constants.V2_TIME, constants.V2_CWT1D, \"dosed\", \"a7\", \"spinky\"]\n",
    "    model_names_sorted = [n for n in reference_order if n in model_names]\n",
    "    \n",
    "    for i_offset, model_name in enumerate(model_names_sorted):\n",
    "        x, y = plotter.piecewise_constant_histogram(\n",
    "            iou_hist_bins, metric_dict[model_name][\"IoU_hist\"])\n",
    "        y = y_sep * y / max_value\n",
    "        ax.plot(\n",
    "            [metric_dict[model_name][\"mIoU\"], metric_dict[model_name][\"mIoU\"]], \n",
    "            [this_center, this_center + 0.8*y_sep],\n",
    "            linewidth=1.5, color=\"k\", zorder=25, label='mIoU')\n",
    "        ax.fill_between(\n",
    "            x, this_center + y, this_center,\n",
    "            edgecolor=model_specs[model_name][\"color\"], linewidth=1,\n",
    "            facecolor=viz.GREY_COLORS[3], zorder=20)\n",
    "        ax.plot(\n",
    "            0.05, this_center + 0.2*y_sep, \n",
    "            markersize=markersize, c=model_specs[model_name][\"color\"], zorder=15, \n",
    "            marker=model_specs[model_name][\"marker\"], linestyle=\"None\")\n",
    "        this_center = this_center - y_sep\n",
    "        if i_offset == 0:\n",
    "            lg = ax.legend(loc='upper left', fontsize=8, frameon=False, bbox_to_anchor=(0, 1.05))\n",
    "            \n",
    "    ax.tick_params(labelsize=8)\n",
    "    ax.set_xlabel(\"IoU de par\", fontsize=8)\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_xticks([0, 1.0])\n",
    "    ax.set_xticks(np.arange(0, 1 + 0.001, 0.1), minor=True)\n",
    "    ax.xaxis.labelpad = -8\n",
    "    if i == 0:\n",
    "        ax.set_ylabel(\"Densidad\", fontsize=8)\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.set_yticks([])\n",
    "    ax.grid(axis=\"x\", which=\"minor\")\n",
    "    ax.set_aspect(\"equal\")\n",
    "    \n",
    "    ax.text(\n",
    "        x=-0.01, y=1.05, fontsize=16, s=r\"$\\bf{%s}$\" % letters2[i],\n",
    "        ha=\"left\", transform=ax.transAxes)\n",
    "    \n",
    "plt.tight_layout()\n",
    "\n",
    "# Get legend methods\n",
    "labels_to_lines_dict = {}\n",
    "for ax in axes[0, :]:\n",
    "    t_lines, t_labels = ax.get_legend_handles_labels()\n",
    "    for lbl, lin in zip(t_labels, t_lines):\n",
    "        labels_to_lines_dict[lbl] = lin\n",
    "labels = [\"REDv2-Time\", \"REDv2-CWT\", \"DOSED\", \"A7\", \"Spinky\"]\n",
    "lines = [labels_to_lines_dict[lbl] for lbl in labels]\n",
    "lg1 = fig.legend(\n",
    "    lines, labels, fontsize=7, loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.5, 0.49), ncol=len(labels), frameon=False, handletextpad=0.5)\n",
    "\n",
    "if save_figure:\n",
    "    # Save figure\n",
    "    fname_prefix = \"result_comparison_f1_iou\"\n",
    "    plt.savefig(\"%s.pdf\" % fname_prefix, bbox_extra_artists=(lg1,), bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.png\" % fname_prefix, bbox_extra_artists=(lg1,), bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.svg\" % fname_prefix, bbox_extra_artists=(lg1,), bbox_inches=\"tight\", pad_inches=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfe53b4",
   "metadata": {},
   "source": [
    "# Parameters: By-event overlap\n",
    "[5CV only, MODA y MASS-KC, by-event all-in] matches individuales: duracion real vs predicha (ajuste lineal y R2), duracion real vs IoU  ¿scatter o hist2D?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9677b1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_durations(events_list, detections_list):\n",
    "    # iou_matching = []  # Array for IoU for every true event (gs)\n",
    "    # idx_matching = []  # Array for the index associated with the true event.\n",
    "    _, idx_matching_list = metrics.matching_with_list(events_list, detections_list)\n",
    "    durations_real_list = []\n",
    "    durations_pred_list = []\n",
    "    for i in range(len(events_list)):\n",
    "        events = events_list[i]\n",
    "        detections = detections_list[i]\n",
    "        if events.size == 0 or detections.size == 0:\n",
    "            continue\n",
    "        idx_matching = idx_matching_list[i]\n",
    "        valid_event_locs = np.where(idx_matching != -1)[0]\n",
    "        if valid_event_locs.size == 0:\n",
    "            continue\n",
    "        events_m = events[valid_event_locs]\n",
    "        detections_m = detections[idx_matching[valid_event_locs]]\n",
    "        durations_real = events_m[:, 1] - events_m[:, 0] + 1\n",
    "        durations_pred = detections_m[:, 1] - detections_m[:, 0] + 1\n",
    "        durations_real_list.append(durations_real)\n",
    "        durations_pred_list.append(durations_pred)\n",
    "    durations_real_list = np.concatenate(durations_real_list)\n",
    "    durations_pred_list = np.concatenate(durations_pred_list)\n",
    "    return durations_real_list, durations_pred_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5cb9bc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "baselines_ss = ['dosed', 'a7']\n",
    "baselines_kc = ['dosed', 'spinky']\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT',\n",
    "    'dosed': 'DOSED',\n",
    "    'a7': 'A7',\n",
    "    'spinky': 'Spinky'\n",
    "}\n",
    "print_dataset_names = {\n",
    "    (constants.MASS_SS_NAME, 1): \"MASS-SS2-E1SS\",\n",
    "    (constants.MASS_SS_NAME, 2): \"MASS-SS2-E2SS\",\n",
    "    (constants.MASS_KC_NAME, 1): \"MASS-SS2-KC\",\n",
    "    (constants.MODA_SS_NAME, 1): \"MASS-MODA\",\n",
    "    (constants.INTA_SS_NAME, 1): \"INTA-UCH\",\n",
    "}\n",
    "\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "\n",
    "metrics_list = []\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    baselines = baselines_ss if dataset.event_name == constants.SPINDLE else baselines_kc\n",
    "    \n",
    "    # Collect predictions\n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        tmp_dict = fig_utils.get_red_predictions(model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        # Retrieve only predictions, same format as baselines\n",
    "        pred_dict[model_version] = {}\n",
    "        for k in tmp_dict.keys():\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "            pred_dict[model_version][k] = {s: pred for s, pred in zip(fold_subjects, fold_predictions)}\n",
    "    for baseline_name in baselines:\n",
    "        pred_dict[baseline_name] = fig_utils.get_baseline_predictions(baseline_name, config[\"strategy\"], config[\"dataset_name\"], config[\"expert\"])\n",
    "    # print(\"Loaded models:\", pred_dict.keys())\n",
    "    \n",
    "    # Retrieve matchings (it does not matter macro or micro because all events are grouped together)\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    table = {'Detector': [], 'Duration_real': [], 'Duration_pred': []}\n",
    "    for model_name in pred_dict.keys():\n",
    "        durations_real_list = []\n",
    "        durations_pred_list = []\n",
    "        for k in range(n_folds):\n",
    "            subject_ids = test_ids_list[k]\n",
    "            feed_d = FeederDataset(dataset, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "            events_list = feed_d.get_stamps()\n",
    "            detections_list = [pred_dict[model_name][k][subject_id] for subject_id in subject_ids]\n",
    "            durations_real, durations_pred = get_durations(events_list, detections_list)\n",
    "            durations_real_list.append(durations_real)\n",
    "            durations_pred_list.append(durations_pred)\n",
    "        durations_real_list = np.concatenate(durations_real_list).astype(np.float32) / dataset.fs\n",
    "        durations_pred_list = np.concatenate(durations_pred_list).astype(np.float32) / dataset.fs\n",
    "        table['Detector'].append(model_name)\n",
    "        table['Duration_real'].append(durations_real_list)\n",
    "        table['Duration_pred'].append(durations_pred_list)\n",
    "    metrics_list.append(table)\n",
    "print(\"Metrics computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e35a9d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_figure = False\n",
    "\n",
    "use_hist = True\n",
    "hist_temp_res = 0.05\n",
    "scatter_alpha = 0.01\n",
    "baseline_color = viz.GREY_COLORS[8]\n",
    "letters = ['A', 'B', 'C', 'D']\n",
    "letters2 = ['E', 'F', 'G', 'H']\n",
    "model_specs = {\n",
    "    constants.V2_TIME: dict(marker='o', color=viz.PALETTE['blue']),\n",
    "    constants.V2_CWT1D: dict(marker='o', color=viz.PALETTE['red']),\n",
    "    'dosed': dict(marker='s', color=baseline_color),\n",
    "    'a7': dict(marker='^', color=baseline_color),\n",
    "    'spinky': dict(marker='v', color=baseline_color),\n",
    "}\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(8, 4.7), dpi=200, sharex=True, sharey=True)\n",
    "for i, config in enumerate(eval_configs):\n",
    "    \n",
    "    max_dur = 2 #3 if 'moda' in config[\"dataset_name\"] else 3\n",
    "    \n",
    "    x_bins = np.arange(0, max_dur + 0.001, hist_temp_res)\n",
    "    y_bins = np.arange(0, max_dur + 0.001, hist_temp_res)\n",
    "    x_centers = x_bins[:-1] + x_bins[1]/2 - x_bins[0]/2\n",
    "    y_centers = y_bins[:-1] + y_bins[1]/2 - y_bins[0]/2\n",
    "    xv, yv = np.meshgrid(x_centers, y_centers)\n",
    "    \n",
    "    # Duration scatter\n",
    "    axx = axes[i, :]\n",
    "    metric_dict = metrics_list[i]\n",
    "    n_models = len(metric_dict['Detector'])\n",
    "    for j in range(n_models):\n",
    "        model_name = metric_dict['Detector'][j]\n",
    "        ax = axx[j]\n",
    "        if use_hist:\n",
    "            hist, _, _ = np.histogram2d(\n",
    "                metric_dict['Duration_real'][j], metric_dict['Duration_pred'][j], \n",
    "                bins=[x_bins, y_bins], density=True)\n",
    "            ax.hist2d(\n",
    "                xv.flatten(), yv.flatten(), bins=[x_bins, y_bins], weights=np.transpose(hist).flatten(), cmap='Blues')\n",
    "        else:\n",
    "            ax.plot(\n",
    "                metric_dict['Duration_real'][j], metric_dict['Duration_pred'][j], \n",
    "                linestyle='None', marker='o', markersize=3, alpha=scatter_alpha, markeredgewidth=0.0)\n",
    "        dataset_str = print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])]\n",
    "        model_str = print_model_names[model_name]\n",
    "        ax.set_title('%s, %s' % (model_str, dataset_str), loc=\"left\", fontsize=8)\n",
    "        ax.tick_params(labelsize=8)\n",
    "        ax.set_xlim([0, max_dur])\n",
    "        ax.set_ylim([0, max_dur])\n",
    "        ax.set_xticks([0, max_dur])\n",
    "        ax.set_yticks([0, max_dur])\n",
    "        ax.set_xticks(np.arange(0, max_dur + 0.001, 0.5), minor=True)\n",
    "        ax.set_yticks(np.arange(0, max_dur + 0.001, 0.5), minor=True)\n",
    "        ax.set_aspect('equal')\n",
    "        ax.xaxis.labelpad = -7\n",
    "        ax.yaxis.labelpad = -7\n",
    "        ax.grid(which=\"minor\")\n",
    "        ax.plot([0, max_dur], [0, max_dur], color=viz.GREY_COLORS[4], linewidth=0.7, zorder=5)\n",
    "        fig_utils.linear_regression(metric_dict['Duration_real'][j], metric_dict['Duration_pred'][j], 0.3, 1.7, ax)\n",
    "        print(dataset_str, \"max\",metric_dict['Duration_real'][j].max(), \"prct\", np.percentile(metric_dict['Duration_real'][j], 98))\n",
    "        if i == 1:\n",
    "            axes[i, j].set_xlabel(\"Duración real (s)\", fontsize=8)\n",
    "        letters_selected = letters if i == 0 else letters2\n",
    "        ax.text(\n",
    "            x=-0.01, y=1.15, fontsize=16, s=r\"$\\bf{%s}$\" % letters_selected[j],\n",
    "            ha=\"left\", transform=ax.transAxes)\n",
    "            \n",
    "    axes[i, 0].set_ylabel(\"Duración predicha (s)\", fontsize=8)\n",
    "        \n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figure:\n",
    "    # Save figure\n",
    "    fname_prefix = \"result_comparison_durations\"\n",
    "    plt.savefig(\"%s.pdf\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "    plt.savefig(\"%s.png\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "    plt.savefig(\"%s.svg\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee74ce84",
   "metadata": {},
   "source": [
    "# Parameters: By-subject parameters\n",
    "[5CV only, MODA y MASS-KC, by-subject, pintar por fase] parámetro experto vs modelo, mostrando ajuste lineal y R2: duracion promedio, densidad promedio, amplitud PP promedio, y PR (maxSigma/broadNoDelta) promedio (only SS).\n",
    "\n",
    "\n",
    "```\n",
    "Skipped subject, moda_ss a7 Events shape (2, 2) Detections shape (0, 2)\n",
    "Skipped subject, moda_ss a7 Events shape (2, 2) Detections shape (0, 2)\n",
    "Skipped subject, moda_ss a7 Events shape (2, 2) Detections shape (0, 2)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e85f2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "baselines_ss = ['dosed', 'a7']\n",
    "baselines_kc = ['dosed', 'spinky']\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT',\n",
    "    'dosed': 'DOSED',\n",
    "    'a7': 'A7',\n",
    "    'spinky': 'Spinky'\n",
    "}\n",
    "print_dataset_names = {\n",
    "    (constants.MASS_SS_NAME, 1): \"MASS-SS2-E1SS\",\n",
    "    (constants.MASS_SS_NAME, 2): \"MASS-SS2-E2SS\",\n",
    "    (constants.MASS_KC_NAME, 1): \"MASS-SS2-KC\",\n",
    "    (constants.MODA_SS_NAME, 1): \"MASS-MODA\",\n",
    "    (constants.INTA_SS_NAME, 1): \"INTA-UCH\",\n",
    "}\n",
    "\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "\n",
    "metrics_list = []\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    baselines = baselines_ss if dataset.event_name == constants.SPINDLE else baselines_kc\n",
    "    \n",
    "    # Collect predictions\n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        tmp_dict = fig_utils.get_red_predictions(model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        # Retrieve only predictions, same format as baselines\n",
    "        pred_dict[model_version] = {}\n",
    "        for k in tmp_dict.keys():\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "            pred_dict[model_version][k] = {s: pred for s, pred in zip(fold_subjects, fold_predictions)}\n",
    "    for baseline_name in baselines:\n",
    "        pred_dict[baseline_name] = fig_utils.get_baseline_predictions(baseline_name, config[\"strategy\"], config[\"dataset_name\"], config[\"expert\"])\n",
    "    # print(\"Loaded models:\", pred_dict.keys())\n",
    "    \n",
    "    # Retrieve by subject parameters (MODA only if 10 blocks)\n",
    "    if config[\"dataset_name\"] == constants.MODA_SS_NAME:\n",
    "        valid_subjects = [sub_id for sub_id in dataset.all_ids if dataset.data[sub_id]['n_blocks'] == 10]\n",
    "        phase_subjects = {sub_id: dataset.data[sub_id]['phase'] for sub_id in valid_subjects}\n",
    "        stat_spindle = True\n",
    "    else:\n",
    "        valid_subjects = dataset.all_ids\n",
    "        phase_subjects = {sub_id: 1 for sub_id in valid_subjects}\n",
    "        stat_spindle = False\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    table = {\n",
    "        'Detector': [], \n",
    "        'Phase': [],\n",
    "        'Duration_mean_real': [], \n",
    "        'Duration_mean_pred': [], \n",
    "        'Density_real': [],\n",
    "        'Density_pred': [],\n",
    "        'AmplitudePP_mean_real': [],\n",
    "        'AmplitudePP_mean_pred': [],\n",
    "    }\n",
    "    for model_name in pred_dict.keys():\n",
    "        tmp_table = {\n",
    "            'Phase': [],\n",
    "            'Duration_mean_real': [], \n",
    "            'Duration_mean_pred': [], \n",
    "            'Density_real': [],\n",
    "            'Density_pred': [],\n",
    "            'AmplitudePP_mean_real': [],\n",
    "            'AmplitudePP_mean_pred': [],\n",
    "        }\n",
    "        for k in range(n_folds):\n",
    "            subject_ids = test_ids_list[k]\n",
    "            feed_d = FeederDataset(dataset, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "            events_list = feed_d.get_stamps()\n",
    "            detections_list = [pred_dict[model_name][k][subject_id] for subject_id in subject_ids]\n",
    "            for i_sub, subject_id in enumerate(subject_ids):\n",
    "                if subject_id not in valid_subjects:\n",
    "                    continue\n",
    "                tmp_table['Phase'].append(phase_subjects[subject_id])\n",
    "                events = events_list[i_sub]\n",
    "                detections = detections_list[i_sub]\n",
    "                if events.size * detections.size == 0:\n",
    "                    print(\"Skipped subject,\", config[\"dataset_name\"], model_name, \"Events shape\", events.shape, \"Detections shape\", detections.shape)\n",
    "                    continue\n",
    "                \n",
    "                # Duration\n",
    "                duration_real = np.mean((events[:, 1] - events[:, 0] + 1) / dataset.fs)\n",
    "                duration_pred = np.mean((detections[:, 1] - detections[:, 0] + 1) / dataset.fs)\n",
    "                tmp_table['Duration_mean_real'].append(duration_real)\n",
    "                tmp_table['Duration_mean_pred'].append(duration_pred)\n",
    "                \n",
    "                # Density\n",
    "                n2_pages = dataset.get_subject_pages(subject_id, pages_subset=constants.N2_RECORD)\n",
    "                n2_minutes = n2_pages.size * dataset.page_duration / 60\n",
    "                density_real = events.shape[0] / n2_minutes\n",
    "                density_pred = detections.shape[0] / n2_minutes\n",
    "                tmp_table['Density_real'].append(density_real)\n",
    "                tmp_table['Density_pred'].append(density_pred)\n",
    "                \n",
    "                # Amplitude\n",
    "                signal = dataset.get_subject_signal(subject_id, normalize_clip=False)\n",
    "                if stat_spindle:\n",
    "                    filt_signal = utils.broad_filter(signal, dataset.fs, lowcut=9, highcut=17)\n",
    "                else:\n",
    "                    filt_signal = utils.filter_iir_lowpass(signal, dataset.fs, highcut=7)\n",
    "                signal_events = [filt_signal[e[0]:e[1]+1] for e in events]\n",
    "                signal_detections = [filt_signal[e[0]:e[1]+1] for e in detections]\n",
    "                amplitude_real = np.mean([(s.max()-s.min()) for s in signal_events])\n",
    "                amplitude_pred = np.mean([(s.max()-s.min()) for s in signal_detections])\n",
    "                tmp_table['AmplitudePP_mean_real'].append(amplitude_real)\n",
    "                tmp_table['AmplitudePP_mean_pred'].append(amplitude_pred)\n",
    "                \n",
    "        table['Detector'].append(model_name)\n",
    "        for key in tmp_table.keys():\n",
    "            table[key].append(tmp_table[key])\n",
    "    metrics_list.append(table)\n",
    "print(\"Metrics computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c5c48",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "save_figure = False\n",
    "\n",
    "scatter_alpha = 0.5\n",
    "markersize = 3\n",
    "baseline_color = viz.GREY_COLORS[8]\n",
    "letters = ['A', 'B', 'C', 'D']\n",
    "letters2 = ['E', 'F', 'G', 'H']\n",
    "letters3 = ['I', 'J', 'K', 'L']\n",
    "model_specs = {\n",
    "    constants.V2_TIME: dict(marker='o', color=viz.PALETTE['blue']),\n",
    "    constants.V2_CWT1D: dict(marker='o', color=viz.PALETTE['red']),\n",
    "    'dosed': dict(marker='s', color=baseline_color),\n",
    "    'a7': dict(marker='^', color=baseline_color),\n",
    "    'spinky': dict(marker='v', color=baseline_color),\n",
    "}\n",
    "print_name = {\n",
    "    'Duration_mean': 'Duración', 'Density': 'Densidad', 'AmplitudePP_mean': 'Amplitud PP'\n",
    "}\n",
    "units = {\n",
    "    'Duration_mean': 's', 'Density': 'epm', 'AmplitudePP_mean': '$\\mu$V'\n",
    "}\n",
    "decimals = {\n",
    "    'Duration_mean': 1, 'Density': 0, 'AmplitudePP_mean': -1\n",
    "}\n",
    "resolutions = {\n",
    "    'Duration_mean': 0.1, 'Density': 1, 'AmplitudePP_mean': 10\n",
    "}\n",
    "for i_config, config in enumerate(eval_configs):\n",
    "    metric_dict = metrics_list[i_config]\n",
    "    n_models = len(metric_dict['Detector'])\n",
    "    dataset_str = print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])]\n",
    "    print(\"Processing\", dataset_str)\n",
    "    fig, axes = plt.subplots(3, 4, figsize=(8, 7), dpi=200)\n",
    "    for i, param_name in enumerate(['Duration_mean', 'Density', 'AmplitudePP_mean']):\n",
    "        # Find range\n",
    "        min_val = 1000\n",
    "        max_val = 0\n",
    "        for j in range(n_models):\n",
    "            x_data = np.array(metric_dict['%s_real' % param_name][j])\n",
    "            y_data = np.array(metric_dict['%s_pred' % param_name][j])\n",
    "            joint_data = np.concatenate([x_data, y_data])\n",
    "            min_val = min(min_val, joint_data.min())\n",
    "            max_val = max(max_val, joint_data.max())\n",
    "        range_width = max_val - min_val\n",
    "        min_val = max(0, min_val - 0.1 * range_width)\n",
    "        max_val = max_val + 0.1 * range_width\n",
    "        min_val = np.around(min_val, decimals=decimals[param_name])\n",
    "        max_val = np.around(max_val, decimals=decimals[param_name])\n",
    "        # print(param_name, min_val, max_val)\n",
    "        if config[\"dataset_name\"] == constants.MODA_SS_NAME and param_name == 'AmplitudePP_mean':\n",
    "            this_resolution = resolutions[param_name] / 2\n",
    "        elif config[\"dataset_name\"] == constants.MASS_KC_NAME and param_name == 'Density':\n",
    "            this_resolution = resolutions[param_name] / 2\n",
    "        else:\n",
    "            this_resolution = resolutions[param_name]\n",
    "        minor_ticks = np.arange(min_val, max_val + 0.001, this_resolution)\n",
    "        major_ticks = [min_val, max_val]\n",
    "        \n",
    "        for j in range(n_models):\n",
    "            ax = axes[i, j]\n",
    "            model_name = metric_dict['Detector'][j]\n",
    "            x_data = np.array(metric_dict['%s_real' % param_name][j])\n",
    "            y_data = np.array(metric_dict['%s_pred' % param_name][j])\n",
    "            ax.plot(\n",
    "                x_data, y_data, linestyle=\"None\", marker='o', \n",
    "                markersize=markersize, alpha=scatter_alpha, markeredgewidth=0.0, color=viz.PALETTE['blue'])\n",
    "\n",
    "            model_str = print_model_names[model_name]\n",
    "            ax.set_title('%s' % model_str, loc=\"left\", fontsize=8)\n",
    "            ax.tick_params(labelsize=8)\n",
    "            ax.set_aspect('equal')\n",
    "            ax.set_xlim([min_val, max_val])\n",
    "            ax.set_ylim([min_val, max_val])\n",
    "            ax.plot([min_val, max_val], [min_val, max_val], color=viz.GREY_COLORS[4], linewidth=0.7, zorder=5)\n",
    "            ax.set_xlabel(\"%s real (%s)\" % (print_name[param_name], units[param_name]), fontsize=8)\n",
    "            ax.set_xticks(major_ticks)\n",
    "            ax.set_xticks(minor_ticks, minor=True)\n",
    "            ax.set_yticks(major_ticks)\n",
    "            ax.set_yticks(minor_ticks, minor=True)\n",
    "            ax.grid(which=\"minor\")\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(\"%s pred. (%s)\" % (print_name[param_name], units[param_name]), fontsize=8)\n",
    "            else:\n",
    "                ax.set_yticklabels([])\n",
    "            \n",
    "            ax.xaxis.labelpad = -7\n",
    "            if config[\"dataset_name\"] == constants.MODA_SS_NAME and param_name == 'Duration_mean':\n",
    "                ax.yaxis.labelpad = -9.5\n",
    "            elif config[\"dataset_name\"] == constants.MODA_SS_NAME and param_name == 'AmplitudePP_mean':\n",
    "                ax.yaxis.labelpad = -9\n",
    "            elif config[\"dataset_name\"] == constants.MASS_KC_NAME and param_name == 'AmplitudePP_mean':\n",
    "                ax.yaxis.labelpad = -12\n",
    "            elif config[\"dataset_name\"] == constants.MASS_KC_NAME and param_name == 'Density':\n",
    "                ax.yaxis.labelpad = -1\n",
    "            elif config[\"dataset_name\"] == constants.MASS_KC_NAME and param_name == 'Duration_mean':\n",
    "                ax.yaxis.labelpad = -8.5\n",
    "            else:\n",
    "                ax.yaxis.labelpad = -7\n",
    "            new_range = max_val - min_val\n",
    "            fig_utils.linear_regression(\n",
    "                x_data, y_data, min_val + 0.1*new_range, max_val-0.1*new_range, ax,\n",
    "                frameon=False, fontsize=8, loc=\"lower right\", bbox_to_anchor=(1.05, -0.05)\n",
    "            )\n",
    "            letters_selected = [letters, letters2, letters3][i]\n",
    "            ax.text(\n",
    "                x=-0.01, y=1.15, fontsize=16, s=r\"$\\bf{%s}$\" % letters_selected[j],\n",
    "                ha=\"left\", transform=ax.transAxes)\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_figure:\n",
    "        # Save figure\n",
    "        fname_prefix = \"result_comparison_bysubject_%s\" % config[\"dataset_name\"]\n",
    "        plt.savefig(\"%s.pdf\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "        plt.savefig(\"%s.png\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "        plt.savefig(\"%s.svg\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.01)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a320413",
   "metadata": {},
   "source": [
    "# Subgroup performance analysis\n",
    "[5CV only, MODA y MASS-KC, by-fold ambos micro] Desempeño en subgrupos: intervalo de duracion, intervalo de amplitud; only SS: intervalo de PR (maxSigma/broadNoDelta) , frecuencia bajo o sobre 13 (medida por cruces por cero)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b07f2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd3ee84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea7d83a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
