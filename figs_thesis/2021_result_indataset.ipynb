{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777296f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.signal import find_peaks, hilbert\n",
    "import pickle\n",
    "\n",
    "project_root = '..'\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from sleeprnn.common import viz, constants\n",
    "from sleeprnn.helpers import reader, plotter, misc, performer\n",
    "from sleeprnn.detection import metrics, det_utils, ensemble\n",
    "from figs_thesis import fig_utils\n",
    "from baselines_scripts.butils import get_partitions\n",
    "from sleeprnn.detection.feeder_dataset import FeederDataset\n",
    "from sklearn.linear_model import LinearRegression, HuberRegressor\n",
    "from sleeprnn.data import utils\n",
    "\n",
    "RESULTS_PATH = os.path.join(project_root, 'results')\n",
    "BASELINES_PATH = os.path.join(project_root, 'resources', 'comparison_data', 'baselines_2021')\n",
    "\n",
    "%matplotlib inline\n",
    "viz.notebook_full_width()\n",
    "\n",
    "param_filtering_fn = fig_utils.get_filtered_signal_for_event\n",
    "param_frequency_fn = fig_utils.get_frequency_by_fft\n",
    "param_amplitude_fn = fig_utils.get_amplitude_event"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160c357c",
   "metadata": {},
   "source": [
    "# Comparación REDv2-Time y REDv2-CWT\n",
    "\n",
    "Métricas en cada base de datos (5CV): F1-score y mIoU entre ambos REDv2 y entre ellos mismos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d128c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT'\n",
    "}\n",
    "print_dataset_names = {\n",
    "    (constants.MASS_SS_NAME, 1): \"MASS-SS2-E1SS\",\n",
    "    (constants.MASS_SS_NAME, 2): \"MASS-SS2-E2SS\",\n",
    "    (constants.MASS_KC_NAME, 1): \"MASS-SS2-KC\",\n",
    "    (constants.MODA_SS_NAME, 1): \"MASS-MODA\",\n",
    "    (constants.INTA_SS_NAME, 1): \"INTA-UCH\",\n",
    "}\n",
    "\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=2, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.INTA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "metrics_list = []\n",
    "metrics_raw_list = []\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    average_mode = constants.MICRO_AVERAGE if (config[\"dataset_name\"] == constants.MODA_SS_NAME) else constants.MACRO_AVERAGE\n",
    "    # Collect predictions\n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        tmp_dict = fig_utils.get_red_predictions(model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        # Retrieve only predictions, same format as baselines\n",
    "        pred_dict[model_version] = {s: {} for s in dataset.all_ids}\n",
    "        for k in range(n_folds):\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "            for s, pred in zip(fold_subjects, fold_predictions):\n",
    "                pred_dict[model_version][s][k] = pred\n",
    "    # Generate typical dict\n",
    "    pred_dict_original = {}\n",
    "    for model_version in models:\n",
    "        pred_dict_original[model_version] = {}\n",
    "        for k in range(n_folds):\n",
    "            pred_dict_original[model_version][k] = {s: pred_dict[model_version][s][k] for s in test_ids_list[k]}\n",
    "    # Generate surrogate model\n",
    "    # Random permutation of fold assignments of predictions\n",
    "    pred_dict_permuted = {}\n",
    "    for model_version in models:\n",
    "        pred_dict_permuted[model_version] = {}\n",
    "        for i_sub, subject_id in enumerate(dataset.all_ids):\n",
    "            byfold_preds = pred_dict[model_version][subject_id]\n",
    "            subject_folds = list(byfold_preds.keys())\n",
    "            subject_preds = [byfold_preds[k] for k in subject_folds]\n",
    "            subject_folds = np.random.RandomState(seed=i_sub).permutation(subject_folds)\n",
    "            pred_dict_permuted[model_version][subject_id] = {k: pred for k, pred in zip(subject_folds, subject_preds)}\n",
    "    pred_dict_permuted_original = {}\n",
    "    for model_version in models:\n",
    "        pred_dict_permuted_original[model_version] = {}\n",
    "        for k in range(n_folds):\n",
    "            pred_dict_permuted_original[model_version][k] = {s: pred_dict_permuted[model_version][s][k] for s in test_ids_list[k]}\n",
    "    \n",
    "    # Performance\n",
    "    table = {'Comparison': [], 'F1-score': [], 'Recall': [], 'Precision': [], 'mIoU': [], 'Fold': []}\n",
    "    # Measure performance of model with itself\n",
    "    for model_version in models:\n",
    "        for k in range(n_folds):\n",
    "            subject_ids = test_ids_list[k]\n",
    "            events_list = [pred_dict_original[model_version][k][subject_id] for subject_id in subject_ids]\n",
    "            detections_list = [pred_dict_permuted_original[model_version][k][subject_id] for subject_id in subject_ids]\n",
    "            performance = fig_utils.compute_fold_performance(events_list, detections_list, average_mode)\n",
    "            table['Comparison'].append('%s_vs_%s' % (model_version, model_version))\n",
    "            table['F1-score'].append(performance['F1-score'])\n",
    "            table['Recall'].append(performance['Recall'])\n",
    "            table['Precision'].append(performance['Precision'])\n",
    "            table['mIoU'].append(performance['mIoU'])\n",
    "            table['Fold'].append(k)\n",
    "    # Measure performance of time vs cwt\n",
    "    for k in range(n_folds):\n",
    "        subject_ids = test_ids_list[k]\n",
    "        events_list = [pred_dict_original[models[0]][k][subject_id] for subject_id in subject_ids]\n",
    "        detections_list = [pred_dict_original[models[1]][k][subject_id] for subject_id in subject_ids]\n",
    "        performance = fig_utils.compute_fold_performance(events_list, detections_list, average_mode)\n",
    "        table['Comparison'].append('%s_vs_%s' % (models[0], models[1]))\n",
    "        table['F1-score'].append(performance['F1-score'])\n",
    "        table['Recall'].append(performance['Recall'])\n",
    "        table['Precision'].append(performance['Precision'])\n",
    "        table['mIoU'].append(performance['mIoU'])\n",
    "        table['Fold'].append(k)\n",
    "    \n",
    "    table = pd.DataFrame.from_dict(table)\n",
    "    metrics_raw_list.append(table)\n",
    "    mean_table = table.groupby(by=[\"Comparison\"]).mean()[[\"F1-score\", \"mIoU\"]].add_suffix(\"_mean\")\n",
    "    std_table = table.groupby(by=[\"Comparison\"]).std(ddof=0)[[\"F1-score\", \"mIoU\"]].add_suffix(\"_std\")\n",
    "    subgroup_stats_table = mean_table.join(std_table)\n",
    "    subgroup_stats_table = subgroup_stats_table.reindex(sorted(subgroup_stats_table.columns), axis=1)\n",
    "    subgroup_stats_table = subgroup_stats_table.reset_index()\n",
    "    metrics_list.append(subgroup_stats_table)  \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086b32f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla Latex\n",
    "comparisons_order = [\"v2_time_vs_v2_time\", \"v2_cwt1d_vs_v2_cwt1d\", \"v2_time_vs_v2_cwt1d\"]\n",
    "comparisons_print_name = {\n",
    "    \"v2_time_vs_v2_time\": \"REDv2-Time vs REDv2-Time\", \n",
    "    \"v2_cwt1d_vs_v2_cwt1d\": \"REDv2-CWT vs REDv2-CWT\", \n",
    "    \"v2_time_vs_v2_cwt1d\": \"REDv2-Time vs REDv2-CWT\"\n",
    "}\n",
    "\n",
    "print(\"Datos & Comparación & F1-score (%) & mIoU (%) \\\\\\\\\")\n",
    "for i_config, config in enumerate(eval_configs):\n",
    "    print(\"\")\n",
    "    dataset_str = print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])]\n",
    "    metrics_dict = metrics_list[i_config].set_index('Comparison').to_dict('index')\n",
    "    for comparison in comparisons_order:\n",
    "        mets = metrics_dict[comparison]\n",
    "        metric_str = \"$%1.1f\\pm %1.1f$ & $%1.1f\\pm %1.1f$\" % (\n",
    "            100 * mets['F1-score_mean'], 100 * mets['F1-score_std'],\n",
    "            100 * mets['mIoU_mean'], 100 * mets['mIoU_std'])\n",
    "        row_str = \"%s & %s & %s \\\\\\\\\" % (dataset_str, comparisons_print_name[comparison], metric_str)\n",
    "        print(row_str)\n",
    "        \n",
    "    # Statistical tests\n",
    "    reference_comparison = comparisons_order[-1]\n",
    "    print(\"P-value test against %s\" % reference_comparison)\n",
    "    table = metrics_raw_list[i_config]\n",
    "    for comparison in comparisons_order[:-1]:\n",
    "        print(\"%s:\" % comparison.ljust(30), end='')\n",
    "        for metric_name in [\"F1-score\", \"mIoU\"]:\n",
    "            model_metrics = table[table[\"Comparison\"] == comparison][metric_name].values\n",
    "            reference_metrics = table[table[\"Comparison\"] == reference_comparison][metric_name].values\n",
    "            pvalue = stats.ttest_ind(model_metrics, reference_metrics, equal_var=False)[1]\n",
    "            print(\" P(%s) %1.4f\" % (metric_name, pvalue), end='')\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de45a4f",
   "metadata": {},
   "source": [
    "# Ensamble de RED\n",
    "\n",
    "Desempeño al ensamblar las detecciones de ambos modelos (y ensambles de un modelo consigo mismo haciendo el truco de la permutacion) con un AND, con un OR, o al promediar las probabilidades ajustadas antes de aplicar el umbral. Esto para ver si las pequeñas diferencias que tienen ayudan o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3563a118",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT'\n",
    "}\n",
    "print_dataset_names = {\n",
    "    (constants.MASS_SS_NAME, 1): \"MASS-SS2-E1SS\",\n",
    "    (constants.MASS_SS_NAME, 2): \"MASS-SS2-E2SS\",\n",
    "    (constants.MASS_KC_NAME, 1): \"MASS-SS2-KC\",\n",
    "    (constants.MODA_SS_NAME, 1): \"MASS-MODA\",\n",
    "    (constants.INTA_SS_NAME, 1): \"INTA-UCH\",\n",
    "}\n",
    "\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=2, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.INTA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "ensemble_criterion_list = [\n",
    "    'and', \n",
    "    # 'or', \n",
    "    'avg'\n",
    "]\n",
    "\n",
    "metrics_list = []\n",
    "metrics_raw_list = []\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    average_mode = constants.MICRO_AVERAGE if (config[\"dataset_name\"] == constants.MODA_SS_NAME) else constants.MACRO_AVERAGE\n",
    "    # Collect predictions\n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        tmp_dict = fig_utils.get_red_predictions(\n",
    "            model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        # Retrieve probas and stamps\n",
    "        pred_dict[model_version] = {s: {} for s in dataset.all_ids}\n",
    "        for k in range(n_folds):\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            fold_probas = tmp_dict[k][constants.TEST_SUBSET].get_probabilities(return_adjusted=True)\n",
    "            fold_stamps = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "            for s, proba, stamp in zip(fold_subjects, fold_probas, fold_stamps):\n",
    "                pred_dict[model_version][s][k] = {'probability': proba, 'stamp': stamp} \n",
    "    # Generate typical dict\n",
    "    pred_dict_original = {}\n",
    "    for model_version in models:\n",
    "        pred_dict_original[model_version] = {}\n",
    "        for k in range(n_folds):\n",
    "            pred_dict_original[model_version][k] = {s: pred_dict[model_version][s][k] for s in test_ids_list[k]}\n",
    "    # Generate surrogate model\n",
    "    # Random permutation of fold assignments of predictions\n",
    "    pred_dict_permuted = {}\n",
    "    for model_version in models:\n",
    "        pred_dict_permuted[model_version] = {}\n",
    "        for i_sub, subject_id in enumerate(dataset.all_ids):\n",
    "            byfold_preds = pred_dict[model_version][subject_id]\n",
    "            subject_folds = list(byfold_preds.keys())\n",
    "            subject_preds = [byfold_preds[k] for k in subject_folds]\n",
    "            subject_folds = np.random.RandomState(seed=i_sub).permutation(subject_folds)\n",
    "            pred_dict_permuted[model_version][subject_id] = {k: pred for k, pred in zip(subject_folds, subject_preds)}\n",
    "    pred_dict_permuted_original = {}\n",
    "    for model_version in models:\n",
    "        pred_dict_permuted_original[model_version] = {}\n",
    "        for k in range(n_folds):\n",
    "            pred_dict_permuted_original[model_version][k] = {s: pred_dict_permuted[model_version][s][k] for s in test_ids_list[k]}\n",
    "            \n",
    "    # Performance\n",
    "    # AND: ensemble of stamps -> thr = 1.0\n",
    "    # OR: ensemble of stamps -> thr = 1 / n_models\n",
    "    # AVG: ensemble of probas with thr of 0.5\n",
    "    table = {'Ensemble': [], 'F1-score': [], 'Recall': [], 'Precision': [], 'mIoU': [], 'Fold': []}\n",
    "    pred_sources = {\n",
    "        'v2_time': pred_dict_original['v2_time'],\n",
    "        'v2_time_perm': pred_dict_permuted_original['v2_time'],\n",
    "        'v2_cwt1d': pred_dict_original['v2_cwt1d'],\n",
    "        'v2_cwt1d_perm': pred_dict_permuted_original['v2_cwt1d'],\n",
    "    }\n",
    "    pairs = [\n",
    "        ('v2_time', 'v2_time'),\n",
    "        ('v2_cwt1d', 'v2_cwt1d'),\n",
    "        ('v2_time', 'v2_time_perm'),\n",
    "        ('v2_cwt1d', 'v2_cwt1d_perm'),\n",
    "        ('v2_time', 'v2_cwt1d'),\n",
    "    ]\n",
    "    for k in range(n_folds):\n",
    "        subject_ids = test_ids_list[k]\n",
    "        print(\"Fold %s\" % (k))\n",
    "        reference_feeder_dataset = FeederDataset(dataset, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "        events_list = reference_feeder_dataset.get_stamps()\n",
    "        for pred_source_name_1, pred_source_name_2 in pairs:\n",
    "            pred_source_1 = pred_sources[pred_source_name_1]\n",
    "            pred_source_2 = pred_sources[pred_source_name_2]\n",
    "            if pred_source_name_1 == pred_source_name_2:\n",
    "                detections_list = [pred_source_1[k][subject_id]['stamp'] for subject_id in subject_ids]\n",
    "                performance = fig_utils.compute_fold_performance(events_list, detections_list, average_mode)\n",
    "                ensemble_str = pred_source_name_1\n",
    "                table['Ensemble'].append(ensemble_str)\n",
    "                table['F1-score'].append(performance['F1-score'])\n",
    "                table['Recall'].append(performance['Recall'])\n",
    "                table['Precision'].append(performance['Precision'])\n",
    "                table['mIoU'].append(performance['mIoU'])\n",
    "                table['Fold'].append(k)\n",
    "            else:\n",
    "                for criterion in ensemble_criterion_list:\n",
    "                    if criterion == 'and':\n",
    "                        dict_of_stamps = {s: [pred_source_1[k][s]['stamp'], pred_source_2[k][s]['stamp']] for s in subject_ids}\n",
    "                        ensemble_pred_obj = ensemble.generate_ensemble_from_stamps(dict_of_stamps, reference_feeder_dataset, skip_setting_threshold=True)\n",
    "                        ensemble_pred_obj.set_parent_dataset(dataset)\n",
    "                        ensemble_pred_obj.set_probability_threshold(1.0)\n",
    "                    elif criterion == 'or':\n",
    "                        dict_of_stamps = {s: [pred_source_1[k][s]['stamp'], pred_source_2[k][s]['stamp']] for s in subject_ids}\n",
    "                        ensemble_pred_obj = ensemble.generate_ensemble_from_stamps(dict_of_stamps, reference_feeder_dataset, skip_setting_threshold=True)\n",
    "                        ensemble_pred_obj.set_parent_dataset(dataset)\n",
    "                        ensemble_pred_obj.set_probability_threshold(0.5)\n",
    "                    elif criterion == 'avg':\n",
    "                        dict_of_probas = {s: [pred_source_1[k][s]['probability'], pred_source_2[k][s]['probability']] for s in subject_ids}\n",
    "                        ensemble_pred_obj = ensemble.generate_ensemble_from_probabilities(dict_of_probas, reference_feeder_dataset, skip_setting_threshold=True)\n",
    "                        ensemble_pred_obj.set_parent_dataset(dataset)\n",
    "                        ensemble_pred_obj.set_probability_threshold(0.5)\n",
    "                    else:\n",
    "                        raise ValueError()\n",
    "                    detections_list = ensemble_pred_obj.get_stamps()\n",
    "                    performance = fig_utils.compute_fold_performance(events_list, detections_list, average_mode)\n",
    "                    ensemble_str = '%s(%s,%s)' % (criterion, pred_source_name_1, pred_source_name_2)\n",
    "                    table['Ensemble'].append(ensemble_str)\n",
    "                    table['F1-score'].append(performance['F1-score'])\n",
    "                    table['Recall'].append(performance['Recall'])\n",
    "                    table['Precision'].append(performance['Precision'])\n",
    "                    table['mIoU'].append(performance['mIoU'])\n",
    "                    table['Fold'].append(k)\n",
    "    table = pd.DataFrame.from_dict(table)\n",
    "    metrics_raw_list.append(table)\n",
    "    mean_table = table.groupby(by=[\"Ensemble\"]).mean().drop(columns=[\"Fold\"]).add_suffix(\"_mean\")\n",
    "    std_table = table.groupby(by=[\"Ensemble\"]).std(ddof=0).drop(columns=[\"Fold\"]).add_suffix(\"_std\")\n",
    "    subgroup_stats_table = mean_table.join(std_table)\n",
    "    subgroup_stats_table = subgroup_stats_table.reindex(sorted(subgroup_stats_table.columns), axis=1)\n",
    "    subgroup_stats_table = subgroup_stats_table.reset_index()\n",
    "    metrics_list.append(subgroup_stats_table)  \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc958851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla Latex\n",
    "ensembles_order = [\n",
    "    \"v2_time\", \n",
    "    \"v2_cwt1d\",\n",
    "    \"and(v2_time,v2_time_perm)\",\n",
    "    \"and(v2_cwt1d,v2_cwt1d_perm)\",\n",
    "    \"and(v2_time,v2_cwt1d)\",\n",
    "    \"avg(v2_time,v2_time_perm)\",\n",
    "    \"avg(v2_cwt1d,v2_cwt1d_perm)\",\n",
    "    \"avg(v2_time,v2_cwt1d)\",\n",
    "]\n",
    "ensembles_print_name = {\n",
    "    \"v2_time\": \"REDv2-Time\", \n",
    "    \"v2_cwt1d\": \"REDv2-CWT\",\n",
    "    \"and(v2_time,v2_time_perm)\": \"AND(REDv2-Time, REDv2-Time)\",\n",
    "    \"and(v2_cwt1d,v2_cwt1d_perm)\": \"AND(REDv2-CWT, REDv2-CWT)\",\n",
    "    \"and(v2_time,v2_cwt1d)\": \"AND(REDv2-Time, REDv2-CWT)\",\n",
    "    \"avg(v2_time,v2_time_perm)\": \"AVG(REDv2-Time, REDv2-Time)\",\n",
    "    \"avg(v2_cwt1d,v2_cwt1d_perm)\": \"AVG(REDv2-CWT, REDv2-CWT)\",\n",
    "    \"avg(v2_time,v2_cwt1d)\": \"AVG(REDv2-Time, REDv2-CWT)\",\n",
    "}\n",
    "print(\"\\\\toprule\")\n",
    "print(\"Datos & Detector & F1-score (\\%) & mIoU (\\%) \\\\\\\\\")\n",
    "for i_config, config in enumerate(eval_configs):\n",
    "    print(\"\\midrule\")\n",
    "    dataset_str = print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])]\n",
    "    metrics_dict = metrics_list[i_config].set_index('Ensemble').to_dict('index')\n",
    "    for i_ens, ensemble in enumerate(ensembles_order):\n",
    "        mets = metrics_dict[ensemble]\n",
    "        metric_str = \"$%1.1f\\pm %1.1f$ & $%1.1f\\pm %1.1f$\" % (\n",
    "            100 * mets['F1-score_mean'], 100 * mets['F1-score_std'],\n",
    "            100 * mets['mIoU_mean'], 100 * mets['mIoU_std'])\n",
    "        dataset_to_print = '%s\\n' % dataset_str if (i_ens == 0) else ''\n",
    "        row_str = \"%s & %s & %s \\\\\\\\\" % (dataset_to_print, ensembles_print_name[ensemble].ljust(30), metric_str)\n",
    "        print(row_str)\n",
    "        \n",
    "    # Statistical tests\n",
    "    #reference_ensemble = ensembles_order[0]\n",
    "    #print(\"P-value test against %s\" % reference_ensemble)\n",
    "    #table = metrics_raw_list[i_config]\n",
    "    #for ensemble in ensembles_order[1:]:\n",
    "    #    print(\"%s:\" % ensemble.ljust(50), end='')\n",
    "    #    for metric_name in [\"F1-score\", \"mIoU\"]:\n",
    "    #        model_metrics = table[table[\"Ensemble\"] == ensemble][metric_name].values\n",
    "    #        reference_metrics = table[table[\"Ensemble\"] == reference_ensemble][metric_name].values\n",
    "    #        pvalue = stats.ttest_ind(model_metrics, reference_metrics, equal_var=False)[1]\n",
    "    #        print(\" P(%s) %1.4f\" % (metric_name, pvalue), end='')\n",
    "    #    print(\"\")\n",
    "print(\"\\\\bottomrule\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a325a090",
   "metadata": {},
   "source": [
    "# Perturbaciones en la entrada\n",
    "Medir cambios en SubsetMetric vs perturbacion, donde subset metric es la metrica mean+-std del 5CV del dataset, y puede ser f1-score, recall, precision y mIoU (lo bueno es que las 4 están en el rango 0-1).\n",
    "- Escalar la señal de entrada. Curva continua\n",
    "- Inversión de voltaje (multiplicar por -1) y de tiempo (flipped signal y labels, para implementarlo se podria hacer flip de la entrada, y el vector de probabilidad de salida volver a hacerle un flip). Discreto (barras).\n",
    "- Filtrar (quitar) bandas de potencia (modelado ya entrenado). Delta separarlo en delta lenta y rapida. Discreto (barras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66974e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT'\n",
    "}\n",
    "print_dataset_names = {\n",
    "    (constants.MASS_SS_NAME, 1): \"MASS-SS2-E1SS\",\n",
    "    (constants.MASS_SS_NAME, 2): \"MASS-SS2-E2SS\",\n",
    "    (constants.MASS_KC_NAME, 1): \"MASS-SS2-KC\",\n",
    "    (constants.MODA_SS_NAME, 1): \"MASS-MODA\",\n",
    "    (constants.INTA_SS_NAME, 1): \"INTA-UCH\",\n",
    "}\n",
    "\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "metrics_list = []\n",
    "metrics_raw_list = []\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    average_mode = constants.MICRO_AVERAGE if (config[\"dataset_name\"] == constants.MODA_SS_NAME) else constants.MACRO_AVERAGE\n",
    "    # Collect predictions\n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        pred_dict[model_version] = {}\n",
    "        tmp_pert_dict = fig_utils.get_red_predictions_for_perturbations(model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        perturbations = list(tmp_pert_dict.keys())\n",
    "        for perturbation_name in perturbations:\n",
    "            pred_dict[model_version][perturbation_name] = {}\n",
    "            tmp_dict = tmp_pert_dict[perturbation_name]\n",
    "            for k in tmp_dict.keys():\n",
    "                fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "                fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "                pred_dict[model_version][perturbation_name][k] = {s: pred for s, pred in zip(fold_subjects, fold_predictions)}\n",
    "\n",
    "    # Performance\n",
    "    table = {'Detector': [], 'Perturbación': [], 'F1-score': [], 'Recall': [], 'Precision': [], 'mIoU': [], 'Fold': []}\n",
    "    # Measure performance of model with itself\n",
    "    for model_version in models:\n",
    "        for perturbation_name in perturbations:\n",
    "            for k in range(n_folds):\n",
    "                subject_ids = test_ids_list[k]\n",
    "                feed_d = FeederDataset(dataset, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "                events_list = feed_d.get_stamps()\n",
    "                detections_list = [pred_dict[model_version][perturbation_name][k][subject_id] for subject_id in subject_ids]\n",
    "                performance = fig_utils.compute_fold_performance(events_list, detections_list, average_mode)\n",
    "                table['Detector'].append(model_version)\n",
    "                table['Perturbación'].append(perturbation_name)\n",
    "                table['F1-score'].append(performance['F1-score'])\n",
    "                table['Recall'].append(performance['Recall'])\n",
    "                table['Precision'].append(performance['Precision'])\n",
    "                table['mIoU'].append(performance['mIoU'])\n",
    "                table['Fold'].append(k)\n",
    "    table = pd.DataFrame.from_dict(table)\n",
    "    print(\"By-fold statistics\")\n",
    "    metrics_raw_list.append(table)\n",
    "    mean_table = table.groupby(by=[\"Detector\", \"Perturbación\"]).mean().drop(columns=[\"Fold\"]).add_suffix(\"_mean\")\n",
    "    std_table = table.groupby(by=[\"Detector\", \"Perturbación\"]).std(ddof=0).drop(columns=[\"Fold\"]).add_suffix(\"_std\")\n",
    "    subgroup_stats_table = mean_table.join(std_table)\n",
    "    subgroup_stats_table = subgroup_stats_table.reindex(sorted(subgroup_stats_table.columns), axis=1)\n",
    "    subgroup_stats_table = subgroup_stats_table.reset_index()\n",
    "    metrics_list.append(subgroup_stats_table)  \n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc963194",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate table for latex\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT',\n",
    "}\n",
    "ref_order = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "pert_prefix_order = ['scale', 'invert', 'filter']\n",
    "pert_labels = {\n",
    "    'scale': 'Factor de escala',\n",
    "    'invert': 'Inversión',\n",
    "    'filter': 'Filtro rechaza-banda',\n",
    "}\n",
    "pert_sorted_values = {\n",
    "    'scale': np.round(np.arange(0.5, 1.5 + 0.001, 0.1), 1),\n",
    "    'invert': ['value', 'time'],\n",
    "    'filter': [(0, 2), (2, 4), (4, 8), (8, 11), (10, 16), (16, 30)]\n",
    "}\n",
    "pert_names_table = {\n",
    "    'scale': {x: '%1.1f' % x for x in pert_sorted_values['scale']},\n",
    "    'invert': {x: x for x in pert_sorted_values['invert']},\n",
    "    'filter': {b: '%d-%d' % (b[0], b[1]) for b in pert_sorted_values['filter']}\n",
    "}\n",
    "pert_names_print = {\n",
    "    'scale': {x: '%1.1f' % x for x in pert_sorted_values['scale']},\n",
    "    'invert': {'time': 'Tiempo', 'value': 'Amplitud'},\n",
    "    'filter': {b: '%d-%d Hz' % (b[0], b[1]) for b in pert_sorted_values['filter']}\n",
    "}\n",
    "print(\"Datos & Perturbación & Valor & %s \\\\\\\\\" % \" & \".join([print_model_names[model_name] for model_name in ref_order]))\n",
    "for i_config, config in enumerate(eval_configs):\n",
    "    dataset_str = print_dataset_names[(config['dataset_name'], config['expert'])]\n",
    "    table = metrics_list[i_config]\n",
    "    model_names = [m for m in ref_order if m in np.unique(table['Detector'])]\n",
    "    n_models = len(model_names)\n",
    "    table = table[['Detector', 'Perturbación', 'F1-score_mean', 'F1-score_std']]\n",
    "    perturbations = np.unique(table['Perturbación'])\n",
    "    print(\"\\n%s\" % dataset_str)\n",
    "    for pert_prefix in pert_prefix_order:      \n",
    "        print(\"& %s\" % pert_labels[pert_prefix])\n",
    "        for pert_value in pert_sorted_values[pert_prefix]:\n",
    "            metric_str_list = []\n",
    "            pert_name_table = '%s-%s' % (pert_prefix, pert_names_table[pert_prefix][pert_value])\n",
    "            for model_name in model_names:\n",
    "                model_table = table[(table['Detector'] == model_name) & (np.isin(table['Perturbación'], pert_name_table))].drop(columns=['Detector'])\n",
    "                model_table = model_table.set_index('Perturbación')\n",
    "                metrics_dict = model_table.to_dict('index')\n",
    "                metric_str = '$%1.1f\\pm %1.1f$' % (\n",
    "                    100 * metrics_dict[pert_name_table]['F1-score_mean'], 100 * metrics_dict[pert_name_table]['F1-score_std'])\n",
    "                metric_str_list.append(metric_str)\n",
    "            metric_str = \" & \".join(metric_str_list)\n",
    "            pert_name_to_print = pert_names_print[pert_prefix][pert_value]\n",
    "            metric_str = \" & & %s & %s \\\\\\\\\" % (pert_name_to_print, metric_str)\n",
    "            print(metric_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3e82ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure\n",
    "\n",
    "save_figure = True\n",
    "markersize = 4\n",
    "number_of_std = 1\n",
    "groups_total_width = 0.5\n",
    "\n",
    "letters = ['A', 'B', 'C', 'D', 'E', 'F']\n",
    "baseline_color = viz.GREY_COLORS[8]\n",
    "model_specs = {\n",
    "    constants.V2_TIME: dict(marker='o', color=viz.PALETTE['blue']),\n",
    "    constants.V2_CWT1D: dict(marker='o', color=viz.PALETTE['red']),\n",
    "}\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT',\n",
    "}\n",
    "ref_order = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "pert_prefix_order = ['scale', 'invert', 'filter']\n",
    "pert_labels = {\n",
    "    'scale': 'Factor de escala',\n",
    "    'invert': 'Inversión',\n",
    "    'filter': 'Filtro rechaza-banda (Hz)',\n",
    "}\n",
    "pert_sorted_values = {\n",
    "    'scale': np.round(np.arange(0.5, 1.5 + 0.001, 0.1), 1),\n",
    "    'invert': ['none', 'value', 'time'],\n",
    "    'filter': [(0, 2), (2, 4), (4, 8), (8, 11), (10, 16), (16, 30)]\n",
    "}\n",
    "pert_names_table = {\n",
    "    'scale': {x: '%1.1f' % x for x in pert_sorted_values['scale']},\n",
    "    'invert': {x: x for x in pert_sorted_values['invert']},\n",
    "    'filter': {b: '%d-%d' % (b[0], b[1]) for b in pert_sorted_values['filter']}\n",
    "}\n",
    "pert_names_print = {\n",
    "    'scale': {x: '%1.1f' % x for x in pert_sorted_values['scale']},\n",
    "    'invert': {'none': 'Ninguna', 'time': 'Tiempo', 'value': 'Amplitud'},\n",
    "    'filter': {b: '%d-%d' % (b[0], b[1]) for b in pert_sorted_values['filter']}\n",
    "}\n",
    "metrics_sorted = ['F1-score', 'Recall', 'Precision', 'mIoU']\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(8, 9), dpi=200)\n",
    "axes = np.concatenate([axes[:1, :], axes[1:, :]], axis=1) \n",
    "axes = axes.flatten()\n",
    "\n",
    "ax_loc = -1  # global loc\n",
    "for i_config, config in enumerate(eval_configs):\n",
    "    table = metrics_list[i_config]\n",
    "    model_names = [m for m in ref_order if m in np.unique(table['Detector'])]\n",
    "    for model_name in model_names:\n",
    "        original_perf_row = table[(table['Detector'] == model_name) & (table['Perturbación'] == 'scale-1.0')].to_dict(orient='records')[0]\n",
    "        original_perf_row['Perturbación'] = 'invert-none'\n",
    "        table = table.append(original_perf_row, ignore_index=True)\n",
    "    n_models = len(model_names)\n",
    "    for pert_prefix in pert_prefix_order:\n",
    "        ax_loc += 1\n",
    "        ax = axes[ax_loc]\n",
    "        pert_values = pert_sorted_values[pert_prefix]\n",
    "        pert_table = ['%s-%s' % (pert_prefix, pert_names_table[pert_prefix][pert_value]) for pert_value in pert_values]\n",
    "    \n",
    "        n_groups = len(pert_values)\n",
    "        positions = np.arange(n_groups)\n",
    "        groups_width = groups_total_width / n_models\n",
    "        initial_group_center_offset = groups_width * (1 - n_models) / 2\n",
    "        offsets = initial_group_center_offset + np.arange(n_models) * groups_width\n",
    "        distance_from_edge = groups_total_width / 2 + 0.05\n",
    "\n",
    "        for j, model_name in enumerate(model_names):\n",
    "            \n",
    "            model_table = table[(table['Detector'] == model_name) & (np.isin(table['Perturbación'], pert_table))].drop(columns=['Detector'])\n",
    "            model_table = model_table.set_index('Perturbación')\n",
    "            metrics_dict = model_table.to_dict('index')\n",
    "            \n",
    "            metric_lims = []\n",
    "            for i, metric_name in enumerate(metrics_sorted):\n",
    "                offset = - 1.2 * i\n",
    "                metric_lims.append([offset, offset + 1])\n",
    "                # Margins\n",
    "                ax.axhline(offset, linewidth=0.8, color=\"k\")\n",
    "                ax.axhline(offset + 1, linewidth=0.8, color=\"k\")\n",
    "                ax.plot(\n",
    "                    [positions[0]-distance_from_edge, positions[0]-distance_from_edge], \n",
    "                    [offset + 0.01, offset + 1 - 0.01], linewidth=1.6, color=\"k\")\n",
    "                ax.plot(\n",
    "                    [positions[-1]+distance_from_edge, positions[-1]+distance_from_edge], \n",
    "                    [offset + 0.01, offset + 1 - 0.01], linewidth=1.6, color=\"k\")\n",
    "                if pert_prefix == 'scale':\n",
    "                    center_pos = n_groups // 2\n",
    "                    ax.plot(\n",
    "                        [positions[center_pos], positions[center_pos]], \n",
    "                        [offset + 0.01, offset + 1 - 0.01], linewidth=1.1, color=\"k\", zorder=10, linestyle=\"--\")\n",
    "                # Data\n",
    "                mean_data = offset + np.array([metrics_dict[pert_name_table]['%s_mean' % metric_name] for pert_name_table in pert_table])\n",
    "                std_data = np.array([metrics_dict[pert_name_table]['%s_std' % metric_name] for pert_name_table in pert_table])\n",
    "                this_positions = positions + offsets[j]\n",
    "                ax.plot(\n",
    "                    this_positions, mean_data, label=print_model_names[model_name], linestyle=\"None\",\n",
    "                    marker=model_specs[model_name][\"marker\"], markersize=markersize, markeredgewidth=0.0,\n",
    "                    color=model_specs[model_name][\"color\"], zorder=30)\n",
    "                for i_sg in range(n_groups):\n",
    "                    ax.plot(\n",
    "                        [this_positions[i_sg], this_positions[i_sg]],\n",
    "                        [\n",
    "                            mean_data[i_sg] - number_of_std*std_data[i_sg], \n",
    "                            mean_data[i_sg] + number_of_std*std_data[i_sg]\n",
    "                        ],\n",
    "                        linewidth=1, color=model_specs[model_name][\"color\"], zorder=20\n",
    "                    )\n",
    "        \n",
    "        ax.spines['left'].set_visible(False)\n",
    "        ax.spines['right'].set_visible(False)\n",
    "        ax.set_xlim([positions[0] - distance_from_edge, positions[-1] + distance_from_edge])\n",
    "        ax.set_ylim([offset, 1])\n",
    "        yticks = np.concatenate([[m[0], (m[0]+m[1])/2, m[1]] for m in metric_lims])\n",
    "        yticklabels = np.concatenate([[0, n, 1] for n in metrics_sorted])\n",
    "        yticks_minor = np.concatenate([np.arange(m[0], m[1]+0.001, 0.1) for m in metric_lims])\n",
    "        ax.set_yticks(yticks)\n",
    "        ax.set_yticklabels(yticklabels)\n",
    "        ax.set_yticks(yticks_minor, minor=True)\n",
    "        for i_tick, t in enumerate(ax.get_yticklabels()):\n",
    "            if i_tick % 3 == 1:\n",
    "                t.set_rotation('vertical')\n",
    "                t.set_verticalalignment('center')\n",
    "        ax.grid(axis=\"y\", which=\"minor\")\n",
    "        ax.yaxis.labelpad = -8\n",
    "        ax.tick_params(labelsize=8)\n",
    "        ax.set_xticks([i for i in range(n_groups)])\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_xticklabels([pert_names_print[pert_prefix][pert_value] for pert_value in pert_values])\n",
    "        ax.set_xlabel(pert_labels[pert_prefix], fontsize=8)\n",
    "        dataset_str = print_dataset_names[(config['dataset_name'], config['expert'])]\n",
    "        ax.set_title(\"Perturbación en %s\" % dataset_str, loc=\"center\", fontsize=8)   \n",
    "        ax.text(\n",
    "            x=-0.01, y=1.02, fontsize=16, s=r\"$\\bf{%s}$\" % letters[ax_loc],\n",
    "            ha=\"left\", transform=ax.transAxes)\n",
    "        \n",
    "plt.tight_layout()\n",
    "\n",
    "# Get legend methods\n",
    "labels_to_lines_dict = {}\n",
    "for ax in axes:\n",
    "    t_lines, t_labels = ax.get_legend_handles_labels()\n",
    "    for lbl, lin in zip(t_labels, t_lines):\n",
    "        labels_to_lines_dict[lbl] = lin\n",
    "labels = [\"REDv2-Time\", \"REDv2-CWT\"]\n",
    "lines = [labels_to_lines_dict[lbl] for lbl in labels]\n",
    "lg1 = fig.legend(\n",
    "    lines, labels, fontsize=8, loc=\"lower center\",\n",
    "    bbox_to_anchor=(0.5, 0.01), ncol=len(labels), frameon=False, handletextpad=0.5)\n",
    "\n",
    "if save_figure:\n",
    "    # Save figure\n",
    "    fname_prefix = \"result_indata_perturbations\"\n",
    "    plt.savefig(\"%s.pdf\" % fname_prefix, bbox_extra_artists=(lg1,), bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.png\" % fname_prefix, bbox_extra_artists=(lg1,), bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.svg\" % fname_prefix, bbox_extra_artists=(lg1,), bbox_inches=\"tight\", pad_inches=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79872dd7",
   "metadata": {},
   "source": [
    "# PINK\n",
    "\n",
    "Respuesta del modelo ya entrenado ante ruido rosado , incluyendo qué pasa si el ruido rosado cambia su desviacion estandar (escalamiento de 1 a 2 con paso 0.5). Medir tasa promedio de falsos por horas de la señal, y visualizar detecciones en caso de haber, y ver qué tan estable es dicha deteccion (si la predicen varios checkpoints o no). \n",
    "\n",
    "Todos los checkpoints predicen todo pink.\n",
    "\n",
    "Ideas:\n",
    "- Numero de detecciones por minuto u hora vs escala.\n",
    "- Probabilidad asignada a las detecciones vs escala.\n",
    "- Para la escala 1.0: Distribucion de amplitud, duracion, y frecuencia si es SS.\n",
    "- Visualización de algunas detecciones con amplitud creciente, mostrando los vectores de probabilidad ajustada de todos los folds.\n",
    "- Grand-average de \"complejo K\" alineado con el peak negativo (minimo valor dentro de la marca)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c133fea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT'\n",
    "}\n",
    "print_dataset_names = {\n",
    "    (constants.MASS_SS_NAME, 1): \"MASS-SS2-E1SS\",\n",
    "    (constants.MASS_SS_NAME, 2): \"MASS-SS2-E2SS\",\n",
    "    (constants.MASS_KC_NAME, 1): \"MASS-SS2-KC\",\n",
    "    (constants.MODA_SS_NAME, 1): \"MASS-MODA\",\n",
    "    (constants.INTA_SS_NAME, 1): \"INTA-UCH\",\n",
    "}\n",
    "\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "\n",
    "# Collect predictions\n",
    "stats_list = []\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    source_dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    pink = reader.load_dataset(constants.PINK_NAME, verbose=False)\n",
    "    pink.event_name = source_dataset.event_name\n",
    "    _, _, test_ids_list = get_partitions(source_dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    pred_dict = {}\n",
    "    table = []\n",
    "    for model_version in models:\n",
    "        pred_dict[model_version] = {}\n",
    "        tmp_pert_dict = fig_utils.get_red_predictions_for_pink(\n",
    "            model_version, config[\"strategy\"], source_dataset, config[\"expert\"], \n",
    "            pink_dataset=pink, verbose=False)\n",
    "        perturbations = list(tmp_pert_dict.keys())\n",
    "        for perturbation_name in perturbations:\n",
    "            pred_dict[model_version][perturbation_name] = {}\n",
    "            tmp_dict = tmp_pert_dict[perturbation_name]\n",
    "            for k in tmp_dict.keys():\n",
    "                fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "                fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "                pred_dict[model_version][perturbation_name][k] = {s: pred for s, pred in zip(fold_subjects, fold_predictions)}\n",
    "                for subject_id in pink.all_ids:\n",
    "                    this_pred = pred_dict[model_version][perturbation_name][k][subject_id]\n",
    "                    table.append(\n",
    "                        {'model': model_version, 'scale': perturbation_name, 'fold': k, 'subject_id': subject_id, 'n_events': this_pred.shape[0]}\n",
    "                    )\n",
    "    table = pd.DataFrame(table)\n",
    "    stats_list.append(table)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ebf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pink = reader.load_dataset(constants.PINK_NAME, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9538be01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table of stats\n",
    "total_n2_hours = np.concatenate(pink.get_pages(pages_subset=constants.N2_RECORD)).size * pink.page_duration / 3600\n",
    "\n",
    "print(\"Datos & Factor de escala & Detector & Detecciones & Densidad (eph) \\\\\\\\\")\n",
    "for i_config, config in enumerate(eval_configs):\n",
    "    table = stats_list[i_config]\n",
    "    agg_table = table.drop(columns=[\"subject_id\"]).groupby(by=[\"model\", \"scale\", \"fold\"]).sum()\n",
    "    agg_table = agg_table.reset_index()\n",
    "    agg_table_mean = agg_table.drop(columns=[\"fold\"]).groupby(by=[\"model\", \"scale\"]).mean().add_suffix(\"_mean\")\n",
    "    agg_table_std = agg_table.drop(columns=[\"fold\"]).groupby(by=[\"model\", \"scale\"]).std(ddof=0).add_suffix(\"_std\")\n",
    "    agg_table = agg_table_mean.join(agg_table_std)\n",
    "    agg_table_density = (agg_table / total_n2_hours).add_suffix(\"_per_hour\")\n",
    "    agg_table = agg_table.join(agg_table_density)\n",
    "    agg_table = agg_table.reset_index()\n",
    "    agg_table = agg_table.to_dict()\n",
    "    \n",
    "    dataset_str = print_dataset_names[(config['dataset_name'], config['expert'])]\n",
    "    print(\"\\n%s\" % dataset_str)\n",
    "    rows_list = []\n",
    "    for j in range(len(agg_table['model'])):\n",
    "        row_str = \"& %s & %s & $%1.1f \\pm %1.1f$ & $%1.1f \\pm %1.1f$ \\\\\\\\\" % (\n",
    "            agg_table['scale'][j].split(\"-\")[-1],\n",
    "            print_model_names[agg_table['model'][j]],\n",
    "            agg_table['n_events_mean'][j],\n",
    "            agg_table['n_events_std'][j],\n",
    "            agg_table['n_events_mean_per_hour'][j],\n",
    "            agg_table['n_events_std_per_hour'][j],\n",
    "        )\n",
    "        rows_list.append(row_str)\n",
    "    rows_list = np.sort(rows_list)\n",
    "    for row in rows_list:\n",
    "        print(row)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f87d925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# boxplots de parametros 1: probability of detections\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "\n",
    "\n",
    "metrics_list = []\n",
    "for config in eval_configs:\n",
    "    \n",
    "    stat_spindle = (config[\"dataset_name\"] == constants.MODA_SS_NAME)\n",
    "    chosen_scale = 'scale-2.0' if stat_spindle else 'scale-1.0'\n",
    "    \n",
    "    print(\"\\nLoading\", config)\n",
    "    source_dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    \n",
    "    # source stuff\n",
    "    pred_dict = {}\n",
    "    pred_proba_dict = {}\n",
    "    for model_version in models:\n",
    "        pred_dict[model_version] = {}\n",
    "        pred_proba_dict[model_version] = {}\n",
    "        tmp_dict = fig_utils.get_red_predictions(model_version, config[\"strategy\"], source_dataset, config[\"expert\"], verbose=False)\n",
    "        for k in tmp_dict.keys():\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "            fold_probas = tmp_dict[k][constants.TEST_SUBSET].get_stamps_probabilities()\n",
    "            pred_dict[model_version][k] = {s: pred for s, pred in zip(fold_subjects, fold_predictions)}\n",
    "            pred_proba_dict[model_version][k] = {s: pred for s, pred in zip(fold_subjects, fold_probas)}\n",
    "    source_pred_dict = pred_dict\n",
    "    source_pred_proba_dict = pred_proba_dict\n",
    "    \n",
    "    # Pink stuff\n",
    "    pink = reader.load_dataset(constants.PINK_NAME, verbose=False)\n",
    "    pink.event_name = source_dataset.event_name\n",
    "    \n",
    "    pred_dict = {}\n",
    "    pred_proba_dict = {}\n",
    "    for model_version in models:\n",
    "        pred_dict[model_version] = {}\n",
    "        pred_proba_dict[model_version] = {}\n",
    "        tmp_pert_dict = fig_utils.get_red_predictions_for_pink(\n",
    "            model_version, config[\"strategy\"], source_dataset, config[\"expert\"], \n",
    "            pink_dataset=pink, verbose=False)\n",
    "        perturbation_name = chosen_scale\n",
    "        tmp_dict = tmp_pert_dict[perturbation_name]\n",
    "        for k in tmp_dict.keys():\n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "            fold_probas = tmp_dict[k][constants.TEST_SUBSET].get_stamps_probabilities()\n",
    "            pred_dict[model_version][k] = {s: pred for s, pred in zip(fold_subjects, fold_predictions)}\n",
    "            pred_proba_dict[model_version][k] = {s: pred for s, pred in zip(fold_subjects, fold_probas)}\n",
    "    pink_pred_dict = pred_dict\n",
    "    pink_pred_proba_dict = pred_proba_dict\n",
    "    \n",
    "    # Retrieve parameters, all events together\n",
    "    table = {\n",
    "        'Dataset': [],\n",
    "        'Detector': [],\n",
    "        'Proba': [],\n",
    "        'Duration': [], \n",
    "        'AmplitudePP': [],\n",
    "        'Frequency': [],\n",
    "    }\n",
    "    \n",
    "    # from source dataset detections\n",
    "    _, _, test_ids_list = get_partitions(source_dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    for model_name in models:\n",
    "        tmp_table = {\n",
    "            'Proba': [],\n",
    "            'Duration': [], \n",
    "            'AmplitudePP': [],\n",
    "            'Frequency': [],\n",
    "        }\n",
    "        for k in range(n_folds):\n",
    "            subject_ids = test_ids_list[k]\n",
    "            feed_d = FeederDataset(source_dataset, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "            detections_list = [source_pred_dict[model_name][k][subject_id] for subject_id in subject_ids]\n",
    "            probas_list = [source_pred_proba_dict[model_name][k][subject_id] for subject_id in subject_ids]\n",
    "            for i_sub, subject_id in enumerate(subject_ids):\n",
    "                detections = detections_list[i_sub]\n",
    "                if detections.size == 0:\n",
    "                    continue\n",
    "                # Duration\n",
    "                duration = (detections[:, 1] - detections[:, 0] + 1) / source_dataset.fs\n",
    "                tmp_table['Duration'].append(duration)\n",
    "                # Amplitude\n",
    "                signal = source_dataset.get_subject_signal(subject_id, normalize_clip=False)\n",
    "                event_name = 'spindle' if stat_spindle else 'kcomplex'\n",
    "                filt_signal = param_filtering_fn(signal, source_dataset.fs, event_name)\n",
    "                signal_events = [filt_signal[e[0]:e[1]+1] for e in detections]\n",
    "                amplitude = np.array([param_amplitude_fn(s, source_dataset.fs, event_name) for s in signal_events])\n",
    "                tmp_table['AmplitudePP'].append(amplitude)\n",
    "                # Frequency\n",
    "                if stat_spindle:\n",
    "                    freq_central = np.array([param_frequency_fn(s, source_dataset.fs) for s in signal_events])\n",
    "                else:\n",
    "                    freq_central = np.array([1] * len(signal_events))\n",
    "                tmp_table['Frequency'].append(freq_central) \n",
    "                # Proba\n",
    "                tmp_table['Proba'].append(probas_list[i_sub])\n",
    "        table['Detector'].append(model_name)\n",
    "        table['Dataset'].append('Source')\n",
    "        for key in tmp_table.keys():\n",
    "            table[key].append(np.concatenate(tmp_table[key]))\n",
    "    \n",
    "    # from pink detections\n",
    "    for model_name in models:\n",
    "        tmp_table = {\n",
    "            'Proba': [],\n",
    "            'Duration': [], \n",
    "            'AmplitudePP': [],\n",
    "            'Frequency': [],\n",
    "        }\n",
    "        for k in range(n_folds):\n",
    "            subject_ids = pink.all_ids\n",
    "            feed_d = FeederDataset(pink, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "            detections_list = [pink_pred_dict[model_name][k][subject_id] for subject_id in subject_ids]\n",
    "            probas_list = [pink_pred_proba_dict[model_name][k][subject_id] for subject_id in subject_ids]\n",
    "            for i_sub, subject_id in enumerate(subject_ids):\n",
    "                detections = detections_list[i_sub]\n",
    "                if detections.size == 0:\n",
    "                    continue\n",
    "                # Duration\n",
    "                duration = (detections[:, 1] - detections[:, 0] + 1) / pink.fs\n",
    "                tmp_table['Duration'].append(duration)\n",
    "                # Amplitude\n",
    "                signal = pink.get_subject_signal(subject_id, normalize_clip=False)\n",
    "                event_name = 'spindle' if stat_spindle else 'kcomplex'\n",
    "                filt_signal = param_filtering_fn(signal, pink.fs, event_name)\n",
    "                signal_events = [filt_signal[e[0]:e[1]+1] for e in detections]\n",
    "                amplitude = np.array([param_amplitude_fn(s, pink.fs, event_name) for s in signal_events])\n",
    "                tmp_table['AmplitudePP'].append(amplitude)\n",
    "                # Frequency\n",
    "                if stat_spindle:\n",
    "                    freq_central = np.array([param_frequency_fn(s, pink.fs) for s in signal_events])\n",
    "                else:\n",
    "                    freq_central = np.array([1] * len(signal_events))\n",
    "                tmp_table['Frequency'].append(freq_central) \n",
    "                # Proba\n",
    "                tmp_table['Proba'].append(probas_list[i_sub])\n",
    "        table['Detector'].append(model_name)\n",
    "        table['Dataset'].append('Pink')\n",
    "        for key in tmp_table.keys():\n",
    "            table[key].append(np.concatenate(tmp_table[key]))\n",
    "    \n",
    "    metrics_list.append(table)\n",
    "    \n",
    "print(\"Metrics computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edb4656",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i_config = 0\n",
    "save_figure = True\n",
    "\n",
    "table = metrics_list[i_config]\n",
    "config = eval_configs[i_config]\n",
    "\n",
    "print_parameter = {\n",
    "    'Duration': 'Duración (s)', 'AmplitudePP': 'Amplitud PP ($\\mu$V)', 'Frequency': 'Frecuencia (Hz)', 'Proba': 'Probabilidad'\n",
    "}\n",
    "params_order = ['Proba', 'Duration', 'AmplitudePP', 'Frequency']\n",
    "params_lims = {\n",
    "    'Duration': [0, 2.0], 'AmplitudePP': [0, 60], 'Frequency': [9, 17], 'Proba': [0.4, 1.0]\n",
    "}\n",
    "\n",
    "fig, axess = plt.subplots(2, 4, figsize=(8, 4), dpi=200)\n",
    "for i_m, model_version in enumerate(models):\n",
    "    axes = axess[i_m, :]\n",
    "    letters = ['A', 'B', 'C', 'D'] if i_m == 0 else ['E', 'F', 'G', 'H']\n",
    "    \n",
    "    source_loc = np.where((np.array(table['Detector']) == model_version) & (np.array(table['Dataset']) == 'Source'))[0][0]\n",
    "    pink_loc = np.where((np.array(table['Detector']) == model_version) & (np.array(table['Dataset']) == 'Pink'))[0][0]\n",
    "    \n",
    "    dataset_str = print_dataset_names[(config['dataset_name'], config['expert'])]\n",
    "    model_str = print_model_names[model_version]\n",
    "    axes[0].set_title(\"%s\\n(ajustado en %s)\" % (model_str, dataset_str), fontsize=8, loc=\"left\")\n",
    "    for i_p, param_name in enumerate(params_order):\n",
    "        ax = axes[i_p]\n",
    "        source_data = table[param_name][source_loc]\n",
    "        pink_data = table[param_name][pink_loc]\n",
    "        ax.boxplot(\n",
    "            [source_data, pink_data], \n",
    "            labels=['Fuente', 'PINK (x2)'], showfliers=True, vert=False, whis=20, showmeans=True, meanline=True, widths=0.5,\n",
    "            meanprops=dict(linewidth=1.5, linestyle=\"-\", color=viz.PALETTE['blue']),\n",
    "            medianprops=dict(linewidth=0, linestyle=\"none\"),\n",
    "            flierprops={'markersize': 2}, zorder=20)\n",
    "        if i_p > 0:\n",
    "            ax.set_yticklabels([])\n",
    "\n",
    "        ax.set_xlabel(print_parameter[param_name], fontsize=8)\n",
    "        ax.tick_params(labelsize=8)\n",
    "        ax.set_xlim(params_lims[param_name])\n",
    "        ax.grid(axis=\"x\")\n",
    "        \n",
    "        ax.text(\n",
    "            x=-0.15, y=1.1, fontsize=16, s=r\"$\\bf{%s}$\" % letters[i_p],\n",
    "            ha=\"left\", transform=ax.transAxes)\n",
    "        \n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figure:\n",
    "    # Save figure\n",
    "    fname_prefix = \"result_indata_pink_params_ss\"\n",
    "    plt.savefig(\"%s.pdf\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.png\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.svg\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0334aea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_config = 1\n",
    "save_figure = True\n",
    "\n",
    "table = metrics_list[i_config]\n",
    "config = eval_configs[i_config]\n",
    "\n",
    "print_parameter = {\n",
    "    'Duration': 'Duración (s)', 'AmplitudePP': 'Amplitud PP ($\\mu$V)', 'Frequency': 'Frecuencia (Hz)', 'Proba': 'Probabilidad'\n",
    "}\n",
    "params_order = ['Proba', 'Duration', 'AmplitudePP']\n",
    "params_lims = {\n",
    "    'Duration': [0, 2.0], 'AmplitudePP': [0, 200], 'Frequency': [9, 17], 'Proba': [0.4, 1.0]\n",
    "}\n",
    "\n",
    "fig, axess = plt.subplots(2, 3, figsize=(8, 4), dpi=200)\n",
    "for i_m, model_version in enumerate(models):\n",
    "    axes = axess[i_m, :]\n",
    "    letters = ['A', 'B', 'C'] if i_m == 0 else ['D', 'E', 'F']\n",
    "    \n",
    "    source_loc = np.where((np.array(table['Detector']) == model_version) & (np.array(table['Dataset']) == 'Source'))[0][0]\n",
    "    pink_loc = np.where((np.array(table['Detector']) == model_version) & (np.array(table['Dataset']) == 'Pink'))[0][0]\n",
    "    \n",
    "    dataset_str = print_dataset_names[(config['dataset_name'], config['expert'])]\n",
    "    model_str = print_model_names[model_version]\n",
    "    axes[0].set_title(\"%s\\n(ajustado en %s)\" % (model_str, dataset_str), fontsize=8, loc=\"left\")\n",
    "    for i_p, param_name in enumerate(params_order):\n",
    "        ax = axes[i_p]\n",
    "        source_data = table[param_name][source_loc]\n",
    "        pink_data = table[param_name][pink_loc]\n",
    "        ax.boxplot(\n",
    "            [source_data, pink_data], \n",
    "            labels=['Fuente', 'PINK'], showfliers=True, vert=False, whis=20, showmeans=True, meanline=True, widths=0.5,\n",
    "            meanprops=dict(linewidth=1.5, linestyle=\"-\", color=viz.PALETTE['blue']),\n",
    "            medianprops=dict(linewidth=0, linestyle=\"none\"),\n",
    "            flierprops={'markersize': 2}, zorder=20)\n",
    "        if i_p > 0:\n",
    "            ax.set_yticklabels([])\n",
    "\n",
    "        ax.set_xlabel(print_parameter[param_name], fontsize=8)\n",
    "        ax.tick_params(labelsize=8)\n",
    "        ax.set_xlim(params_lims[param_name])\n",
    "        ax.grid(axis=\"x\")\n",
    "        \n",
    "        ax.text(\n",
    "            x=-0.15, y=1.1, fontsize=16, s=r\"$\\bf{%s}$\" % letters[i_p],\n",
    "            ha=\"left\", transform=ax.transAxes)\n",
    "        \n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figure:\n",
    "    # Save figure\n",
    "    fname_prefix = \"result_indata_pink_params_kc\"\n",
    "    plt.savefig(\"%s.pdf\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.png\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.svg\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d17599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grand-average KC\n",
    "# boxplots de parametros 1: probability of detections\n",
    "config = dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3)\n",
    "window_duration = 5\n",
    "\n",
    "stat_spindle = (config[\"dataset_name\"] == constants.MODA_SS_NAME)\n",
    "chosen_scale = 'scale-2.0' if stat_spindle else 'scale-1.0'\n",
    "\n",
    "print(\"\\nLoading\", config)\n",
    "source_dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "\n",
    "# Pink stuff\n",
    "pink = reader.load_dataset(constants.PINK_NAME, verbose=False)\n",
    "pink.event_name = source_dataset.event_name\n",
    "window_size = int(window_duration * pink.fs)\n",
    "\n",
    "all_kc = {}\n",
    "for model_version in models:\n",
    "    all_kc[model_version] = []\n",
    "    tmp_pert_dict = fig_utils.get_red_predictions_for_pink(\n",
    "        model_version, config[\"strategy\"], source_dataset, config[\"expert\"], \n",
    "        pink_dataset=pink, verbose=False)\n",
    "    perturbation_name = chosen_scale\n",
    "    tmp_dict = tmp_pert_dict[perturbation_name]\n",
    "    for k in tmp_dict.keys():\n",
    "        fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "        fold_predictions = tmp_dict[k][constants.TEST_SUBSET].get_stamps()\n",
    "        for i_sub in range(len(fold_subjects)):\n",
    "            subject_id = fold_subjects[i_sub]\n",
    "            subject_dets = fold_predictions[i_sub]\n",
    "            signal = pink.get_subject_signal(subject_id, normalize_clip=False)\n",
    "            for e in subject_dets:\n",
    "                kc = signal[e[0]:e[1]+1]\n",
    "                kc_negpeak = np.argmin(kc)\n",
    "                kc_negpeak_loc = kc_negpeak + e[0]\n",
    "                # extract window with center at kc_neg_peak_loc\n",
    "                start_sample = kc_negpeak_loc - window_size // 2\n",
    "                end_sample = start_sample + window_size\n",
    "                segment = signal[start_sample:end_sample]\n",
    "                all_kc[model_version].append(segment)\n",
    "    all_kc[model_version] = np.stack(all_kc[model_version], axis=0)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf84049",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_figure = True\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 2), dpi=200)\n",
    "time_axis = np.arange(window_size) / pink.fs\n",
    "time_axis = time_axis - time_axis.mean()\n",
    "letters = ['A', 'B']\n",
    "for i_m, model_version in enumerate(models):\n",
    "    ax = axes[i_m]\n",
    "    model_kc = all_kc[model_version]\n",
    "    kc_mean = model_kc.mean(axis=0)\n",
    "    kc_std = model_kc.std(axis=0)\n",
    "    ax.plot(time_axis, kc_mean, color=viz.PALETTE['blue'], linewidth=1)\n",
    "    ax.fill_between(\n",
    "        time_axis,\n",
    "        kc_mean + kc_std,\n",
    "        kc_mean - kc_std,\n",
    "        facecolor=viz.PALETTE['blue'],\n",
    "        alpha = 0.3\n",
    "    )\n",
    "    # ax.plot(kc_mean + kc_std)\n",
    "    # ax.plot(kc_mean - kc_std)\n",
    "    ax.tick_params(labelsize=8)\n",
    "    ax.set_xlabel(\"Tiempo (s)\", fontsize=8)\n",
    "    ax.set_xlim([-window_duration/2, window_duration/2])\n",
    "    ax.set_ylim([-50, 50])\n",
    "    ax.set_xticks([-2, -1, 0, 1, 2])\n",
    "    ax.set_xticks(np.arange(-2.5, 2.5 + 0.001, 0.5), minor=True)\n",
    "    ax.set_yticks([-50, -25, 0, 25, 50])\n",
    "    ax.set_yticks([-50, -25, 0, 25, 50], minor=True)\n",
    "    if i_m > 0:\n",
    "        ax.set_yticklabels([])\n",
    "    else:\n",
    "        ax.set_ylabel(\"Amplitud ($\\mu$V)\", fontsize=8)\n",
    "    ax.grid(which=\"minor\")\n",
    "    ax.set_title(print_model_names[model_version], fontsize=8, loc=\"left\")\n",
    "    \n",
    "    ax.text(\n",
    "        x=-0.07, y=1.1, fontsize=16, s=r\"$\\bf{%s}$\" % letters[i_m],\n",
    "        ha=\"left\", transform=ax.transAxes)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "if save_figure:\n",
    "    # Save figure\n",
    "    fname_prefix = \"result_indata_pink_avg_kc\"\n",
    "    plt.savefig(\"%s.pdf\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.png\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "    plt.savefig(\"%s.svg\" % fname_prefix, bbox_inches=\"tight\", pad_inches=0.4)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feddbbea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# viz of cases (4 of each)\n",
    "window_duration = 5\n",
    "ref_model = constants.V2_TIME\n",
    "\n",
    "segments_list = []\n",
    "\n",
    "for config in eval_configs[:1]:\n",
    "    \n",
    "    segments_data = []\n",
    "    \n",
    "    stat_spindle = (config[\"dataset_name\"] == constants.MODA_SS_NAME)\n",
    "\n",
    "    print(\"\\nLoading\", config)\n",
    "    source_dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "\n",
    "    # Pink stuff\n",
    "    pink = reader.load_dataset(constants.PINK_NAME, verbose=False)\n",
    "    pink.event_name = source_dataset.event_name\n",
    "    window_size = int(window_duration * pink.fs)\n",
    "\n",
    "    if stat_spindle:\n",
    "        # recover scale 1.0 det in subject 6, redtime\n",
    "        chosen_scale = 'scale-1.0'\n",
    "        for subject_id in [6]:\n",
    "            signal = pink.get_subject_signal(subject_id, normalize_clip=False)\n",
    "            # find detection\n",
    "            tmp_pert_dict = fig_utils.get_red_predictions_for_pink(\n",
    "                ref_model, config[\"strategy\"], source_dataset, config[\"expert\"], \n",
    "                pink_dataset=pink, verbose=False)\n",
    "            tmp_dict = tmp_pert_dict[chosen_scale]\n",
    "            dets = [tmp_dict[k][constants.TEST_SUBSET].get_subject_stamps(subject_id) for k in tmp_dict.keys()]\n",
    "            dets = np.concatenate(dets, axis=0)\n",
    "            dets = utils.seq2stamp(utils.stamp2seq(dets, 0, signal.size-1))\n",
    "            \n",
    "            # now load data\n",
    "            model_probas = {}\n",
    "            for model_version in models:\n",
    "                tmp_pert_dict = fig_utils.get_red_predictions_for_pink(\n",
    "                    model_version, config[\"strategy\"], source_dataset, config[\"expert\"], \n",
    "                    pink_dataset=pink, verbose=False)\n",
    "                tmp_dict = tmp_pert_dict[chosen_scale]\n",
    "                fold_probas = []\n",
    "                for k in tmp_dict.keys():\n",
    "                    this_proba = tmp_dict[k][constants.TEST_SUBSET].get_subject_probabilities(subject_id, return_adjusted=True)\n",
    "                    this_proba = np.repeat(this_proba, 8)\n",
    "                    fold_probas.append(this_proba)\n",
    "                fold_probas = np.stack(fold_probas, axis=0)\n",
    "                model_probas[model_version] = fold_probas\n",
    "            for det in dets:\n",
    "                start_sample = int(det.mean() - window_size // 2)\n",
    "                end_sample = start_sample + window_size\n",
    "                segment_signal = signal[start_sample:end_sample]\n",
    "                segment_proba_time = model_probas[constants.V2_TIME][start_sample:end_sample]\n",
    "                segment_proba_cwt = model_probas[constants.V2_CWT1D][start_sample:end_sample]\n",
    "                segments_data.append({'signal_original': segment_signal, 'proba_time': segment_proba_time, 'proba_cwt': segment_proba_cwt, 'scale': chosen_scale})\n",
    "                \n",
    "    # now do regular stuff\n",
    "    chosen_scale = 'scale-2.0' if stat_spindle else 'scale-1.0'\n",
    "    \n",
    "    for subject_id in pink.all_ids:\n",
    "        signal = pink.get_subject_signal(subject_id, normalize_clip=False)\n",
    "        # find detection\n",
    "        tmp_pert_dict = fig_utils.get_red_predictions_for_pink(\n",
    "            ref_model, config[\"strategy\"], source_dataset, config[\"expert\"], \n",
    "            pink_dataset=pink, verbose=False)\n",
    "        tmp_dict = tmp_pert_dict[chosen_scale]\n",
    "        dets = [tmp_dict[k][constants.TEST_SUBSET].get_subject_stamps(subject_id) for k in tmp_dict.keys()]\n",
    "        dets = np.concatenate(dets, axis=0)\n",
    "        dets = utils.seq2stamp(utils.stamp2seq(dets, 0, signal.size-1))\n",
    "\n",
    "        # now load data\n",
    "        model_probas = {}\n",
    "        for model_version in models:\n",
    "            tmp_pert_dict = fig_utils.get_red_predictions_for_pink(\n",
    "                model_version, config[\"strategy\"], source_dataset, config[\"expert\"], \n",
    "                pink_dataset=pink, verbose=False)\n",
    "            tmp_dict = tmp_pert_dict[chosen_scale]\n",
    "            fold_probas = []\n",
    "            for k in tmp_dict.keys():\n",
    "                this_proba = tmp_dict[k][constants.TEST_SUBSET].get_subject_probabilities(subject_id, return_adjusted=True)\n",
    "                this_proba = np.repeat(this_proba, 8)\n",
    "                fold_probas.append(this_proba)\n",
    "            fold_probas = np.stack(fold_probas, axis=1)\n",
    "            model_probas[model_version] = fold_probas\n",
    "        for det in dets:\n",
    "            start_sample = int(det.mean() - window_size // 2)\n",
    "            end_sample = start_sample + window_size\n",
    "            segment_signal = signal[start_sample:end_sample]\n",
    "            segment_proba_time = model_probas[constants.V2_TIME][start_sample:end_sample]\n",
    "            segment_proba_cwt = model_probas[constants.V2_CWT1D][start_sample:end_sample]\n",
    "            segments_data.append({'signal_original': segment_signal, 'proba_time': segment_proba_time, 'proba_cwt': segment_proba_cwt, 'scale': chosen_scale})\n",
    "\n",
    "    segments_list.append(segments_data)  # <- from these extracted segments we can sample cases\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2d613e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ff1d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc660f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e01912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e87631e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20234a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0789050f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee9c90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = 6\n",
    "tmp_signal = pink.get_subject_signal(subject_id=subject_id, normalize_clip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3fbb215",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_str = \"REDv2-Time\"\n",
    "dataset_str = print_dataset_names[(constants.MODA_SS_NAME, 1)]\n",
    "event_str = \"Sleep Spindle\"\n",
    "fold_id = 14\n",
    "mark = np.array(\n",
    "    [453376, 453471]\n",
    ")\n",
    "\n",
    "window_duration = 10\n",
    "border_duration = 4\n",
    "fs = pink.fs\n",
    "center_sample = int(mark.mean())\n",
    "window_size = int(window_duration * fs)\n",
    "border_size = int(border_duration * fs)\n",
    "start_sample = int(center_sample - window_size // 2)\n",
    "end_sample = start_sample + window_size\n",
    "segment_signal = tmp_signal[start_sample - border_size:end_sample + border_size]\n",
    "segment_signal_filt = utils.apply_bandpass(segment_signal, fs, 4, 35)\n",
    "segment_signal = segment_signal[border_size:-border_size]\n",
    "segment_signal_filt = segment_signal_filt[border_size:-border_size]\n",
    "time_axis = np.arange(start_sample, end_sample) / fs\n",
    "\n",
    "start_spindle_relative = mark[0] - start_sample\n",
    "end_spindle_relative = mark[1] - start_sample\n",
    "\n",
    "y_lim = 50\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 4), dpi=120, sharex=True, sharey=True)\n",
    "ax = axes[0]\n",
    "ax.plot(\n",
    "    time_axis, segment_signal, linewidth=0.8, label=\"EEG 0-35 Hz\", \n",
    "    color=viz.GREY_COLORS[6])\n",
    "ax.plot(\n",
    "    time_axis[start_spindle_relative:end_spindle_relative], segment_signal[start_spindle_relative:end_spindle_relative], linewidth=1.1,\n",
    "    color=viz.PALETTE['red'])\n",
    "# ax.plot(mark / fs, [-y_lim*0.8]*2, color=viz.PALETTE['red'], linewidth=4, alpha=0.8)\n",
    "ax.set_ylim([-y_lim, y_lim])\n",
    "ax.tick_params(labelsize=8)\n",
    "ax.grid()\n",
    "ax.legend(loc=\"upper right\", fontsize=8)\n",
    "ax.set_title(\"Detector %s trained on %s-Fold%02d (%s). Prediction on PINK, Signal ID %02d.\" % (model_str, dataset_str, fold_id+1, event_str, subject_id), fontsize=10)\n",
    "\n",
    "ax = axes[1]\n",
    "ax.plot(\n",
    "    time_axis, segment_signal_filt, linewidth=0.8, label=\"EEG 4-35 Hz\", \n",
    "    color=viz.GREY_COLORS[6])\n",
    "ax.plot(\n",
    "    time_axis[start_spindle_relative:end_spindle_relative], segment_signal_filt[start_spindle_relative:end_spindle_relative], linewidth=1.1,\n",
    "    color=viz.PALETTE['red'])\n",
    "# ax.plot(mark / fs, [-y_lim*0.8]*2, color=viz.PALETTE['red'], linewidth=4, alpha=0.8)\n",
    "ax.set_ylim([-y_lim, y_lim])\n",
    "ax.tick_params(labelsize=8)\n",
    "ax.set_xlabel(\"Tiempo (s)\", fontsize=8)\n",
    "ax.grid()\n",
    "ax.legend(loc=\"upper right\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "spindle = tmp_signal[mark[0]:mark[1]+1]\n",
    "duration = (spindle.size + 1) / fs\n",
    "amplitude_of_spindle = fig_utils.get_amplitude_spindle(spindle, fs)\n",
    "freq_axis, amp_axis = fig_utils.get_fft_spectrum(spindle, fs, f_min=4)\n",
    "frequency_of_spindle = freq_axis[np.argmax(amp_axis)]\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3), dpi=120)\n",
    "ax = axes[0]\n",
    "ax.set_title(\"Detection segment (0-35 Hz).\\nDuration %1.2f s, PP %1.2f $\\mu$V.\" % (duration, amplitude_of_spindle), fontsize=10)\n",
    "ax.plot(np.arange(spindle.size) / fs, spindle)\n",
    "ax.set_xlabel(\"Time (s)\", fontsize=8)\n",
    "ax.set_ylabel(\"Amplitude ($\\mu$V)\", fontsize=8)\n",
    "ax.tick_params(labelsize=8)\n",
    "ax.set_ylim([-20, 20])\n",
    "#ax.xticklabels([])\n",
    "#ax.xticks(np.arange(0, spindle.size + 0.001, 0.5))\n",
    "ax.grid()\n",
    "\n",
    "ax = axes[1]\n",
    "ax.set_title(\"FFT.\\nPeak frequency %1.2f Hz.\" % frequency_of_spindle, fontsize=10)\n",
    "ax.plot(freq_axis, amp_axis)\n",
    "ax.set_xlabel(\"Frequency (Hz)\", fontsize=8)\n",
    "ax.set_ylabel(\"Amplitude\", fontsize=8)\n",
    "ax.set_yticks([])\n",
    "ax.axvline(frequency_of_spindle, color=\"k\", linestyle=\"--\")\n",
    "ax.tick_params(labelsize=8)\n",
    "ax.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8acf920a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mostra todas las probabilidades predichas para dicho sujeto\n",
    "selected_subject_id = 6\n",
    "selected_scale = \"scale-1.0\"\n",
    "\n",
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    # dict(dataset_name=constants.MASS_KC_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    source_dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    _, _, test_ids_list = get_partitions(source_dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    proba_dict = {}\n",
    "    for model_version in models:\n",
    "        proba_dict[model_version] = []\n",
    "        tmp_pert_dict = fig_utils.get_red_predictions_for_pink(model_version, config[\"strategy\"], source_dataset, config[\"expert\"], verbose=False)\n",
    "        tmp_dict = tmp_pert_dict[selected_scale]\n",
    "        for k in tmp_dict.keys():\n",
    "            this_proba = tmp_dict[k][constants.TEST_SUBSET].get_subject_probabilities(selected_subject_id, return_adjusted=True)\n",
    "            this_proba = np.repeat(this_proba, 8)\n",
    "            proba_dict[model_version].append(this_proba)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71827d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_signal = pink.get_subject_signal(subject_id=selected_subject_id, normalize_clip=False)\n",
    "\n",
    "mark = np.array(\n",
    "    [453376, 453471]\n",
    ")\n",
    "\n",
    "window_duration = 10\n",
    "fs = pink.fs\n",
    "center_sample = int(mark.mean())\n",
    "window_size = int(window_duration * fs)\n",
    "start_sample = int(center_sample - window_size // 2)\n",
    "end_sample = start_sample + window_size\n",
    "segment_signal = tmp_signal[start_sample:end_sample]\n",
    "time_axis = np.arange(start_sample, end_sample) / fs\n",
    "\n",
    "start_spindle_relative = mark[0] - start_sample\n",
    "end_spindle_relative = mark[1] - start_sample\n",
    "\n",
    "y_lim = 50\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 6), dpi=120)\n",
    "ax = axes[0]\n",
    "ax.plot(\n",
    "    time_axis, segment_signal, linewidth=0.8, label=\"EEG 0-35 Hz\", \n",
    "    color=viz.GREY_COLORS[6])\n",
    "ax.plot(\n",
    "    time_axis[start_spindle_relative:end_spindle_relative], segment_signal[start_spindle_relative:end_spindle_relative], linewidth=1.1,\n",
    "    color=viz.PALETTE['red'])\n",
    "ax.set_ylim([-y_lim, y_lim])\n",
    "ax.tick_params(labelsize=8)\n",
    "ax.grid()\n",
    "ax.legend(loc=\"upper right\", fontsize=8)\n",
    "ax.set_title(\"Prediction on PINK, Signal ID %02d.\" % (selected_subject_id), fontsize=10)\n",
    "\n",
    "ax = axes[1]\n",
    "model_version = \"v2_time\"\n",
    "for proba in proba_dict[model_version]:\n",
    "    proba_segment = proba[start_sample:end_sample]\n",
    "    ax.plot(time_axis, proba_segment, linewidth=1.5, alpha=0.3, color=viz.PALETTE['red'])\n",
    "ax.tick_params(labelsize=8)\n",
    "ax.set_ylim([-0.1, 1.1])\n",
    "ax.set_yticks([0, 0.5, 1])\n",
    "ax.grid()\n",
    "ax.axhline(0.5, linewidth=1, color=viz.PALETTE['red'], label=\"REDv2-Time\")\n",
    "ax.legend(loc=\"upper right\", fontsize=8)\n",
    "    \n",
    "ax = axes[2]\n",
    "model_version = \"v2_cwt1d\"\n",
    "for proba in proba_dict[model_version]:\n",
    "    proba_segment = proba[start_sample:end_sample]\n",
    "    ax.plot(time_axis, proba_segment, linewidth=1.5, alpha=0.3, color=viz.PALETTE['red'])\n",
    "ax.tick_params(labelsize=8)\n",
    "ax.set_ylim([-0.1, 1.1])\n",
    "ax.set_yticks([0, 0.5, 1])\n",
    "ax.grid()\n",
    "ax.axhline(0.5, linewidth=1, color=viz.PALETTE['red'], label=\"REDv2-CWT\")\n",
    "ax.legend(loc=\"upper right\", fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6066b181",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
