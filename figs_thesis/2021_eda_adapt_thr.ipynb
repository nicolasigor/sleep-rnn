{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9974fed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "import sys\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "project_root = '..'\n",
    "sys.path.append(project_root)\n",
    "\n",
    "from sleeprnn.common import viz, constants\n",
    "from sleeprnn.helpers import reader, plotter, misc, performer\n",
    "from sleeprnn.detection import metrics, det_utils, ensemble\n",
    "from figs_thesis import fig_utils\n",
    "from baselines_scripts.butils import get_partitions\n",
    "from sleeprnn.detection.feeder_dataset import FeederDataset\n",
    "from sleeprnn.common.optimal_thresholds import OPTIMAL_THR_FOR_CKPT_DICT\n",
    "from sleeprnn.data import utils\n",
    "\n",
    "RESULTS_PATH = os.path.join(project_root, 'results')\n",
    "BASELINES_PATH = os.path.join(project_root, 'resources', 'comparison_data', 'baselines_2021')\n",
    "\n",
    "%matplotlib inline\n",
    "viz.notebook_full_width()\n",
    "\n",
    "param_filtering_fn = fig_utils.get_filtered_signal_for_event\n",
    "param_frequency_fn = fig_utils.get_frequency_by_fft\n",
    "param_amplitude_fn = fig_utils.get_amplitude_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ed1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheating performance\n",
    "cheat_thr_df = pd.read_csv('cheating_thresholds.csv')\n",
    "adapt_thr_df = pd.read_csv('adapted_thresholds.csv')\n",
    "shuffle_thr_df = pd.read_csv('adapted_thresholds_shuffle.csv')\n",
    "\n",
    "def get_cheat_thr(dataset_str, model_version, fold_id, subject_id):\n",
    "    subject_id = str(subject_id)\n",
    "    row = cheat_thr_df[\n",
    "        (cheat_thr_df.dataset == dataset_str) \n",
    "        & (cheat_thr_df.model == model_version)\n",
    "        & (cheat_thr_df.fold == fold_id)\n",
    "        & (cheat_thr_df.subject == subject_id)\n",
    "    ]\n",
    "    this_cheat_thr = row.cheat_thr.values.item()\n",
    "    return this_cheat_thr\n",
    "\n",
    "def get_adapt_thr(dataset_str, model_version, fold_id, subject_id, minutes):\n",
    "    # min minutes:\n",
    "    # MASS1: 6\n",
    "    # MASS2: 3\n",
    "    # MODA: 3\n",
    "    # INTA: 5\n",
    "    min_minutes_by_dataset = {\n",
    "        'MASS-SS2-E1SS': 6,\n",
    "        'MASS-SS2-E2SS': 3,\n",
    "        'MASS-MODA': 3,\n",
    "        'INTA-UCH': 5,\n",
    "    }\n",
    "    min_minutes = min_minutes_by_dataset[dataset_str]\n",
    "    if minutes < min_minutes:\n",
    "        return -1\n",
    "    \n",
    "    # Now we can read\n",
    "    subject_id = str(subject_id)\n",
    "    row = adapt_thr_df[\n",
    "        (adapt_thr_df.dataset == dataset_str) \n",
    "        & (adapt_thr_df.model == model_version)\n",
    "        & (adapt_thr_df.fold == fold_id)\n",
    "        & (adapt_thr_df.subject == subject_id)\n",
    "        & (adapt_thr_df.minutes == minutes)\n",
    "    ]\n",
    "    this_adapt_thr = row.adapt_thr.values.item()\n",
    "    return this_adapt_thr\n",
    "\n",
    "\n",
    "def get_adapt_thr_shuffle(dataset_str, model_version, fold_id, subject_id, minutes):\n",
    "    # min minutes:\n",
    "    # MASS1: 6\n",
    "    # MASS2: 3\n",
    "    # MODA: 5\n",
    "    # INTA: 5\n",
    "    min_minutes_by_dataset = {\n",
    "        'MASS-SS2-E1SS': 6,\n",
    "        'MASS-SS2-E2SS': 3,\n",
    "        'MASS-MODA': 5,\n",
    "        'INTA-UCH': 5,\n",
    "    }\n",
    "    min_minutes = min_minutes_by_dataset[dataset_str]\n",
    "    if minutes < min_minutes:\n",
    "        return -1\n",
    "    \n",
    "    # Now we can read\n",
    "    subject_id = str(subject_id)\n",
    "    row = shuffle_thr_df[\n",
    "        (shuffle_thr_df.dataset == dataset_str) \n",
    "        & (shuffle_thr_df.model == model_version)\n",
    "        & (shuffle_thr_df.fold == fold_id)\n",
    "        & (shuffle_thr_df.subject == subject_id)\n",
    "        & (shuffle_thr_df.minutes == minutes)\n",
    "    ]\n",
    "    # print(row)\n",
    "    this_adapt_thr = row.adapt_thr.values.item()\n",
    "    return this_adapt_thr\n",
    "\n",
    "\n",
    "def get_subject_ids(dataset):\n",
    "    # In MODA, only some subjects are used (N=28)\n",
    "    if dataset.dataset_name == constants.MODA_SS_NAME:\n",
    "        valid_subjects = [\n",
    "            sub_id for sub_id in dataset.all_ids\n",
    "            if (dataset.data[sub_id]['n_blocks'] == 10)\n",
    "               and (sub_id not in ['01-01-0012', '01-01-0022'])\n",
    "        ]\n",
    "        # print(\"moda, using n=\", len(valid_subjects))\n",
    "    else:\n",
    "        valid_subjects = dataset.all_ids\n",
    "    return valid_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c51a986",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [constants.V2_TIME, constants.V2_CWT1D]\n",
    "print_model_names = {\n",
    "    constants.V2_TIME: 'REDv2-Time',\n",
    "    constants.V2_CWT1D: 'REDv2-CWT',\n",
    "}\n",
    "print_dataset_names = {\n",
    "    (constants.MASS_SS_NAME, 1): \"MASS-SS2-E1SS\",\n",
    "    (constants.MASS_SS_NAME, 2): \"MASS-SS2-E2SS\",\n",
    "    (constants.MODA_SS_NAME, 1): \"MASS-MODA\",\n",
    "    (constants.INTA_SS_NAME, 1): \"INTA-UCH\",\n",
    "}\n",
    "eval_configs = [\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MASS_SS_NAME, expert=2, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.MODA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "    dict(dataset_name=constants.INTA_SS_NAME, expert=1, strategy='5cv', seeds=3),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5941f036",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(8, 4), dpi=120, sharey=True)\n",
    "\n",
    "minutes_list = [3, 5, 7.5, 10, 15, 20, 25, 30]\n",
    "\n",
    "minutes_list = np.array(minutes_list)\n",
    "for i_config, config in enumerate(eval_configs):\n",
    "    \n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    dataset_str = print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])]\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    valid_subjects = get_subject_ids(dataset)\n",
    "    ckpt_folder = '20210529_thesis_indata_%s_e%d_%s_train_%s' % (config[\"strategy\"], config[\"expert\"], constants.N2_RECORD, dataset.dataset_name)\n",
    "    \n",
    "    valid_minutes_list = minutes_list[minutes_list <= 10] if dataset_str == 'MASS-MODA' else [10, 20, 30]\n",
    "    \n",
    "    \n",
    "    for i_model, model_version in enumerate(models):\n",
    "        model_str = print_model_names[model_version]\n",
    "        ax = axes[i_model, i_config]\n",
    "        # #############\n",
    "        minutes_extended = np.concatenate([[0], valid_minutes_list, [100]])\n",
    "        thr_list_of_list = []\n",
    "\n",
    "        \n",
    "        grid_folder_complete = os.path.join(ckpt_folder, model_version)\n",
    "        print(\"Loading checkpoint %s\" % grid_folder_complete)\n",
    "        for k in range(len(test_ids_list)):\n",
    "            fold_subjects = test_ids_list[k]\n",
    "            fold_thr = OPTIMAL_THR_FOR_CKPT_DICT[grid_folder_complete][k]\n",
    "            for subject_id in fold_subjects:\n",
    "                if subject_id not in valid_subjects:\n",
    "                    continue\n",
    "                subject_list = [fold_thr]\n",
    "                for minutes in valid_minutes_list:\n",
    "                    subject_adapt_thr = get_adapt_thr_shuffle(dataset_str, model_version, k, subject_id, minutes)\n",
    "                    subject_list.append(subject_adapt_thr)\n",
    "                subject_cheat_thr = get_cheat_thr(dataset_str, model_version, k, subject_id)\n",
    "                subject_list.append(subject_cheat_thr)\n",
    "                thr_list_of_list.append(subject_list)\n",
    "\n",
    "        all_x_data = []\n",
    "        all_y_data = []\n",
    "        for data in thr_list_of_list:\n",
    "            data = np.array(data)\n",
    "            valid_locs = data >= 0\n",
    "            x_data = minutes_extended[valid_locs]\n",
    "            y_data = data[valid_locs]\n",
    "\n",
    "            y_data = y_data - y_data[-1]\n",
    "            y_data = y_data[:-1]\n",
    "            x_data = x_data[:-1]\n",
    "\n",
    "            all_x_data.append(x_data)\n",
    "            all_y_data.append(y_data)\n",
    "        all_x_data = all_x_data[0]\n",
    "        all_y_data = list(np.stack(all_y_data, axis=0).T)\n",
    "        \n",
    "        ax.boxplot(all_y_data, labels=all_x_data, flierprops=dict(markersize=2), medianprops=dict(color=viz.PALETTE['blue']))\n",
    "        \n",
    "        if i_config == 0:\n",
    "            ax.set_ylabel(\"$\\Delta$ Umbral\", fontsize=8)\n",
    "        ax.set_xlabel(\"Minutos de ajuste\", fontsize=8)\n",
    "        ax.set_ylim([-0.5, 0.5])\n",
    "        ax.tick_params(labelsize=8)\n",
    "        ax.set_title('%s\\n%s' % (dataset_str, model_str), fontsize=8, loc=\"left\")\n",
    "        ax.set_yticks(np.arange(-0.4, 0.4 + 0.001, 0.2))\n",
    "        ax.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0697e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f054272a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9540512e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficar umbral a los 30 min vs cheat thr:\n",
    "\n",
    "# config = eval_configs[1]\n",
    "minutes_to_plot = 30\n",
    "print_weird = False\n",
    "top_weird = 10\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(8, 10), dpi=120, sharex=True, sharey=True)\n",
    "\n",
    "for i_config, config in enumerate(eval_configs):\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    dataset_str = print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])]\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    valid_minutes_to_plot = min(minutes_to_plot, 10) if dataset_str == 'MASS-MODA' else minutes_to_plot\n",
    "    \n",
    "    \n",
    "    for i_m, model_version in enumerate(models):\n",
    "\n",
    "        cheat_thr_list = []\n",
    "        fold_thr_list = []\n",
    "        adapt_thr_list = []\n",
    "        adapt_thr_shuffle_list = []\n",
    "        subject_list = []\n",
    "        for k in range(n_folds):\n",
    "            fold_subjects = test_ids_list[k]\n",
    "            valid_subjects = get_subject_ids(dataset)\n",
    "            ckpt_folder = '20210529_thesis_indata_%s_e%d_%s_train_%s' % (\n",
    "                config[\"strategy\"], config[\"expert\"], constants.N2_RECORD, dataset.dataset_name)\n",
    "            grid_folder_complete = os.path.join(ckpt_folder, model_version)\n",
    "            fold_thr = OPTIMAL_THR_FOR_CKPT_DICT[grid_folder_complete][k]\n",
    "            for subject_id in fold_subjects:\n",
    "                if subject_id not in valid_subjects:\n",
    "                    continue\n",
    "                \n",
    "                subject_adapt_thr = get_adapt_thr(dataset_str, model_version, k, subject_id, valid_minutes_to_plot)   \n",
    "                subject_adapt_thr_shuffle = get_adapt_thr_shuffle(dataset_str, model_version, k, subject_id, valid_minutes_to_plot)   \n",
    "                subject_cheat_thr = get_cheat_thr(dataset_str, model_version, k, subject_id)\n",
    "                \n",
    "                adapt_thr_shuffle_list.append(subject_adapt_thr_shuffle)\n",
    "                cheat_thr_list.append(subject_cheat_thr)\n",
    "                fold_thr_list.append(fold_thr)\n",
    "                adapt_thr_list.append(subject_adapt_thr)\n",
    "                subject_list.append(subject_id)\n",
    "        cheat_thr_list = np.array(cheat_thr_list)\n",
    "        fold_thr_list = np.array(fold_thr_list)\n",
    "        adapt_thr_list = np.array(adapt_thr_list)\n",
    "        adapt_thr_shuffle_list = np.array(adapt_thr_shuffle_list)\n",
    "        subject_list = np.array(subject_list)\n",
    "\n",
    "        ax = axes[i_config, 0 + i_m * 2]\n",
    "        ax.plot(cheat_thr_list, adapt_thr_list, linestyle=\"none\", marker='o', markersize=5, alpha=0.3)\n",
    "        ax.set_title('%s\\n%s' % (dataset_str, model_version), fontsize=8)\n",
    "        ax.set_xlabel(\"Cheat thr\", fontsize=8)\n",
    "        ax.set_ylabel(\"Adapt thr (%s min)\" % valid_minutes_to_plot, fontsize=8)\n",
    "\n",
    "        ax = axes[i_config, 1 + i_m * 2]\n",
    "        ax.plot(cheat_thr_list, adapt_thr_shuffle_list, linestyle=\"none\", marker='o', markersize=5, alpha=0.3)\n",
    "        ax.set_title('%s\\n%s' % (dataset_str, model_version), fontsize=8)\n",
    "        ax.set_xlabel(\"Cheat thr\", fontsize=8)\n",
    "        ax.set_ylabel(\"Shuffle thr (%s min)\" % valid_minutes_to_plot, fontsize=8)\n",
    "\n",
    "        if print_weird:\n",
    "            sorted_locs = np.argsort(-np.abs(cheat_thr_list - adapt_thr_list))\n",
    "            for loc in sorted_locs[:top_weird]:\n",
    "                print(\"Subject %s with cheat %1.2f and adapt %1.2f\" % (subject_list[loc], cheat_thr_list[loc], adapt_thr_list[loc]))\n",
    "\n",
    "for ax in axes.flatten():\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.plot([0, 1], [0, 1], linewidth=0.8, color=\"k\")\n",
    "    ax.grid()\n",
    "    ax.set_aspect('equal')\n",
    "    ax.tick_params(labelsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8cd2c1",
   "metadata": {},
   "source": [
    "# Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31286520",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "metrics_adapt_list = []\n",
    "for config in eval_configs:\n",
    "    print(\"\\nLoading\", config)\n",
    "    dataset = reader.load_dataset(config[\"dataset_name\"], verbose=False)\n",
    "    dataset_str = print_dataset_names[(config[\"dataset_name\"], config[\"expert\"])]\n",
    "    valid_subjects = get_subject_ids(dataset)\n",
    "    ckpt_folder = '20210529_thesis_indata_%s_e%d_%s_train_%s' % (\n",
    "        config[\"strategy\"], config[\"expert\"], constants.N2_RECORD, dataset.dataset_name)\n",
    "    \n",
    "    valid_minutes_list = [5, 7.5, 10] if dataset_str == 'MASS-MODA' else [10, 20, 30]\n",
    "    minutes_extended = np.concatenate([[0], valid_minutes_list, [100]])\n",
    "    \n",
    "    pred_dict = {}\n",
    "    for model_version in models:\n",
    "        grid_folder_complete = os.path.join(ckpt_folder, model_version)\n",
    "        \n",
    "        tmp_dict = fig_utils.get_red_predictions(model_version, config[\"strategy\"], dataset, config[\"expert\"], verbose=False)\n",
    "        # Retrieve only predictions, same format as baselines\n",
    "        pred_dict[model_version] = {}\n",
    "        for k in tmp_dict.keys():\n",
    "            fold_thr = OPTIMAL_THR_FOR_CKPT_DICT[grid_folder_complete][k]\n",
    "            \n",
    "            fold_subjects = tmp_dict[k][constants.TEST_SUBSET].all_ids\n",
    "            pred_dict[model_version][k] = {}\n",
    "            for subject_id in fold_subjects:\n",
    "                if subject_id not in valid_subjects:\n",
    "                    continue\n",
    "                    \n",
    "                # Compute possible thr using minutes as hash\n",
    "                pred_dict[model_version][k][subject_id] = {}\n",
    "                for minutes in minutes_extended:\n",
    "                    if minutes == 0:\n",
    "                        this_thr = fold_thr\n",
    "                    elif minutes == 100:\n",
    "                        this_thr = get_cheat_thr(dataset_str, model_version, k, subject_id)\n",
    "                    else:\n",
    "                        this_thr = get_adapt_thr_shuffle(dataset_str, model_version, k, subject_id, minutes)\n",
    "                    tmp_dict[k][constants.TEST_SUBSET].set_probability_threshold(this_thr)\n",
    "                    subject_predictions = tmp_dict[k][constants.TEST_SUBSET].get_subject_stamps(subject_id)\n",
    "                    pred_dict[model_version][k][subject_id][minutes] = subject_predictions\n",
    "    \n",
    "    # Measure performance by subject\n",
    "    _, _, test_ids_list = get_partitions(dataset, config[\"strategy\"], config[\"seeds\"])\n",
    "    n_folds = len(test_ids_list)\n",
    "    table = {'Detector': [], 'F1-score': [], 'Recall': [], 'Precision': [], 'mIoU': [], 'Subject': [], 'Minutes': [], 'Fold': []}\n",
    "    \n",
    "    # common test set: remove maximum value of minutes\n",
    "    max_minutes = minutes_extended[-2]\n",
    "    n_pages_to_remove = int(max_minutes * 60 / dataset.page_duration)\n",
    "    print(\"At test set, removing %d pages (%s minutes)\" % (n_pages_to_remove, max_minutes))\n",
    "    \n",
    "    for model_name in models:\n",
    "        for k in range(n_folds):\n",
    "            subject_ids = test_ids_list[k]\n",
    "            subject_ids = [s for s in subject_ids if s in valid_subjects]\n",
    "            feed_d = FeederDataset(dataset, subject_ids, constants.N2_RECORD, which_expert=config[\"expert\"])\n",
    "            \n",
    "            # Common test set for all minute sizes\n",
    "            n2_pages_list = feed_d.get_pages(pages_subset=constants.N2_RECORD)\n",
    "            n2_pages_list = [np.random.RandomState(seed=0).permutation(n2_pages) for n2_pages in n2_pages_list]\n",
    "            n2_pages_list = [n2_pages[n_pages_to_remove:] for n2_pages in n2_pages_list]\n",
    "            n2_pages_list = [np.sort(n2_pages) for n2_pages in n2_pages_list]\n",
    "            \n",
    "            # Get events and extract appropiate subset\n",
    "            events_list = feed_d.get_stamps()\n",
    "            events_list = [\n",
    "                utils.extract_pages_for_stamps(events, n2_pages, dataset.page_size) \n",
    "                for events, n2_pages in zip(events_list, n2_pages_list)\n",
    "            ]\n",
    "            \n",
    "            for minutes in minutes_extended:\n",
    "                # Get detections and extract appropiate subset\n",
    "                detections_list = [pred_dict[model_name][k][subject_id][minutes] for subject_id in subject_ids]\n",
    "                detections_list = [\n",
    "                    utils.extract_pages_for_stamps(detections, n2_pages, dataset.page_size) \n",
    "                    for detections, n2_pages in zip(detections_list, n2_pages_list)\n",
    "                ]\n",
    "                performance = fig_utils.compute_subject_performance(events_list, detections_list)\n",
    "                for i, subject_id in enumerate(subject_ids):\n",
    "                    if subject_id in valid_subjects:\n",
    "                        table['Detector'].append(model_name)\n",
    "                        table['F1-score'].append(performance['F1-score'][i])\n",
    "                        table['Recall'].append(performance['Recall'][i])\n",
    "                        table['Precision'].append(performance['Precision'][i])\n",
    "                        table['mIoU'].append(performance['mIoU'][i])\n",
    "                        table['Subject'].append(subject_id)\n",
    "                        table['Minutes'].append(minutes)\n",
    "                        table['Fold'].append(k)\n",
    "    table = pd.DataFrame.from_dict(table)\n",
    "    metrics_adapt_list.append(table)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ff832",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = metrics_adapt_list[3]\n",
    "table_bysubject = table.groupby(by=[\"Detector\", \"Minutes\", \"Subject\"]).mean().reset_index().drop(columns=\"Fold\")\n",
    "table_bysubject.drop(columns=[\"Subject\"]).groupby(by=[\"Detector\", \"Minutes\"]).mean() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d8b545",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_bysubject.drop(columns=[\"Subject\"]).groupby(by=[\"Detector\", \"Minutes\"]).std(ddof=0) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a908f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
